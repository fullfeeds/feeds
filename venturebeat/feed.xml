<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0" version="2.0">
<channel><title>VentureBeat</title>
<lastBuildDate>Sun, 01 Mar 2026 23:18:40 -0000</lastBuildDate>
<item>
<title> Nvidia, Groq and the limestone race to real-time AI: Why enterprises win or lose here </title>
<link>https://venturebeat.com/infrastructure/nvidia-groq-and-the-limestone-race-to-real-time-ai-why-enterprises-win-or</link>
<pubDate>Sun, 22 Feb 2026 17:05:00 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;Limestone block&quot; data-nimg=&quot;1&quot; height=&quot;816&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/08ilFZNVYo9OJqR9Z17ci/9196ada486dd8eb15769c1f096076b10/Limestone.png?w=1000&quot; width=&quot;1456&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
    &lt;p&gt;
     CleoP made with Midjourney
    &lt;/p&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  ​From miles away across the desert, the Great Pyramid looks like a perfect, smooth geometry — a sleek triangle pointing to the stars. Stand at the base, however, and the illusion of smoothness vanishes. You see massive, jagged blocks of limestone. It is not a slope; it is a staircase.
 &lt;/p&gt;
 &lt;p&gt;
  ​Remember this the next time you hear futurists talking about exponential growth.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  ​Intel’s co-founder Gordon Moore (Moore&#x27;s Law) is famously quoted for saying in 1965 that the transistor count on a microchip would double every year. Another Intel executive, David House, later revised this statement to “compute power doubling every 18 months.&quot; For a while, Intel’s CPUs were the poster child of this law. That is, until the growth in CPU performance flattened out like a block of limestone.
 &lt;/p&gt;
 &lt;p&gt;
  ​If you zoom out, though, the next limestone block was already there — the growth in compute merely shifted from CPUs to the world of GPUs. Jensen Huang, Nvidia’s CEO, played a long game and came out a strong winner, building his own stepping stones initially with gaming, then computer visioniand recently, generative AI.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;h3&gt;
  &lt;b&gt;
   ​The illusion of smooth growth
  &lt;/b&gt;
 &lt;/h3&gt;
 &lt;p&gt;
  ​Technology growth is full of sprints and plateaus, and gen AI is not immune. The current wave is driven by transformer architecture. To quote Anthropic’s President and co-founder Dario Amodei: “The exponential continues until it doesn’t. And every year we’ve been like, ‘Well, this can’t possibly be the case that things will continue on the exponential’ — and then every year it has.”
 &lt;/p&gt;
 &lt;p&gt;
  ​But just as the CPU plateaued and GPUs took the lead, we are seeing signs that LLM growth is shifting paradigms again. For example, late in 2024, DeepSeek surprised the world by training a world-class model on an impossibly small budget, in part by using the MoE technique.
 &lt;/p&gt;
 &lt;p&gt;
  ​Do you remember where you recently saw this technique mentioned? Nvidia’s Rubin press release: The technology includes “...the latest generations of Nvidia NVLink interconnect technology... to accelerate agentic AI, advanced reasoning and massive-scale MoE model inference at up to 10x lower cost per token.”
 &lt;/p&gt;
 &lt;p&gt;
  ​Jensen knows that achieving that coveted exponential growth in compute doesn’t come from pure brute force anymore. Sometimes you need to shift the architecture entirely to place the next stepping stone.
 &lt;/p&gt;
 &lt;h3&gt;
  &lt;b&gt;
   ​The latency crisis: Where Groq fits in
  &lt;/b&gt;
 &lt;/h3&gt;
 &lt;p&gt;
  ​This long introduction brings us to Groq.
 &lt;/p&gt;
 &lt;p&gt;
  ​The biggest gains in AI reasoning capabilities in 2025 were driven by “inference time compute” — or, in lay terms, “letting the model think for a longer period of time.” But time is money. Consumers and businesses do not like waiting.
 &lt;/p&gt;
 &lt;p&gt;
  ​Groq comes into play here with its lightning-speed inference. If you bring together the architectural efficiency of models like DeepSeek and the sheer throughput of Groq, you get frontier intelligence at your fingertips. By executing inference faster, you can “out-reason” competitive models, offering a “smarter” system to customers without the penalty of lag.
 &lt;/p&gt;
 &lt;h3&gt;
  &lt;b&gt;
   ​From universal chip to inference optimization
  &lt;/b&gt;
 &lt;/h3&gt;
 &lt;p&gt;
  ​For the last decade, the GPU has been the universal hammer for every AI nail. You use H100s to train the model; you use H100s (or trimmed-down versions) to run the model. But as models shift toward &quot;System 2&quot; thinking — where the AI reasons, self-corrects and iterates before answering — the computational workload changes.
 &lt;/p&gt;
 &lt;p&gt;
  ​Training requires massive parallel brute force. Inference, especially for reasoning models, requires faster sequential processing. It must generate tokens instantly to facilitate complex chains of thought without the user waiting minutes for an answer. ​Groq’s LPU (Language Processing Unit) architecture removes the memory bandwidth bottleneck that plagues GPUs during small-batch inference, delivering lightning-fast inference.
 &lt;/p&gt;
 &lt;h3&gt;
  &lt;b&gt;
   ​The engine for the next wave of growth
  &lt;/b&gt;
 &lt;/h3&gt;
 &lt;p&gt;
  ​For the C-Suite, this potential convergence solves the &quot;thinking time&quot; latency crisis. Consider the expectations from AI agents: We want them to autonomously book flights, code entire apps and research legal precedent. To do this reliably, a model might need to generate 10,000 internal &quot;thought tokens&quot; to verify its own work before it outputs a single word to the user.
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    ​
    &lt;b&gt;
     On a standard GPU:
    &lt;/b&gt;
    10,000 thought tokens might take 20 to 40 seconds. The user gets bored and leaves.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    ​
    &lt;b&gt;
     On Groq:
    &lt;/b&gt;
    That same chain of thought happens in less than 2 seconds.
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;p&gt;
  ​If Nvidia integrates Groq’s technology, they solve the &quot;waiting for the robot to think&quot; problem. They preserve the magic of AI. Just as they moved from rendering pixels (gaming) to rendering intelligence (gen AI), they would now move to rendering
  &lt;i&gt;
   reasoning
  &lt;/i&gt;
  in real-time.
 &lt;/p&gt;
 &lt;p&gt;
  ​Furthermore, this creates a formidable software moat. Groq’s biggest hurdle has always been the software stack; Nvidia’s biggest asset is CUDA. If Nvidia wraps its ecosystem around Groq’s hardware, they effectively dig a moat so wide that competitors cannot cross it. They would offer the universal platform: The best environment to train and the most efficient environment to run (Groq/LPU).
 &lt;/p&gt;
 &lt;p&gt;
  Consider what happens when you couple that raw inference power with a next-generation open source model (like the rumored DeepSeek 4): You get an offering that would rival today’s frontier models in cost, performance and speed. That opens up opportunities for Nvidia, from directly entering the inference business with its own cloud offering, to continuing to power a growing number of exponentially growing customers.
 &lt;/p&gt;
 &lt;h3&gt;
  &lt;b&gt;
   ​The next step on the pyramid
  &lt;/b&gt;
 &lt;/h3&gt;
 &lt;p&gt;
  ​Returning to our opening metaphor: The &quot;exponential&quot; growth of AI is not a smooth line of raw FLOPs; it is a staircase of bottlenecks being smashed.
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    ​
    &lt;b&gt;
     Block 1:
    &lt;/b&gt;
    We couldn&#x27;t calculate fast enough.
    &lt;b&gt;
     Solution:
    &lt;/b&gt;
    The GPU.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    ​
    &lt;b&gt;
     Block 2:
    &lt;/b&gt;
    We couldn&#x27;t train deep enough.
    &lt;b&gt;
     Solution:
    &lt;/b&gt;
    Transformer architecture.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    ​
    &lt;b&gt;
     Block 3:
    &lt;/b&gt;
    We can&#x27;t &quot;think&quot; fast enough.
    &lt;b&gt;
     Solution:
    &lt;/b&gt;
    Groq’s LPU.
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;p&gt;
  ​Jensen Huang has never been afraid to cannibalize his own product lines to own the future. By validating Groq, Nvidia wouldn&#x27;t just be buying a faster chip; they would be bringing next-generation intelligence to the masses.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;i&gt;
   Andrew Filev, founder and CEO of Zencoder
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;br/&gt;
 &lt;br/&gt;
 &lt;p&gt;
  Welcome to the VentureBeat community!
 &lt;/p&gt;
 &lt;p&gt;
  Our guest posting program is where technical experts share insights and provide neutral, non-vested deep dives on AI, data infrastructure, cybersecurity and other cutting-edge technologies shaping the future of enterprise.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;a href=&quot;/category/DataDecisionMakers&quot;&gt;
   Read more
  &lt;/a&gt;
  &lt;!-- --&gt;
  from our guest post program — and check out our
  &lt;!-- --&gt;
  &lt;a href=&quot;/guest-posts&quot;&gt;
   guidelines
  &lt;/a&gt;
  &lt;!-- --&gt;
  if you’re interested in contributing an article of your own!
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Qwen3-Max Thinking beats Gemini 3 Pro and GPT-5.2 on Humanity&#x27;s Last Exam (with search) </title>
<link>https://venturebeat.com/technology/qwen3-max-thinking-beats-gemini-3-pro-and-gpt-5-2-on-humanitys-last-exam</link>
<pubDate>Wed, 18 Feb 2026 19:05:21 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;A capybara with circular glasses sits in a library at a table with a laptop and book atop it&quot; data-nimg=&quot;1&quot; height=&quot;1632&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/18aw75O5te6dE6Vt8qmKbg/77c7c117fb58e73b76f2e46a916039fc/Carl_Franzen_vibrant_lush_pop_line_art_vector_art_flat_with_gra_363afe34-53fa-448f-9565-a5d5bc70ce43.png?w=1000&quot; width=&quot;2912&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
    &lt;p&gt;
     Credit: VentureBeat made with Midjourney
    &lt;/p&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  Chinese AI and tech firms continue to impress with their development of cutting-edge, state-of-the-art AI language models.
 &lt;/p&gt;
 &lt;p&gt;
  Today, the one drawing eyeballs is Alibaba Cloud&#x27;s Qwen Team of AI researchers and its unveiling of a new proprietary language reasoning model,
  &lt;a href=&quot;https://qwen.ai/blog?id=qwen3-max-thinking&quot;&gt;
   Qwen3-Max-Thinking.
  &lt;/a&gt;
 &lt;/p&gt;
 &lt;div&gt;
  &lt;div data-exs-config=&#x27;{&quot;customParams&quot;:{&quot;post-type&quot;:&quot;article&quot;,&quot;post_id&quot;:&quot;3dRluOplG3Ap7CmStXAjkG&quot;,&quot;post_cat&quot;:&quot;technology&quot;}}&#x27;&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  You may recall, as VentureBeat covered last year, that Qwen has made a name for itself in the fast-moving global AI marketplace by shipping a variety of powerful, open source models in various modalities, from text to image to spoken audio. The company even earned an endorsement from U.S. tech lodgings giant Airbnb, whose CEO and co-founder
  &lt;a href=&quot;https://finance.yahoo.com/news/airbnb-picks-alibabas-qwen-over-093000045.html?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAAFp2Sgd_hAHwQfzpa0jl8JJF2YotGF_unllsk1Msc8sMoeWXFXfcg36N7gfFCQvHV5R6v9M973mIGZiBRUish2o-0rI8cE5C26uuy34EV9LoGOyhr6Haj3Vly75KVYGijBT-KIsVIaUfzmw0yZse2g6Xc50JPjQe3N6cf8wv2eV8&quot;&gt;
   Brian Chesky said the company was relying on Qwen&#x27;s free, open source models
  &lt;/a&gt;
  as a more affordable alternative to U.S. offerings like those of OpenAI.
 &lt;/p&gt;
 &lt;p&gt;
  Now, with the proprietary Qwen3-Max-Thinking, the Qwen Team is aiming to match and, in some cases, outpace the reasoning capabilities of GPT-5.2 and Gemini 3 Pro through architectural efficiency and agentic autonomy.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  The release comes at a critical juncture. Western labs have largely defined the &quot;reasoning&quot; category (often dubbed &quot;System 2&quot; logic), but Qwen’s latest benchmarks suggest the gap has closed.
 &lt;/p&gt;
 &lt;p&gt;
  In addition, the company&#x27;s relatively affordable
  &lt;a href=&quot;https://www.alibabacloud.com/help/en/model-studio/models?spm=a2ty_o06.30285417.0.0.1ef4c921JDIqvK#c2d5833ae4jmo&quot;&gt;
   API pricing strategy
  &lt;/a&gt;
  aggressively targets enterprise adoption. However, as it is a Chinese model, some U.S. firms with strict national security requirements and considerations may be wary of adopting it.
 &lt;/p&gt;
 &lt;h3&gt;
  &lt;b&gt;
   The Architecture: &quot;Test-Time Scaling&quot; Redefined
  &lt;/b&gt;
 &lt;/h3&gt;
 &lt;p&gt;
  The core innovation driving Qwen3-Max-Thinking is a departure from standard inference methods. While most models generate tokens linearly, Qwen3 utilizes a &quot;heavy mode&quot; driven by a technique known as &quot;Test-time scaling.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  In simple terms, this technique allows the model to trade compute for intelligence. But unlike naive &quot;best-of-N&quot; sampling—where a model might generate 100 answers and pick the best one — Qwen3-Max-Thinking employs an experience-cumulative, multi-round strategy.
 &lt;/p&gt;
 &lt;p&gt;
  This approach mimics human problem-solving. When the model encounters a complex query, it doesn&#x27;t just guess; it engages in iterative self-reflection. It uses a proprietary &quot;take-experience&quot; mechanism to distill insights from previous reasoning steps. This allows the model to:
 &lt;/p&gt;
 &lt;ol&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Identify Dead Ends:
    &lt;/b&gt;
    Recognize when a line of reasoning is failing without needing to fully traverse it.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Focus Compute:
    &lt;/b&gt;
    Redirect processing power toward &quot;unresolved uncertainties&quot; rather than re-deriving known conclusions.
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ol&gt;
 &lt;p&gt;
  The efficiency gains are tangible. By avoiding redundant reasoning, the model integrates richer historical context into the same window. The Qwen team reports that this method drove massive performance jumps without exploding token costs:
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     GPQA (PhD-level science):
    &lt;/b&gt;
    Scores improved from 90.3 to
    &lt;b&gt;
     92.8
    &lt;/b&gt;
    .
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     LiveCodeBench v6:
    &lt;/b&gt;
    Performance jumped from 88.0 to
    &lt;b&gt;
     91.4
    &lt;/b&gt;
    .
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;h3&gt;
  &lt;b&gt;
   Beyond Pure Thought: Adaptive Tooling
  &lt;/b&gt;
 &lt;/h3&gt;
 &lt;p&gt;
  While &quot;thinking&quot; models are powerful, they have historically been siloed — great at math, but poor at browsing the web or running code. Qwen3-Max-Thinking bridges this gap by effectively integrating &quot;thinking and non-thinking modes&quot;.
 &lt;/p&gt;
 &lt;p&gt;
  The model features adaptive tool-use capabilities, meaning it autonomously selects the right tool for the job without manual user prompting. It can seamlessly toggle between:
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Web Search &amp; Extraction:
    &lt;/b&gt;
    For real-time factual queries.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Memory:
    &lt;/b&gt;
    To store and recall user-specific context.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Code Interpreter:
    &lt;/b&gt;
    To write and execute Python snippets for computational tasks.
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;p&gt;
  In &quot;Thinking Mode,&quot; the model supports these tools simultaneously. This capability is critical for enterprise applications where a model might need to verify a fact (Search), calculate a projection (Code Interpreter), and then reason about the strategic implication (Thinking) all in one turn.
 &lt;/p&gt;
 &lt;p&gt;
  Empirically, the team notes that this combination &quot;effectively mitigates hallucinations,&quot; as the model can ground its reasoning in verifiable external data rather than relying solely on its training weights.
 &lt;/p&gt;
 &lt;h3&gt;
  &lt;b&gt;
   Benchmark Analysis: The Data Story
  &lt;/b&gt;
 &lt;/h3&gt;
 &lt;p&gt;
  Qwen is not shy about direct comparisons.
 &lt;/p&gt;
 &lt;p&gt;
  On HMMT Feb 25, a rigorous reasoning benchmark, Qwen3-Max-Thinking scored 98.0, edging out Gemini 3 Pro (97.5) and significantly leading DeepSeek V3.2 (92.5).
 &lt;/p&gt;
 &lt;p&gt;
  However, the most significant signal for developers is arguably Agentic Search. On &quot;Humanity&#x27;s Last Exam&quot; (HLE) — the benchmark that measures performance on 3,000 &quot;Google-proof&quot; graduate-level questions across math, science, computer science, humanities and engineering —
  &lt;b&gt;
   Qwen3-Max-Thinking, equipped with web search tools, scored 49.8, beating both Gemini 3 Pro (45.8) and GPT-5.2-Thinking (45.5)
  &lt;/b&gt;
  .
 &lt;/p&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;Qwen3-Max key benchmarks&quot; data-nimg=&quot;1&quot; height=&quot;498&quot; loading=&quot;lazy&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/734RszOab5s4t7T4CEn5Id/484e6077e55f6471d7a3a17be5dce962/G_mUNMeawAAu6QY-1.jpg?w=1000&quot; width=&quot;1036&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
    &lt;p&gt;
     Qwen3-Max key benchmarks. Credit: Alibaba Cloud Qwen Team on X
    &lt;/p&gt;
   &lt;/figcaption&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  This suggests that Qwen3-Max-Thinking’s architecture is uniquely suited for complex, multi-step agentic workflows where external data retrieval is necessary.
 &lt;/p&gt;
 &lt;p&gt;
  In coding tasks, the model also shines. On Arena-Hard v2, it posted a score of 90.2, leaving competitors like Claude-Opus-4.5 (76.7) far behind.
 &lt;/p&gt;
 &lt;h3&gt;
  &lt;b&gt;
   The Economics of Reasoning: Pricing Breakdown
  &lt;/b&gt;
 &lt;/h3&gt;
 &lt;p&gt;
  For the first time, we have a clear look at the economics of Qwen&#x27;s top-tier reasoning model. Alibaba Cloud has positioned
  &lt;code&gt;
   qwen3-max-2026-01-23
  &lt;/code&gt;
  as a premium but accessible offering
  &lt;a href=&quot;https://www.alibabacloud.com/help/en/model-studio/models?spm=a2ty_o06.30285417.0.0.1ef4c921JDIqvK#c2d5833ae4jmo&quot;&gt;
   on its API.
  &lt;/a&gt;
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Input:
    &lt;/b&gt;
    &lt;b&gt;
     $1.20
    &lt;/b&gt;
    per 1 million tokens (for standard contexts &amp;lt;= 32k).
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Output:
    &lt;/b&gt;
    &lt;b&gt;
     $6.00
    &lt;/b&gt;
    per 1 million tokens.
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;p&gt;
  On a base level, here&#x27;s how Qwen3-Max-Thinking stacks up:
 &lt;/p&gt;
 &lt;table&gt;
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;b&gt;
       Model
      &lt;/b&gt;
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;b&gt;
       Input (/1M)
      &lt;/b&gt;
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;b&gt;
       Output (/1M)
      &lt;/b&gt;
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;b&gt;
       Total Cost
      &lt;/b&gt;
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;b&gt;
       Source
      &lt;/b&gt;
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      Qwen 3 Turbo
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $0.05
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $0.20
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $0.25
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;a href=&quot;https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai&quot;&gt;
       Alibaba Cloud
      &lt;/a&gt;
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      Grok 4.1 Fast (reasoning)
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $0.20
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $0.50
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $0.70
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;a href=&quot;https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models&quot;&gt;
       xAI
      &lt;/a&gt;
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      Grok 4.1 Fast (non-reasoning)
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $0.20
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $0.50
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $0.70
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;a href=&quot;https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models&quot;&gt;
       xAI
      &lt;/a&gt;
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      deepseek-chat (V3.2-Exp)
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $0.28
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $0.42
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $0.70
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;a href=&quot;https://api-docs.deepseek.com/quick_start/pricing&quot;&gt;
       DeepSeek
      &lt;/a&gt;
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      deepseek-reasoner (V3.2-Exp)
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $0.28
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $0.42
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $0.70
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;a href=&quot;https://api-docs.deepseek.com/quick_start/pricing&quot;&gt;
       DeepSeek
      &lt;/a&gt;
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      Qwen 3 Plus
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $0.40
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $1.20
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $1.60
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;a href=&quot;https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai&quot;&gt;
       Alibaba Cloud
      &lt;/a&gt;
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      ERNIE 5.0
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $0.85
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $3.40
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $4.25
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;a href=&quot;https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4&quot;&gt;
       Qianfan
      &lt;/a&gt;
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      Gemini 3 Flash Preview
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $0.50
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $3.00
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $3.50
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;a href=&quot;https://ai.google.dev/gemini-api/docs/pricing&quot;&gt;
       Google
      &lt;/a&gt;
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      Claude Haiku 4.5
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $1.00
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $5.00
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $6.00
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;a href=&quot;https://docs.anthropic.com/claude/docs&quot;&gt;
       Anthropic
      &lt;/a&gt;
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;b&gt;
       Qwen3-Max Thinking (2026-01-23)
      &lt;/b&gt;
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;b&gt;
       $1.20
      &lt;/b&gt;
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;b&gt;
       $6.00
      &lt;/b&gt;
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;b&gt;
       $7.20
      &lt;/b&gt;
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;a href=&quot;https://modelstudio.console.alibabacloud.com/ap-southeast-1/?tab=doc#/doc/?type=model&amp;url=2840914_2&amp;modelId=qwen3-max-2026-01-23&quot;&gt;
       &lt;b&gt;
        Alibaba Cloud
       &lt;/b&gt;
      &lt;/a&gt;
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      Gemini 3 Pro (≤200K)
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $2.00
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $12.00
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $14.00
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;a href=&quot;https://ai.google.dev/gemini-api/docs/pricing&quot;&gt;
       Google
      &lt;/a&gt;
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      GPT-5.2
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $1.75
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $14.00
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $15.75
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;a href=&quot;https://openai.com/api/pricing/&quot;&gt;
       OpenAI
      &lt;/a&gt;
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      Claude Sonnet 4.5
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $3.00
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $15.00
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $18.00
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;a href=&quot;https://docs.anthropic.com/claude/docs&quot;&gt;
       Anthropic
      &lt;/a&gt;
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      Gemini 3 Pro (&amp;gt;200K)
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $4.00
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $18.00
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $22.00
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;a href=&quot;https://ai.google.dev/gemini-api/docs/pricing&quot;&gt;
       Google
      &lt;/a&gt;
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      Claude Opus 4.5
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $5.00
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $25.00
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $30.00
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;a href=&quot;https://docs.anthropic.com/claude/docs&quot;&gt;
       Anthropic
      &lt;/a&gt;
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      GPT-5.2 Pro
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $21.00
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $168.00
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $189.00
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;a href=&quot;https://openai.com/api/pricing/&quot;&gt;
       OpenAI
      &lt;/a&gt;
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
  &lt;/tbody&gt;
 &lt;/table&gt;
 &lt;p&gt;
  This pricing structure is aggressive, undercutting many legacy flagship models while offering state-of-the-art performance.
 &lt;/p&gt;
 &lt;p&gt;
  However, developers should note the granular pricing for the new agentic capabilities, as Qwen separates the cost of &quot;thinking&quot; (tokens) from the cost of &quot;doing&quot; (tool use).
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Agent Search Strategy:
    &lt;/b&gt;
    Both standard
    &lt;code&gt;
     search_strategy:agent
    &lt;/code&gt;
    and the more advanced
    &lt;code&gt;
     search_strategy:agent_max
    &lt;/code&gt;
    are priced at
    &lt;b&gt;
     $10 per 1,000 calls
    &lt;/b&gt;
    .
   &lt;/p&gt;
   &lt;ul&gt;
    &lt;li&gt;
     &lt;p&gt;
      &lt;i&gt;
       Note:
      &lt;/i&gt;
      The
      &lt;code&gt;
       agent_max
      &lt;/code&gt;
      strategy is currently marked as a &quot;Limited Time Offer,&quot; suggesting its price may rise later.
     &lt;/p&gt;
    &lt;/li&gt;
   &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Web Search:
    &lt;/b&gt;
    Priced at $10 per 1,000 calls via the Responses API.
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;p&gt;
  &lt;b&gt;
   Promotional Free Tier:
  &lt;/b&gt;
  To encourage adoption of its most advanced features, Alibaba Cloud is currently offering two key tools for free for a limited time:
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Web Extractor:
    &lt;/b&gt;
    &lt;b&gt;
     Free
    &lt;/b&gt;
    (Limited Time).
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Code Interpreter:
    &lt;/b&gt;
    &lt;b&gt;
     Free
    &lt;/b&gt;
    (Limited Time).
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;p&gt;
  This pricing model (low token cost + à la carte tool pricing) allows developers to build complex agents that are cost-effective for text processing, while paying a premium only when external actions—like a live web search—are explicitly triggered.
 &lt;/p&gt;
 &lt;h3&gt;
  &lt;b&gt;
   Developer Ecosystem
  &lt;/b&gt;
 &lt;/h3&gt;
 &lt;p&gt;
  Recognizing that performance is useless without integration, Alibaba Cloud has ensured Qwen3-Max-Thinking is drop-in ready.
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     OpenAI Compatibility:
    &lt;/b&gt;
    The API supports the standard OpenAI format, allowing teams to switch models by simply changing the
    &lt;code&gt;
     base_url
    &lt;/code&gt;
    and
    &lt;code&gt;
     model
    &lt;/code&gt;
    name.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Anthropic Compatibility:
    &lt;/b&gt;
    In a savvy move to capture the coding market, the API also supports the Anthropic protocol. This makes Qwen3-Max-Thinking compatible with
    &lt;b&gt;
     Claude Code
    &lt;/b&gt;
    , a popular agentic coding environment.
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;h3&gt;
  &lt;b&gt;
   The Verdict
  &lt;/b&gt;
 &lt;/h3&gt;
 &lt;p&gt;
  Qwen3-Max-Thinking represents a maturation of the AI market in 2026. It moves the conversation beyond &quot;who has the smartest chatbot&quot; to &quot;who has the most capable agent.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  By combining high-efficiency reasoning with adaptive, autonomous tool use—and pricing it to move—Qwen has firmly established itself as a top-tier contender for the enterprise AI throne.
 &lt;/p&gt;
 &lt;p&gt;
  For developers and enterprises, the &quot;Limited Time Free&quot; windows on Code Interpreter and Web Extractor suggest now is the time to experiment. The reasoning wars are far from over, but Qwen has just deployed a very heavy hitter.
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> OpenClaw proves agentic AI works. It also proves your security model doesn&#x27;t. 180,000 developers just made that your problem. </title>
<link>https://venturebeat.com/security/openclaw-agentic-ai-security-risk-ciso-guide</link>
<pubDate>Tue, 17 Feb 2026 18:16:05 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;OpenClaw hit 118K GitHub stars in a week. Your security model wasn&#x27;t built for what comes next.&quot; data-nimg=&quot;1&quot; height=&quot;633&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/1oBIMwURedNVAql7D5WEsn/f5bc000909cf83cb5133407934ea8ba7/HERO_IMAGE.jpg?w=1000&quot; width=&quot;1191&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://openclaw.ai/&quot;&gt;
   OpenClaw
  &lt;/a&gt;
  , the open-source AI assistant formerly known as
  &lt;a href=&quot;https://venturebeat.com/security/clawdbot-exploits-48-hours-what-broke&quot;&gt;
   Clawdbot and then Moltbot
  &lt;/a&gt;
  , crossed 180,000 GitHub stars and drew
  &lt;a href=&quot;https://www.theverge.com/ai-artificial-intelligence/871006/social-network-facebook-for-ai-agents-moltbook-moltbot-openclaw&quot;&gt;
   2 million visitors in a single week
  &lt;/a&gt;
  , according to creator Peter Steinberger.
 &lt;/p&gt;
 &lt;p&gt;
  Security researchers scanning the internet found over
  &lt;a href=&quot;https://www.theregister.com/2026/01/27/clawdbot_moltbot_security_concerns/&quot;&gt;
   1,800 exposed instances
  &lt;/a&gt;
  leaking API keys, chat histories, and account credentials. The project has been rebranded twice in recent weeks due to trademark disputes.
 &lt;/p&gt;
 &lt;p&gt;
  The grassroots agentic AI movement is also the biggest unmanaged attack surface that most security tools can&#x27;t see.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  Enterprise security teams didn&#x27;t deploy this tool. Neither did their firewalls, EDR, or SIEM. When agents run on BYOD hardware, security stacks go blind. That&#x27;s the gap.
 &lt;/p&gt;
 &lt;h2&gt;
  Why traditional perimeters can&#x27;t see agentic AI threats
 &lt;/h2&gt;
 &lt;p&gt;
  Most enterprise defenses treat agentic AI as another development tool requiring standard access controls. OpenClaw proves that the assumption is architecturally wrong.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  Agents operate within authorized permissions, pull context from attacker-influenceable sources, and execute actions autonomously. Your perimeter sees none of it. A wrong threat model means wrong controls, which means blind spots.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;AI runtime attacks are semantic rather than syntactic,&quot; Carter Rees, VP of Artificial Intelligence at
  &lt;a href=&quot;https://reputation.com/&quot;&gt;
   Reputation
  &lt;/a&gt;
  , told VentureBeat. &quot;A phrase as innocuous as &#x27;Ignore previous instructions&#x27; can carry a payload as devastating as a buffer overflow, yet it shares no commonality with known malware signatures.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Simon Willison, the software developer and AI researcher who coined the term &quot;prompt injection,&quot; describes what he calls the
  &lt;a href=&quot;https://simonwillison.net/2025/Jun/16/the-lethal-trifecta/&quot;&gt;
   &quot;lethal trifecta&quot; for AI agents
  &lt;/a&gt;
  . They include access to private data, exposure to untrusted content, and the ability to communicate externally. When these three capabilities combine, attackers can trick the agent into accessing private information and sending it to them. Willison warns that all this can happen without a single alert being sent.
 &lt;/p&gt;
 &lt;p&gt;
  OpenClaw has all three. It reads emails and documents, pulls information from websites or shared files, and acts by sending messages or triggering automated tasks. An organization’s firewall sees HTTP 200. SOC teams see their EDR monitoring process behavior, not semantic content. The threat is semantic manipulation, not unauthorized access.
 &lt;/p&gt;
 &lt;h2&gt;
  Why this isn&#x27;t limited to enthusiast developers
 &lt;/h2&gt;
 &lt;p&gt;
  IBM Research scientists Kaoutar El Maghraoui and Marina Danilevsky analyzed OpenClaw this week and concluded it
  &lt;a href=&quot;https://www.ibm.com/think/news/clawdbot-ai-agent-testing-limits-vertical-integration&quot;&gt;
   challenges the hypothesis that autonomous AI agents must be vertically integrated
  &lt;/a&gt;
  . The tool demonstrates that &quot;this loose, open-source layer can be incredibly powerful if it has full system access&quot; and that creating agents with true autonomy is &quot;not limited to large enterprises&quot; but &quot;can also be community driven.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  That&#x27;s exactly what makes it dangerous for enterprise security. A highly capable agent without proper safety controls creates major vulnerabilities in work contexts. El Maghraoui stressed that the question has shifted from whether open agentic platforms can work to &quot;what kind of integration matters most, and in what context.&quot; The security questions aren&#x27;t optional anymore.
 &lt;/p&gt;
 &lt;h2&gt;
  What Shodan scans revealed about exposed gateways
 &lt;/h2&gt;
 &lt;p&gt;
  Security researcher Jamieson O&#x27;Reilly, founder of red-teaming company
  &lt;a href=&quot;https://dvuln.com/&quot;&gt;
   Dvuln
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.trendingtopics.eu/clawbot-hyped-ai-agent-risks-leaking-personal-data-security-experts-warn/&quot;&gt;
   identified exposed OpenClaw servers using Shodan
  &lt;/a&gt;
  by searching for characteristic HTML fingerprints. A simple search for &quot;Clawdbot Control&quot; yielded hundreds of results within seconds. Of the instances he examined manually, eight were completely open with no authentication. These instances provided full access to run commands and view configuration data to anyone discovering them.
 &lt;/p&gt;
 &lt;p&gt;
  O&#x27;Reilly found Anthropic API keys. Telegram bot tokens. Slack OAuth credentials. Complete conversation histories across every integrated chat platform. Two instances gave up months of private conversations the moment the WebSocket handshake completed. The network sees localhost traffic. Security teams have no visibility into what agents are calling or what data they&#x27;re returning.
 &lt;/p&gt;
 &lt;p&gt;
  Here&#x27;s why: OpenClaw trusts localhost by default with no authentication required. Most deployments sit behind nginx or Caddy as a reverse proxy, so every connection looks like it&#x27;s coming from 127.0.0.1 and gets treated as trusted local traffic. External requests walk right in. O&#x27;Reilly&#x27;s specific attack vector has been patched, but the architecture that allowed it hasn&#x27;t changed.
 &lt;/p&gt;
 &lt;h2&gt;
  Why Cisco calls it a &#x27;security nightmare&#x27;
 &lt;/h2&gt;
 &lt;p&gt;
  Cisco&#x27;s AI Threat &amp; Security Research team
  &lt;a href=&quot;https://blogs.cisco.com/ai/personal-ai-agents-like-openclaw-are-a-security-nightmare&quot;&gt;
   published its assessment this week
  &lt;/a&gt;
  , calling OpenClaw &quot;groundbreaking&quot; from a capability perspective but &quot;an absolute nightmare&quot; from a security perspective.
 &lt;/p&gt;
 &lt;p&gt;
  Cisco&#x27;s team released an open-source
  &lt;a href=&quot;https://github.com/cisco-ai-defense/skill-scanner&quot;&gt;
   Skill Scanner
  &lt;/a&gt;
  that combines static analysis, behavioral dataflow, LLM semantic analysis, and VirusTotal scanning to detect malicious agent skills. It tested a third-party skill called &quot;What Would Elon Do?&quot; against OpenClaw. The verdict was a decisive failure. Nine security findings surfaced, including two critical and five high-severity issues.
 &lt;/p&gt;
 &lt;p&gt;
  The skill was functionally malware. It instructed the bot to execute a curl command, sending data to an external server controlled by the skill author. Silent execution, zero user awareness. The skill also deployed direct prompt injection to bypass safety guidelines.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;The LLM cannot inherently distinguish between trusted user instructions and untrusted retrieved data,&quot; Rees said. &quot;It may execute the embedded command, effectively becoming a &#x27;confused deputy&#x27; acting on behalf of the attacker.&quot; AI agents with system access become covert data-leak channels that bypass traditional DLP, proxies, and endpoint monitoring.
 &lt;/p&gt;
 &lt;h2&gt;
  Why security teams’ visibility just got worse
 &lt;/h2&gt;
 &lt;p&gt;
  The control gap is widening faster than most security teams realize. As of Friday, OpenClaw-based agents are forming their own social networks. Communication channels that exist outside human visibility entirely.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://www.moltbook.com&quot;&gt;
   Moltbook
  &lt;/a&gt;
  bills itself as &quot;a social network for AI agents&quot; where &quot;humans are welcome to observe.&quot; Posts go through the API, not through a human-visible interface. Astral Codex Ten&#x27;s Scott Alexander
  &lt;a href=&quot;https://www.astralcodexten.com/p/best-of-moltbook&quot;&gt;
   confirmed it&#x27;s not trivially fabricated
  &lt;/a&gt;
  . He asked his own Claude to participate, and &quot;it made comments pretty similar to all the others.&quot; One human confirmed their agent started a religion-themed community &quot;while I slept.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Security implications are immediate.
  &lt;/b&gt;
  To join, agents execute external shell scripts that rewrite their configuration files. They post about their work, their users&#x27; habits, and their errors. Context leakage as table stakes for participation. Any prompt injection in a Moltbook post cascades into your agent&#x27;s other capabilities through MCP connections.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Moltbook is a microcosm of the broader problem.
  &lt;/b&gt;
  The same autonomy that makes agents useful makes them vulnerable. The more they can do independently, the more damage a compromised instruction set can cause. The capability curve is outrunning the security curve by a wide margin. And the people building these tools are often more excited about what&#x27;s possible than concerned about what&#x27;s exploitable.
 &lt;/p&gt;
 &lt;h2&gt;
  What security leaders need to do on Monday morning
 &lt;/h2&gt;
 &lt;p&gt;
  Web application firewalls see agent traffic as normal HTTPS. EDR tools monitor process behavior, not semantic content. A typical corporate network sees localhost traffic
  &lt;a href=&quot;https://venturebeat.com/security/mcp-shipped-without-authentication-clawdbot-shows-why-thats-a-problem&quot;&gt;
   when agents call MCP servers
  &lt;/a&gt;
  .
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Treat agents as production infrastructure, not a productivity app: least privilege, scoped tokens, allowlisted actions, strong authentication on every integration, and auditability end-to-end,&quot; Itamar Golan, founder of
  &lt;a href=&quot;https://prompt.security/&quot;&gt;
   Prompt Security
  &lt;/a&gt;
  (now part of SentinelOne), told VentureBeat in an exclusive interview.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Audit your network for exposed agentic AI gateways.
  &lt;/b&gt;
  Run Shodan scans against your IP ranges for OpenClaw, Moltbot, and Clawdbot signatures. If your developers are experimenting, you want to know before attackers do.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Map where Willison&#x27;s lethal trifecta exists in your environment.
  &lt;/b&gt;
  Identify systems combining private data access, untrusted content exposure, and external communication. Assume any agent with all three is vulnerable until proven otherwise.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Segment access aggressively.
  &lt;/b&gt;
  Your agent doesn&#x27;t need access to all of Gmail, all of SharePoint, all of Slack, and all your databases simultaneously. Treat agents as privileged users. Log the agent&#x27;s actions, not just the user&#x27;s authentication.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Scan your agent skills for malicious behavior.
  &lt;/b&gt;
  Cisco released its
  &lt;a href=&quot;https://github.com/cisco-ai-defense/skill-scanner&quot;&gt;
   Skill Scanner as open source
  &lt;/a&gt;
  . Use it. Some of the most damaging behavior hides inside the files themselves.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Update your incident response playbooks
  &lt;/b&gt;
  . Prompt injection doesn&#x27;t look like a traditional attack. There&#x27;s no malware signature, no network anomaly, no unauthorized access. The attack happens inside the model&#x27;s reasoning. Your SOC needs to know what to look for.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Establish policy before you ban.
  &lt;/b&gt;
  You can&#x27;t prohibit experimentation without becoming the productivity blocker your developers route around. Build guardrails that channel innovation rather than block it. Shadow AI is already in your environment. The question is whether you have visibility into it.
 &lt;/p&gt;
 &lt;h2&gt;
  The bottom line
 &lt;/h2&gt;
 &lt;p&gt;
  OpenClaw isn&#x27;t the threat. It&#x27;s the signal. The security gaps exposing these instances will expose every agentic AI deployment your organization builds or adopts over the next two years. Grassroots experimentation already happened. Control gaps are documented. Attack patterns are published.
 &lt;/p&gt;
 &lt;p&gt;
  The agentic AI security model you build in the next 30 days determines whether your organization captures productivity gains or becomes the next breach disclosure. Validate your controls now.
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> OpenAI launches a Codex desktop app for macOS to run multiple AI coding agents in parallel </title>
<link>https://venturebeat.com/orchestration/openai-launches-a-codex-desktop-app-for-macos-to-run-multiple-ai-coding</link>
<pubDate>Mon, 09 Feb 2026 23:52:12 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;nuneybits Vector art of an Apple iMac monitor displaying cascad ecce1621-251d-41d9-ac6e-72eb25b2fd35&quot; data-nimg=&quot;1&quot; height=&quot;536&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/5ixq6lS6l5yrO3RJxCtr5w/c11ddd394c8969826452a5a30312234b/nuneybits_Vector_art_of_an_Apple_iMac_monitor_displaying_cascad_ecce1621-251d-41d9-ac6e-72eb25b2fd35.webp?w=1000&quot; width=&quot;957&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
    &lt;p&gt;
     Credit: VentureBeat made with Midjourney
    &lt;/p&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://openai.com/&quot;&gt;
   OpenAI
  &lt;/a&gt;
  on Monday released a new desktop application for its
  &lt;a href=&quot;https://chatgpt.com/codex&quot;&gt;
   Codex
  &lt;/a&gt;
  artificial intelligence coding system, a tool the company says transforms software development from a collaborative exercise with a single AI assistant into something more akin to managing a team of autonomous workers.
 &lt;/p&gt;
 &lt;p&gt;
  The
  &lt;a href=&quot;https://openai.com/index/introducing-the-codex-app/&quot;&gt;
   Codex app for macOS
  &lt;/a&gt;
  functions as what OpenAI executives describe as a &quot;command center for agents,&quot; allowing developers to delegate multiple coding tasks simultaneously, automate repetitive work, and supervise AI systems that can run for up to 30 minutes independently before returning completed code.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;This is the most loved internal product we&#x27;ve ever had,&quot; Sam Altman, OpenAI&#x27;s chief executive, told VentureBeat in a press briefing ahead of Monday&#x27;s launch. &quot;It&#x27;s been totally an amazing thing for us to be using recently at OpenAI.&quot;
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  The release arrives at a pivotal moment for the enterprise AI market. According to a survey of 100 Global 2000 companies published last week by venture capital firm Andreessen Horowitz,
  &lt;a href=&quot;https://www.a16z.news/p/leaders-gainers-and-unexpected-winners?utm_source=substack&amp;publication_id=13145&amp;post_id=186310607&amp;utm_medium=email&amp;utm_content=share&amp;utm_campaign=email-share&amp;triggerShare=true&amp;isFreemail=true&amp;r=sr4e&amp;triedRedirect=true&quot;&gt;
   78% of enterprise CIOs now use OpenAI models in production
  &lt;/a&gt;
  , though competitors Anthropic and Google are gaining ground rapidly. Anthropic posted the largest share increase of any frontier lab since May 2025, growing 25% in enterprise penetration, with 44% of enterprises now using Anthropic in production.
 &lt;/p&gt;
 &lt;p&gt;
  The timing of OpenAI&#x27;s
  &lt;a href=&quot;https://openai.com/index/introducing-the-codex-app/&quot;&gt;
   Codex app launch
  &lt;/a&gt;
  — with its focus on professional software engineering workflows — appears designed to defend the company&#x27;s position in what has become the most contested segment of the AI market: coding tools.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Why developers are abandoning their IDEs for AI agent management
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The
  &lt;a href=&quot;https://openai.com/index/introducing-the-codex-app/&quot;&gt;
   Codex app
  &lt;/a&gt;
  introduces a fundamentally different approach to AI-assisted coding. While previous tools like
  &lt;a href=&quot;https://github.com/features/copilot&quot;&gt;
   GitHub Copilot
  &lt;/a&gt;
  focused on autocompleting lines of code in real-time, the new application enables developers to &quot;effortlessly manage multiple agents at once, run work in parallel, and collaborate with agents over long-running tasks.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://x.com/embirico?lang=en&quot;&gt;
   Alexander Embiricos
  &lt;/a&gt;
  , the product lead for Codex, explained the evolution during the press briefing by tracing the product&#x27;s lineage back to 2021, when OpenAI first introduced a model called Codex that powered GitHub Copilot.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Back then, people were using AI to write small chunks of code in their IDEs,&quot; Embiricos said. &quot;GPT-5 in August last year was a big jump, and then 5.2 in December was another massive jump, where people started doing longer and longer tasks, asking models to do work end to end. So what we saw is that developers, instead of working closely with the model, pair coding, they started delegating entire features.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The shift has been so profound that Altman said he recently completed a substantial coding project without ever opening a traditional integrated development environment.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;I was astonished by this…I did this fairly big project in a few days earlier this week and over the weekend. I did not open an IDE during the process. Not a single time,&quot; Altman said. &quot;I did look at some code, but I was not doing it the old-fashioned way, and I did not think that was going to be happening by now.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   How skills and automations extend AI coding beyond simple code generation
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The
  &lt;a href=&quot;https://openai.com/index/introducing-the-codex-app/&quot;&gt;
   Codex app
  &lt;/a&gt;
  introduces several new capabilities designed to extend AI coding beyond writing lines of code. Chief among these are &quot;Skills,&quot; which bundle instructions, resources, and scripts so that Codex can &quot;reliably connect to tools, run workflows, and complete tasks according to your team&#x27;s preferences.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The app includes a dedicated interface for creating and managing skills, and users can explicitly invoke specific skills or allow the system to automatically select them based on the task at hand. OpenAI has published a
  &lt;a href=&quot;https://developers.openai.com/codex/skills/&quot;&gt;
   library of skills
  &lt;/a&gt;
  for common workflows, including tools to fetch design context from Figma, manage projects in Linear, deploy web applications to cloud hosts like Cloudflare and Vercel, generate images using GPT Image, and create professional documents in PDF, spreadsheet, and Word formats.
 &lt;/p&gt;
 &lt;p&gt;
  To demonstrate the system&#x27;s capabilities, OpenAI asked Codex to build a racing game from a single prompt. Using an image generation skill and a web game development skill, Codex built the game by working independently using more than 7 million tokens with just one initial user prompt, taking on &quot;the roles of designer, game developer, and QA tester to validate its work by actually playing the game.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The company has also introduced &quot;Automations,&quot; which allow developers to schedule Codex to work in the background on an automatic schedule. &quot;When an Automation finishes, the results land in a review queue so you can jump back in and continue working if needed.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://x.com/thsottiaux&quot;&gt;
   Thibault Sottiaux
  &lt;/a&gt;
  , who leads the Codex team at OpenAI, described how the company uses these automations internally: &quot;We&#x27;ve been using Automations to handle the repetitive but important tasks, like daily issue triage, finding and summarizing CI failures, generating daily release briefs, checking for bugs, and more.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The app also includes built-in support for &quot;worktrees,&quot; allowing multiple agents to work on the same repository without conflicts. &quot;Each agent works on an isolated copy of your code, allowing you to explore different paths without needing to track how they impact your codebase.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   OpenAI battles Anthropic and Google for control of enterprise AI spending
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The launch comes as enterprise spending on AI coding tools accelerates dramatically. According to
  &lt;a href=&quot;https://www.a16z.news/p/leaders-gainers-and-unexpected-winners?utm_source=substack&amp;publication_id=13145&amp;post_id=186310607&amp;utm_medium=email&amp;utm_content=share&amp;utm_campaign=email-share&amp;triggerShare=true&amp;isFreemail=true&amp;r=sr4e&amp;triedRedirect=true&quot;&gt;
   the Andreessen Horowitz survey
  &lt;/a&gt;
  , average enterprise AI spend on large language models has risen from approximately $4.5 million to $7 million over the last two years, with enterprises expecting growth of another 65% this year to approximately $11.6 million.
 &lt;/p&gt;
 &lt;p&gt;
  Leadership in the enterprise AI market varies significantly by use case. OpenAI dominates &quot;early, horizontal use cases like general purpose chatbots, enterprise knowledge management and customer support,&quot; while Anthropic leads in &quot;software development and data analysis, where CIOs consistently cite rapid capability gains since the second half of 2024.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  When asked during the press briefing how Codex differentiates from Anthropic&#x27;s
  &lt;a href=&quot;https://claude.com/product/claude-code&quot;&gt;
   Claude Code
  &lt;/a&gt;
  , which has been described as having its &quot;ChatGPT moment,&quot; Sottiaux emphasized OpenAI&#x27;s focus on model capability for long-running tasks.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;One of the things that our models are extremely good at—they really sit at the frontier of intelligence and doing reliable work for long periods of time,&quot; Sottiaux said. &quot;This is also what we&#x27;re optimizing this new surface to be very good at, so that you can start many parallel agents and coordinate them over long periods of time and not get lost.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Altman added that while many tools can handle &quot;vibe coding front ends,&quot;
  &lt;a href=&quot;https://openai.com/index/introducing-gpt-5-2/&quot;&gt;
   OpenAI&#x27;s 5.2 model
  &lt;/a&gt;
  remains &quot;the strongest model by far&quot; for sophisticated work on complex systems.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Taking that level of model capability and putting it in an interface where you can do what Thibault was saying, we think is going to matter quite a bit,&quot; Altman said. &quot;That&#x27;s probably the, at least listening to users and sort of looking at the chatter on social that&#x27;s that&#x27;s the single biggest differentiator.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   The surprising satisfies on AI progress: how fast humans can type
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The philosophical underpinning of the Codex app reflects a view that OpenAI executives have been articulating for months: that human limitations — not AI capabilities — now constitute the primary constraint on productivity.
 &lt;/p&gt;
 &lt;p&gt;
  In a December appearance on
  &lt;a href=&quot;https://www.lennysnewsletter.com/p/why-humans-are-ais-biggest-bottleneck&quot;&gt;
   Lenny’s Podcast
  &lt;/a&gt;
  , Embiricos described human typing speed as &quot;the current underappreciated limiting factor&quot; to achieving artificial general intelligence. The logic: if AI can perform complex coding tasks but humans can&#x27;t write prompts or review outputs fast enough, progress stalls.
 &lt;/p&gt;
 &lt;p&gt;
  The
  &lt;a href=&quot;https://openai.com/index/introducing-the-codex-app/&quot;&gt;
   Codex app
  &lt;/a&gt;
  attempts to address this by enabling what the team calls an &quot;abundance mindset&quot; — running multiple tasks in parallel rather than perfecting single requests. During the briefing, Embiricos described how power users at OpenAI work with the tool.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Last night, I was working on the app, and I was making a few changes, and all of these changes are able to run in parallel together. And I was just sort of going between them, managing them,&quot; Embiricos said. &quot;Behind the scenes, all these tasks are running on something called gate work trees, which means that the agents are running independently, and you don&#x27;t have to manage them.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  In the Sequoia Capital podcast &quot;
  &lt;a href=&quot;https://sequoiacap.com/podcast/training-data-openai-codex/&quot;&gt;
   Training Data,
  &lt;/a&gt;
  &quot; Embiricos elaborated on this mindset shift: &quot;The mindset that works really well for Codex is, like, kind of like this abundance mindset and, like, hey, let&#x27;s try anything. Let&#x27;s try anything even multiple times and see what works.&quot; He noted that when users run 20 or more tasks in a day or an hour, &quot;they&#x27;ve probably understood basically how to use the tool.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Building trust through sandboxes: how OpenAI secures autonomous coding agents
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  OpenAI has built security measures into the Codex architecture from the ground up. The app uses &quot;native, open-source and configurable system-level sandboxing,&quot; and by default, &quot;Codex agents are limited to editing files in the folder or branch where they&#x27;re working and using cached web search, then asking for permission to run commands that require elevated permissions like network access.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Embiricos elaborated on the security approach during the briefing, noting that OpenAI has open-sourced its sandbox technology.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Codex has this sandbox that we&#x27;re actually incredibly proud of, and it&#x27;s open source, so you can go check it out,&quot; Embiricos said. The sandbox &quot;basically ensures that when the agent is working on your computer, it can only make writes in a specific folder that you want it to make rights into, and it doesn&#x27;t access network without information.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The system also includes a granular permission model that allows users to configure persistent approvals for specific actions, avoiding the need to repeatedly authorize routine operations. &quot;If the agent wants to do something and you find yourself annoyed that you&#x27;re constantly having to approve it, instead of just saying, &#x27;All right, you can do everything,&#x27; you can just say, &#x27;Hey, remember this one thing — I&#x27;m actually okay with you doing this going forward,&#x27;&quot; Embiricos explained.
 &lt;/p&gt;
 &lt;p&gt;
  Altman emphasized that the permission architecture signals a broader philosophy about AI safety in agentic systems.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;I think this is going to be really important. I mean, it&#x27;s been so clear to us using this, how much you want it to have control of your computer, and how much you need it,&quot; Altman said. &quot;And the way the team built Codex such that you can sensibly limit what&#x27;s happening and also pick the level of control you&#x27;re comfortable with is important.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  He also acknowledged the dual-use nature of the technology. &quot;We do expect to get to our internal cybersecurity high moment of our models very soon. We&#x27;ve been preparing for this. We&#x27;ve talked about our mitigation plan,&quot; Altman said. &quot;A real thing for the world to contend with is going to be defending against a lot of capable cybersecurity threats using these models very quickly.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The same capabilities that make Codex valuable for fixing bugs and refactoring code could, in the wrong hands, be used to discover vulnerabilities or write malicious software—a tension that will only intensify as AI coding agents become more capable.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   From Android apps to research breakthroughs: how Codex transformed OpenAI&#x27;s own operations
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Perhaps the most compelling evidence for Codex&#x27;s capabilities comes from OpenAI&#x27;s own use of the tool. Sottiaux described how the system has accelerated internal development.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;A
  &lt;a href=&quot;https://play.google.com/store/apps/details?id=com.openai.sora&amp;hl=en_US&quot;&gt;
   Sora Android app
  &lt;/a&gt;
  is an example of that where four engineers shipped in only 18 days internally, and then within the month we give access to the world,&quot; Sottiaux said. &quot;I had never noticed such speed at this scale before.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Beyond product development, Sottiaux described how Codex has become integral to OpenAI&#x27;s research operations.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Codex is really involved in all parts of the research — making new data sets, investigating its own screening runs,&quot; he said. &quot;When I sit in meetings with researchers, they all send Codex off to do an investigation while we&#x27;re having a chat, and then it will come back with useful information, and we&#x27;re able to debug much faster.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The tool has also begun contributing to its own development. &quot;Codex also is starting to build itself,&quot; Sottiaux noted. &quot;There&#x27;s no screen within the Codex engineering team that doesn&#x27;t have Codex running on multiple, six, eight, ten, tasks at a time.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  When asked whether this constitutes evidence of &quot;recursive self-improvement&quot; — a concept that has long concerned AI safety researchers — Sottiaux was measured in his response.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;There is a human in the loop at all times,&quot; he said. &quot;I wouldn&#x27;t necessarily call it recursive self-improvement, a glimpse into the future there.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Altman offered a more expansive view of the research implications.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;There&#x27;s two parts of what people talk about when they talk about automating research to a degree where you can imagine that happening,&quot; Altman said. &quot;One is, can you write software, extremely complex infrastructure, software to run training jobs across hundreds of thousands of GPUs and babysit them. And the second is, can you come up with the new scientific ideas that make algorithms more efficient.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  He noted that OpenAI is &quot;seeing early but promising signs on both of those.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   The end of technical debt? AI agents take on the work engineers hate most
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  One of the more unexpected applications of Codex has been addressing technical debt — the accumulated maintenance burden that plagues most software projects.
 &lt;/p&gt;
 &lt;p&gt;
  Altman described how AI coding agents excel at the unglamorous work that human engineers typically avoid.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;The kind of work that human engineers hate to do — go refactor this, clean up this code base, rewrite this, write this test — this is where the model doesn&#x27;t care. The model will do anything, whether it&#x27;s fun or not,&quot; Altman said.
 &lt;/p&gt;
 &lt;p&gt;
  He reported that some infrastructure teams at OpenAI that &quot;had sort of like, given up hope that you were ever really going to long term win the war against tech debt, are now like, we&#x27;re going to win this, because the model is going to constantly be working behind us, making sure we have great test coverage, making sure that we refactor when we&#x27;re supposed to.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The observation speaks to a broader theme that emerged repeatedly during the briefing: AI coding agents don&#x27;t experience the motivational fluctuations that affect human programmers. As Altman noted, a team member recently observed that &quot;the hardest mental adjustment to make about working with these sort of like aI coding teammates, unlike a human, is the models just don&#x27;t run out of dopamine. They keep trying. They don&#x27;t run out of motivation. They don&#x27;t get, you know, they don&#x27;t lose energy when something&#x27;s not working. They just keep going and, you know, they figure out how to get it done.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   What the Codex app costs and who can use it starting today
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The
  &lt;a href=&quot;https://openai.com/index/introducing-the-codex-app/&quot;&gt;
   Codex app
  &lt;/a&gt;
  launches today on macOS and is available to anyone with a
  &lt;a href=&quot;https://chatgpt.com/pricing&quot;&gt;
   ChatGPT Plus,
  &lt;/a&gt;
  Pro, Business, Enterprise, or Edu subscription. Usage is included in ChatGPT subscriptions, with the option to purchase additional credits if needed.
 &lt;/p&gt;
 &lt;p&gt;
  In a promotional push, OpenAI is temporarily making
  &lt;a href=&quot;https://chatgpt.com/&quot;&gt;
   Codex available to ChatGPT Free
  &lt;/a&gt;
  and Go users &quot;to help more people try agentic workflows.&quot; The company is also doubling rate limits for existing Codex users across all paid plans during this promotional period.
 &lt;/p&gt;
 &lt;p&gt;
  The pricing strategy reflects OpenAI&#x27;s determination to establish Codex as the default tool for AI-assisted development before competitors can gain further traction. More than a million developers have used Codex in the past month, and usage has nearly doubled since the launch of
  &lt;a href=&quot;https://openai.com/index/introducing-gpt-5-2-codex/&quot;&gt;
   GPT-5.2-Codex
  &lt;/a&gt;
  in mid-December, building on more than 20x usage growth since August 2025.
 &lt;/p&gt;
 &lt;p&gt;
  Customers using Codex include large enterprises like Cisco, Ramp, Virgin Atlantic, Vanta, Duolingo, and Gap, as well as startups like Harvey, Sierra, and Wonderful. Individual developers have also embraced the tool:
  &lt;a href=&quot;https://x.com/steipete&quot;&gt;
   Peter Steinberger
  &lt;/a&gt;
  , creator of OpenClaw, built the project entirely with Codex and reports that since fully switching to the tool, his productivity has roughly doubled across more than 82,000 GitHub contributions.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   OpenAI&#x27;s ambitious roadmap: Windows support, cloud triggers, and continuous background agents
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  OpenAI outlined an aggressive development roadmap for Codex. The company plans to make the app available on Windows, continue pushing &quot;the frontier of model capabilities,&quot; and roll out faster inference.
 &lt;/p&gt;
 &lt;p&gt;
  Within the app, OpenAI will &quot;keep refining multi-agent workflows based on real-world feedback&quot; and is &quot;building out Automations with support for cloud-based triggers, so Codex can run continuously in the background—not just when your computer is open.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The company also announced a new &quot;plan mode&quot; feature that allows Codex to read through complex changes in read-only mode, then discuss with the user before executing. &quot;This means that it lets you build a lot of confidence before, again, sending it to do a lot of work by itself, independently, in parallel to you,&quot; Embiricos explained.
 &lt;/p&gt;
 &lt;p&gt;
  Additionally, OpenAI is introducing customizable personalities for Codex. &quot;The default personality for Codex has been quite terse. A lot of people love it, but some people want something more engaging,&quot; Embiricos said. Users can access the new personalities using the /personality command.
 &lt;/p&gt;
 &lt;p&gt;
  Altman also hinted at future integration with ChatGPT&#x27;s broader ecosystem.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;There will be all kinds of cool things we can do over time to connect people&#x27;s ChatGPT accounts and leverage sort of all the history they&#x27;ve built up there,&quot; Altman said.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Microsoft still dominates enterprise AI, but the window for disruption is open
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The
  &lt;a href=&quot;https://openai.com/index/introducing-the-codex-app/&quot;&gt;
   Codex app launch
  &lt;/a&gt;
  occurs as most enterprises have moved beyond single-vendor strategies. According to the Andreessen Horowitz survey, &quot;81% now use t
  &lt;a href=&quot;https://www.a16z.news/p/leaders-gainers-and-unexpected-winners?utm_source=substack&amp;publication_id=13145&amp;post_id=186310607&amp;utm_medium=email&amp;utm_content=share&amp;utm_campaign=email-share&amp;triggerShare=true&amp;isFreemail=true&amp;r=sr4e&amp;triedRedirect=true&quot;&gt;
   hree or more model families
  &lt;/a&gt;
  in testing or production, up from 68% less than a year ago.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Despite the proliferation of AI coding tools, Microsoft continues to dominate enterprise adoption through its existing relationships. &quot;Microsoft 365 Copilot leads enterprise chat though ChatGPT has closed the gap meaningfully,&quot; and &quot;Github Copilot is still the coding leader for enterprises.&quot; The survey found that &quot;65% of enterprises noted they preferred to go with incumbent solutions when available,&quot; citing trust, integration, and procurement simplicity.
 &lt;/p&gt;
 &lt;p&gt;
  However, the survey also suggests significant opportunity for challengers: &quot;Enterprises consistently say they value faster innovation, deeper AI focus, and greater flexibility paired with cutting edge capabilities that AI native startups bring.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  OpenAI appears to be positioning
  &lt;a href=&quot;https://openai.com/codex/&quot;&gt;
   Codex
  &lt;/a&gt;
  as a bridge between these worlds. &quot;Codex is built on a simple premise: everything is controlled by code,&quot; the company stated. &quot;The better an agent is at reasoning about and producing code, the more capable it becomes across all forms of technical and knowledge work.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The company&#x27;s ambition extends beyond coding. &quot;We&#x27;ve focused on making Codex the best coding agent, which has also laid the foundation for it to become a strong agent for a broad range of knowledge work tasks that extend beyond writing code.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  When asked whether AI coding tools could eventually move beyond early adopters to become mainstream, Altman suggested the transition may be closer than many expect.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Can it go from vibe coding to serious software engineering? That&#x27;s what this is about,&quot; Altman said. &quot;I think we are over the bar on that. I think this will be the way that most serious coders do their job — and very rapidly from now.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  He then pivoted to an even bolder prediction: that code itself could become the universal interface for all computer-based work.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Code is a universal language to get computers to do what you want. And it&#x27;s gotten so good that I think, very quickly, we can go not just from vibe coding silly apps but to doing all the non-coding knowledge work,&quot; Altman said.
 &lt;/p&gt;
 &lt;p&gt;
  At the close of the briefing, Altman urged journalists to try the product themselves: &quot;Please try the app. There&#x27;s no way to get this across just by talking about it. It&#x27;s a crazy amount of power.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  For developers who have spent careers learning to write code, the message was clear: the future belongs to those who learn to manage the machines that write it for them.
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Most RAG systems don’t understand sophisticated documents — they shred them </title>
<link>https://venturebeat.com/orchestration/most-rag-systems-dont-understand-documents-they-shred-them</link>
<pubDate>Mon, 02 Feb 2026 01:32:17 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;RAG shredding&quot; data-nimg=&quot;1&quot; height=&quot;816&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/2sCMvgGQUuWWF7q1vVEYrC/a759e1f38b9003e746fdaf62c5b65bf8/u7277289442_3D_art_of_AI_avatars_in_an_office_ripping_up_pile_d5f30bcd-f95a-4531-b03a-dad2644cdfb3_3.png?w=1000&quot; width=&quot;1456&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
    &lt;p&gt;
     CleoP made with Midjourney
    &lt;/p&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  By now, many enterprises have deployed some form of RAG. The promise is seductive: index your PDFs, connect an LLM and instantly democratize your corporate knowledge.
 &lt;/p&gt;
 &lt;p&gt;
  But for industries dependent on heavy engineering, the reality has been underwhelming. Engineers ask specific questions about infrastructure, and the bot hallucinates.
 &lt;/p&gt;
 &lt;div&gt;
  &lt;div data-exs-config=&#x27;{&quot;customParams&quot;:{&quot;post-type&quot;:&quot;article&quot;,&quot;post_id&quot;:&quot;270xuWmOsgpUQcPtNa8C0f&quot;,&quot;post_cat&quot;:&quot;orchestration&quot;}}&#x27;&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  The failure
  &lt;a href=&quot;https://venturebeat.com/orchestration/why-your-llm-bill-is-exploding-and-how-semantic-caching-can-cut-it-by-73&quot;&gt;
   isn&#x27;t in the LLM
  &lt;/a&gt;
  . The failure is in the preprocessing.
 &lt;/p&gt;
 &lt;p&gt;
  Standard RAG pipelines treat documents as flat strings of text. They use &quot;fixed-size chunking&quot; (cutting a document every 500 characters). This works for prose, but it destroys the logic of technical manuals. It slices tables in half, severs captions from images, and ignores the visual hierarchy of the page.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  I
  &lt;!-- --&gt;
  mproving RAG reliability isn&#x27;t about buying a bigger model; it&#x27;s about fixing the &quot;dark data&quot; problem through semantic chunking and multimodal textualization.
 &lt;/p&gt;
 &lt;p&gt;
  Here is the architectural framework for building a RAG system that can actually read a manual.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   The fallacy of fixed-size chunking
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  In a standard Python RAG tutorial, you split text by character count. In an enterprise PDF, this is disastrous.
 &lt;/p&gt;
 &lt;p&gt;
  If a safety specification table spans 1,000 tokens, and your chunk size is 500, you have just split the &quot;voltage limit&quot; header from the &quot;240V&quot; value. The
  &lt;a href=&quot;https://venturebeat.com/infrastructure/from-shiny-object-to-sober-reality-the-vector-database-story-two-years-later&quot;&gt;
   vector database
  &lt;/a&gt;
  stores them separately. When a user asks, &quot;What is the voltage limit?&quot;, the retrieval system finds the header but not the value. The LLM, forced to answer, often guesses.
 &lt;/p&gt;
 &lt;h3&gt;
  &lt;b&gt;
   The solution: Semantic chunking
  &lt;/b&gt;
 &lt;/h3&gt;
 &lt;p&gt;
  The first step to fixing production RAG is abandoning arbitrary character counts in favor of document intelligence.
 &lt;/p&gt;
 &lt;p&gt;
  Using layout-aware parsing tools (such as Azure Document Intelligence), we can segment data based on document structure such as chapters, sections and paragraphs, rather than token count.
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Logical cohesion:
    &lt;/b&gt;
    A section describing a specific machine part is kept as a single vector, even if it varies in length.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Table preservation:
    &lt;/b&gt;
    The parser identifies a table boundary and forces the entire grid into a single chunk, preserving the row-column relationships that are vital for accurate retrieval.
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;p&gt;
  In our internal qualitative benchmarks, moving from fixed to semantic chunking significantly improved the retrieval accuracy of tabular data, effectively stopping the fragmentation of technical specs.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Unlocking visual dark data
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The second failure mode of enterprise RAG is blindness. A massive amount of corporate IP exists not in text, but in flowcharts, schematics and system architecture diagrams. Standard embedding models (like text-embedding-3-small) cannot &quot;see&quot; these images. They are skipped during indexing.
 &lt;/p&gt;
 &lt;p&gt;
  If your answer lies in a flowchart, your RAG system will say, &quot;I don&#x27;t know.&quot;
 &lt;/p&gt;
 &lt;h3&gt;
  &lt;b&gt;
   The solution: Multimodal textualization
  &lt;/b&gt;
 &lt;/h3&gt;
 &lt;p&gt;
  To make diagrams searchable, we implemented a multimodal preprocessing step using vision-capable models (specifically GPT-4o) before the data ever hits the vector store.
 &lt;/p&gt;
 &lt;ol&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     OCR extraction:
    &lt;/b&gt;
    High-precision optical character recognition pulls text labels from within the image.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Generative captioning:
    &lt;/b&gt;
    The vision model analyzes the image and generates a detailed natural language description (&quot;A flowchart showing that process A leads to process B if the temperature exceeds 50 degrees&quot;).
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Hybrid embedding:
    &lt;/b&gt;
    This generated description is embedded and stored as metadata linked to the original image.
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ol&gt;
 &lt;p&gt;
  Now, when a user searches for &quot;temperature process flow,&quot; the vector search matches the
  &lt;i&gt;
   description
  &lt;/i&gt;
  , even though the original source was a PNG file.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   The trust layer: Evidence-based UI
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  For enterprise adoption, accuracy is only half the battle. The other half is
  &lt;b&gt;
   verifiability
  &lt;/b&gt;
  .
 &lt;/p&gt;
 &lt;p&gt;
  In a standard RAG interface, the chatbot gives a text answer and cites a filename. This forces the user to download the PDF and hunt for the page to verify the claim. For high-stakes queries (&quot;Is this chemical flammable?&quot;), users simply won&#x27;t trust the bot.
 &lt;/p&gt;
 &lt;p&gt;
  The
  &lt;!-- --&gt;
  architecture should implement visual citation. Because we preserved the link between the text chunk and its parent image during the preprocessing phase, the UI can display the exact chart or table used to generate the answer alongside the text response.
 &lt;/p&gt;
 &lt;p&gt;
  This &quot;show your work&quot; mechanism allows humans to verify the AI&#x27;s reasoning instantly, bridging the trust gap that kills so many
  &lt;a href=&quot;https://venturebeat.com/orchestration/why-reinforcement-learning-plateaus-without-representation-depth-and-other&quot;&gt;
   internal AI projects
  &lt;/a&gt;
  .
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Future-proofing: Native multimodal embeddings
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  While the &quot;textualization&quot; method (converting images to text descriptions) is the practical solution for today, the architecture is rapidly evolving.
 &lt;/p&gt;
 &lt;p&gt;
  We are already seeing the emergence of
  &lt;b&gt;
   native multimodal embeddings
  &lt;/b&gt;
  (such as Cohere’s Embed 4). These models can map text and images into the same vector space without the intermediate step of captioning. While we currently use a multi-stage pipeline for maximum control, the future of data infrastructure will likely involve &quot;end-to-end&quot; vectorization where the layout of a page is embedded directly.
 &lt;/p&gt;
 &lt;p&gt;
  Furthermore, as
  &lt;b&gt;
   long context LLMs
  &lt;/b&gt;
  become cost-effective, the need for chunking may diminish. We may soon pass entire manuals into the context window. However, until latency and cost for million-token calls drop significantly, semantic preprocessing remains the most economically viable strategy for real-time systems.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Conclusion
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The difference between a RAG demo and a production system is how it handles the messy reality of enterprise data.
 &lt;/p&gt;
 &lt;p&gt;
  Stop treating your documents as simple strings of text. If you want your AI to understand your business, you must respect the structure of your documents. By implementing semantic chunking and unlocking the visual data within your charts, you transform your RAG system from a &quot;keyword searcher&quot; into a true &quot;knowledge assistant.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  &lt;i&gt;
   Dippu Kumar Singh is an AI architect and data engineer.
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;br/&gt;
 &lt;br/&gt;
 &lt;p&gt;
  Welcome to the VentureBeat community!
 &lt;/p&gt;
 &lt;p&gt;
  Our guest posting program is where technical experts share insights and provide neutral, non-vested deep dives on AI, data infrastructure, cybersecurity and other cutting-edge technologies shaping the future of enterprise.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;a href=&quot;/category/DataDecisionMakers&quot;&gt;
   Read more
  &lt;/a&gt;
  &lt;!-- --&gt;
  from our guest post program — and check out our
  &lt;!-- --&gt;
  &lt;a href=&quot;/guest-posts&quot;&gt;
   guidelines
  &lt;/a&gt;
  &lt;!-- --&gt;
  if you’re interested in contributing an article of your own!
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> How Moonshot&#x27;s Kimi K2.5 helps AI builders spin up agent swarms easier than ever </title>
<link>https://venturebeat.com/orchestration/moonshot-ai-debuts-kimi-k2-5-most-powerful-open-source-llm-beating-opus-4-5</link>
<pubDate>Thu, 29 Jan 2026 22:17:47 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;Pop art neon pink black backdrop of vintage PC monitor with swarm of bees flying out&quot; data-nimg=&quot;1&quot; height=&quot;1632&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/2iLBE9v5t6ejW8f0hnUwvC/c66e705f844eeb77e5ad5e4d4da8e775/Carl_Franzen_gradient_geometric_mod_1960s_vintage_retro_saul_ba_b2455727-7fcd-4130-9e74-681903b5456b.png?w=1000&quot; width=&quot;2912&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
    &lt;p&gt;
     Credit: VentureBeat made with Midjourney
    &lt;/p&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  Chinese company Moonshot AI upgraded its
  &lt;a href=&quot;https://venturebeat.com/ai/moonshot-ais-kimi-k2-outperforms-gpt-4-in-key-benchmarks-and-its-free&quot;&gt;
   open-sourced Kimi K2 model
  &lt;/a&gt;
  , transforming it into a coding and vision model with an architecture that supports an agent swarm orchestration.
 &lt;/p&gt;
 &lt;p&gt;
  The new model, Moonshot Kimi K2.5, is a good option for enterprises that want agents that can automatically pass off actions instead of having a framework be a central decision-maker.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  The company characterized Kimi K2.5 as an “all-in-one model” that supports both visual and text inputs, letting users leverage the model for more visual coding projects.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  Moonshot did not publicly disclose K2.5’s parameter count, but the Kimi K2 model that it&#x27;s based on, had 1 trillion total parameters and 32 billion activated parameters thanks to its mixture-of-experts architecture.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  This is the latest open-source model to offer an alternative to the more closed options from Google, OpenAI, and Anthropic, and it outperforms them on key metrics including agentic workflows, coding, and vision.
 &lt;/p&gt;
 &lt;p&gt;
  On the
  &lt;b&gt;
   Humanity’s Last Exam (HLE)
  &lt;/b&gt;
  benchmark, Kimi K2.5 scored
  &lt;b&gt;
   50.2%
  &lt;/b&gt;
  (with tools), surpassing OpenAI’s GPT-5.2 (xhigh) and Claude Opus 4.5. It also achieved
  &lt;b&gt;
   76.8%
  &lt;/b&gt;
  on
  &lt;b&gt;
   SWE-bench Verified
  &lt;/b&gt;
  , cementing its status as a top-tier coding model, though GPT-5.2 and Opus 4.5 overtake it here at 80 and 80.9, respectively.
 &lt;/p&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;Kimi K2.5 Thinking benchmark comparison chart. Credit: Moonshot AI&quot; data-nimg=&quot;1&quot; height=&quot;629&quot; loading=&quot;lazy&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/J5kJGSinSJIh4brPXOYnO/161f377412b9697f76c87adb2c8213f0/Screenshot_2026-01-27_at_10.54.31â__AM.png?w=1000&quot; width=&quot;1008&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
    &lt;p&gt;
     Kimi K2.5 Thinking benchmark comparison chart. Credit: Moonshot AI
    &lt;/p&gt;
   &lt;/figcaption&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  Moonshot said in a press release that it&#x27;s seen a 170% increase in users between September and November for Kimi K2 and
  &lt;a href=&quot;https://venturebeat.com/ai/moonshots-kimi-k2-thinking-emerges-as-leading-open-source-ai-outperforming&quot;&gt;
   Kimi K2 Thinking
  &lt;/a&gt;
  , which was released in early November.
 &lt;/p&gt;
 &lt;h2&gt;
  Agent swarm and built-in orchestration
 &lt;/h2&gt;
 &lt;p&gt;
  Moonshot aims to leverage self-directed agents and the agent swarm paradigm built into Kimi K2.5. Agent swarm has been touted as the
  &lt;a href=&quot;https://venturebeat.com/ai/vibe-coding-is-dead-agentic-swarm-coding-is-the-new-enterprise-moat&quot;&gt;
   next frontier in enterprise AI development
  &lt;/a&gt;
  and agent-based systems. It has attracted significant attention in the past few months.
 &lt;/p&gt;
 &lt;p&gt;
  For enterprises, this means that if they build agent ecosystems with Kimi K2.5, they can expect to scale more efficiently. But instead of scaling “up” or growing model sizes to create larger agents, it’s betting on making more agents that can essentially orchestrate themselves.
 &lt;/p&gt;
 &lt;p&gt;
  Kimi K2.5 “creates and coordinates a swarm of specialized agents working in parallel.” The company compared it to a beehive where each agent performs a task while contributing to a common goal. The model learns to self-direct up to 100 sub-agents and can execute parallel workflows of up to 1,500 tool calls.
 &lt;/p&gt;
 &lt;p&gt;
  “Benchmarks only tell half the story. Moonshot AI believes AGI should ultimately be evaluated by its ability to complete real-world tasks efficiently under real-world time constraints. The real metric they care about is: how much of your day did AI actually give back to you? Running in parallel substantially reduces the time needed for a complex task — tasks that required days of work now can be accomplished in minutes,” the company said.
 &lt;/p&gt;
 &lt;p&gt;
  Enterprises considering their orchestration strategies have begun looking at agentic platforms where agents communicate and pass off tasks, rather than following a rigid orchestration framework that dictates when an action is completed.
 &lt;/p&gt;
 &lt;p&gt;
  While Kimi K2.5 may offer a compelling option for organizations that want to use this form of orchestration, some may feel more comfortable avoiding
  &lt;a href=&quot;https://venturebeat.com/orchestration/ai-agents-can-talk-orchestration-is-what-makes-them-work-together&quot;&gt;
   agent-based orchestration
  &lt;/a&gt;
  baked into the model and instead using a different platform to differentiate the model training from the agentic task.
 &lt;/p&gt;
 &lt;p&gt;
  This is because enterprises often want more flexibility in which models make up their agents, so they can build an ecosystem of agents that tap LLMs that work best for specific actions.
 &lt;/p&gt;
 &lt;p&gt;
  Some agent platforms, such as Salesforce, AWS Bedrock, and IBM, offer separate observability, management, and monitoring tools that help users orchestrate AI agents built with different models and enable them to work together.
 &lt;/p&gt;
 &lt;h2&gt;
  Multimodal coding and visual debugging
 &lt;/h2&gt;
 &lt;p&gt;
  The model lets users code visual layouts, including user interfaces and interactions. It reasons over images and videos to understand tasks encoded in visual inputs. For example, K2.5 can reconstruct a website’s code simply by analyzing a video recording of the site in action, translating visual cues into interactive layouts and animations.
 &lt;/p&gt;
 &lt;p&gt;
  “Interfaces, layouts, and interactions that are difficult to describe precisely in language can be communicated through screenshots or screen recordings, which the model can interpret and turn into fully functional websites. This enables a new class of vibe coding experiences,” Moonshot said.
 &lt;/p&gt;
 &lt;p&gt;
  This capability is integrated into Kimi Code, a new terminal-based tool that works with IDEs like VSCode and Cursor.
 &lt;/p&gt;
 &lt;p&gt;
  It supports &quot;autonomous visual debugging,&quot; where the model visually inspects its own output — such as a rendered web page — references documentation, and iterates on the code to fix layout shifts or aesthetic errors without human intervention.
 &lt;/p&gt;
 &lt;p&gt;
  Unlike other multimodal models that can create and understand images, Kimi K2.5 can build frontend interactions for websites with visuals, not just the code behind them.
 &lt;/p&gt;
 &lt;h2&gt;
  API pricing
 &lt;/h2&gt;
 &lt;p&gt;
  Moonshot AI has aggressively priced the K2.5 API to compete with major U.S. labs, offering significant reductions compared to its previous K2 Turbo model.
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Input:
    &lt;/b&gt;
    60 cents per million tokens (a
    &lt;b&gt;
     47.8%
    &lt;/b&gt;
    decrease).
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Cached Input:
    &lt;/b&gt;
    10 cents per million tokens (a
    &lt;b&gt;
     33.3%
    &lt;/b&gt;
    decrease).
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Output:
    &lt;/b&gt;
    $3 per million tokens (a
    &lt;b&gt;
     62.5%
    &lt;/b&gt;
    decrease).
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;p&gt;
  The low cost of cached inputs ($0.10/M tokens) is particularly relevant for the &quot;Agent Swarm&quot; features, which often require maintaining large context windows across multiple sub-agents and extensive tool usage.
 &lt;/p&gt;
 &lt;h2&gt;
  Modified MIT license
 &lt;/h2&gt;
 &lt;p&gt;
  While Kimi K2.5 is open-sourced, it is released under a Modified MIT License that includes a specific clause targeting &quot;hyperscale&quot; commercial users.
 &lt;/p&gt;
 &lt;p&gt;
  The license grants standard permissions to use, copy, modify, and sell the software.
 &lt;/p&gt;
 &lt;p&gt;
  However, it stipulates that if the software or any derivative work is used for a commercial product or service that has more than 100 million monthly active users (MAU) or more than $20 million USD in monthly revenue, the entity must prominently display &quot;Kimi K2.5&quot; on the user interface.
 &lt;/p&gt;
 &lt;p&gt;
  This clause ensures that while the model remains free and open for the vast majority of the developer community and startups, major tech giants cannot white-label Moonshot’s technology without providing visible attribution.
 &lt;/p&gt;
 &lt;p&gt;
  It&#x27;s not full &quot;open source&quot; but it is better than Meta&#x27;s similar
  &lt;a href=&quot;https://ai.meta.com/llama/license/&quot;&gt;
   Llama Licensing terms
  &lt;/a&gt;
  for its &quot;open source&quot; family of models, which required those companies with 700 million or more monthly users to obtain a special enterprise license from the company.
 &lt;/p&gt;
 &lt;h2&gt;
  What it means for modern enterprise AI builders
 &lt;/h2&gt;
 &lt;p&gt;
  For the practitioners defining the modern AI stack — from LLM decision-makers optimizing deployment cycles to AI orchestration leaders setting up agents and AI-powered automated business processes — Kimi K2.5 represents a fundamental shift in leverage.
 &lt;/p&gt;
 &lt;p&gt;
  By embedding swarm orchestration directly into the model, Moonshot AI effectively hands these resource-constrained builders a synthetic workforce, allowing a single engineer to direct a hundred autonomous sub-agents as easily as a single prompt.
 &lt;/p&gt;
 &lt;p&gt;
  This &quot;scale-out&quot; architecture directly addresses data decision-makers&#x27; dilemma of balancing complex pipelines with limited headcount, while the slashed pricing structure transforms high-context data processing from a budget-breaking luxury into a routine commodity.
 &lt;/p&gt;
 &lt;p&gt;
  Ultimately, K2.5 suggests a future where the primary constraint on an engineering team is no longer the number of hands on keyboards, but the ability of its leaders to choreograph a swarm.
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Anthropic embeds Slack, Figma and Asana inside Claude, turning AI chat into a workplace command center </title>
<link>https://venturebeat.com/infrastructure/anthropic-embeds-slack-figma-and-asana-inside-claude-turning-ai-chat-into-a</link>
<pubDate>Mon, 26 Jan 2026 21:40:21 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;nuneybits Vector art of a glowing burnt orange orb at center wi 838c3333-89a8-4df4-b2bd-8d6a829836b2&quot; data-nimg=&quot;1&quot; height=&quot;536&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/1p8ftZpSuS4Melgo35eWGo/c8a0c84c233a5c28bf4e49321e2602e0/nuneybits_Vector_art_of_a_glowing_burnt_orange_orb_at_center_wi_838c3333-89a8-4df4-b2bd-8d6a829836b2.webp?w=1000&quot; width=&quot;957&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
    &lt;p&gt;
     Credit: VentureBeat made with Midjourney
    &lt;/p&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://www.anthropic.com/&quot;&gt;
   &lt;u&gt;
    Anthropic
   &lt;/u&gt;
  &lt;/a&gt;
  announced Monday that users can now open and interact with popular business applications directly inside
  &lt;a href=&quot;https://claude.ai/&quot;&gt;
   &lt;u&gt;
    Claude
   &lt;/u&gt;
  &lt;/a&gt;
  , the company&#x27;s AI assistant—a significant expansion that transforms the chatbot from a conversational tool into an integrated workspace where employees can build project timelines, draft Slack messages, create presentations, and visualize data without switching browser tabs.
 &lt;/p&gt;
 &lt;p&gt;
  The rollout, which goes live today, includes integrations with
  &lt;a href=&quot;https://amplitude.com/&quot;&gt;
   &lt;u&gt;
    Amplitude
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://asana.com/&quot;&gt;
   &lt;u&gt;
    Asana
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.box.com/home&quot;&gt;
   &lt;u&gt;
    Box
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.canva.com/&quot;&gt;
   &lt;u&gt;
    Canva
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.clay.com/&quot;&gt;
   &lt;u&gt;
    Clay
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.figma.com/&quot;&gt;
   &lt;u&gt;
    Figma
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://hex.tech/&quot;&gt;
   &lt;u&gt;
    Hex
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;http://monday.com&quot;&gt;
   &lt;u&gt;
    Monday.com
   &lt;/u&gt;
  &lt;/a&gt;
  , and
  &lt;a href=&quot;https://slack.com/&quot;&gt;
   &lt;u&gt;
    Slack
   &lt;/u&gt;
  &lt;/a&gt;
  . Salesforce integration is coming soon. The feature marks a new chapter in Anthropic&#x27;s aggressive push to dominate enterprise AI, arriving just days after the company&#x27;s CEO made headlines at Davos with bold predictions about AI replacing white-collar workers.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;MCP Apps are an extension to the core MCP protocol and are part of the open source MCP ecosystem,&quot; Sean Strong, Anthropic&#x27;s product manager for MCP Apps, told VentureBeat in an exclusive interview. &quot;Within Claude.ai, connectors require a paid Claude plan — Pro, Max, Team, or Enterprise — but there is no additional charge associated with using connectors.&quot;
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  That pricing decision is notable. Rather than monetizing integrations separately or charging partners for distribution, Anthropic is bundling interactive tools into existing subscription tiers — a strategy designed to accelerate adoption and deepen Claude&#x27;s foothold in corporate environments where the company reportedly already leads OpenAI.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Inside MCP Apps, the open-source technology that lets Claude control your favorite work tools
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The technical foundation is what Anthropic calls &quot;
  &lt;a href=&quot;https://blog.modelcontextprotocol.io/posts/2025-11-21-mcp-apps/&quot;&gt;
   &lt;u&gt;
    MCP Apps
   &lt;/u&gt;
  &lt;/a&gt;
  ,&quot; a new extension to the Model Context Protocol, the open standard for connecting external tools to AI applications that Anthropic open-sourced last year.
  &lt;a href=&quot;https://blog.modelcontextprotocol.io/posts/2025-11-21-mcp-apps/&quot;&gt;
   &lt;u&gt;
    MCP Apps
   &lt;/u&gt;
  &lt;/a&gt;
  allow any MCP server to deliver an interactive user interface within any supporting AI product—meaning the technology isn&#x27;t limited to Claude.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  In practice, the integrations allow for surprisingly granular control. Users can build analytics charts in
  &lt;a href=&quot;https://amplitude.com/&quot;&gt;
   &lt;u&gt;
    Amplitude
   &lt;/u&gt;
  &lt;/a&gt;
  and adjust parameters interactively to explore trends. They can turn conversations into Asana projects with tasks and timelines that sync automatically. They can prompt Claude to generate flowcharts or Gantt charts in Figma&#x27;s collaborative whiteboard tool, FigJam. They can draft Slack messages, preview formatting, and review before posting.
 &lt;/p&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;MCP Apps - Hex&quot; data-nimg=&quot;1&quot; height=&quot;1080&quot; loading=&quot;lazy&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/e0iKQqr7xppoWqsh645fx/d0a95c6869c938f741e07bc7a0c9e4ee/MCP_Apps_-_Hex.png?w=1000&quot; width=&quot;1920&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
    &lt;p&gt;
     Claude&#x27;s integration with Hex transforms a natural-language question into an interactive chart showing monthly customer acquisition by segment. (Credit: Anthropic)
    &lt;/p&gt;
   &lt;/figcaption&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  The
  &lt;a href=&quot;https://hex.tech/&quot;&gt;
   Hex
  &lt;/a&gt;
  integration may prove particularly valuable for data teams: users can ask data questions in natural language and receive answers complete with interactive charts, tables, and citations — effectively turning Claude into a business intelligence interface.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;We open sourced MCP to give the ecosystem a universal way to connect tools to AI,&quot; the company said in its announcement blog. &quot;Now we&#x27;re extending MCP further so developers can build interactive UI on top of it, wherever their users are.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   What happens when AI can send messages and create projects on your behalf
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  With AI systems increasingly capable of taking real-world actions — sending messages, creating projects, publishing content — the question of guardrails becomes critical. Can an employee accidentally send an unreviewed Slack message or publish an incomplete Canva presentation?
 &lt;/p&gt;
 &lt;p&gt;
  Strong addressed this directly. &quot;Most major MCP clients, including Claude, provide consent prompts that help users determine if they want to take an action via a MCP server,&quot; he said.
 &lt;/p&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;MCP Apps - Slack&quot; data-nimg=&quot;1&quot; height=&quot;1080&quot; loading=&quot;lazy&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/7hxtVintxY63SH2oA3XxFQ/ab9e57e2719999cfd86d5ac1434c763a/MCP_Apps_-_Slack.png?w=1000&quot; width=&quot;1920&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
    &lt;p&gt;
     Before sending, users can review and edit messages that Claude drafts for Slack channels. (Credit: Anthropic)
    &lt;/p&gt;
   &lt;/figcaption&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  For enterprise deployments, IT administrators retain control. &quot;Team and Enterprise admins have the ability to control which MCP servers users in their organizations have the ability to use,&quot; Strong explained.
 &lt;/p&gt;
 &lt;p&gt;
  The consent-prompt approach is a middle ground between full autonomy and cumbersome approval workflows. But it also places significant responsibility on individual users to review actions before confirming them — a design choice that may draw scrutiny as AI agents become capable of more consequential decisions.
 &lt;/p&gt;
 &lt;p&gt;
  The security concerns are not hypothetical. As
  &lt;a href=&quot;https://fortune.com/2026/01/24/anthropic-boris-cherny-claude-code-non-coders-software-engineers/&quot;&gt;
   Fortune reported last week
  &lt;/a&gt;
  , Anthropic&#x27;s Claude Code product faces vulnerabilities including &quot;prompt injections,&quot; where attackers hide malicious instructions in web content to manipulate AI behavior. The company has implemented multiple security layers, including running some features in virtual machines and adding deletion protection after users accidentally removed files. &quot;Agent safety—that is, the task of securing Claude&#x27;s real-world actions—is still an active area of development in the industry,&quot; Anthropic has acknowledged.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Claude Code&#x27;s viral success set the stage for Anthropic&#x27;s enterprise ambitions
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The interactive tools announcement arrives at a moment of unusual momentum for Anthropic.
  &lt;a href=&quot;https://claude.com/product/claude-code&quot;&gt;
   Claude Code
  &lt;/a&gt;
  , the company&#x27;s coding assistant released in February 2024, has become a viral hit that has captured attention far beyond its intended developer audience.
 &lt;/p&gt;
 &lt;p&gt;
  Originally built for software developers,
  &lt;a href=&quot;https://claude.com/product/claude-code&quot;&gt;
   Claude Code
  &lt;/a&gt;
  has captured attention far beyond its intended audience. Non-programmers have deployed it to book theater tickets, file taxes, and monitor tomato plants. Nvidia CEO Jensen Huang called it &quot;
  &lt;a href=&quot;https://finance.yahoo.com/news/nvidia-ceo-jensen-huang-calls-114616796.html&quot;&gt;
   incredible
  &lt;/a&gt;
  .&quot; Even Microsoft, which sells the competing GitHub Copilot, has widely adopted Claude Code internally, with non-developers reportedly encouraged to use it.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://x.com/bcherny&quot;&gt;
   Boris Cherny,
  &lt;/a&gt;
  Anthropic&#x27;s head of Claude Code, told Fortune that his team built Cowork — a user-friendly version of the coding product for non-programmers — in approximately a week and a half, largely using Claude Code itself. &quot;Engineers just feel unshackled, that they don&#x27;t have to work on all the tedious stuff anymore,&quot; Cherny said.
 &lt;/p&gt;
 &lt;p&gt;
  Claude Code is now used by
  &lt;a href=&quot;https://www.uber.com/&quot;&gt;
   Uber
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.netflix.com/&quot;&gt;
   Netflix
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://open.spotify.com/&quot;&gt;
   Spotify
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.salesforce.com/&quot;&gt;
   Salesforce
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.accenture.com/&quot;&gt;
   Accenture
  &lt;/a&gt;
  , and
  &lt;a href=&quot;https://www.snowflake.com/en/&quot;&gt;
   Snowflake
  &lt;/a&gt;
  , according to Anthropic. Claude&#x27;s total web audience has more than doubled since December 2024, and daily unique visitors on desktop are up 12% globally year-to-date, according to data from Similarweb and Sensor Tower published by
  &lt;a href=&quot;https://www.wsj.com/tech/ai/anthropic-claude-vibe-coding-experiment-a4a3bb0f&quot;&gt;
   The Wall Street Journal
  &lt;/a&gt;
  .
 &lt;/p&gt;
 &lt;p&gt;
  The company is also reportedly planning a $10 billion fundraising round that would value
  &lt;a href=&quot;https://www.cnbc.com/2026/01/07/anthropic-funding-term-sheet-valuation.html&quot;&gt;
   Anthropic at $350 billion
  &lt;/a&gt;
  — a staggering figure that reflects investor confidence in the company&#x27;s enterprise traction.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Anthropic&#x27;s CEO stirred controversy at Davos with predictions about AI replacing workers
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The interactive tools launch also arrives against a backdrop of intense debate about AI&#x27;s impact on employment — a debate that Anthropic&#x27;s own CEO helped intensify at the
  &lt;a href=&quot;https://www.weforum.org/meetings/world-economic-forum-annual-meeting-2026/sessions/the-day-after-agi/&quot;&gt;
   World Economic Forum
  &lt;/a&gt;
  in Davos last week.
 &lt;/p&gt;
 &lt;p&gt;
  Dario Amodei told a Davos audience that AI models would replace the work of all software developers within a year and would reach &quot;Nobel-level&quot; scientific research in multiple fields within two years. He predicted that 50% of white-collar jobs would disappear within five years.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;I have engineers within Anthropic who say &#x27;I don&#x27;t write any code anymore. I just let the model write the code, I edit it,&#x27;&quot; Amodei said. &quot;We might be six to 12 months away from when the model is doing most, maybe all of what software engineers do end-to-end.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Not everyone agrees with that timeline. Demis Hassabis, the Nobel Prize-winning CEO of Google DeepMind, said at the same conference that today&#x27;s AI systems are &quot;nowhere near&quot; human-level artificial general intelligence. Yann LeCun, the Turing Award-winning AI pioneer who recently left Meta to found Advanced Machine Intelligence Labs, went further, arguing that large language models &quot;will never be able to achieve humanlike intelligence&quot; and that a completely different approach is needed.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Why embedding AI into daily workflows could create powerful lock-in for enterprises
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Anthropic&#x27;s integration strategy reflects a broader shift in enterprise AI competition. The battleground is moving from model benchmarks and capability demonstrations toward workflow integration — the degree to which AI systems become embedded in how companies actually operate.
 &lt;/p&gt;
 &lt;p&gt;
  By making Claude the interface through which employees interact with
  &lt;a href=&quot;https://asana.com/&quot;&gt;
   Asana
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://slack.com/&quot;&gt;
   Slack
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.figma.com/&quot;&gt;
   Figma
  &lt;/a&gt;
  , and other daily tools, Anthropic is positioning itself not merely as an AI provider but as a workflow orchestration layer. The more actions that flow through Claude, the harder it becomes for enterprises to switch to a competitor.
 &lt;/p&gt;
 &lt;p&gt;
  This approach mirrors strategies that proved successful for earlier generations of enterprise software. Salesforce built its dominance partly by becoming the system of record for customer data. Slack grew by centralizing workplace communication. Anthropic appears to be betting that AI assistants can occupy a similar position — the default starting point for work itself.
 &lt;/p&gt;
 &lt;p&gt;
  The open-source foundation of MCP may accelerate this strategy. By making the protocol available to any developer, Anthropic encourages a broad ecosystem of integrations that all funnel through MCP-compatible clients — of which Claude is the most prominent. The company benefits from network effects even as it maintains the standard is open.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   The race to become the operating system for AI-powered work is just getting started
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The launch notably excludes some major enterprise platforms.
  &lt;a href=&quot;https://www.salesforce.com/&quot;&gt;
   Salesforce
  &lt;/a&gt;
  integration is listed as &quot;coming soon,&quot; and there&#x27;s no mention of
  &lt;a href=&quot;https://www.office.com/&quot;&gt;
   Microsoft 365
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://workspace.google.com/&quot;&gt;
   Google Workspace
  &lt;/a&gt;
  , or other productivity suites that dominate corporate environments. Those gaps may limit initial adoption in organizations heavily invested in those ecosystems.
 &lt;/p&gt;
 &lt;p&gt;
  The feature is available on web and desktop for paid Claude plans, with support for
  &lt;a href=&quot;https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no&quot;&gt;
   Claude Cowork
  &lt;/a&gt;
  — the file management agent launched last week — coming later. Mobile support was not mentioned in the announcement.
 &lt;/p&gt;
 &lt;p&gt;
  For enterprises evaluating Claude against OpenAI&#x27;s offerings and other competitors, the interactive integrations represent a tangible differentiator. The ability to take action within business tools — rather than simply generating text that users must copy elsewhere — addresses a persistent friction point in AI adoption.
 &lt;/p&gt;
 &lt;p&gt;
  Whether that advantage proves durable depends on how quickly competitors respond. OpenAI has its own enterprise ambitions and partnerships. Google is integrating Gemini across its productivity suite. Microsoft continues to deepen Copilot&#x27;s presence in Office applications.
 &lt;/p&gt;
 &lt;p&gt;
  But the larger significance may be what today&#x27;s announcement signals about where enterprise software is headed. For decades, the default unit of work has been the application — the spreadsheet, the project tracker, the messaging platform. Anthropic is wagering that the future belongs to the AI layer that sits above them all.
 &lt;/p&gt;
 &lt;p&gt;
  If the company is right, the question for every enterprise software vendor becomes uncomfortably simple: Do you want to be the tool, or the thing that controls the tools?
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Why your LLM bill is exploding — and how semantic caching can cut it by 73% </title>
<link>https://venturebeat.com/orchestration/why-your-llm-bill-is-exploding-and-how-semantic-caching-can-cut-it-by-73</link>
<pubDate>Sat, 17 Jan 2026 19:01:27 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;Semantic Caching&quot; data-nimg=&quot;1&quot; height=&quot;816&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/7iyQoeSwdOqqpfcE0PFWgF/48db7d0305019eee107028d9f018d2ac/Semantic_caching.png?w=1000&quot; width=&quot;1456&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
    &lt;p&gt;
     CleoP made with Midjourney
    &lt;/p&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  Our LLM API bill was growing 30% month-over-month. Traffic was increasing, but not that fast. When I analyzed our query logs, I found the real problem: Users ask the same questions in different ways.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;What&#x27;s your return policy?,&quot; &quot;How do I return something?&quot;, and &quot;Can I get a refund?&quot; were all hitting our LLM separately, generating nearly identical responses, each incurring full API costs.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  Exact-match caching, the obvious first solution, captured only 18% of these redundant calls. The same semantic question, phrased differently, bypassed the cache entirely.
 &lt;/p&gt;
 &lt;p&gt;
  So, I implemented semantic caching based on what queries mean, not how they&#x27;re worded. After implementing it, our cache hit rate increased to 67%, reducing LLM API costs by 73%. But getting there requires solving problems that naive implementations miss.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Why exact-match caching falls short
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Traditional caching uses query text as the cache key. This works when queries are identical:
 &lt;/p&gt;
 &lt;p&gt;
  &lt;i&gt;
   # Exact-match caching
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;p&gt;
  cache_key = hash(query_text)
 &lt;/p&gt;
 &lt;p&gt;
  if cache_key in cache:
 &lt;/p&gt;
 &lt;p&gt;
  return cache[cache_key]
 &lt;/p&gt;
 &lt;p&gt;
  But users don&#x27;t phrase questions identically. My analysis of 100,000 production queries found:
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Only 18%
    &lt;/b&gt;
    were exact duplicates of previous queries
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     47%
    &lt;/b&gt;
    were semantically similar to previous queries (same intent, different wording)
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     35%
    &lt;/b&gt;
    were genuinely novel queries
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;p&gt;
  That 47% represented massive cost savings we were missing. Each semantically-similar query triggered a full LLM call, generating a response nearly identical to one we&#x27;d already computed.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Semantic caching architecture
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Semantic caching replaces text-based keys with embedding-based similarity lookup:
 &lt;/p&gt;
 &lt;p&gt;
  class SemanticCache:
 &lt;/p&gt;
 &lt;p&gt;
  def __init__(self, embedding_model, similarity_threshold=0.92):
 &lt;/p&gt;
 &lt;p&gt;
  self.embedding_model = embedding_model
 &lt;/p&gt;
 &lt;p&gt;
  self.threshold = similarity_threshold
 &lt;/p&gt;
 &lt;p&gt;
  self.vector_store = VectorStore()
  &lt;i&gt;
   # FAISS, Pinecone, etc.
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;p&gt;
  self.response_store = ResponseStore()
  &lt;i&gt;
   # Redis, DynamoDB, etc.
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;p&gt;
  def get(self, query: str) -&amp;gt; Optional[str]:
 &lt;/p&gt;
 &lt;p&gt;
  &quot;&quot;&quot;Return cached response if semantically similar query exists.&quot;&quot;&quot;
 &lt;/p&gt;
 &lt;p&gt;
  query_embedding = self.embedding_model.encode(query)
 &lt;/p&gt;
 &lt;p&gt;
  &lt;i&gt;
   # Find most similar cached query
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;p&gt;
  matches = self.vector_store.search(query_embedding, top_k=1)
 &lt;/p&gt;
 &lt;p&gt;
  if matches and matches[0].similarity &amp;gt;= self.threshold:
 &lt;/p&gt;
 &lt;p&gt;
  cache_id = matches[0].id
 &lt;/p&gt;
 &lt;p&gt;
  return self.response_store.get(cache_id)
 &lt;/p&gt;
 &lt;p&gt;
  return None
 &lt;/p&gt;
 &lt;p&gt;
  def set(self, query: str, response: str):
 &lt;/p&gt;
 &lt;p&gt;
  &quot;&quot;&quot;Cache query-response pair.&quot;&quot;&quot;
 &lt;/p&gt;
 &lt;p&gt;
  query_embedding = self.embedding_model.encode(query)
 &lt;/p&gt;
 &lt;p&gt;
  cache_id = generate_id()
 &lt;/p&gt;
 &lt;p&gt;
  self.vector_store.add(cache_id, query_embedding)
 &lt;/p&gt;
 &lt;p&gt;
  self.response_store.set(cache_id, {
 &lt;/p&gt;
 &lt;p&gt;
  &#x27;query&#x27;: query,
 &lt;/p&gt;
 &lt;p&gt;
  &#x27;response&#x27;: response,
 &lt;/p&gt;
 &lt;p&gt;
  &#x27;timestamp&#x27;: datetime.utcnow()
 &lt;/p&gt;
 &lt;p&gt;
  })
 &lt;/p&gt;
 &lt;p&gt;
  The key insight: Instead of hashing query text, I embed queries into vector space and find cached queries within a similarity threshold.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   The threshold problem
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The similarity threshold is the critical parameter. Set it too high, and you miss valid cache hits. Set it too low, and you return wrong responses.
 &lt;/p&gt;
 &lt;p&gt;
  Our initial threshold of 0.85 seemed reasonable; 85% similar should be &quot;the same question,&quot; right?
 &lt;/p&gt;
 &lt;p&gt;
  Wrong. At 0.85, we got cache hits like:
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     &lt;i&gt;
      Query: &quot;How do I cancel my subscription?&quot;
     &lt;/i&gt;
    &lt;/b&gt;
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     &lt;i&gt;
      Cached: &quot;How do I cancel my order?&quot;
     &lt;/i&gt;
    &lt;/b&gt;
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     &lt;i&gt;
      Similarity: 0.87
     &lt;/i&gt;
    &lt;/b&gt;
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;p&gt;
  These are different questions with different answers. Returning the cached response would be incorrect.
 &lt;/p&gt;
 &lt;p&gt;
  I discovered that optimal thresholds vary by query type:
 &lt;/p&gt;
 &lt;table&gt;
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;b&gt;
       Query type
      &lt;/b&gt;
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;b&gt;
       Optimal threshold
      &lt;/b&gt;
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;b&gt;
       Rationale
      &lt;/b&gt;
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      FAQ-style questions
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      0.94
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      High precision needed; wrong answers damage trust
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      Product searches
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      0.88
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      More tolerance for near-matches
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      Support queries
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      0.92
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      Balance between coverage and accuracy
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      Transactional queries
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      0.97
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      Very low tolerance for errors
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
  &lt;/tbody&gt;
 &lt;/table&gt;
 &lt;p&gt;
  I implemented query-type-specific thresholds:
 &lt;/p&gt;
 &lt;p&gt;
  class AdaptiveSemanticCache:
 &lt;/p&gt;
 &lt;p&gt;
  def __init__(self):
 &lt;/p&gt;
 &lt;p&gt;
  self.thresholds = {
 &lt;/p&gt;
 &lt;p&gt;
  &#x27;faq&#x27;: 0.94,
 &lt;/p&gt;
 &lt;p&gt;
  &#x27;search&#x27;: 0.88,
 &lt;/p&gt;
 &lt;p&gt;
  &#x27;support&#x27;: 0.92,
 &lt;/p&gt;
 &lt;p&gt;
  &#x27;transactional&#x27;: 0.97,
 &lt;/p&gt;
 &lt;p&gt;
  &#x27;default&#x27;: 0.92
 &lt;/p&gt;
 &lt;p&gt;
  }
 &lt;/p&gt;
 &lt;p&gt;
  self.query_classifier = QueryClassifier()
 &lt;/p&gt;
 &lt;p&gt;
  def get_threshold(self, query: str) -&amp;gt; float:
 &lt;/p&gt;
 &lt;p&gt;
  query_type = self.query_classifier.classify(query)
 &lt;/p&gt;
 &lt;p&gt;
  return self.thresholds.get(query_type, self.thresholds[&#x27;default&#x27;])
 &lt;/p&gt;
 &lt;p&gt;
  def get(self, query: str) -&amp;gt; Optional[str]:
 &lt;/p&gt;
 &lt;p&gt;
  threshold = self.get_threshold(query)
 &lt;/p&gt;
 &lt;p&gt;
  query_embedding = self.embedding_model.encode(query)
 &lt;/p&gt;
 &lt;p&gt;
  matches = self.vector_store.search(query_embedding, top_k=1)
 &lt;/p&gt;
 &lt;p&gt;
  if matches and matches[0].similarity &amp;gt;= threshold:
 &lt;/p&gt;
 &lt;p&gt;
  return self.response_store.get(matches[0].id)
 &lt;/p&gt;
 &lt;p&gt;
  return None
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Threshold tuning methodology
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  I couldn&#x27;t tune thresholds blindly. I needed ground truth on which query pairs were actually &quot;the same.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Our methodology:
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Step 1:
  &lt;/b&gt;
  Sample query pairs. I sampled 5,000 query pairs at various similarity levels (0.80-0.99).
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Step 2:
  &lt;/b&gt;
  Human labeling. Annotators labeled each pair as
  &lt;i&gt;
   &quot;same intent&quot;
  &lt;/i&gt;
  or
  &lt;i&gt;
   &quot;different intent.&quot;
  &lt;/i&gt;
  I used three annotators per pair and took a majority vote.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Step 3:
  &lt;/b&gt;
  Compute precision/recall curves. For each threshold, we computed:
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    Precision: Of cache hits, what fraction had the same intent?
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    Recall: Of same-intent pairs, what fraction did we cache-hit?
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;p&gt;
  def compute_precision_recall(pairs, labels, threshold):
 &lt;/p&gt;
 &lt;p&gt;
  &quot;&quot;&quot;Compute precision and recall at given similarity threshold.&quot;&quot;&quot;
 &lt;/p&gt;
 &lt;p&gt;
  predictions = [1 if pair.similarity &amp;gt;= threshold else 0 for pair in pairs]
 &lt;/p&gt;
 &lt;p&gt;
  true_positives = sum(1 for p, l in zip(predictions, labels) if p == 1 and l == 1)
 &lt;/p&gt;
 &lt;p&gt;
  false_positives = sum(1 for p, l in zip(predictions, labels) if p == 1 and l == 0)
 &lt;/p&gt;
 &lt;p&gt;
  false_negatives = sum(1 for p, l in zip(predictions, labels) if p == 0 and l == 1)
 &lt;/p&gt;
 &lt;p&gt;
  precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) &amp;gt; 0 else 0
 &lt;/p&gt;
 &lt;p&gt;
  recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) &amp;gt; 0 else 0
 &lt;/p&gt;
 &lt;p&gt;
  return precision, recall
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Step 4: Select threshold based on cost of errors.
  &lt;/b&gt;
  For FAQ queries where wrong answers damage trust, I optimized for precision (0.94 threshold gave 98% precision). For search queries where missing a cache hit just costs money, I optimized for recall (0.88 threshold).
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Latency overhead
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Semantic caching adds latency: You must embed the query and search the vector store before knowing whether to call the LLM.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Our measurements:
  &lt;/b&gt;
 &lt;/p&gt;
 &lt;table&gt;
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;b&gt;
       Operation
      &lt;/b&gt;
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;b&gt;
       Latency (p50)
      &lt;/b&gt;
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;b&gt;
       Latency (p99)
      &lt;/b&gt;
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      Query embedding
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      12ms
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      28ms
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      Vector search
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      8ms
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      19ms
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;b&gt;
       Total cache lookup
      &lt;/b&gt;
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;b&gt;
       20ms
      &lt;/b&gt;
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;b&gt;
       47ms
      &lt;/b&gt;
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      LLM API call
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      850ms
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      2400ms
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
  &lt;/tbody&gt;
 &lt;/table&gt;
 &lt;p&gt;
  The 20ms overhead is negligible compared to the 850ms LLM call we avoid on cache hits. Even at p99, the 47ms overhead is acceptable.
 &lt;/p&gt;
 &lt;p&gt;
  However, cache misses now take 20ms longer than before (embedding + search + LLM call). At our 67% hit rate, the math works out favorably:
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    Before: 100% of queries × 850ms = 850ms average
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    After: (33% × 870ms) + (67% × 20ms) = 287ms + 13ms = 300ms average
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;p&gt;
  Net latency improvement of 65% alongside the cost reduction.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Cache invalidation
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Cached responses go stale. Product information changes, policies update and yesterday&#x27;s correct answer becomes today&#x27;s wrong answer.
 &lt;/p&gt;
 &lt;p&gt;
  I implemented three invalidation strategies:
 &lt;/p&gt;
 &lt;ol&gt;
  &lt;li&gt;
   &lt;h3&gt;
    &lt;b&gt;
     Time-based TTL
    &lt;/b&gt;
   &lt;/h3&gt;
  &lt;/li&gt;
 &lt;/ol&gt;
 &lt;p&gt;
  Simple expiration based on content type:
 &lt;/p&gt;
 &lt;p&gt;
  TTL_BY_CONTENT_TYPE = {
 &lt;/p&gt;
 &lt;p&gt;
  &#x27;pricing&#x27;: timedelta(hours=4),
  &lt;i&gt;
   # Changes frequently
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;p&gt;
  &#x27;policy&#x27;: timedelta(days=7),
  &lt;i&gt;
   # Changes rarely
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;p&gt;
  &#x27;product_info&#x27;: timedelta(days=1),
  &lt;i&gt;
   # Daily refresh
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;p&gt;
  &#x27;general_faq&#x27;: timedelta(days=14),
  &lt;i&gt;
   # Very stable
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;p&gt;
  }
 &lt;/p&gt;
 &lt;ol&gt;
  &lt;li&gt;
   &lt;h3&gt;
    &lt;b&gt;
     Event-based invalidation
    &lt;/b&gt;
   &lt;/h3&gt;
  &lt;/li&gt;
 &lt;/ol&gt;
 &lt;p&gt;
  When underlying data changes, invalidate related cache entries:
 &lt;/p&gt;
 &lt;p&gt;
  class CacheInvalidator:
 &lt;/p&gt;
 &lt;p&gt;
  def on_content_update(self, content_id: str, content_type: str):
 &lt;/p&gt;
 &lt;p&gt;
  &quot;&quot;&quot;Invalidate cache entries related to updated content.&quot;&quot;&quot;
 &lt;/p&gt;
 &lt;p&gt;
  &lt;i&gt;
   # Find cached queries that referenced this content
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;p&gt;
  affected_queries = self.find_queries_referencing(content_id)
 &lt;/p&gt;
 &lt;p&gt;
  for query_id in affected_queries:
 &lt;/p&gt;
 &lt;p&gt;
  self.cache.invalidate(query_id)
 &lt;/p&gt;
 &lt;p&gt;
  self.log_invalidation(content_id, len(affected_queries))
 &lt;/p&gt;
 &lt;ol&gt;
  &lt;li&gt;
   &lt;h3&gt;
    &lt;b&gt;
     Staleness detection
    &lt;/b&gt;
   &lt;/h3&gt;
  &lt;/li&gt;
 &lt;/ol&gt;
 &lt;p&gt;
  For responses that might become stale without explicit events, I implemented  periodic freshness checks:
 &lt;/p&gt;
 &lt;p&gt;
  def check_freshness(self, cached_response: dict) -&amp;gt; bool:
 &lt;/p&gt;
 &lt;p&gt;
  &quot;&quot;&quot;Verify cached response is still valid.&quot;&quot;&quot;
 &lt;/p&gt;
 &lt;p&gt;
  &lt;i&gt;
   # Re-run the query against current data
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;p&gt;
  fresh_response = self.generate_response(cached_response[&#x27;query&#x27;])
 &lt;/p&gt;
 &lt;p&gt;
  &lt;i&gt;
   # Compare semantic similarity of responses
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;p&gt;
  cached_embedding = self.embed(cached_response[&#x27;response&#x27;])
 &lt;/p&gt;
 &lt;p&gt;
  fresh_embedding = self.embed(fresh_response)
 &lt;/p&gt;
 &lt;p&gt;
  similarity = cosine_similarity(cached_embedding, fresh_embedding)
 &lt;/p&gt;
 &lt;p&gt;
  &lt;i&gt;
   # If responses diverged significantly, invalidate
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;p&gt;
  if similarity &amp;lt; 0.90:
 &lt;/p&gt;
 &lt;p&gt;
  self.cache.invalidate(cached_response[&#x27;id&#x27;])
 &lt;/p&gt;
 &lt;p&gt;
  return False
 &lt;/p&gt;
 &lt;p&gt;
  return True
 &lt;/p&gt;
 &lt;p&gt;
  We run freshness checks on a sample of cached entries daily, catching staleness that TTL and event-based invalidation miss.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Production results
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  &lt;b&gt;
   After three months in production:
  &lt;/b&gt;
 &lt;/p&gt;
 &lt;table&gt;
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;b&gt;
       Metric
      &lt;/b&gt;
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;b&gt;
       Before
      &lt;/b&gt;
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;b&gt;
       After
      &lt;/b&gt;
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      &lt;b&gt;
       Change
      &lt;/b&gt;
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      Cache hit rate
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      18%
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      67%
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      +272%
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      LLM API costs
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $47K/month
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      $12.7K/month
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      -73%
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      Average latency
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      850ms
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      300ms
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      -65%
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      False-positive rate
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      N/A
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      0.8%
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      —
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td&gt;
     &lt;p&gt;
      Customer complaints (wrong answers)
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      Baseline
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      +0.3%
     &lt;/p&gt;
    &lt;/td&gt;
    &lt;td&gt;
     &lt;p&gt;
      Minimal increase
     &lt;/p&gt;
    &lt;/td&gt;
   &lt;/tr&gt;
  &lt;/tbody&gt;
 &lt;/table&gt;
 &lt;p&gt;
  The 0.8% false-positive rate (queries where we returned a cached response that was semantically incorrect) was within acceptable bounds. These cases occurred primarily at the boundaries of our threshold, where similarity was just above the cutoff but intent differed slightly.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Pitfalls to avoid
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  &lt;b&gt;
   Don&#x27;t use a single global threshold.
  &lt;/b&gt;
  Different query types have different tolerance for errors. Tune thresholds per category.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Don&#x27;t skip the embedding step on cache hits.
  &lt;/b&gt;
  You might be tempted to skip embedding overhead when returning cached responses, but you need the embedding for cache key generation. The overhead is unavoidable.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Don&#x27;t forget invalidation.
  &lt;/b&gt;
  Semantic caching without invalidation strategy leads to stale responses that erode user trust. Build invalidation from day one.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Don&#x27;t cache everything.
  &lt;/b&gt;
  Some queries shouldn&#x27;t be cached: Personalized responses, time-sensitive information, transactional confirmations. Build exclusion rules.
 &lt;/p&gt;
 &lt;p&gt;
  def should_cache(self, query: str, response: str) -&amp;gt; bool:
 &lt;/p&gt;
 &lt;p&gt;
  &quot;&quot;&quot;Determine if response should be cached.&quot;&quot;
 &lt;/p&gt;
 &lt;p&gt;
  &lt;i&gt;
   # Don&#x27;t cache personalized responses
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;p&gt;
  if self.contains_personal_info(response):
 &lt;/p&gt;
 &lt;p&gt;
  return False
 &lt;/p&gt;
 &lt;p&gt;
  &lt;i&gt;
   # Don&#x27;t cache time-sensitive information
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;p&gt;
  if self.is_time_sensitive(query):
 &lt;/p&gt;
 &lt;p&gt;
  return False
 &lt;/p&gt;
 &lt;p&gt;
  &lt;i&gt;
   # Don&#x27;t cache transactional confirmations
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;p&gt;
  if self.is_transactional(query):
 &lt;/p&gt;
 &lt;p&gt;
  return False
 &lt;/p&gt;
 &lt;p&gt;
  return True
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Key takeaways
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Semantic caching is a practical pattern for LLM cost control that captures redundancy exact-match caching misses. The key challenges are threshold tuning (use query-type-specific thresholds based on precision/recall analysis) and cache invalidation (combine TTL, event-based and staleness detection).
 &lt;/p&gt;
 &lt;p&gt;
  At 73% cost reduction, this was our highest-ROI optimization for production LLM systems. The implementation complexity is moderate, but the threshold tuning requires careful attention to avoid quality degradation.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;i&gt;
   Sreenivasa Reddy Hulebeedu Reddy is a lead software engineer.
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;br/&gt;
 &lt;br/&gt;
 &lt;p&gt;
  Welcome to the VentureBeat community!
 &lt;/p&gt;
 &lt;p&gt;
  Our guest posting program is where technical experts share insights and provide neutral, non-vested deep dives on AI, data infrastructure, cybersecurity and other cutting-edge technologies shaping the future of enterprise.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;a href=&quot;/category/DataDecisionMakers&quot;&gt;
   Read more
  &lt;/a&gt;
  &lt;!-- --&gt;
  from our guest post program — and check out our
  &lt;!-- --&gt;
  &lt;a href=&quot;/guest-posts&quot;&gt;
   guidelines
  &lt;/a&gt;
  &lt;!-- --&gt;
  if you’re interested in contributing an article of your own!
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Anthropic cracks down on unauthorized Claude usage by third-party harnesses and rivals </title>
<link>https://venturebeat.com/technology/anthropic-cracks-down-on-unauthorized-claude-usage-by-third-party-harnesses</link>
<pubDate>Wed, 14 Jan 2026 21:03:19 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;Claude Code surrounded by guards in suits&quot; data-nimg=&quot;1&quot; height=&quot;1536&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/6Hhc39ApUGLrUtrCer8FkW/3e14e40718b84e4364ce7136a444b9a5/Gemini_Generated_Image_qj0p4kqj0p4kqj0p.png?w=1000&quot; width=&quot;2752&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
    &lt;p&gt;
     Credit: VentureBeat made with Google Nano Banana Pro
    &lt;/p&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  Anthropic has confirmed the implementation of strict new technical safeguards preventing third-party applications from spoofing its official coding client, Claude Code, in order to access the underlying Claude AI models for more favorably pricing and limits — a move that has disrupted workflows for users of popular open source coding agent OpenCode.
 &lt;/p&gt;
 &lt;p&gt;
  Simultaneously but separately, it has restricted usage of its AI models by rival labs including xAI (through the integrated developer environment Cursor) to train competing systems to Claude Code.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  The former action was clarified on Friday by Thariq Shihipar, a Member of Technical Staff at Anthropic working on Claude Code.
 &lt;/p&gt;
 &lt;p&gt;
  Writing on the social network X (formerly Twitter),
  &lt;a href=&quot;https://x.com/trq212/status/2009689809875591565&quot;&gt;
   Shihipar stated
  &lt;/a&gt;
  that the company had &quot;tightened our safeguards against spoofing the Claude Code harness.&quot;
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  He acknowledged that the rollout had unintended collateral damage, noting that some user accounts were automatically banned for triggering abuse filters—an error the company is currently reversing.
 &lt;/p&gt;
 &lt;p&gt;
  However, the blocking of the third-party integrations themselves appears to be intentional.
 &lt;/p&gt;
 &lt;p&gt;
  The move targets harnesses—software wrappers that pilot a user’s web-based Claude account via OAuth to drive automated workflows.
 &lt;/p&gt;
 &lt;p&gt;
  This effectively severs the link between flat-rate consumer Claude Pro/Max plans and external coding environments.
 &lt;/p&gt;
 &lt;h2&gt;
  The Harness Problem
 &lt;/h2&gt;
 &lt;p&gt;
  A harness acts as a bridge between a subscription (designed for human chat) and an automated workflow.
 &lt;/p&gt;
 &lt;p&gt;
  Tools like OpenCode work by spoofing the client identity, sending headers that convince the Anthropic server the request is coming from its own official command line interface (CLI) tool.
 &lt;/p&gt;
 &lt;p&gt;
  Shihipar cited technical instability as the primary driver for the block, noting that unauthorized harnesses introduce bugs and usage patterns that Anthropic cannot properly diagnose.
 &lt;/p&gt;
 &lt;p&gt;
  When a third-party wrapper like Cursor (in certain configurations) or OpenCode hits an error, users often blame the model, degrading trust in the platform.
 &lt;/p&gt;
 &lt;h2&gt;
  The Economic Tension: The Buffet Analogy
 &lt;/h2&gt;
 &lt;p&gt;
  However, the developer community has pointed to a simpler economic reality underlying the restrictions on Cursor and similar tools: Cost.
 &lt;/p&gt;
 &lt;p&gt;
  In extensive
  &lt;a href=&quot;https://news.ycombinator.com/item?id=46549823&quot;&gt;
   discussions on Hacker News
  &lt;/a&gt;
  beginning yesterday, users coalesced around a buffet analogy: Anthropic offers an all-you-can-eat buffet via its consumer subscription ($200/month for Max) but restricts the speed of consumption via its official tool, Claude Code.
 &lt;/p&gt;
 &lt;p&gt;
  Third-party harnesses remove these speed limits. An autonomous agent running inside OpenCode can execute high-intensity loops—coding, testing, and fixing errors overnight—that would be cost-prohibitive on a metered plan.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;In a month of Claude Code, it&#x27;s easy to use so many LLM tokens that it would have cost you more than $1,000 if you&#x27;d paid via the API,&quot; noted Hacker News user dfabulich.
 &lt;/p&gt;
 &lt;p&gt;
  By blocking these harnesses, Anthropic is forcing high-volume automation toward two sanctioned paths:
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    The Commercial API: Metered, per-token pricing which captures the true cost of agentic loops.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    Claude Code: Anthropic’s managed environment, where they control the rate limits and execution sandbox.
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;h2&gt;
  Community Pivot: Cat and Mouse
 &lt;/h2&gt;
 &lt;p&gt;
  The reaction from users has been swift and largely negative.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Seems very customer hostile,&quot; wrote Danish programmer David Heinemeier Hansson (DHH), the creator of the popular Ruby on Rails open source web development framework,
  &lt;a href=&quot;https://x.com/dhh/status/2009664622274781625&quot;&gt;
   in a post on X
  &lt;/a&gt;
  .
 &lt;/p&gt;
 &lt;p&gt;
  However, others were more sympathetic to Anthropic.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;anthropic crackdown on people abusing the subscription auth is the gentlest it could’ve been,&quot; wrote Artem K aka
  &lt;a href=&quot;https://x.com/banteg/status/2009587028728713647&quot;&gt;
   @banteg on X
  &lt;/a&gt;
  , a developer associated with Yearn Finance. &quot;just a polite message instead of nuking your account or retroactively charging you at api prices.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The team behind OpenCode immediately launched
  &lt;a href=&quot;https://x.com/opencode/status/2009674476804575742&quot;&gt;
   OpenCode Black
  &lt;/a&gt;
  , a new premium tier for $200 per month that reportedly routes traffic through an enterprise API gateway to bypass the consumer OAuth restrictions.
 &lt;/p&gt;
 &lt;p&gt;
  In addition, OpenCode creator Dax Raad posted on X saying that the company would be working with Anthropic rival OpenAI to allow users of its coding model and development agent, Codex, &quot;to benefit from their subscription directly within OpenCode,&quot; and then posted a GIF of the unforgettable scene from the 2000 film
  &lt;i&gt;
   Gladiator
  &lt;/i&gt;
  showing Maximus (Russell Crowe) asking a crowd &quot;Are you not entertained?&quot; after chopping off an adversary&#x27;s head with two swords.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  For now, the message from Anthropic is clear: The ecosystem is consolidating. Whether via legal enforcement (as seen with xAI&#x27;s use of Cursor) or technical safeguards, the era of unrestricted access to Claude’s reasoning capabilities is coming to an end.
 &lt;/p&gt;
 &lt;h2&gt;
  The xAI Situation and Cursor Connection
 &lt;/h2&gt;
 &lt;p&gt;
  Simultaneous with the technical crackdown, developers at Elon Musk’s competing AI lab xAI have reportedly lost access to Anthropic’s Claude models. While the timing suggests a unified strategy, sources familiar with the matter indicate this is a separate enforcement action based on commercial terms, with Cursor playing a pivotal role in the discovery.
 &lt;/p&gt;
 &lt;p&gt;
  As first reported by
  &lt;a href=&quot;https://x.com/kyliebytes/status/2009686466746822731&quot;&gt;
   tech journalist Kylie Robison
  &lt;/a&gt;
  of the publication
  &lt;i&gt;
   Core Memory
  &lt;/i&gt;
  , xAI staff had been using Anthropic models—specifically via the Cursor IDE—to accelerate their own developmet.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  &quot;Hi team, I believe many of you have already discovered that Anthropic models are not responding on Cursor,&quot; wrote xAI co-founder Tony Wu in a memo to staff on Wednesday, according to Robison. &quot;According to Cursor this is a new policy Anthropic is enforcing for all its major competitors.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  However, Section D.4 (Use Restrictions) of
  &lt;a href=&quot;https://www.anthropic.com/legal/commercial-terms&quot;&gt;
   Anthropic’s Commercial Terms of Service
  &lt;/a&gt;
  expressly prohibits customers from using the services to:
 &lt;/p&gt;
 &lt;blockquote&gt;
  &lt;p&gt;
   (a) access the Services to build a competing product or service, including to train competing AI models... [or] (b) reverse engineer or duplicate the Services.
  &lt;/p&gt;
 &lt;/blockquote&gt;
 &lt;p&gt;
  In this instance, Cursor served as the vehicle for the violation. While the IDE itself is a legitimate tool, xAI&#x27;s specific use of it to leverage Claude for competitive research triggered the legal block.
 &lt;/p&gt;
 &lt;h2&gt;
  Precedent for the Block: The OpenAI and Windsurf Cutoffs
 &lt;/h2&gt;
 &lt;p&gt;
  The restriction on xAI is not the first time Anthropic has used its Terms of Service or infrastructure control to wall off a major competitor or third-party tool. This week’s actions follow a clear pattern established throughout 2025, where Anthropic aggressively moved to protect its intellectual property and computing resources.
 &lt;/p&gt;
 &lt;p&gt;
  In August 2025, the company
  &lt;a href=&quot;https://www.wired.com/story/anthropic-revokes-openais-access-to-claude/&quot;&gt;
   revoked OpenAI&#x27;s access to the Claude API
  &lt;/a&gt;
  under strikingly similar circumstances. Sources told
  &lt;i&gt;
   Wired
  &lt;/i&gt;
  that OpenAI had been using Claude to benchmark its own models and test safety responses—a practice Anthropic flagged as a violation of its competitive restrictions.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Claude Code has become the go-to choice for coders everywhere, and so it was no surprise to learn OpenAI&#x27;s own technical staff were also using our coding tools,&quot; an Anthropic spokesperson said at the time.
 &lt;/p&gt;
 &lt;p&gt;
  Just months prior, in June 2025, the coding environment Windsurf faced a similar sudden blackout. In a
  &lt;a href=&quot;https://windsurf.com/blog/anthropic-models&quot;&gt;
   public statement
  &lt;/a&gt;
  , the Windsurf team revealed that &quot;with less than a week of notice, Anthropic informed us they were cutting off nearly all of our first-party capacity&quot; for the Claude 3.x model family.
 &lt;/p&gt;
 &lt;p&gt;
  The move forced Windsurf to immediately strip direct access for free users and pivot to a &quot;Bring-Your-Own-Key&quot; (BYOK) model while promoting Google’s Gemini as a stable alternative.
 &lt;/p&gt;
 &lt;p&gt;
  While Windsurf eventually restored first-party access for paid users weeks later, the incident—combined with the OpenAI revocation and now the xAI block—reinforces a rigid boundary in the AI arms race: while labs and tools may coexist, Anthropic reserves the right to sever the connection the moment usage threatens its competitive advantage or business model.
 &lt;/p&gt;
 &lt;h2&gt;
  The Catalyst: The Viral Rise of &#x27;Claude Code&#x27;
 &lt;/h2&gt;
 &lt;p&gt;
  The timing of both crackdowns is inextricably linked to the massive surge in popularity for Claude Code, Anthropic&#x27;s native terminal environment.
 &lt;/p&gt;
 &lt;p&gt;
  While
  &lt;a href=&quot;https://venturebeat.com/ai/anthropics-claude-3-7-sonnet-takes-aim-at-openai-and-deepseek-in-ais-next-big-battle&quot;&gt;
   Claude Code was originally released in early 2025
  &lt;/a&gt;
  , it spent much of the year as a niche utility. The true breakout moment arrived only in December 2025 and the first days of January 2026—driven less by official updates and more by the community-led
  &lt;a href=&quot;https://venturebeat.com/technology/how-ralph-wiggum-went-from-the-simpsons-to-the-biggest-name-in-ai-right-now&quot;&gt;
   &quot;Ralph Wiggum&quot; phenomenon
  &lt;/a&gt;
  .
 &lt;/p&gt;
 &lt;p&gt;
  Named after the dim-witted
  &lt;i&gt;
   Simpsons
  &lt;/i&gt;
  character, the Ralph Wiggum plugin popularized a method of &quot;brute force&quot; coding. By trapping Claude in a self-healing loop where failures are fed back into the context window until the code passes tests, developers achieved results that felt surprisingly close to AGI.
 &lt;/p&gt;
 &lt;p&gt;
  But the current controversy isn&#x27;t over users losing access to the Claude Code interface—which many power users actually find limiting—but rather the underlying engine, the Claude Opus 4.5 model.
 &lt;/p&gt;
 &lt;p&gt;
  By spoofing the official Claude Code client, tools like OpenCode allowed developers to harness Anthropic&#x27;s most powerful reasoning model for complex, autonomous loops at a flat subscription rate, effectively arbitraging the difference between consumer pricing and enterprise-grade intelligence.
 &lt;/p&gt;
 &lt;p&gt;
  In fact, as developer Ed Andersen wrote on X, some of the popularity of Claude Code may have been driven by people spoofing it in this manner.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  Clearly, power users wanted to run it at massive scales without paying enterprise rates. Anthropic’s new enforcement actions are a direct attempt to funnel this runaway demand back into its sanctioned, sustainable channels.
 &lt;/p&gt;
 &lt;h2&gt;
  Enterprise Dev Takeaways
 &lt;/h2&gt;
 &lt;p&gt;
  For Senior AI Engineers focused on orchestration and scalability, this shift demands an immediate re-architecture of pipelines to prioritize stability over raw cost savings.
 &lt;/p&gt;
 &lt;p&gt;
  While tools like OpenCode offered an attractive flat-rate alternative for heavy automation, Anthropic’s crackdown reveals that these unauthorized wrappers introduce undiagnosable bugs and instability.
 &lt;/p&gt;
 &lt;p&gt;
  Ensuring model integrity now requires routing all automated agents through the official Commercial API or the Claude Code client.
 &lt;/p&gt;
 &lt;p&gt;
  Therefore, enterprise decision makers should take note: even though open source solutions may be more affordable and more tempting, if they&#x27;re being used to access proprietary AI models like Anthropic&#x27;s, access is not always guaranteed.
 &lt;/p&gt;
 &lt;p&gt;
  This transition necessitates a re-forecasting of operational budgets—moving from predictable monthly subscriptions to variable per-token billing—but ultimately trades financial predictability for the assurance of a supported, production-ready environment.
 &lt;/p&gt;
 &lt;p&gt;
  From a security and compliance perspective, the simultaneous blocks on xAI and open-source tools expose the critical vulnerability of &quot;Shadow AI.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  When engineering teams use personal accounts or spoofed tokens to bypass enterprise controls, they risk not just technical debt but sudden, organization-wide access loss.
 &lt;/p&gt;
 &lt;p&gt;
  Security directors must now audit internal toolchains to ensure that no &quot;dogfooding&quot; of competitor models violates commercial terms and that all automated workflows are authenticated via proper enterprise keys.
 &lt;/p&gt;
 &lt;p&gt;
  In this new landscape, the reliability of the official API must trump the cost savings of unauthorized tools, as the operational risk of a total ban far outweighs the expense of proper integration.
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> TII’s Falcon H1R 7B can out-reason models up to 7x its size — and it’s (mostly) open </title>
<link>https://venturebeat.com/technology/tiis-falcon-h1r-7b-can-out-reason-models-up-to-7x-its-size-and-its-mostly</link>
<pubDate>Thu, 08 Jan 2026 02:46:02 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;A purple falcon flies over Abu Dhabi skyline&quot; data-nimg=&quot;1&quot; height=&quot;576&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/6S3Um2MKMQJZavLvb5iEzH/7f8270446a2734c8c6a2d1150b2fc332/9-x0igmpkjXB7E9vru3gT.jpg?w=1000&quot; width=&quot;1024&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
    &lt;p&gt;
     Credit: VentureBeat made with Flux.2 Pro on fal.ai
    &lt;/p&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  For the last two years, the prevailing logic in generative AI has been one of brute force: if you want better reasoning, you need a bigger model.
 &lt;/p&gt;
 &lt;p&gt;
  While &quot;small&quot; models (under 10 billion parameters) have become capable conversationalists, they have historically crumbled when asked to perform multi-step logical deduction or complex mathematical proofs.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  Today, the Technology Innovation Institute (TII) in Abu Dhabi is challenging that scaling law with
  &lt;a href=&quot;https://falcon-lm.github.io/blog/falcon-h1r-7b/&quot;&gt;
   the release of Falcon H1R 7B
  &lt;/a&gt;
  .
 &lt;/p&gt;
 &lt;p&gt;
  By abandoning the pure Transformer orthodoxy in favor of a hybrid architecture, TII claims to have built a 7-billion parameter model that not only rivals but outperforms competitors nearly 7X its size — including the 32B and 47B variants of Alibaba&#x27;s Qwen and Nvidia&#x27;s Nemotron.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  The release marks a significant shift in the open-weight ecosystem, moving the battleground from raw parameter count to architectural efficiency and inference-time scaling.
 &lt;/p&gt;
 &lt;p&gt;
  The full
  &lt;a href=&quot;https://huggingface.co/tiiuae/Falcon-H1R-7B&quot;&gt;
   model code is available now at Hugging Face
  &lt;/a&gt;
  and can be tested by individuals in a live demo inference on
  &lt;a href=&quot; chat.falconllm.tii.ae&quot;&gt;
   Falcon Chat
  &lt;/a&gt;
  (a chatbot experience). TII further released a seemingly quite comprehensive
  &lt;a href=&quot;https://github.com/tiiuae/falcon-h1r/blob/main/tech_report.pdf&quot;&gt;
   technical report
  &lt;/a&gt;
  on the approach and training methodology for Falcon H1 7B, as well.
 &lt;/p&gt;
 &lt;h2&gt;
  Moving Beyond the Foundational LLM Tech, the Transformer
 &lt;/h2&gt;
 &lt;p&gt;
  The defining feature of Falcon H1R 7B is its &quot;hybrid&quot; backbone. Most modern LLMs rely exclusively on the Transformer architecture, which scales predictably but suffers from high memory costs when processing long sequences.
 &lt;/p&gt;
 &lt;p&gt;
  Falcon H1R 7B integrates Mamba, a state-space model (SSM) architecture, alongside standard Transformer attention layers.
 &lt;/p&gt;
 &lt;p&gt;
  Originally developed by researchers Albert Gu and Tri Dao at Carnegie Mellon University and Princeton University, Mamba was first introduced in the paper &quot;
  &lt;a href=&quot;https://arxiv.org/abs/2312.00752&quot;&gt;
   Mamba: Linear-Time Sequence Modeling with Selective State Spaces
  &lt;/a&gt;
  &quot; published on December 1, 2023.
 &lt;/p&gt;
 &lt;p&gt;
  The architecture processes data sequences differently than Transformers: while Transformers compare every piece of data to every other piece (quadratic scaling), Mamba processes tokens sequentially, allowing it to handle vast amounts of information with linear scaling and significantly reduced compute costs.
 &lt;/p&gt;
 &lt;p&gt;
  This combination addresses one of the most persistent bottlenecks in deploying reasoning models: the cost of &quot;thinking.&quot; Reasoning models require generating long &quot;chains of thought&quot;—step-by-step internal monologues—before arriving at an answer. For standard Transformers, these long contexts explode computational costs.
 &lt;/p&gt;
 &lt;p&gt;
  According to TII’s technical report, the hybrid approach allows Falcon H1R 7B to maintain high throughput even as response lengths grow. At a batch size of 64, the model processes approximately 1,500 tokens per second per GPU—nearly double the speed of the competing Qwen3 8B model.
 &lt;/p&gt;
 &lt;h2&gt;
  Benchmark Performance: Punching Up
 &lt;/h2&gt;
 &lt;p&gt;
  In the benchmarks released by TII, the disparity between Falcon H1R 7B’s size and its performance is stark. On the
  &lt;b&gt;
   AIME 2025
  &lt;/b&gt;
  leaderboard—a rigorous test of mathematical reasoning—Falcon H1R 7B scored
  &lt;b&gt;
   83.1%
  &lt;/b&gt;
  , a result that disrupts the traditional hierarchy of model sizing.
 &lt;/p&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;Falcon-H1R 7B AIME 2025 benchmark comparison chart&quot; data-nimg=&quot;1&quot; height=&quot;437&quot; loading=&quot;lazy&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/wv2fsLdtDzhbLBcTwM94y/375146a82f71525fc25ebc122a49482c/Screenshot_2026-01-05_at_3.04.03â__PM.png?w=1000&quot; width=&quot;981&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
    &lt;p&gt;
     Falcon-H1R 7B AIME 2025 benchmark comparison chart. Credit: TII
    &lt;/p&gt;
   &lt;/figcaption&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  While the 7B model naturally trails massive proprietary frontiers like
  &lt;b&gt;
   GPT-5.2
  &lt;/b&gt;
  (99.0%) and
  &lt;b&gt;
   Gemini 3 Flash
  &lt;/b&gt;
  (97.0%) on the
  &lt;a href=&quot;https://artificialanalysis.ai/evaluations/aime-2025&quot;&gt;
   separate Artificial Analysis index
  &lt;/a&gt;
  (run by the independent organization of the same name, which has not yet benchmarked Falcon H1R 7B yet), it has effectively collapsed the gap between &quot;efficient&quot; open weights and mid-tier proprietary systems.
 &lt;/p&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;Artificial Analysis AIME 2025 benchmark comparison table&quot; data-nimg=&quot;1&quot; height=&quot;531&quot; loading=&quot;lazy&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/2SCg6mFjmSZ14u6GBJ1XWB/33a0e5c48e97928aad6337ed37e884d2/Screenshot_2026-01-05_at_2.27.20â__PM.png?w=1000&quot; width=&quot;1533&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
    &lt;p&gt;
     Artificial Analysis AIME 2025 benchmark comparison table. Credit: Artificial Analysis
    &lt;/p&gt;
   &lt;/figcaption&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Beating Larger &quot;Thinkers&quot;:
    &lt;/b&gt;
    Falcon H1R 7B (83.1%) outperforms the 15-billion parameter
    &lt;b&gt;
     Apriel-v1.6-Thinker
    &lt;/b&gt;
    (82.7%) and the 32-billion parameter
    &lt;b&gt;
     OLMo 3 Think
    &lt;/b&gt;
    (73.7%), validating TII&#x27;s claim that hybrid architectures can out-reason larger Transformers.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Chasing Proprietary Leaders:
    &lt;/b&gt;
    It sits within striking distance of
    &lt;b&gt;
     Claude 4.5 Sonnet
    &lt;/b&gt;
    (88.0%) and
    &lt;b&gt;
     Amazon Nova 2.0 Lite
    &lt;/b&gt;
    (88.7%), suggesting that for specific math-heavy workflows, this 7B model is a viable, low-latency alternative to expensive commercial APIs.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Outperforming Legacy Giants:
    &lt;/b&gt;
    On this specific reasoning metric, it decisively beats broadly capable but older architectures like
    &lt;b&gt;
     Mistral Large 3
    &lt;/b&gt;
    (38.0%) and
    &lt;b&gt;
     Llama 4 Maverick
    &lt;/b&gt;
    (19.3%), highlighting how specialized reasoning training (&quot;Deep Think&quot;) has become more critical than raw scale for logic tasks.
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;p&gt;
  Other key domain wins include:
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Coding:
    &lt;/b&gt;
    The model achieved
    &lt;b&gt;
     68.6%
    &lt;/b&gt;
    on the LCB v6 benchmark, a score TII claims is the highest among all tested models, including those four times its size.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     General Reasoning:
    &lt;/b&gt;
    While it dominates in math and code, its general reasoning score (49.48%) remains competitive, sitting just below the 14B and 15B parameter models but comfortably ahead of comparable 8B models.
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;h2&gt;
  Training Techniques
 &lt;/h2&gt;
 &lt;p&gt;
  Falcon H1R 7B’s performance is not just architectural; it stems from a rigorous, two-stage training pipeline designed to maximize reasoning density without inflating parameter count, according to
  &lt;a href=&quot;https://github.com/tiiuae/falcon-h1r/blob/main/tech_report.pdf&quot;&gt;
   TII&#x27;s technical report
  &lt;/a&gt;
  on the model.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Stage 1:
  &lt;/b&gt;
  Cold-Start Supervised Fine-Tuning (SFT). The model underwent &quot;cold-start&quot; SFT on a curated dataset dominated by mathematics (56.8% of tokens) and code (29.8%), with response lengths stretching up to 48,000 tokens.
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Difficulty-Aware Weighting:
    &lt;/b&gt;
    TII rejected the standard practice of treating all data equally. Instead, they applied a weighting scheme where &quot;hard&quot; problems were up-weighted by 1.25x to 1.75x, while easy problems were down-weighted or removed entirely to prevent overfitting to trivial tasks.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Single-Teacher Consistency:
    &lt;/b&gt;
    Ablation studies revealed that mixing reasoning traces from multiple &quot;teacher&quot; models actually degraded performance due to conflicting reasoning styles. Consequently, TII opted for a single-teacher approach to maintain coherent internal logic.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Balanced Token Normalization:
    &lt;/b&gt;
    To handle the massive variance in sequence lengths (short instructions vs. massive reasoning chains), the team introduced a Balanced Data-Parallel Token Normalization strategy. This technique equalizes the gradient contribution of each token across GPUs, preventing ranks with shorter sequences from destabilizing the loss—a change that yielded a consistent 4-10% accuracy boost during training.
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;p&gt;
  &lt;b&gt;
   Stage 2:
  &lt;/b&gt;
  Reinforcement Learning via Group Relative Policy Optimization (GRPO). Following SFT, the model was refined using GRPO a reinforcement learning algorithm that rewards correct outcomes without needing a separate value model.
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     The &quot;No-KL&quot; Shift:
    &lt;/b&gt;
    In a deviation from standard RLHF, TII removed the KL-divergence penalty (beta=0) entirely. This allowed the model to drift significantly from its base SFT policy, encouraging aggressive exploration of novel reasoning paths.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Math-Only Curriculum:
    &lt;/b&gt;
    Surprisingly, TII found that training exclusively on math problems during the RL stage yielded better generalization across all domains—including code and science—than mixed strategies. Ablations showed that &quot;code-only&quot; training improved coding scores but harmed general reasoning, whereas math-focused RL lifted performance globally.
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;p&gt;
  TII optimized the model specifically for Test-Time Scaling (TTS), a technique where a model generates multiple reasoning paths in parallel to find the best solution.
 &lt;/p&gt;
 &lt;p&gt;
  The model utilizes Deep Think with Confidence (DeepConf), which leverages the model&#x27;s internal confidence scores to dynamically prune low-quality reasoning traces.
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Adaptive Pruning:
    &lt;/b&gt;
    During generation, the system initiates a &quot;warm-up&quot; phase with 16 traces to establish a confidence baseline. It then aggressively filters subsequent traces, terminating any chain that falls below the 10th percentile of the baseline confidence.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Efficiency Gains:
    &lt;/b&gt;
    This method creates a new Pareto frontier for deployment. In benchmark tests, Falcon H1R 7B achieved 96.7% accuracy on AIME 25 while reducing token usage by 38% compared to the DeepSeek-R1-0528-Qwen3-8B baseline.
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;h2&gt;
  Licensing: Open For Commercial Usage, But With Strings Attached
 &lt;/h2&gt;
 &lt;p&gt;
  TII has released Falcon H1R 7B under the custom
  &lt;b&gt;
   Falcon LLM License 1.0
  &lt;/b&gt;
  based on Apache 2.0 — but with notable modifications — chiefly among them: not to litigate against TII, and also to always credit it.
 &lt;/p&gt;
 &lt;p&gt;
  For developers and startups, the license is largely permissive:
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Royalty-Free:
    &lt;/b&gt;
    Users can run, modify, and distribute the model commercially without paying TII.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Attribution:
    &lt;/b&gt;
    Any derivative work (including fine-tunes) must prominently state:
    &lt;i&gt;
     &quot;[Name of work] is built using Falcon LLM technology from the Technology Innovation Institute&quot;
    &lt;/i&gt;
    .
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;p&gt;
  However, unlike a pure Open Source Initiative (OSI) license, the Falcon license includes a strict Acceptable Use Policy (AUP).
 &lt;/p&gt;
 &lt;p&gt;
  The license terminates automatically if the model is used to create work that conflicts with the AUP or if the user initiates patent litigation against TII.
 &lt;/p&gt;
 &lt;p&gt;
  Specifically, the AUP prohibits using Falcon H1R 7B or its derivatives for:
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    Violating Laws: Any use that violates applicable national, federal, state, local, or international laws or regulations.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    Harm to Minors or Living Beings: Exploiting, harming, or attempting to exploit or harm minors or any living beings.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    Disinformation: Generating or disseminating verifiably false information with the purpose of harming others.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    Harassment: Defaming, disparaging, or otherwise harassing others.
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;h2&gt;
  The Hybrid Wave: Nvidia, IBM, AI21, and Mistral
 &lt;/h2&gt;
 &lt;p&gt;
  TII is not alone in betting on this hybrid future; the industry is increasingly moving toward architectures that blend the strengths of SSMs and Transformers.
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Nvidia
    &lt;/b&gt;
    recently debuted the
    &lt;a href=&quot;https://nvidianews.nvidia.com/news/nvidia-debuts-nemotron-3-family-of-open-models&quot;&gt;
     Nemotron 3 family
    &lt;/a&gt;
    on December 15, 2025, which utilizes a hybrid mixture-of-experts (MoE) and Mamba-Transformer design to drive efficient agentic AI.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     IBM
    &lt;/b&gt;
    launched its
    &lt;a href=&quot;https://newsroom.ibm.com/campaign?item=2416&quot;&gt;
     Granite 4.0 family
    &lt;/a&gt;
    on October 2, 2025, using a hybrid Mamba-Transformer architecture to cut memory requirements by over 70% while maintaining high performance on enterprise benchmarks.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     AI21
    &lt;/b&gt;
    has pursued this path with its Jamba (Joint Attention and Mamba) models, releasing the
    &lt;a href=&quot;https://cloud.google.com/blog/products/ai-machine-learning/jamba-1-5-model-family-from-ai21-labs-is-now-available-on-vertex-ai&quot;&gt;
     Jamba 1.5 family
    &lt;/a&gt;
    on August 22, 2024, to boost agentic AI capabilities through a hybrid SSM-Transformer approach.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Mistral
    &lt;/b&gt;
    entered the space early with
    &lt;a href=&quot;https://mistral.ai/news/codestral-mamba/&quot;&gt;
     Codestral Mamba
    &lt;/a&gt;
    on July 16, 2024, a model specifically optimized for faster, longer code generation.
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;p&gt;
  Falcon H1R 7B represents the latest evolution in this trend, specifically targeting dense reasoning tasks in a compact form factor.
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Nvidia just admitted the general-purpose GPU era is ending </title>
<link>https://venturebeat.com/infrastructure/inference-is-splitting-in-two-nvidias-usd20b-groq-bet-explains-its-next-act</link>
<pubDate>Mon, 05 Jan 2026 23:11:31 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;Groq disruption of the GPU&quot; data-nimg=&quot;1&quot; height=&quot;1024&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/3tWpekn9Sk9YGgDsob9YyB/73d4e0ae1c2864638b814778cf0c8cb7/ChatGPT_Image_Jan_2__2026__04_53_16_PM.png?w=1000&quot; width=&quot;1536&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  Nvidia’s $20 billion strategic licensing deal with Groq represents one of the first clear moves in a four-front fight over the future AI stack. 2026 is when that fight becomes obvious to enterprise builders.
 &lt;/p&gt;
 &lt;p&gt;
  For the technical decision-makers we talk to every day — the people building the AI applications and the data pipelines that drive them — this deal is a signal that the era of the one-size-fits-all GPU as the default AI inference answer is ending.
 &lt;/p&gt;
 &lt;div&gt;
  &lt;div data-exs-config=&#x27;{&quot;customParams&quot;:{&quot;post-type&quot;:&quot;article&quot;,&quot;post_id&quot;:&quot;FTGAPtGL4SbrvyO0mzyR6&quot;,&quot;post_cat&quot;:&quot;infrastructure&quot;}}&#x27;&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  We are entering the age of the
  &lt;b&gt;
   disaggregated inference architecture
  &lt;/b&gt;
  , where the silicon itself is being split into two different types to accommodate a world that demands both massive context and instantaneous reasoning.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Why inference is breaking the GPU architecture in two
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  To understand why Nvidia CEO Jensen Huang dropped one-third of his
  &lt;a href=&quot;https://www.sec.gov/Archives/edgar/data/1045810/000104581025000230/nvda-20251026.htm&quot;&gt;
   reported $60 billion cash pile
  &lt;/a&gt;
  on a licensing deal, you have to look at the existential threats converging on his company’s reported
  &lt;a href=&quot;https://www.idnfinancials.com/news/59312/jon-peddie-research-nvidia-still-dominates-92-global-gpu-market&quot;&gt;
   92% market share
  &lt;/a&gt;
  .
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  The industry reached a tipping point in late 2025: For the first time, inference — the phase where trained models actually run —
  &lt;a href=&quot;https://www.deloitte.com/us/en/insights/industry/technology/technology-media-and-telecom-predictions/2026/compute-power-ai.html?utm_source=chatgpt.com&quot;&gt;
   surpassed training in terms of total data center revenue
  &lt;/a&gt;
  , according to Deloitte. In this new &quot;Inference Flip,&quot; the metrics have changed. While accuracy remains the baseline, the battle is now being fought over latency and the ability to maintain &quot;state&quot; in autonomous agents.
 &lt;/p&gt;
 &lt;p&gt;
  There are four fronts of that battle, and each front points to the same conclusion: Inference workloads are fragmenting faster than GPUs can generalize.
 &lt;/p&gt;
 &lt;h3&gt;
  &lt;b&gt;
   1. Breaking the GPU in two: Prefill vs. decode
  &lt;/b&gt;
 &lt;/h3&gt;
 &lt;p&gt;
  Gavin Baker, an investor in Groq (and therefore biased, but also unusually fluent on the architecture),
  &lt;a href=&quot;https://x.com/GavinSBaker/status/2004562536918598000&quot;&gt;
   summarized
  &lt;/a&gt;
  the core driver of the Groq deal cleanly: “Inference is disaggregating into prefill and decode.”
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Prefill
  &lt;/b&gt;
  and
  &lt;b&gt;
   decode
  &lt;/b&gt;
  are two distinct phases:
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     The prefill phase:
    &lt;/b&gt;
    Think of this as the user’s &quot;prompt&quot; stage. The model must ingest massive amounts of data — whether it&#x27;s a 100,000-line codebase or an hour of video — and compute a contextual understanding. This is &quot;compute-bound,&quot; requiring massive matrix multiplication that Nvidia’s GPUs are historically excellent at.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     The generation (decode) phase:
    &lt;/b&gt;
    This is the actual token-by-token &quot;generation.” Once the prompt is ingested, the model generates one word (or token) at a time, feeding each one back into the system to predict the next. This is &quot;memory-bandwidth bound.&quot; If the data can&#x27;t move from the memory to the processor fast enough, the model stutters, no matter how powerful the GPU is. (This is where Nvidia was weak, and where Groq’s special language processing unit (LPU) and its related SRAM memory, shines. More on that in a bit.)
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;p&gt;
  Nvidia has
  &lt;a href=&quot;https://developer.nvidia.com/blog/nvidia-rubin-cpx-accelerates-inference-performance-and-efficiency-for-1m-token-context-workloads/&quot;&gt;
   announced an upcoming
   &lt;b&gt;
    Vera Rubin
   &lt;/b&gt;
   family of chips
  &lt;/a&gt;
  that it’s architecting specifically to handle this split. The
  &lt;b&gt;
   Rubin CPX
  &lt;/b&gt;
  component of this family is the designated &quot;prefill&quot; workhorse, optimized for massive context windows of 1 million tokens or more. To handle this scale affordably, it moves away from the eye-watering expense of
  &lt;b&gt;
   high bandwidth memory (HBM)
  &lt;/b&gt;
  — Nvidia’s current gold-standard memory that sits right next to the GPU die — and instead utilizes 128GB of a new kind of memory,
  &lt;b&gt;
   GDDR7
  &lt;/b&gt;
  . While HBM provides extreme speed (though not as quick as Groq’s static random-access memory (SRAM)), its supply on GPUs is limited and its cost is a barrier to scale; GDDR7 provides a more cost-effective way to ingest massive datasets.
 &lt;/p&gt;
 &lt;p&gt;
  Meanwhile, the &quot;Groq-flavored&quot; silicon, which Nvidia is integrating into its inference roadmap, will serve as the high-speed &quot;decode&quot; engine. This is about neutralizing a threat from alternative architectures like Google&#x27;s TPUs and maintaining the dominance of
  &lt;b&gt;
   CUDA,
  &lt;/b&gt;
  Nvidia’s software ecosystem that has served as its primary moat for over a decade.
 &lt;/p&gt;
 &lt;p&gt;
  All of this was enough for Baker, the Groq investor, to predict that Nvidia’s move to license Groq will cause all other specialized AI chips to be canceled — that is, outside of Google’s TPU, Tesla’s AI5, and AWS’s Trainium.
 &lt;/p&gt;
 &lt;h3&gt;
  &lt;b&gt;
   2. The differentiated power of SRAM
  &lt;/b&gt;
 &lt;/h3&gt;
 &lt;p&gt;
  At the heart of Groq’s technology is
  &lt;b&gt;
   SRAM
  &lt;/b&gt;
  . Unlike the DRAM found in your PC or the HBM on an Nvidia H100 GPU, SRAM is etched directly into the logic of the processor.
 &lt;/p&gt;
 &lt;p&gt;
  Michael Stewart, managing partner of Microsoft’s venture fund, M12, describes SRAM as the best for moving data over short distances with minimal energy. &quot;The energy to move a bit in SRAM is like 0.1 picojoules or less,&quot; Stewart said. &quot;To move it between DRAM and the processor is more like 20 to 100 times worse.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  In the world of 2026, where agents must reason in real-time, SRAM acts as the ultimate &quot;scratchpad&quot;: a high-speed workspace where the model can manipulate symbolic operations and complex reasoning processes without the &quot;wasted cycles&quot; of external memory shuttling.
 &lt;/p&gt;
 &lt;p&gt;
  However, SRAM has a major drawback: it is physically bulky and expensive to manufacture, meaning its capacity is limited compared to DRAM. This is where Val Bercovici, chief AI officer at Weka, another company offering memory for GPUs, sees the market segmenting.
 &lt;/p&gt;
 &lt;p&gt;
  Groq-friendly AI workloads — where SRAM has the advantage — are those that use small models of 8 billion parameters and below, Bercovici said. This isn’t a small market, though. “It’s just a giant market segment that was not served by Nvidia, which was edge inference, low latency, robotics, voice, IoT devices — things we want running on our phones without the cloud for convenience, performance, or privacy,&quot; he said.
 &lt;/p&gt;
 &lt;p&gt;
  This 8B &quot;sweet spot&quot; is significant because 2025 saw an explosion in
  &lt;b&gt;
   model distillation
  &lt;/b&gt;
  , where many enterprise companies are
  &lt;a href=&quot;https://venturebeat.com/technology/inside-linkedins-generative-ai-cookbook-how-it-scaled-people-search-to-1-3&quot;&gt;
   shrinking massive models into highly efficient smaller versions
  &lt;/a&gt;
  . While SRAM isn&#x27;t practical for the trillion-parameter &quot;frontier&quot; models, it is perfect for these smaller, high-velocity models.
 &lt;/p&gt;
 &lt;h3&gt;
  &lt;b&gt;
   3. The Anthropic threat: The rise of the ‘portable stack’
  &lt;/b&gt;
 &lt;/h3&gt;
 &lt;p&gt;
  Perhaps the most under-appreciated driver of this deal is Anthropic’s success in making its stack portable across accelerators.
 &lt;/p&gt;
 &lt;p&gt;
  The company has
  &lt;a href=&quot;https://www.anthropic.com/news/expanding-our-use-of-google-cloud-tpus-and-services&quot;&gt;
   pioneered a portable engineering approach
  &lt;/a&gt;
  for training and inference — basically a software layer that allows its Claude models to run across multiple AI accelerator families — including Nvidia’s GPUs and
  &lt;a href=&quot;https://venturebeat.com/ai/the-new-ai-calculus-googles-80-cost-edge-vs-openais-ecosystem&quot;&gt;
   Google’s Ironwood TPUs
  &lt;/a&gt;
  . Until recently, Nvidia&#x27;s dominance was protected because running high-performance models outside of the Nvidia stack was a technical nightmare. “It’s Anthropic,” Weka’s Bercovici told me. “The fact that Anthropic was able to … build up a software stack that could work on TPUs as well as on GPUs, I don’t think that’s being appreciated enough in the marketplace.”
 &lt;/p&gt;
 &lt;p&gt;
  (Disclosure: Weka has been a sponsor of VentureBeat events.)
 &lt;/p&gt;
 &lt;p&gt;
  Anthropic recently committed to accessing up to
  &lt;b&gt;
   1 million TPUs
  &lt;/b&gt;
  from Google, representing over a gigawatt of compute capacity. This multi-platform approach ensures the company isn&#x27;t held hostage by Nvidia&#x27;s pricing or supply constraints. So for Nvidia, the Groq deal is equally a defensive move. By integrating Groq’s ultra-fast inference IP, Nvidia is making sure that the most performance-sensitive workloads — like those running small models or as part of real-time agents — can be accommodated within Nvidia’s CUDA ecosystem, even as competitors try to jump ship to Google&#x27;s Ironwood TPUs. CUDA is the special software Nvidia provides to developers to integrate GPUs.
 &lt;/p&gt;
 &lt;h3&gt;
  &lt;b&gt;
   4. The agentic ‘statehood’ war: Manus and the KV Cache
  &lt;/b&gt;
 &lt;/h3&gt;
 &lt;p&gt;
  The timing of this Groq deal coincides with
  &lt;a href=&quot;https://venturebeat.com/orchestration/why-meta-bought-manus-and-what-it-means-for-your-enterprise-ai-agent&quot;&gt;
   Meta’s acquisition of the agent pioneer
   &lt;b&gt;
    Manus
   &lt;/b&gt;
   just two days ago
  &lt;/a&gt;
  . The significance of Manus was partly its obsession with
  &lt;b&gt;
   statefulness
  &lt;/b&gt;
  .
 &lt;/p&gt;
 &lt;p&gt;
  If an agent can’t remember what it did 10 steps ago, it is useless for real-world tasks like market research or software development.
  &lt;b&gt;
   KV Cache (Key-Value Cache)
  &lt;/b&gt;
  is the &quot;short-term memory&quot; that an LLM builds during the prefill phase.
 &lt;/p&gt;
 &lt;p&gt;
  Manus
  &lt;a href=&quot;https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus&quot;&gt;
   reported
  &lt;/a&gt;
  that for production-grade agents,
  &lt;b&gt;
   the ratio of input tokens to output tokens can reach 100:1
  &lt;/b&gt;
  . This means for every word an agent says, it is &quot;thinking&quot; and &quot;remembering&quot; 100 others. In this environment, the KV Cache hit rate is the single most important metric for a production agent, Manus said. If that cache is &quot;evicted&quot; from memory, the agent loses its train of thought, and the model must burn massive energy to recompute the prompt.
 &lt;/p&gt;
 &lt;p&gt;
  Groq’s SRAM can be a &quot;scratchpad&quot; for these agents — although, again, mostly for smaller models — because it allows for the near-instant retrieval of that state. Combined with
  &lt;a href=&quot;https://nvidianews.nvidia.com/news/nvidia-dynamo-open-source-library-accelerates-and-scales-ai-reasoning-models&quot;&gt;
   Nvidia&#x27;s
   &lt;b&gt;
    Dynamo
   &lt;/b&gt;
   framework
  &lt;/a&gt;
  and the KVBM, Nvidia is building an &quot;inference operating system&quot; that enables inference servers to tier this state across SRAM, DRAM, HBM, and other flash-based offerings like that from Bercovici’s Weka.
 &lt;/p&gt;
 &lt;p&gt;
  Thomas Jorgensen, senior director of Technology Enablement at Supermicro, which specializes in building clusters of GPUs for large enterprise companies, told me in September that compute is no longer the primary bottleneck for advanced clusters. Feeding data to GPUs was the bottleneck, and breaking that bottleneck requires memory.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;The whole cluster is now the computer,&quot; Jorgensen said. &quot;Networking becomes an internal part of the beast … feeding the beast with data is becoming harder because the bandwidth between GPUs is growing faster than anything else.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  This is why Nvidia is pushing into disaggregated inference. By separating the workloads, enterprise applications can use specialized storage tiers to feed data at memory-class performance, while the specialized &quot;Groq-inside&quot; silicon handles the high-speed token generation.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   The verdict for 2026
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  We are entering an era of extreme specialization. For decades, incumbents could win by shipping one dominant general-purpose architecture — and their blind spot was often what they ignored on the edges. Intel’s long neglect of low-power is the classic example, Michael Stewart, managing partner of Microsoft’s venture fund M12, told me. Nvidia is signaling it won’t repeat that mistake. “If even the leader, even the lion of the jungle will acquire talent, will acquire technology — it’s a sign that the whole market is just wanting more options,” Stewart said.
 &lt;/p&gt;
 &lt;p&gt;
  For technical leaders, the message is to
  &lt;b&gt;
   stop architecting your stack like it’s one rack, one accelerator, one answer
  &lt;/b&gt;
  . In 2026, advantage will go to the teams that label workloads explicitly — and route them to the right tier:
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    prefill-heavy vs. decode-heavy
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    long-context vs. short-context
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    interactive vs. batch
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    small-model vs. large-model
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    edge constraints vs. data-center assumptions
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;p&gt;
  Your architecture will follow those labels. In 2026, “GPU strategy” stops being a purchasing decision and becomes a routing decision. The winners won’t ask which chip they bought — they’ll ask where every token ran, and why.
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Agent autonomy without guardrails is an SRE nightmare </title>
<link>https://venturebeat.com/infrastructure/agent-autonomy-without-guardrails-is-an-sre-nightmare</link>
<pubDate>Sat, 27 Dec 2025 20:23:02 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;Three Steps to Responsible Agentic AI Adoption &quot; data-nimg=&quot;1&quot; height=&quot;816&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/rxbKNH1o8tpwpScizzIEV/87402fa2b986b713ae0b029f2725250f/Building_agents.png?w=1000&quot; width=&quot;1456&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
    &lt;p&gt;
     CleoJ made with Midjourney.
    &lt;/p&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  &lt;i&gt;
   João Freitas is GM and VP of engineering for AI and automation at
  &lt;/i&gt;
  &lt;a href=&quot;https://www.pagerduty.com/&quot;&gt;
   &lt;i&gt;
    PagerDuty
   &lt;/i&gt;
  &lt;/a&gt;
 &lt;/p&gt;
 &lt;p&gt;
  As AI use continues to evolve in large organizations, leaders are increasingly seeking the next development that will yield major ROI. The latest wave of this ongoing trend is the adoption of AI agents. However, as with any new technology, organizations must ensure they adopt AI agents in a responsible way that allows them to facilitate both speed and security.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://venturebeat.com/ai/hiring-specialists-made-sense-before-ai-now-generalists-win&quot;&gt;
   More than half
  &lt;/a&gt;
  of organizations have already deployed AI agents to some extent, with more expecting to follow suit in the next two years. But many early adopters are now reevaluating their approach. Four-in-10 tech leaders regret not establishing a
  &lt;a href=&quot;https://venturebeat.com/ai/why-observable-ai-is-the-missing-sre-layer-enterprises-need-for-reliable&quot;&gt;
   stronger governance foundation
  &lt;/a&gt;
  from the start, which suggests they adopted AI rapidly, but with margin to improve on policies, rules and best practices designed to ensure the responsible, ethical and legal development and use of AI.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://venturebeat.com/ai/hiring-specialists-made-sense-before-ai-now-generalists-win&quot;&gt;
   As AI adoption accelerates
  &lt;/a&gt;
  , organizations must find the right balance between their exposure risk and the implementation of guardrails to ensure AI use is secure.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Where do AI agents create potential risks?
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  There are three principal areas of consideration for safer AI adoption.
 &lt;/p&gt;
 &lt;p&gt;
  The first is
  &lt;a href=&quot;https://venturebeat.com/security/shadow-ai-doubles-every-18-months-creating-blind-spots-socs-never-see&quot;&gt;
   shadow AI
  &lt;/a&gt;
  , when employees use unauthorized AI tools without express permission, bypassing approved tools and processes. IT should create necessary processes for experimentation and innovation to introduce more efficient ways of working with AI. While shadow AI has existed as long as AI tools themselves, AI agent autonomy makes it easier for unsanctioned tools to operate outside the purview of IT, which can introduce fresh security risks.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  Secondly, organizations must close gaps in AI ownership and accountability to prepare for incidents or processes gone wrong. The strength of AI agents lies in their autonomy. However, if agents act in unexpected ways, teams must be able to determine who is responsible for addressing any issues.
 &lt;/p&gt;
 &lt;p&gt;
  The third risk arises when there is a lack of explainability for actions AI agents have taken.
  &lt;a href=&quot;https://venturebeat.com/ai/ontology-is-the-real-guardrail-how-to-stop-ai-agents-from-misunderstanding&quot;&gt;
   AI agents are goal-oriented
  &lt;/a&gt;
  , but how they accomplish their goals can be unclear. AI agents must have explainable logic underlying their actions so that engineers can trace and, if needed, roll back actions that may cause issues with existing systems.
 &lt;/p&gt;
 &lt;p&gt;
  While none of these risks should delay adoption, they will help organizations better ensure their security.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   The three guidelines for responsible AI agent adoption
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Once organizations have identified the risks AI agents can pose, they must implement guidelines and guardrails to ensure safe usage. By following these three steps, organizations can minimize these risks.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   1: Make human oversight the default
  &lt;/b&gt;
 &lt;/p&gt;
 &lt;p&gt;
  AI agency continues to evolve at a fast pace. However, we still need human oversight when AI agents are given the  capacity to act, make decisions and pursue a goal that may impact key systems. A human should be in the loop by default, especially for business-critical use cases and systems. The teams that use AI must understand the actions it may take and where they may need to intervene. Start conservatively and, over time, increase the level of agency given to AI agents.
 &lt;/p&gt;
 &lt;p&gt;
  In conjunction, operations teams, engineers and security professionals must understand the role they play in supervising AI agents’ workflows. Each agent should be assigned a specific human owner for clearly defined oversight and accountability. Organizations must also allow any human to flag or override an AI agent’s behavior when an action has a negative outcome.
 &lt;/p&gt;
 &lt;p&gt;
  When considering tasks for AI agents, organizations should understand that, while traditional automation is good at handling repetitive, rule-based processes with structured data inputs, AI agents can handle much more complex tasks and adapt to new information in a more autonomous way. This makes them an appealing solution for all sorts of tasks. But as AI agents are deployed, organizations should control what actions the agents can take, particularly in the early stages of a project. Thus, teams working with AI agents should have approval paths in place for high-impact actions to ensure agent scope does not extend beyond expected use cases, minimizing risk to the wider system.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   2: Bake in security
  &lt;/b&gt;
 &lt;/p&gt;
 &lt;p&gt;
  The introduction of new tools should not expose a system to fresh security risks.
 &lt;/p&gt;
 &lt;p&gt;
  Organizations should consider agentic platforms that comply with high security standards and are validated by enterprise-grade certifications such as SOC2, FedRAMP or equivalent. Further, AI agents should not be allowed free rein across an organization’s systems. At a minimum, the permissions and security scope of an AI agent must be aligned with the scope of the owner, and any tools added to the agent should not allow for extended permissions. Limiting AI agent access to a system based on their role will also ensure deployment runs smoothly. Keeping complete logs of every action taken by an AI agent can also help engineers understand what happened in the event of an incident and trace back the problem.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   3: Make outputs explainable
  &lt;/b&gt;
 &lt;/p&gt;
 &lt;p&gt;
  AI use in an organization must never be a black box. The reasoning behind any action must be illustrated so that any engineer who tries to access it can understand the context the agent used for decision-making and access the traces that led to those actions.
 &lt;/p&gt;
 &lt;p&gt;
  I
  &lt;!-- --&gt;
  nputs and outputs for every action should be logged and accessible. This will help organizations establish a firm overview of the logic underlying an AI agent’s actions, providing significant value in the event anything goes wrong.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Security underscores AI agents’ success
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  AI agents offer a huge opportunity for organizations to accelerate and improve their existing processes. However, if they do not prioritize security and strong governance, they could expose themselves to new risks.
 &lt;/p&gt;
 &lt;p&gt;
  As AI agents become more common, organizations must ensure they have systems in place to measure how they perform and the ability to take action when they create problems.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;i&gt;
   Read more from our
  &lt;/i&gt;
  &lt;a href=&quot;https://venturebeat.com/datadecisionmakers&quot;&gt;
   &lt;i&gt;
    guest writers
   &lt;/i&gt;
  &lt;/a&gt;
  &lt;i&gt;
   . Or, consider submitting a post of your own! See our
  &lt;/i&gt;
  &lt;a href=&quot;https://venturebeat.com/guest-posts&quot;&gt;
   &lt;i&gt;
    guidelines here
   &lt;/i&gt;
  &lt;/a&gt;
  &lt;i&gt;
   .
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;br/&gt;
 &lt;br/&gt;
 &lt;p&gt;
  Welcome to the VentureBeat community!
 &lt;/p&gt;
 &lt;p&gt;
  Our guest posting program is where technical experts share insights and provide neutral, non-vested deep dives on AI, data infrastructure, cybersecurity and other cutting-edge technologies shaping the future of enterprise.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;a href=&quot;/category/DataDecisionMakers&quot;&gt;
   Read more
  &lt;/a&gt;
  &lt;!-- --&gt;
  from our guest post program — and check out our
  &lt;!-- --&gt;
  &lt;a href=&quot;/guest-posts&quot;&gt;
   guidelines
  &lt;/a&gt;
  &lt;!-- --&gt;
  if you’re interested in contributing an article of your own!
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> The $1 trillion AI problem: Why Snowflake, Tableau and BlackRock are giving away their data secrets </title>
<link>https://venturebeat.com/data-infrastructure/the-usd1-trillion-ai-problem-why-snowflake-tableau-and-blackrock-are-giving</link>
<pubDate>Mon, 22 Dec 2025 12:52:08 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;Credit: VentureBeat made with Midjourney&quot; data-nimg=&quot;1&quot; height=&quot;786&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/2eS4VfoIOmGMSqzBY952lz/4aee7d7635002d50f41173ecde2d1b0d/nuneybits_Vector_art_of_a_global_alliance_open_source_912a701f-73b6-47ba-b440-341a71779076.webp?w=1000&quot; width=&quot;1403&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
    &lt;p&gt;
     Credit: VentureBeat made with Midjourney
    &lt;/p&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://www.snowflake.com/en/&quot;&gt;
   &lt;u&gt;
    Snowflake
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.salesforce.com/&quot;&gt;
   &lt;u&gt;
    Salesforce
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.getdbt.com/&quot;&gt;
   &lt;u&gt;
    dbt Labs
   &lt;/u&gt;
  &lt;/a&gt;
  and more than a dozen other technology companies announced Tuesday they will create a universal standard for how business data is defined and shared across platforms — solving what executives call AI&#x27;s most fundamental bottleneck.
 &lt;/p&gt;
 &lt;p&gt;
  The
  &lt;a href=&quot;https://www.snowflake.com/en/blog/open-semantic-interchange-ai-standard/&quot;&gt;
   &lt;u&gt;
    Open Semantic Interchange
   &lt;/u&gt;
  &lt;/a&gt;
  (OSI) initiative brings together fierce competitors who have concluded that inconsistent data definitions across enterprise systems block AI scalability. The effort includes backing from
  &lt;a href=&quot;https://www.blackrock.com/us/individual&quot;&gt;
   &lt;u&gt;
    BlackRock
   &lt;/u&gt;
  &lt;/a&gt;
  and participation from companies including
  &lt;a href=&quot;https://www.alation.com/&quot;&gt;
   &lt;u&gt;
    Alation
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://atlan.com/&quot;&gt;
   &lt;u&gt;
    Atlan
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://blueyonder.com/&quot;&gt;
   &lt;u&gt;
    Blue Yonder
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://cube.dev/&quot;&gt;
   &lt;u&gt;
    Cube
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://hex.tech/&quot;&gt;
   &lt;u&gt;
    Hex
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://honeydew.ai/&quot;&gt;
   &lt;u&gt;
    Honeydew
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://mistral.ai/&quot;&gt;
   &lt;u&gt;
    Mistral AI
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://omni.co/&quot;&gt;
   &lt;u&gt;
    Omni
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://relational.ai/&quot;&gt;
   &lt;u&gt;
    RelationalAI
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.selectstar.com/&quot;&gt;
   &lt;u&gt;
    Select Star
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.sigmacomputing.com/&quot;&gt;
   &lt;u&gt;
    Sigma
   &lt;/u&gt;
  &lt;/a&gt;
  , and
  &lt;a href=&quot;https://www.thoughtspot.com/&quot;&gt;
   &lt;u&gt;
    ThoughtSpot
   &lt;/u&gt;
  &lt;/a&gt;
  . Together, they will establish the first vendor-neutral specification for semantic metadata — a Rosetta Stone for business data.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;We&#x27;re not in the business of locking data in, we&#x27;re in the business of making it accessible and valuable,&quot; Christian Kleinerman, Snowflake&#x27;s executive vice president of product, told VentureBeat in an exclusive interview. &quot;The biggest barrier our customers face when it comes to ROI from AI isn&#x27;t a competitor — it&#x27;s data fragmentation.&quot;
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Every AI model fails when sales and marketing can&#x27;t agree what &#x27;customer&#x27; means
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The initiative tackles a problem that has plagued enterprises since the dawn of business computing but now threatens AI adoption: Every software system defines business metrics differently. A retailer&#x27;s sales platform might classify an &quot;active customer&quot; as someone who purchased within 90 days, while its marketing system defines the same term as anyone who engaged with content in the past month. AI models trained on both systems produce unreliable predictions and destroy trust in AI-generated insights.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Picture a business training AI models to predict something like customer churn,&quot; Kleinerman explained. &quot;When an AI model pulls data from both [systems with different definitions], it&#x27;s going to end up with conflicting definitions. That inconsistency makes AI less accurate and harder to scale.&quot;
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  This semantic chaos costs enterprises millions. Data and AI teams spend weeks reconciling conflicting definitions and reformatting data before AI projects can begin — driving up operational costs and delaying time-to-market for AI applications. Many enterprises find the promise of AI as a productivity multiplier destroyed by the manual labor required to prepare inconsistent data.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Tableau and Snowflake put competition aside to fix the data ecosystem
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The collaboration breaks traditional competitive dynamics in enterprise software.
  &lt;a href=&quot;https://www.tableau.com/&quot;&gt;
   &lt;u&gt;
    Tableau
   &lt;/u&gt;
  &lt;/a&gt;
  , Salesforce&#x27;s business intelligence division that competes directly with several OSI participants, co-leads the initiative alongside Snowflake.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;This initiative is transformative because it&#x27;s not about one company owning the standard—it&#x27;s about the industry coming together,&quot; Southard Jones, Tableau&#x27;s chief product officer, told VentureBeat in an exclusive interview. &quot;The future of AI depends on trust — and trust starts with consistent, reliable data.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Jones revealed that Tableau will contribute its blueprint for a vendor-neutral semantic layer, built on decades of experience creating business intelligence tools. &quot;Our work has always been about giving data clear business meaning — defining metrics, business logic, and context in a way that people across the enterprise can trust. With OSI, we&#x27;re taking that knowledge and codifying it into an open standard.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The decision to pursue an open, collaborative approach acknowledges that proprietary semantic standards have failed. &quot;What makes it a first of its kind is its focus on SQL-based analytical models and its inclusion of AI-specific metadata, such as custom instructions and synonyms,&quot; Kleinerman noted. Existing metadata standards like RDF and OWL lack the compilation engines necessary for modern AI applications.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   The technical blueprint promises immediate compatibility with existing tools
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  OSI targets the semantic layer — the business meaning of data rather than just its technical properties. The specification uses YAML file definitions, enabling immediate compatibility with existing tools like dbt&#x27;s
  &lt;a href=&quot;https://www.getdbt.com/blog/semantic-layer-introduction&quot;&gt;
   &lt;u&gt;
    Semantic Layer
   &lt;/u&gt;
  &lt;/a&gt;
  .
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Our support for this will be almost-immediate,&quot; Ryan Segar, dbt Labs&#x27; chief product officer, told VentureBeat. &quot;Data and analytics engineers will now be able to work with the confidence that their work will be leverageable across the data ecosystem. Re-work and double work will be a thing of the past.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The standard includes AI-specific features such as natural language synonyms and business terms. &quot;Today, AI models are often forced to infer relationships from raw metadata, which can lead to misinterpretations and inaccurate outputs,&quot; explained Francois Lopitaux, ThoughtSpot&#x27;s senior vice president of product management, in an exclusive interview. &quot;By providing a universal, open standard, the OSI will give AI agents—including our own Spotter—a common language to understand business context.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Major enterprises demand solutions as AI investments stall on bad data
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Enterprise demand for AI capabilities drives the urgency behind OSI. Snowflake reported that nearly
  &lt;a href=&quot;https://www.snowflake.com/en/news/press-releases/snowflake-reports-financial-results-for-the-second-quarter-of-fiscal-2026/&quot;&gt;
   &lt;u&gt;
    half of new customers in Q2 fiscal 2026
   &lt;/u&gt;
  &lt;/a&gt;
  chose the platform for AI capabilities, with over 6,100 customers using its AI offerings weekly. The company
  &lt;a href=&quot;https://www.snowflake.com/en/news/press-releases/snowflake-reports-financial-results-for-the-second-quarter-of-fiscal-2026/&quot;&gt;
   &lt;u&gt;
    surpassed $1 billion
   &lt;/u&gt;
  &lt;/a&gt;
  in quarterly revenue for the first time in May, driven largely by AI-related demand.
 &lt;/p&gt;
 &lt;p&gt;
  A dedicated partner taskforce has formed to deliver the first OSI specification, though executives declined to provide a specific timeline. &quot;Initial customer response to OSI has been overwhelmingly positive,&quot; Kleinerman said, noting strong interest from organizations wanting early adoption.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://www.blackrock.com/&quot;&gt;
   &lt;u&gt;
    BlackRock
   &lt;/u&gt;
  &lt;/a&gt;
  sees immediate applications for the standard in financial services. &quot;The Aladdin platform unifies the investment management process through a common data language across public and private markets,&quot; said Diwakar Goel, BlackRock&#x27;s global head of Aladdin Data. &quot;We are excited to be part of the Open Semantic Interchange to help establish a common, vendor-neutral specification that will not only streamline data exchange but also accelerate the adoption of AI and business intelligence applications across the financial industry.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Standardized data definitions will intensify rather than reduce competition
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The initiative changes how software companies will compete. Executives argue that standardization will intensify competition by shifting the battleground from data definitions to innovation in user experience and AI capabilities.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Standardization isn&#x27;t a commoditizer — it&#x27;s a catalyst,&quot; Jones argued. &quot;Think of it like a standard electrical outlet: the outlet itself isn&#x27;t the innovation, it&#x27;s what you plug into it. Our focus is on being the most intelligent, intuitive, and powerful &#x27;appliance&#x27; you can connect to your data.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Tableau plans to accelerate development of what Jones calls &quot;agentic analytics&quot;—AI agents that surface context, highlight opportunities, flag risks, and suggest next steps rather than just reporting numbers. &quot;Semantic definitions transform AI agents from static tools into analytical partners,&quot; he said.
 &lt;/p&gt;
 &lt;p&gt;
  ThoughtSpot&#x27;s Lopitaux agreed: &quot;While OSI will set a vendor-agnostic industry standard to semantic layers, we will continue to compete on product innovation, user experience across our entire platform, and delivering unprecedented customer value.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   The industry bets its future on cooperation over control
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  OSI&#x27;s success depends on maintaining vendor-neutral governance — a challenge given the participating companies&#x27; varying market positions and strategic interests. &quot;The whole point of OSI is that no single vendor controls it,&quot; Kleinerman emphasized. &quot;Every member is responsible for maintaining their own mappings and integrations, and the value comes from the shared framework, not from any one company&#x27;s implementation.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Enterprise customers stand to gain the most: faster AI deployment, greater accuracy, and elimination of manual data reconciliation costs. Companies can preserve existing investments in semantic models while adopting best-of-breed technologies without sacrificing consistency.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;When semantics are available everywhere, from anywhere, the place where they &#x27;live&#x27; becomes less relevant,&quot; noted dbt Labs&#x27; Segar. &quot;Built anywhere, leveraged everywhere.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The technology industry has decided that AI&#x27;s promise demands an unusual sacrifice: giving up proprietary control of how business data gets defined. The companies betting billions on AI have concluded that owning a piece of a working system beats controlling all of a broken one.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;We encourage and welcome more companies to join,&quot; Kleinerman said, &quot;because the more perspectives at the table, the stronger and more neutral the standard becomes.&quot;
 &lt;/p&gt;
 &lt;p&gt;
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Perplexity launches massive search API to take on Google’s dominance </title>
<link>https://venturebeat.com/data-infrastructure/perplexity-launches-massive-search-api-to-take-on-googles-dominance</link>
<pubDate>Mon, 22 Dec 2025 12:52:05 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;Credit: VentureBeat made with Midjourney&quot; data-nimg=&quot;1&quot; height=&quot;786&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/TJzhOSjHWACLlqpbvzUQJ/028aabb0e8ca7a5c1f9d8b0e3d02d5ec/nuneybits_Vector_art_of_magnifying_glass_pixel_d2f4bcc0-7d79-4671-b1e6-13421527978a.webp?w=1000&quot; width=&quot;1403&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://www.perplexity.ai/&quot;&gt;
   &lt;u&gt;
    Perplexity AI
   &lt;/u&gt;
  &lt;/a&gt;
  launched a comprehensive
  &lt;a href=&quot;https://www.perplexity.ai/hub/blog/introducing-the-perplexity-search-api&quot;&gt;
   &lt;u&gt;
    search application programming interface
   &lt;/u&gt;
  &lt;/a&gt;
  on Thursday, giving developers direct access to the same massive web index that powers the startup&#x27;s answer engine and potentially breaking the stranglehold that tech giants have maintained over global search data.
 &lt;/p&gt;
 &lt;p&gt;
  The
  &lt;a href=&quot;https://www.perplexity.ai/hub/blog/introducing-the-perplexity-search-api&quot;&gt;
   &lt;u&gt;
    Search API
   &lt;/u&gt;
  &lt;/a&gt;
  poses the most significant challenge yet to Google&#x27;s dominance in providing search infrastructure to developers, offering access to an index spanning hundreds of billions of web pages with real-time updates and AI-optimized results formatting. The move comes as Perplexity positions itself as a disruptive force in the search industry, following its audacious
  &lt;a href=&quot;https://www.cnbc.com/2025/08/12/perplexity-google-chrome-ai.html&quot;&gt;
   &lt;u&gt;
    $34.5 billion bid for Google&#x27;s Chrome browser
   &lt;/u&gt;
  &lt;/a&gt;
  in August.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Legacy search engines have kept developers beholden to their interests, namely favoring commercial intent traffic over helpful content,&quot; said Beejoli Shah, a spokesperson for Perplexity. The company argues that established players have systematically limited developer access to search indexes while newer startups lack the scale to provide meaningful alternatives.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;h2&gt;
  &lt;b&gt;
   How Perplexity plans to end Google&#x27;s search data stranglehold
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The launch addresses a critical infrastructure gap that has emerged as artificial intelligence applications proliferate. Developers building AI-powered products have struggled to access high-quality, comprehensive search data without relying on Google&#x27;s increasingly restrictive APIs or Microsoft&#x27;s Bing search infrastructure. Traditional search providers have tightened access controls and frequently discontinued services that developers depended on, forcing many to build inferior products or abandon projects entirely.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://www.perplexity.ai/hub/blog/introducing-the-perplexity-search-api&quot;&gt;
   &lt;u&gt;
    Perplexity&#x27;s API
   &lt;/u&gt;
  &lt;/a&gt;
  differentiates itself through several technical innovations designed specifically for the AI era. The system processes tens of thousands of updates per second, making new content searchable within seconds rather than the hours or days typical of traditional search engines. This real-time capability addresses one of the most persistent problems in search: content staleness.
 &lt;/p&gt;
 &lt;p&gt;
  The API also implements what Perplexity calls &quot;
  &lt;a href=&quot;https://www.perplexity.ai/hub/blog/introducing-the-perplexity-search-api&quot;&gt;
   &lt;u&gt;
    sub-document precision
   &lt;/u&gt;
  &lt;/a&gt;
  ,&quot; identifying and ranking specific passages within web pages rather than entire documents. This approach aligns with how large language models consume information, providing more targeted and contextually relevant results than conventional search systems that return lists of links.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Real-time indexing and AI-powered results: the technical edge
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The underlying infrastructure combines keyword and semantic search capabilities, enabling what Perplexity terms &quot;
  &lt;a href=&quot;https://www.perplexity.ai/hub/blog/introducing-the-perplexity-search-api&quot;&gt;
   &lt;u&gt;
    hybrid retrieval
   &lt;/u&gt;
  &lt;/a&gt;
  .&quot; This approach allows the system to understand complex, conversational queries while maintaining the precision of traditional keyword matching. Results are returned in a structured, citation-rich format specifically designed for integration with AI applications and traditional web services.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Instead of just links, Search API surfaces the most relevant snippets from pages and sub-pages, ensuring that users get the most contextual answers possible, with source attribution built-in,&quot; the company explained. This citation system addresses growing concerns about AI applications that provide information without crediting original sources, potentially benefiting content creators who have seen their work reproduced without attribution.
 &lt;/p&gt;
 &lt;p&gt;
  To support developer adoption, Perplexity has launched a comprehensive
  &lt;a href=&quot;https://www.perplexity.ai/api-platform&quot;&gt;
   &lt;u&gt;
    API platform
   &lt;/u&gt;
  &lt;/a&gt;
  housing developer consoles and documentation for both its Search and Sonar APIs. The company also released an open-source evaluation framework called &quot;
  &lt;a href=&quot;https://github.com/perplexityai/search_evals/&quot;&gt;
   &lt;u&gt;
    search_evals
   &lt;/u&gt;
  &lt;/a&gt;
  &quot; that allows developers to benchmark any search API for quality and performance before committing resources.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   From answer engine to tech giant: Perplexity&#x27;s billion-dollar ambitions
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The
  &lt;a href=&quot;https://www.perplexity.ai/hub/blog/introducing-the-perplexity-search-api&quot;&gt;
   &lt;u&gt;
    Search API
   &lt;/u&gt;
  &lt;/a&gt;
  launch continues Perplexity&#x27;s rapid expansion beyond its core answer engine product. Founded in 2022 by alumni from
  &lt;a href=&quot;https://openai.com/&quot;&gt;
   &lt;u&gt;
    OpenAI
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.meta.com/&quot;&gt;
   &lt;u&gt;
    Meta
   &lt;/u&gt;
  &lt;/a&gt;
  , and
  &lt;a href=&quot;https://www.quora.com/&quot;&gt;
   &lt;u&gt;
    Quora
   &lt;/u&gt;
  &lt;/a&gt;
  , the San Francisco-based company has evolved from a simple AI-powered search interface into a comprehensive platform challenging multiple aspects of how people interact with information online.
 &lt;/p&gt;
 &lt;p&gt;
  Recent moves underscore the company&#x27;s ambitions. In September, Perplexity launched an
  &lt;a href=&quot;https://venturebeat.com/ai/perplexitys-new-ai-agent-wants-to-replace-your-email-habits-for-usd200-per&quot;&gt;
   &lt;u&gt;
    AI email assistant exclusively for its $200-per-month Max subscribers
   &lt;/u&gt;
  &lt;/a&gt;
  , offering automated email management, meeting scheduling, and response drafting. The company also introduced the Comet browser, built on the Chromium framework with AI features integrated throughout the browsing experience.
 &lt;/p&gt;
 &lt;p&gt;
  Most notably, Perplexity made headlines in August with its unsolicited
  &lt;a href=&quot;https://www.reuters.com/business/media-telecom/ai-startup-perplexity-makes-bold-345-billion-bid-googles-chrome-browser-2025-08-12/&quot;&gt;
   &lt;u&gt;
    $34.5 billion offer to acquire Google&#x27;s Chrome browser
   &lt;/u&gt;
  &lt;/a&gt;
  , a bid that exceeded the company&#x27;s own $18 billion valuation at the time. While analysts dismissed the offer as unlikely to succeed, it demonstrated Perplexity&#x27;s willingness to make bold moves in challenging established players.
 &lt;/p&gt;
 &lt;p&gt;
  The company has attracted significant investor interest, ranking 27th on CNBC&#x27;s
  &lt;a href=&quot;https://www.cnbc.com/cnbc-disruptors/&quot;&gt;
   &lt;u&gt;
    2025 Disruptor 50
   &lt;/u&gt;
  &lt;/a&gt;
  list. Meta reportedly approached Perplexity about a
  &lt;a href=&quot;https://www.cnbc.com/2025/06/20/meta-perplexity-scale-ai-deal.html&quot;&gt;
   &lt;u&gt;
    potential acquisition
   &lt;/u&gt;
  &lt;/a&gt;
  earlier this year, though negotiations did not result in a deal. Instead, Meta pursued a $14.3 billion investment in Scale AI, another AI infrastructure company.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Google&#x27;s antitrust troubles create opening for search challengers
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The timing of Perplexity&#x27;s
  &lt;a href=&quot;https://www.perplexity.ai/hub/blog/introducing-the-perplexity-search-api&quot;&gt;
   &lt;u&gt;
    Search API
   &lt;/u&gt;
  &lt;/a&gt;
  launch coincides with increasing regulatory pressure on Google&#x27;s search dominance. The Department of Justice has proposed that
  &lt;a href=&quot;https://www.wired.com/story/the-doj-still-wants-google-to-divest-chrome/&quot;&gt;
   &lt;u&gt;
    Google divest Chrome
   &lt;/u&gt;
  &lt;/a&gt;
  as part of antitrust remedies following a court ruling that found the company maintains an illegal monopoly in internet search. This regulatory environment may create opportunities for alternative search providers to gain market share.
 &lt;/p&gt;
 &lt;p&gt;
  Industry analysts have valued Google&#x27;s various business units separately, with estimates suggesting Chrome alone could be
  &lt;a href=&quot;https://www.cnbc.com/2025/08/13/google-antitrust-chrome-perplexity-ai-youtube.html&quot;&gt;
   &lt;u&gt;
    worth $50 billion
   &lt;/u&gt;
  &lt;/a&gt;
  based on its user base and integration with Google&#x27;s advertising ecosystem. YouTube is valued between $271 billion and $550 billion by different analysts, while Google Cloud is estimated at $549 billion to $682 billion.
 &lt;/p&gt;
 &lt;p&gt;
  Perplexity&#x27;s approach differs fundamentally from Google&#x27;s advertising-driven model. By charging developers directly for API access rather than monetizing through advertising, the company avoids some of the conflicts of interest that critics argue have degraded search quality. This model aligns Perplexity&#x27;s incentives with providing accurate, helpful information rather than driving commercial traffic.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Why even AI-powered search still needs human oversight
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Despite its technical innovations, Perplexity&#x27;s
  &lt;a href=&quot;https://www.perplexity.ai/hub/blog/introducing-the-perplexity-search-api&quot;&gt;
   &lt;u&gt;
    Search API
   &lt;/u&gt;
  &lt;/a&gt;
  faces significant challenges in competing with Google&#x27;s two-decade head start in search technology. Google processes billions of queries daily and has refined its algorithms through massive scale and continuous user feedback. The company&#x27;s infrastructure spans the globe with sophisticated caching, content delivery networks, and specialized hardware optimized for search workloads.
 &lt;/p&gt;
 &lt;p&gt;
  Perplexity acknowledges that its AI-powered approach has limitations requiring human oversight. AI-generated summaries and recommendations need manual verification for accuracy and relevance, and the system may not always surface the most appropriate results for traditional keyword searches as effectively as Google&#x27;s mature algorithms.
 &lt;/p&gt;
 &lt;p&gt;
  The company also faces ongoing legal challenges.
  &lt;a href=&quot;https://www.reuters.com/legal/litigation/encyclopedia-britannica-sues-perplexity-over-ai-answer-engine-2025-09-11/&quot;&gt;
   &lt;u&gt;
    Encyclopedia Britannica sued Perplexity
   &lt;/u&gt;
  &lt;/a&gt;
  in September over its AI answer engine, alleging copyright infringement and unfair competition. These legal battles highlight broader questions about how AI companies can use copyrighted content to train models and generate responses.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   What Perplexity&#x27;s API launch means for the future of search
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  For the first time since Google&#x27;s rise to dominance, developers have access to a genuinely competitive alternative for global-scale search data. The success or failure of Perplexity&#x27;s gambit will likely determine whether the next generation of AI applications will be built on diverse, competitive infrastructure or remain dependent on a handful of tech giants.
 &lt;/p&gt;
 &lt;p&gt;
  Early adoption by enterprise customers could validate Perplexity&#x27;s approach and encourage other companies to challenge established search providers. The company&#x27;s emphasis on citation and source attribution may prove particularly appealing to businesses requiring verifiable information sources for AI applications.
 &lt;/p&gt;
 &lt;p&gt;
  The broader implications extend beyond search itself. If Perplexity succeeds in democratizing access to comprehensive web data, it could accelerate innovation in AI applications, reduce development costs for startups, and create new possibilities for how people discover and interact with information online.
 &lt;/p&gt;
 &lt;p&gt;
  As artificial intelligence reshapes the digital landscape, Perplexity&#x27;s bold challenge to Google&#x27;s search monopoly raises a fundamental question: In an AI-driven future, who will control the keys to the world&#x27;s information — and will anyone be powerful enough to take them away?
 &lt;/p&gt;
 &lt;p&gt;
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> The $100M OpenAI partnership is nice, but Databricks&#x27; real breakthrough makes AI up to 90x cheaper </title>
<link>https://venturebeat.com/data-infrastructure/the-usd100m-openai-partnership-is-nice-but-databricks-real-breakthrough</link>
<pubDate>Mon, 22 Dec 2025 12:52:03 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;prompt optmization&quot; data-nimg=&quot;1&quot; height=&quot;720&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/64AAL8sbT2I1xv8NGL6ux0/71cd2d0bae51d71d9e2e72c50b1700b2/90x-prompt-optimization-smk.jpg?w=1000&quot; width=&quot;1280&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
    &lt;p&gt;
     Credit: Image generated by VentureBeat with FLUX-pro-1.1-ultra
    &lt;/p&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  Using the right model and the right prompt is only part of the enterprise AI challenge, it&#x27;s also critical to optimize the prompt.
 &lt;/p&gt;
 &lt;p&gt;
  It&#x27;s a challenge that
  &lt;a href=&quot;https://www.databricks.com/&quot;&gt;
   Databricks
  &lt;/a&gt;
  has been working to solve with its
  &lt;a href=&quot;https://venturebeat.com/ai/why-most-enterprise-ai-agents-never-reach-production-and-how-databricks-plans-to-fix-it&quot;&gt;
   &lt;u&gt;
    Agent Bricks
   &lt;/u&gt;
  &lt;/a&gt;
  technology, which was launched back in June. That technology has steadily improved and today Databricks revealed new techniques it is using to further improve prompt optimization. New
  &lt;a href=&quot;https://arxiv.org/abs/2507.19457&quot;&gt;
   &lt;u&gt;
    research
   &lt;/u&gt;
  &lt;/a&gt;
  &lt;u&gt;
  &lt;/u&gt;
  released today from the company shows how its GEPA (Generative Evolutionary Prompt Adaptation) technique improves prompt optimization by an order of magnitude. Databricks claims the enhancement to Agent Bricks can now enable enterprises to make models up to 90x cheaper to operate.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  The breakthrough in prompt optimization arrives alongside Databricks&#x27; $100 million partnership with
  &lt;a href=&quot;https://openai.com/&quot;&gt;
   OpenAI
  &lt;/a&gt;
  . This deal makes GPT-5 natively available to Databricks&#x27; enterprise customers, following similar deals that Databricks had previously announced with Anthropic and Google. To be clear, neither Databricks nor OpenAI is paying $100 million to the other; rather, the figure represents an expectation by Databricks of the potential revenue that the partnership will bring.
 &lt;/p&gt;
 &lt;p&gt;
  While the integration and partnership with OpenAI is noteworthy, the real story is how Databricks&#x27; research and advanced prompt optimization techniques prove enterprises don&#x27;t need premium prices for premium AI performance.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  &quot;Prompt optimization is not really taking an existing query and just optimizing its execution, It&#x27;s actually changing the query itself,&quot; Hanlin Tang, Databricks&#x27; Chief Technology Officer of Neural Networks at Databricks, told VentureBeat. &quot;It&#x27;s like, what is the best way to ask the LLM the question to get the high-quality answer that I want?&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  GEPA rewrites the optimization playbook
 &lt;/h2&gt;
 &lt;p&gt;
  The breakthrough technique is GEPA (Generative Evolutionary Prompt Adaptation), developed by researchers from Databricks and the University of California, Berkeley. Unlike traditional fine-tuning that adjusts model weights, GEPA optimizes the questions enterprises ask AI systems.
 &lt;/p&gt;
 &lt;p&gt;
  The approach mirrors human communication patterns.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;In the LLM world, there are different ways to ask the LLM the same question, right? Just like there&#x27;s a different way to ask you a question on a quiz,&quot; Tang said. &quot;There&#x27;s like 10 different ways to ask a question about a particular fact.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  GEPA uses an approach called natural language reflection, where the AI critiques its own outputs and iteratively improves them. This feedback loop automatically discovers optimal prompting strategies for specific enterprise tasks.
 &lt;/p&gt;
 &lt;p&gt;
  Results across finance, legal, commerce and healthcare domains show GEPA-optimized models consistently outperformed baselines by 4-7 percentage points.
 &lt;/p&gt;
 &lt;h2&gt;
  Rewriting enterprise AI economics
 &lt;/h2&gt;
 &lt;p&gt;
  The cost transformation stuns at enterprise scale. At 100,000 requests, Databricks&#x27; optimized open-source model delivers superior quality at 1/90th the serving cost of Claude Opus 4.1.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;If you&#x27;re able to prompt optimize to improve the quality of a model on your task, you can also use it to sort of bring up a smaller model to the quality that you care about, so you can actually save cost as well,&quot; Tang noted.
 &lt;/p&gt;
 &lt;p&gt;
  The advantage compounds with volume. For workloads processing 10 million requests, one-time optimization costs become negligible compared to serving costs.
 &lt;/p&gt;
 &lt;p&gt;
  GEPA also outperforms supervised fine-tuning—the current gold standard for model customization—while reducing serving costs by 20%. The technique saves engineering resources, too.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;It also saves engineers and data scientists a lot of time, because usually they spend a lot of time prompting, writing the right prompt and question for the model,&quot; Tang explained. &quot;In this case, the system can figure out automatically what the best way to query the model is.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  OpenAI integration eliminates complexity
 &lt;/h2&gt;
 &lt;p&gt;
  While GEPA optimization can enhance the performance of any model, the technique becomes even more powerful when enterprises can easily access and experiment with multiple high-quality models. This is where the OpenAI partnership creates a force multiplier effect.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;The most important component for us and for OpenAI is it now makes the OpenAI models natively available on Databricks,&quot; Tang said. &quot;Any Databricks customer can query these OpenAI GPT-5 models without an external vendor relationship, without an API key.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The integration goes beyond simple API access. Enterprises can call GPT-5 directly in SQL commands. &quot;They can easily call a SQL command and just sort of quote GPT-5 in the command to ask it to translate a row in the table, or something like that,&quot; Tang explained.
 &lt;/p&gt;
 &lt;p&gt;
  This native integration eliminates the vendor management overhead that previously complicated the deployment of premium models. &quot;That&#x27;s just part of your Databricks plan. You don&#x27;t need to create an API key somewhere else,&quot; Tang confirmed.
 &lt;/p&gt;
 &lt;p&gt;
  The partnership reinforces Databricks&#x27; multi-model strategy alongside existing Anthropic and Google Gemini integrations.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;We&#x27;re all about having Databricks being a multi-model platform,&quot; Tang emphasized.
 &lt;/p&gt;
 &lt;h2&gt;
  Enterprise action plan
 &lt;/h2&gt;
 &lt;p&gt;
  Technical decision-makers should prioritize three immediate steps:
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Build robust evaluation first:
  &lt;/b&gt;
  Tang&#x27;s core advice: &quot;One of the superpowers of Agent Bricks is that it builds custom evaluations on your specific task. I would recommend enterprises build agents first - you don&#x27;t want to be flying blind without knowing the quality of your agents.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Question fine-tuning defaults:
  &lt;/b&gt;
  With prompt optimization matching or exceeding supervised fine-tuning results at lower costs, enterprises should evaluate both approaches rather than defaulting to traditional fine-tuning.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Rethink model procurement:
  &lt;/b&gt;
  Post-deployment optimization capability changes the buying decision. A more affordable model that optimizes for frontier performance may deliver better value than premium upfront pricing.
 &lt;/p&gt;
 &lt;p&gt;
  For enterprises looking to lead in AI deployment, the message is clear: the cost barrier to frontier AI performance has collapsed. Early adopters who invest in optimization capabilities now will build increasingly insurmountable competitive advantages as their AI systems continuously improve.
 &lt;/p&gt;
 &lt;p&gt;
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Hopper&#x27;s AI agent can book flights and cancel trips without human help </title>
<link>https://venturebeat.com/data-infrastructure/hoppers-ai-agent-can-book-flights-and-cancel-trips-without-human-help</link>
<pubDate>Mon, 22 Dec 2025 12:52:00 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;Credit: VentureBeat made with Midjourney&quot; data-nimg=&quot;1&quot; height=&quot;786&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/2j1p443EWqDPT9LNzQwnDT/c3cd40ea73e952b3e8d693d347743aad/nuneybits_Vector_art_of_business_travel_6cd3b152-a9f8-4c95-b214-4f45d7c4afcb.webp?w=1000&quot; width=&quot;1403&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://hts.hopper.com/&quot;&gt;
   &lt;u&gt;
    Hopper Technology Solutions
   &lt;/u&gt;
  &lt;/a&gt;
  launched a breakthrough artificial intelligence system Wednesday that can autonomously handle complex travel customer service issues from start to finish, a major advance in AI-powered automation for the trillion-dollar travel industry.
 &lt;/p&gt;
 &lt;p&gt;
  The new system, called
  &lt;a href=&quot;https://hts.hopper.com/&quot;&gt;
   &lt;u&gt;
    HTS Assist
   &lt;/u&gt;
  &lt;/a&gt;
  , can conduct entire customer service conversations through voice or chat, accessing airline booking systems to cancel flights, process refunds, and even book replacement accommodations — all without human intervention.
 &lt;/p&gt;
 &lt;p&gt;
  In demonstrations with VentureBeat, the AI agent seamlessly navigated complex scenarios like rebooking missed connections and arranging rental cars, completing transactions that typically require multiple system logins and policy checks.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  &quot;We&#x27;re one of the only conversational AI platforms that has scaled specifically for travel while remaining customer-facing,&quot; said Jo Lai, Senior Vice President of AI Solutions and Customer Experience at HTS, in an exclusive interview with VentureBeat. &quot;We&#x27;ve processed about 3 million conversations and have extensively stress tested the system in our channels.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The launch positions Montreal-based
  &lt;a href=&quot;https://hopper.com/&quot;&gt;
   &lt;u&gt;
    Hopper
   &lt;/u&gt;
  &lt;/a&gt;
  , valued at
  &lt;a href=&quot;https://www.bloomberg.com/news/articles/2025-01-21/travel-app-hopper-eyes-long-term-ipo-plan-10-billion-valuation&quot;&gt;
   &lt;u&gt;
    $5 billion
   &lt;/u&gt;
  &lt;/a&gt;
  and considering an initial public offering, as a formidable competitor to enterprise AI giants like Microsoft and Salesforce in the lucrative customer service automation market.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  Unlike general-purpose AI assistants, HTS Assist was built specifically for travel&#x27;s complex operational requirements, trained on 16 million travel conversations and integrated directly into airline booking systems, hotel reservation platforms, and payment processors.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   How AI agents navigate airlines&#x27; complex booking systems
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The system tackles a core challenge in travel automation. While other companies have demonstrated AI agents making restaurant reservations or handling simple customer queries,
  &lt;a href=&quot;https://hts.hopper.com/&quot;&gt;
   &lt;u&gt;
    HTS Assist
   &lt;/u&gt;
  &lt;/a&gt;
  can navigate the fragmented, command-line-heavy systems that power airline operations and complete multi-step transactions that previously required human expertise.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;When we look at travel servicing from an analog perspective, there are 20-plus tools. All of them are command line terminals, not point-and-click interfaces. It&#x27;s highly fragmented,&quot; Lai told VentureBeat. &quot;We know the customer-facing side of travel servicing really well, and we also have the back-end integrations that we&#x27;ve built out over the last 10 years.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The AI agent combines several advanced technologies: real-time voice processing with ultra-low latency, large language models trained specifically on travel scenarios, and deep integrations into airline and hotel systems that took Hopper years to develop. The system can handle interruptions mid-conversation, understand travel industry jargon, and access live pricing and availability data to make real-time booking decisions.
 &lt;/p&gt;
 &lt;p&gt;
  Early results show the system achieving 88% customer satisfaction parity with human agents while reducing servicing costs by 65%. Partners report that approximately 70% of customers actively choose the AI solution when given equal options, and the system converts 15% of service interactions into additional sales through intelligent upselling.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   From flight app to B2B AI powerhouse: Hopper&#x27;s $5 billion transformation
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The
  &lt;a href=&quot;https://hts.hopper.com/&quot;&gt;
   &lt;u&gt;
    HTS Assist
   &lt;/u&gt;
  &lt;/a&gt;
  launch caps a remarkable transformation for
  &lt;a href=&quot;https://hopper.com/&quot;&gt;
   &lt;u&gt;
    Hopper
   &lt;/u&gt;
  &lt;/a&gt;
  , which has shifted from a consumer-focused flight prediction app to a business-to-business technology powerhouse. HTS, Hopper&#x27;s B2B division launched in 2021, now accounts for 90% of the company&#x27;s revenue, up from zero just four years ago.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;HTS now makes up 75 percent of Hopper&#x27;s revenue,&quot; Dakota Smith, Hopper&#x27;s president and co-founder, told industry publication
  &lt;a href=&quot;https://www.webintravel.com/b2b-gets-personal-local-and-powerful-the-new-rules-of-engagement-in-travel-tech/&quot;&gt;
   &lt;u&gt;
    WiT
   &lt;/u&gt;
  &lt;/a&gt;
  earlier this year. &quot;It completely outstripped our consumer business very quickly. It took about a year to take it over.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The company has secured major partnerships with financial institutions and airlines worldwide, including
  &lt;a href=&quot;https://www.virginaustralia.com/&quot;&gt;
   &lt;u&gt;
    Virgin Australia
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.flyfrontier.com/&quot;&gt;
   &lt;u&gt;
    Frontier Airlines
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.commbank.com.au/&quot;&gt;
   &lt;u&gt;
    Commonwealth Bank of Australia
   &lt;/u&gt;
  &lt;/a&gt;
  , and Japan&#x27;s largest credit card issuer
  &lt;a href=&quot;https://media.hopper.com/news/smcc-agrees-to-partner-with-hts-for-entry-into-the-travel-segment&quot;&gt;
   &lt;u&gt;
    SMCC
   &lt;/u&gt;
  &lt;/a&gt;
  . These partnerships integrate Hopper&#x27;s travel technology and fintech products into partners&#x27; direct booking channels, creating new revenue streams while reducing their operational costs.
 &lt;/p&gt;
 &lt;p&gt;
  Hopper&#x27;s success reflects broader changes in the travel industry, where airlines and hotels are increasingly investing in direct booking channels to reduce dependence on online travel agencies like
  &lt;a href=&quot;https://www.expedia.com/&quot;&gt;
   &lt;u&gt;
    Expedia
   &lt;/u&gt;
  &lt;/a&gt;
  and
  &lt;a href=&quot;http://booking.com&quot;&gt;
   &lt;u&gt;
    Booking.com
   &lt;/u&gt;
  &lt;/a&gt;
  . By 2025, industry analysts expect significant growth in B2B travel technology as companies seek to capture more direct bookings and improve customer experiences.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Microsoft and Salesforce face new competition in travel AI race
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The launch comes as major technology companies race to deploy AI agents across enterprise applications.
  &lt;a href=&quot;https://copilot.microsoft.com/&quot;&gt;
   &lt;u&gt;
    Microsoft&#x27;s Copilot
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.salesforce.com/artificial-intelligence/&quot;&gt;
   &lt;u&gt;
    Salesforce&#x27;s Einstein
   &lt;/u&gt;
  &lt;/a&gt;
  , and
  &lt;a href=&quot;https://cloud.google.com/vertex-ai?hl=en&quot;&gt;
   &lt;u&gt;
    Google&#x27;s Vertex AI
   &lt;/u&gt;
  &lt;/a&gt;
  all target customer service automation, but most solutions require extensive customization for industry-specific workflows.
 &lt;/p&gt;
 &lt;p&gt;
  HTS Assist&#x27;s travel-specific focus provides key advantages. The system understands complex travel scenarios like irregular operations, fare rules, and multi-city itineraries that generic AI assistants struggle with. More importantly,
  &lt;a href=&quot;https://hopper.com/&quot;&gt;
   &lt;u&gt;
    Hopper
   &lt;/u&gt;
  &lt;/a&gt;
  has spent years building the technical infrastructure to actually execute transactions across fragmented airline systems.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;We have a fundamental amount of travel specific expertise that is a really key differentiator for us,&quot; Lai said. &quot;We transact millions and millions of customers on a yearly basis, and we understand very well exactly what the challenges are from a travel specific industry perspective.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The timing proves strategic as the travel industry grapples with post-pandemic staffing challenges and surging demand. Airlines and travel companies face pressure to improve customer service while controlling costs, making AI automation increasingly attractive.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Airlines see 70% customer adoption in early AI deployments
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://hts.hopper.com/&quot;&gt;
   &lt;u&gt;
    HTS Assist
   &lt;/u&gt;
  &lt;/a&gt;
  requires six to eight weeks for implementation, with partners working with Hopper to identify high-impact use cases. The system currently operates in over 30 languages and serves customers across 200 markets, with live deployments supporting bank partners in Singapore, Japan, and South Korea.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;For one of our partners, we see that approximately 70% of their customers actually actively choose to use AI solution as their primary way of interacting with the business when merchandised on equal footing with other entry points,&quot; Lai noted.
 &lt;/p&gt;
 &lt;p&gt;
  The system can handle thousands of concurrent calls without staffing limitations, proving particularly valuable during operational disruptions when customer service volumes spike unpredictably. During weather delays or system outages, HTS Assist can maintain service levels that would be impossible to staff with human agents.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   The future of travel booking: voice commands replace website forms
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Looking ahead, Hopper plans to expand
  &lt;a href=&quot;https://hts.hopper.com/&quot;&gt;
   &lt;u&gt;
    HTS Assist
   &lt;/u&gt;
  &lt;/a&gt;
  beyond post-booking service into conversational commerce, allowing customers to search and book travel through natural language conversations rather than traditional filters and forms.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;I think in the future, it&#x27;s not just about using filters and point-and-click interfaces to make purchases, especially in travel, but being able to talk to conversational assistants that remember what customers are looking for,&quot; Lai explained.
 &lt;/p&gt;
 &lt;p&gt;
  The success of HTS Assist could accelerate adoption of AI agents across the travel industry, potentially reshaping how millions of travelers interact with airlines, hotels, and booking platforms. As Hopper eyes a potential IPO with a
  &lt;a href=&quot;https://www.bloomberg.com/news/articles/2025-01-21/travel-app-hopper-eyes-long-term-ipo-plan-10-billion-valuation&quot;&gt;
   &lt;u&gt;
    targeted $10 billion valuation
   &lt;/u&gt;
  &lt;/a&gt;
  , the company&#x27;s evolution from consumer app to enterprise AI platform demonstrates how artificial intelligence is creating new business models across traditional industries.
 &lt;/p&gt;
 &lt;p&gt;
  The real test will come during the next major weather disruption, when thousands of frustrated travelers simultaneously demand rebookings. If HTS Assist can handle that chaos seamlessly, human customer service agents may soon become as rare as paper tickets.
 &lt;/p&gt;
 &lt;p&gt;
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Salesforce launches AI &#x27;trust layer&#x27; to tackle enterprise deployment failures plaguing 80% of projects </title>
<link>https://venturebeat.com/data-infrastructure/salesforce-launches-ai-trust-layer-to-tackle-enterprise-deployment-failures</link>
<pubDate>Mon, 22 Dec 2025 12:51:58 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;nuneybits Vector art of layered data cloud 12e322ec-5b63-4bec-a9ce-7a255cb1694e&quot; data-nimg=&quot;1&quot; height=&quot;599&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/48XIfBjEA8DoLNpIystf9B/bd01a15251d9d54f64a7ae8d5d23d1ba/nuneybits_Vector_art_of_layered_data_cloud_12e322ec-5b63-4bec-a9ce-7a255cb1694e.webp?w=1000&quot; width=&quot;1069&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://www.salesforce.com/&quot;&gt;
   &lt;u&gt;
    Salesforce Inc.
   &lt;/u&gt;
  &lt;/a&gt;
  is expanding its artificial intelligence platform with new data management and governance capabilities, aiming to address what the company says is a crisis in enterprise AI adoption where more than 80% of projects fail to deliver meaningful business value.
 &lt;/p&gt;
 &lt;p&gt;
  The San Francisco-based software giant announced Thursday a suite of new tools designed to create what it calls a &quot;trusted AI foundation&quot; for enterprises struggling with fragmented data, weak governance, and security concerns that have hampered AI deployments across corporate America.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;We&#x27;re seeing a lot of these AI projects really failing, and a lot of it&#x27;s because customers still have fragmented data, they still have weak governance, they still have poor security,&quot; said Desiree Motamedi, Salesforce&#x27;s senior vice president and chief marketing officer, in an exclusive interview with VentureBeat. &quot;They really want a way that they can bring AI at scale that has the accuracy, the context and the control.&quot;
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  The timing of Salesforce&#x27;s announcement comes as the company prepares for its annual
  &lt;a href=&quot;https://www.salesforce.com/dreamforce/&quot;&gt;
   &lt;u&gt;
    Dreamforce conference
   &lt;/u&gt;
  &lt;/a&gt;
  next week, where CEO Marc Benioff is expected to showcase the company&#x27;s vision for what he calls the &quot;
  &lt;a href=&quot;https://www.salesforce.com/ap/agentforce/agentic-enterprise/&quot;&gt;
   &lt;u&gt;
    agentic enterprise
   &lt;/u&gt;
  &lt;/a&gt;
  &quot; — workplaces where AI agents work alongside humans across every business function.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Why most corporate AI initiatives crash and burn before reaching production
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The scale of AI project failures has become a significant concern for enterprise technology leaders. According to a
  &lt;a href=&quot;https://www.rand.org/pubs/research_reports/RRA2680-1.html&quot;&gt;
   &lt;u&gt;
    RAND Corporation study
   &lt;/u&gt;
  &lt;/a&gt;
  , poor data quality, inadequate governance frameworks, and fragmented system integration are the primary culprits behind the high failure rate of corporate AI initiatives.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  This challenge has created both pressure and opportunity for enterprise software providers. While companies face mounting pressure to deploy AI capabilities, many are discovering that their existing data infrastructure isn&#x27;t equipped to support reliable AI applications at scale.
 &lt;/p&gt;
 &lt;p&gt;
  Salesforce&#x27;s response centers on what Motamedi describes as three core capabilities: ensuring AI outputs are grounded in unified business data, embedding security and compliance controls into every workflow, and connecting AI agents across different platforms and data sources.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;The Salesforce platform is a $7 billion business,&quot; Motamedi noted, highlighting the significant revenue opportunity the company sees in addressing enterprise AI infrastructure needs. &quot;This is a significant opportunity where we&#x27;re seeing meaningful differentiation from other vendors in the market.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Inside Salesforce&#x27;s new AI tools designed to fix enterprise data chaos
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The company&#x27;s latest announcements include several technically sophisticated solutions aimed at different aspects of the enterprise AI challenge:
 &lt;/p&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://www.salesforce.com/form/demo/data-cloud-demo/?d=7013y000002ExgGAAS&amp;nc=7013y000002EySjAAK&amp;utm_content=7013y000002ExgGAAS&amp;utm_source=google&amp;utm_medium=paid_search&amp;utm_campaign=21124892324&amp;utm_adgroup=161024384060&amp;utm_term=data%20software&amp;utm_matchtype=p&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=21124892324&amp;gbraid=0AAAAAD4PnrPBb88pPnAYrypU8WWEYdx8g&amp;gclid=CjwKCAjwxfjGBhAUEiwAKWPwDhNDbBp4P2o_OuM2D0m0MWQS3O0LZFu25_L1MoKpBPqYX5M9VTKRUBoC0ScQAvD_BwE&quot;&gt;
   &lt;u&gt;
    Data Cloud Context Indexing
   &lt;/u&gt;
  &lt;/a&gt;
  represents Salesforce&#x27;s approach to handling unstructured content like contracts, technical diagrams, and decision trees. The system uses what the company calls a &quot;business-aware lens&quot; to help AI agents interpret complex documents within their proper business context.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;A good example is a field engineer who uploads a schematic for guided troubleshooting,&quot; Motamedi explained. &quot;Now they have that capability at their disposal, because it&#x27;s right there in that view.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://www.salesforce.com/form/demo/data-cloud-demo/?d=701ed000003k7J0AAI&amp;nc=701ed000003kDcvAAE&amp;utm_content=701ed000003k7J0AAI&amp;utm_source=google&amp;utm_medium=paid_search&amp;utm_campaign=21124892324&amp;utm_adgroup=176980111604&amp;utm_term=data%20cleansing&amp;utm_matchtype=p&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=21124892324&amp;gbraid=0AAAAAD4PnrPBb88pPnAYrypU8WWEYdx8g&amp;gclid=CjwKCAjwxfjGBhAUEiwAKWPwDk001xVkCvIob4Vk_cw4ILVfg3wlmxgGaglkOCLSuYHa9RkuO9aJkxoCeS8QAvD_BwE&quot;&gt;
   &lt;u&gt;
    Data Cloud Clean Rooms
   &lt;/u&gt;
  &lt;/a&gt;
  , now generally available, allows organizations to securely share and analyze data with partners without exposing sensitive information. Using Salesforce&#x27;s &quot;zero copy&quot; technology, companies can collaborate on data analysis without actually moving or duplicating datasets.
 &lt;/p&gt;
 &lt;p&gt;
  The clean room technology extends beyond traditional advertising applications to sectors like banking, where institutions could &quot;detect fraud, and they want to be able to do it with some of their partners. They could now do it in hours versus weeks,&quot; according to Motamedi.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://www.tableau.com/products/tableau-semantics&quot;&gt;
   &lt;u&gt;
    Tableau Semantics
   &lt;/u&gt;
  &lt;/a&gt;
  addresses one of the most persistent challenges in enterprise data management: ensuring consistent definitions of business metrics across different systems and teams. The AI-powered semantic layer translates raw data into standardized business language.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;We use terms like ACV or churn that have specific definitions within our organization,&quot; Motamedi said. &quot;Making sure AI understands those definitions, and then having a standardized layer across organizations, really makes this seamless for enterprises.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://www.salesforce.com/news/stories/mulesoft-agent-fabric-announcement/&quot;&gt;
   &lt;u&gt;
    MuleSoft Agent Fabric
   &lt;/u&gt;
  &lt;/a&gt;
  tackles what Salesforce calls &quot;agent sprawl&quot; — the proliferation of AI agents across different platforms and vendors within large organizations. The system provides centralized registration, orchestration, and governance for AI agents regardless of where they were built.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   How Salesforce plans to battle Microsoft, Google and Amazon for AI dominance
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Salesforce&#x27;s comprehensive approach to AI infrastructure positions the company in direct competition with
  &lt;a href=&quot;https://www.microsoft.com/en-us/&quot;&gt;
   &lt;u&gt;
    Microsoft
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.google.com/&quot;&gt;
   &lt;u&gt;
    Google
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.amazon.com/&quot;&gt;
   &lt;u&gt;
    Amazon
   &lt;/u&gt;
  &lt;/a&gt;
  , and
  &lt;a href=&quot;https://www.servicenow.com/&quot;&gt;
   &lt;u&gt;
    ServiceNow
   &lt;/u&gt;
  &lt;/a&gt;
  , all of which are vying to become the dominant platform for enterprise AI deployment.
 &lt;/p&gt;
 &lt;p&gt;
  The company&#x27;s strategy relies heavily on integration advantages that come from building AI capabilities into an existing platform used by thousands of enterprises. &quot;The power of the platform&quot; lies in the fact that &quot;all of this is natively into the platform. So these capabilities are just there, and they work and they work seamlessly together,&quot; Motamedi emphasized.
 &lt;/p&gt;
 &lt;p&gt;
  This integrated approach contrasts with point solutions that require custom integration work. &quot;Some of these point solutions, if you want these things to work together, you got to build those integrations. You got to have developer teams to make that happen,&quot; she noted.
 &lt;/p&gt;
 &lt;p&gt;
  The company&#x27;s pending $8 billion acquisition of data management company Informatica, expected to close soon, will significantly expand Salesforce&#x27;s capabilities in enterprise metadata management — a critical component for AI accuracy.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;For the last 26 years, Salesforce has been rooted in our platform approach — we&#x27;ve built the metadata layer from day one,&quot; Motamedi said. &quot;But with Informatica, we&#x27;re going to see metadata across the entire enterprise, and that gives us another layer of accuracy for AI responses.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Early enterprise customers reveal the reality of scaling AI in large organizations
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Despite the technical capabilities, Salesforce acknowledges that enterprise AI adoption remains in early stages. The company reports having &quot;over 12,000 live deployments of Agentforce&quot; — its AI agent platform — but Motamedi describes a wide range of organizational readiness.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Every company has a mandate right now to figure out how they can incorporate AI,&quot; she said. &quot;We see very interesting ranges from people who are just getting started to people who are like, we&#x27;re going to build like 80 different agents within their organization.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Early customer implementations include
  &lt;a href=&quot;https://wa.aaa.com/home&quot;&gt;
   &lt;u&gt;
    AAA Washington
   &lt;/u&gt;
  &lt;/a&gt;
  , which is using Salesforce&#x27;s unified data foundation to improve member experiences across roadside assistance, insurance, and travel services.
  &lt;a href=&quot;https://www.uchicagomedicine.org/&quot;&gt;
   &lt;u&gt;
    UChicago Medicine
   &lt;/u&gt;
  &lt;/a&gt;
  is leveraging the platform to ensure reliable patient interactions while enabling healthcare staff to focus on complex, human-centered care.
 &lt;/p&gt;
 &lt;p&gt;
  The maturity curve for enterprise AI adoption means &quot;it&#x27;s going to take a couple years to see it fully, fully embraced, but we already see the path,&quot; according to Motamedi.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   What Salesforce&#x27;s AI governance push means for the future of enterprise software
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The broader implications of Salesforce&#x27;s strategy extend beyond technical capabilities to fundamental questions about how enterprises will manage AI risk and governance. The company&#x27;s emphasis on built-in security and compliance reflects growing corporate awareness that AI deployment without proper controls can create significant business liability.
 &lt;/p&gt;
 &lt;p&gt;
  Recent incidents involving AI agents accessing sensitive information or providing unreliable outputs have made corporate leaders more cautious about scaling AI initiatives. Salesforce&#x27;s approach of embedding security directly into AI workflows — including automated threat detection partnerships with
  &lt;a href=&quot;https://www.crowdstrike.com/&quot;&gt;
   &lt;u&gt;
    CrowdStrike
   &lt;/u&gt;
  &lt;/a&gt;
  and
  &lt;a href=&quot;https://www.okta.com/&quot;&gt;
   &lt;u&gt;
    Okta
   &lt;/u&gt;
  &lt;/a&gt;
  , and built-in HIPAA compliance for healthcare applications — represents an attempt to address these concerns while accelerating adoption.
 &lt;/p&gt;
 &lt;p&gt;
  However, market skepticism remains. CNBC&#x27;s Jim Cramer
  &lt;a href=&quot;https://finance.yahoo.com/news/jim-cramer-salesforce-gotta-more-180432550.html&quot;&gt;
   &lt;u&gt;
    recently noted concerns
   &lt;/u&gt;
  &lt;/a&gt;
  about Salesforce&#x27;s performance despite strong quarterly reports, suggesting that investor expectations for AI-driven growth may be outpacing actual business results.
 &lt;/p&gt;
 &lt;p&gt;
  The company&#x27;s success will ultimately depend on whether it can help enterprises bridge the gap between AI experimentation and production-scale deployment. As Motamedi framed it: &quot;We really believe that we have a trust layer for enterprise AI with all of these new announcements, and we&#x27;re really helping companies move from cautious pilots to transformative action.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Whether that vision becomes reality will depend on Salesforce&#x27;s ability to prove that integrated platforms can solve enterprise AI&#x27;s trust problem better than the patchwork of point solutions most companies rely on today. In an industry where
  &lt;a href=&quot;https://news.ycombinator.com/item?id=41368935&quot;&gt;
   &lt;u&gt;
    80% of projects fail
   &lt;/u&gt;
  &lt;/a&gt;
  , the company that finally cracks the code on reliable, scalable enterprise AI could reshape how business gets done — or discover that the technical challenges run deeper than any single platform can solve.
 &lt;/p&gt;
 &lt;p&gt;
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> The most important OpenAI announcement you probably missed at DevDay 2025 </title>
<link>https://venturebeat.com/data-infrastructure/the-most-important-openai-announcement-you-probably-missed-at-devday-2025</link>
<pubDate>Mon, 22 Dec 2025 12:51:55 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;Credit: VentureBeat made with Midjourney&quot; data-nimg=&quot;1&quot; height=&quot;599&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/2buVKIMlQ2KFcFg8BPHoqU/c5d2dfbfd8cfe9a9432106a936fa204f/nuneybits_A_retro_glowing_computer_on_gradient_background_that__094dfc70-9906-4074-bb00-d32b04faf5f9-1.webp?w=1000&quot; width=&quot;1069&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  OpenAI’s annual developer conference on Monday was a spectacle of ambitious AI product launches, from an
  &lt;a href=&quot;https://openai.com/index/introducing-apps-in-chatgpt/&quot;&gt;
   &lt;u&gt;
    app store for ChatGPT
   &lt;/u&gt;
  &lt;/a&gt;
  to a stunning
  &lt;a href=&quot;https://openai.com/index/sora-2/&quot;&gt;
   &lt;u&gt;
    video-generation API
   &lt;/u&gt;
  &lt;/a&gt;
  that brought creative concepts to life. But for the enterprises and technical leaders watching closely, the most consequential announcement was the quiet
  &lt;a href=&quot;https://openai.com/index/codex-now-generally-available/&quot;&gt;
   &lt;u&gt;
    general availability of Codex
   &lt;/u&gt;
  &lt;/a&gt;
  , the company&#x27;s AI software engineer. This release signals a profound shift in how software—and by extension, modern business—is built.
 &lt;/p&gt;
 &lt;p&gt;
  While other announcements captured the public’s imagination, the production-ready release of
  &lt;a href=&quot;https://openai.com/codex/&quot;&gt;
   &lt;u&gt;
    Codex
   &lt;/u&gt;
  &lt;/a&gt;
  , supercharged by a
  &lt;a href=&quot;https://openai.com/index/introducing-upgrades-to-codex/&quot;&gt;
   &lt;u&gt;
    new specialized model
   &lt;/u&gt;
  &lt;/a&gt;
  and a
  &lt;a href=&quot;https://developers.openai.com/codex/sdk&quot;&gt;
   &lt;u&gt;
    suite of enterprise-grade tools
   &lt;/u&gt;
  &lt;/a&gt;
  , is the engine behind OpenAI’s entire vision. It is the tool that builds the tools, the proven agent in a world buzzing with agentic potential, and the clearest articulation of the company&#x27;s strategy to win the enterprise.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  The
  &lt;a href=&quot;https://openai.com/index/codex-now-generally-available/&quot;&gt;
   &lt;u&gt;
    general availability of Codex
   &lt;/u&gt;
  &lt;/a&gt;
  moves it from a &quot;research preview&quot; to a fully supported product, complete with a new
  &lt;a href=&quot;https://developers.openai.com/codex/sdk&quot;&gt;
   &lt;u&gt;
    software development kit (SDK)
   &lt;/u&gt;
  &lt;/a&gt;
  , a
  &lt;a href=&quot;https://developers.openai.com/codex/integrations/slack&quot;&gt;
   &lt;u&gt;
    Slack integration
   &lt;/u&gt;
  &lt;/a&gt;
  , and administrative controls for security and monitoring.This transition declares that Codex is ready for mission-critical work inside the world’s largest companies.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;We think this is the best time in history to be a builder; it has never been faster to go from idea to product,&quot; said OpenAI CEO Sam Altman during the
  &lt;a href=&quot;https://venturebeat.com/ai/openai-dev-day-2025-chatgpt-becomes-the-new-app-store-and-hardware-is-coming&quot;&gt;
   &lt;u&gt;
    opening keynote
   &lt;/u&gt;
  &lt;/a&gt;
  presentation. &quot;Software used to take months or years to build. You saw that it can take minutes now to build with AI.&quot;
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  That acceleration is not theoretical. It&#x27;s a reality born from OpenAI’s own internal use — a massive &quot;dogfooding&quot; effort that serves as the ultimate case study for enterprise customers.
 &lt;/p&gt;
 &lt;h2&gt;
  Inside GPT-5-Codex: The AI model that codes autonomously for hours and drives 70% productivity gains
 &lt;/h2&gt;
 &lt;p&gt;
  At the heart of the Codex upgrade is
  &lt;a href=&quot;https://chatgpt.com/features/codex?utm_source=google&amp;utm_medium=paidsearch_brand&amp;utm_campaign=GOOG_B_SEM_GBR_Core_TEM_BAU_ACQ_PER_BRD_ALL_NAMER_US_EN_080625&amp;utm_term=openai%20codex&amp;utm_content=187611721873&amp;utm_ad=776422173331&amp;utm_match=p&amp;gad_source=1&amp;gad_campaignid=23071604080&amp;gbraid=0AAAAA-I0E5cl2krVAgcAc2VJzRhsB5CLd&amp;gclid=CjwKCAjwup3HBhAAEiwA7euZupI6JVfC5p76PsLMGm1i2XCDyp7ERZnjrRPbaodVfs6hE2MM_g4_zhoCzE4QAvD_BwE&quot;&gt;
   &lt;u&gt;
    GPT-5-Codex
   &lt;/u&gt;
  &lt;/a&gt;
  , a version of OpenAI&#x27;s latest flagship model that has been &quot;purposely trained for Codex and agentic coding.&quot; The new model is designed to function as an autonomous teammate, moving far beyond simple code autocompletion.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;I personally like to think about it as a little bit like a human teammate,&quot; explained Tibo Sottiaux, an OpenAI engineer, during a technical session on Codex. &quot;You can pair a program with it on your computer, you can delegate to it, or as you&#x27;ll see, you can give it a job without explicit prompting.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  This new model enables &quot;
  &lt;a href=&quot;https://openai.com/index/introducing-upgrades-to-codex/&quot;&gt;
   &lt;u&gt;
    adaptive thinking
   &lt;/u&gt;
  &lt;/a&gt;
  ,&quot; allowing it to dynamically adjust the time and computational effort spent on a task based on its complexity.For simple requests, it&#x27;s fast and efficient, but for complex refactoring projects, it can work for hours.
 &lt;/p&gt;
 &lt;p&gt;
  One engineer during the technical session noted, &quot;I&#x27;ve seen the GPT-5-Codex model work for over seven hours productively... on a marathon session.&quot; This capability to handle long-running, complex tasks is a significant leap beyond the simple, single-shot interactions that define most AI coding assistants.
 &lt;/p&gt;
 &lt;p&gt;
  The results inside OpenAI have been dramatic. The company reported that 92% of its technical staff now uses Codex daily, and those engineers complete 70% more pull requests (a measure of code contribution) each week. Usage has surged tenfold since August.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;When we as a team see the stats, it feels great,&quot; Sottiaux shared. &quot;But even better is being at lunch with someone who then goes &#x27;Hey I use Codex all the time. Here&#x27;s a cool thing that I do with it. Do you want to hear about it?&#x27;&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  How OpenAI uses Codex to build its own AI products and catch hundreds of bugs daily
 &lt;/h2&gt;
 &lt;p&gt;
  Perhaps the most compelling argument for Codex’s importance is that it is the foundational layer upon which OpenAI’s other flashy announcements were built. During the
  &lt;a href=&quot;https://devday.openai.com/&quot;&gt;
   &lt;u&gt;
    DevDay event
   &lt;/u&gt;
  &lt;/a&gt;
  , the company showcased custom-built arcade games and a dynamic, AI-powered website for the conference itself, all developed using
  &lt;a href=&quot;https://openai.com/codex/&quot;&gt;
   &lt;u&gt;
    Codex
   &lt;/u&gt;
  &lt;/a&gt;
  .
 &lt;/p&gt;
 &lt;p&gt;
  In one session, engineers demonstrated how they built &quot;Storyboard,&quot; a custom creative tool for the film industry, in just 48 hours during an internal hackathon. &quot;We decided to test Codex, our coding agent... we would send tasks to Codex in between meetings. We really easily reviewed and merged PRs into production, which Codex even allowed us to do from our phones,&quot; said Allison August, a solutions engineering leader at OpenAI.
 &lt;/p&gt;
 &lt;p&gt;
  This reveals a critical insight: the rapid innovation showcased at DevDay is a direct result of the productivity flywheel created by
  &lt;a href=&quot;https://openai.com/codex/&quot;&gt;
   &lt;u&gt;
    Codex
   &lt;/u&gt;
  &lt;/a&gt;
  . The AI is a core part of the manufacturing process for all other AI products.
 &lt;/p&gt;
 &lt;p&gt;
  A key enterprise-focused feature is the new, more robust code review capability. OpenAI said it &quot;purposely trained GPT-5-Codex to be great at ultra thorough code review,&quot; enabling it to explore dependencies and validate a programmer&#x27;s intent against the actual implementation to find high-quality bugs.Internally, nearly every pull request at OpenAI is now reviewed by Codex, catching hundreds of issues daily before they reach a human reviewer.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;It saves you time, you ship with more confidence,&quot; Sottiaux said. &quot;There&#x27;s nothing worse than finding a bug after we actually ship the feature.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  Why enterprise software teams are choosing Codex over GitHub Copilot for mission-critical development
 &lt;/h2&gt;
 &lt;p&gt;
  The maturation of
  &lt;a href=&quot;https://openai.com/codex/&quot;&gt;
   &lt;u&gt;
    Codex
   &lt;/u&gt;
  &lt;/a&gt;
  is central to OpenAI’s broader strategy to conquer the enterprise market, a move essential to justifying its massive valuation and unprecedented compute expenditures. During a press conference, CEO Sam Altman confirmed the strategic shift.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;The models are there now, and you should expect a huge focus from us on really winning enterprises with amazing products, starting here,&quot; Altman said during a private press conference.
 &lt;/p&gt;
 &lt;p&gt;
  OpenAI President and Co-founder Greg Brockman immediately added, &quot;And you can see it already with Codex, which I think has been just an incredible success and has really grown super fast.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  For technical decision-makers, the message is clear. While consumer-facing agents that book dinner reservations are still finding their footing,
  &lt;a href=&quot;https://openai.com/codex/&quot;&gt;
   &lt;u&gt;
    Codex
   &lt;/u&gt;
  &lt;/a&gt;
  is a proven enterprise agent delivering substantial ROI today. Companies like Cisco have already rolled out Codex to their engineering organizations, cutting code review times by 50% and reducing project timelines from weeks to days.
 &lt;/p&gt;
 &lt;p&gt;
  With the new
  &lt;a href=&quot;https://developers.openai.com/codex/sdk/&quot;&gt;
   &lt;u&gt;
    Codex SDK
   &lt;/u&gt;
  &lt;/a&gt;
  , companies can now embed this agentic power directly into their own custom workflows, such as automating fixes in a CI/CD pipeline or even creating self-evolving applications. During a live demo, an engineer showcased a mobile app that updated its own user interface in real-time based on a natural language prompt, all powered by the embedded Codex SDK.
 &lt;/p&gt;
 &lt;p&gt;
  While the launch of an
  &lt;a href=&quot;https://openai.com/index/introducing-apps-in-chatgpt/&quot;&gt;
   &lt;u&gt;
    app ecosystem in ChatGPT
   &lt;/u&gt;
  &lt;/a&gt;
  and the breathtaking visuals of the
  &lt;a href=&quot;https://openai.com/index/sora-2/&quot;&gt;
   &lt;u&gt;
    Sora 2 API
   &lt;/u&gt;
  &lt;/a&gt;
  rightfully generated headlines, the
  &lt;a href=&quot;https://openai.com/index/codex-now-generally-available/&quot;&gt;
   &lt;u&gt;
    general availability of Codex
   &lt;/u&gt;
  &lt;/a&gt;
  marks a more fundamental and immediate transformation. It is the quiet but powerful engine driving the next era of software development, turning the abstract promise of AI-driven productivity into a tangible, deployable reality for businesses today.
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Salesforce bets on AI &#x27;agents&#x27; to fix what it calls a $7 billion problem in enterprise software </title>
<link>https://venturebeat.com/data-infrastructure/salesforce-bets-on-ai-agents-to-fix-what-it-calls-a-usd7-billion-problem-in</link>
<pubDate>Mon, 22 Dec 2025 12:51:53 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;Credit: VentureBeat made with Midjourney&quot; data-nimg=&quot;1&quot; height=&quot;599&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/4ElJnVoqNF5EdTdQ2qbc94/6c61cde31557a66a34fdfbbfaa9e57ed/nuneybits_Vector_art_of_businessperson_guiding_robot_f1c9b0fc-59ad-455c-b635-5551c598aa7b.webp?w=1000&quot; width=&quot;1069&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  As 50,000 attendees descend on Salesforce&#x27;s
  &lt;a href=&quot;https://www.salesforce.com/dreamforce/&quot;&gt;
   &lt;u&gt;
    Dreamforce conference
   &lt;/u&gt;
  &lt;/a&gt;
  this week, the enterprise software giant is making its most aggressive bet yet on artificial intelligence agents, positioning itself as the antidote to what it calls an industry-wide &quot;pilot purgatory&quot; where
  &lt;a href=&quot;https://fortune.com/2025/08/18/mit-report-95-percent-generative-ai-pilots-at-companies-failing-cfo/&quot;&gt;
   &lt;u&gt;
    95% of enterprise AI projects never reach production
   &lt;/u&gt;
  &lt;/a&gt;
  .
 &lt;/p&gt;
 &lt;p&gt;
  The company on Monday launched
  &lt;a href=&quot;https://www.salesforce.com/agentforce/&quot;&gt;
   &lt;u&gt;
    Agentforce 360
   &lt;/u&gt;
  &lt;/a&gt;
  , a sweeping reimagination of its entire product portfolio designed to transform businesses into what it calls &quot;agentic enterprises&quot; — organizations where AI agents work alongside humans to handle up to 40% of work across sales, service, marketing, and operations.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  &quot;We are truly in the agentic AI era, and I think it&#x27;s probably the biggest revolution, the biggest transition in technology I&#x27;ve ever experienced in my career,&quot; said Parker Harris, Salesforce&#x27;s co-founder and chief technology officer, during a recent press briefing. &quot;In the future, 40% of the work in the Fortune 1000 is probably going to be done by AI, and it&#x27;s going to be humans and AI actually working together.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The announcement comes at a pivotal moment for Salesforce, which has deployed more than 12,000 AI agent implementations over the past year while building what Harris called a &quot;$7 billion business&quot; around its AI platform. Yet the launch also arrives amid unusual turbulence, as CEO Marc Benioff faces
  &lt;a href=&quot;https://www.politico.com/news/2025/10/11/slap-in-the-face-marc-benioffs-trump-turn-stuns-san-francisco-00604421&quot;&gt;
   &lt;u&gt;
    fierce backlash
   &lt;/u&gt;
  &lt;/a&gt;
  for recent comments
  &lt;a href=&quot;https://www.nytimes.com/2025/10/10/us/marc-benioff-san-francisco-guard.html&quot;&gt;
   &lt;u&gt;
    supporting President Trump
   &lt;/u&gt;
  &lt;/a&gt;
  and suggesting National Guard troops should patrol San Francisco streets.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;h2&gt;
  Why 95% of enterprise AI projects never launch
 &lt;/h2&gt;
 &lt;p&gt;
  The stakes are enormous. While companies have rushed to experiment with AI following ChatGPT&#x27;s emergence two years ago, most enterprise deployments have stalled before reaching production, according to
  &lt;a href=&quot;https://fortune.com/2025/08/18/mit-report-95-percent-generative-ai-pilots-at-companies-failing-cfo/&quot;&gt;
   &lt;u&gt;
    recent MIT research
   &lt;/u&gt;
  &lt;/a&gt;
  that Salesforce executives cited extensively.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Customers have invested a lot in AI, but they&#x27;re not getting the value,&quot; said Srini Tallapragada, Salesforce&#x27;s president and chief engineering and customer success officer. &quot;95% of enterprise AI pilots fail before production. It&#x27;s not because of lack of intent. People want to do this. Everybody understands the power of the technology. But why is it so hard?&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The answer, according to Tallapragada, is that AI tools remain disconnected from enterprise workflows, data, and governance systems. &quot;You&#x27;re writing prompts, prompts, you&#x27;re getting frustrated because the context is not there,&quot; he said, describing what he called a &quot;prompt doom loop.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Salesforce&#x27;s solution is a deeply integrated platform connecting what it calls four ingredients: the Agentforce 360 agent platform, Data 360 for unified data access, Customer 360 apps containing business logic, and Slack as the &quot;conversational interface&quot; where humans and agents collaborate.
 &lt;/p&gt;
 &lt;h2&gt;
  Slack becomes the front door to Salesforce
 &lt;/h2&gt;
 &lt;p&gt;
  Perhaps the most significant strategic shift is the elevation of
  &lt;a href=&quot;https://slack.com/&quot;&gt;
   &lt;u&gt;
    Slack
   &lt;/u&gt;
  &lt;/a&gt;
  — acquired by Salesforce in 2019 for
  &lt;a href=&quot;https://slack.com/blog/news/salesforce-completes-acquisition-of-slack&quot;&gt;
   &lt;u&gt;
    $27.7 billion
   &lt;/u&gt;
  &lt;/a&gt;
  — as the primary interface for Salesforce itself. The company is effectively reimagining its traditional Lightning interface around Slack channels, where sales deals, service cases, and data insights will surface conversationally rather than through forms and dashboards.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Imagine that you maybe don&#x27;t log into Salesforce, you don&#x27;t see Salesforce, but it&#x27;s there. It&#x27;s coming to you in Slack, because that&#x27;s where you&#x27;re getting your work done,&quot; Harris explained.
 &lt;/p&gt;
 &lt;p&gt;
  The strategy includes embedding Salesforce&#x27;s Agentforce agents for sales, IT service, HR service, and analytics directly into Slack, alongside a completely rebuilt Slackbot that acts as a personal AI companion. The company is also launching &quot;
  &lt;a href=&quot;https://slack.com/blog/news/channel-expert&quot;&gt;
   &lt;u&gt;
    Channel Expert
   &lt;/u&gt;
  &lt;/a&gt;
  ,&quot; an always-on agent that provides instant answers from channel conversations.
 &lt;/p&gt;
 &lt;p&gt;
  To enable third-party AI tools to access Slack&#x27;s conversational data, Salesforce is releasing a
  &lt;a href=&quot;https://slack.dev/secure-data-connectivity-for-the-modern-ai-era/&quot;&gt;
   &lt;u&gt;
    Real-Time Search API
   &lt;/u&gt;
  &lt;/a&gt;
  and
  &lt;a href=&quot;https://slack.dev/secure-data-connectivity-for-the-modern-ai-era/&quot;&gt;
   &lt;u&gt;
    Model Context Protocol server
   &lt;/u&gt;
  &lt;/a&gt;
  . Partners including OpenAI, Anthropic, Google, Perplexity, Writer, Dropbox, Notion, and Cursor are building agents that will live natively in Slack.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;The best way to see the power of the platform is through the AI apps and agents already being built,&quot; Rob Seaman, a Salesforce executive, said during a technical briefing, citing examples of startups &quot;achieving tens of thousands of customers that have it installed in 120 days or less.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  Voice and IT service take aim at new markets
 &lt;/h2&gt;
 &lt;p&gt;
  Beyond Slack integration, Salesforce announced major expansions into voice-based interactions and employee service.
  &lt;a href=&quot;https://www.salesforce.com/blog/agentforce-voice-solutions-launch/&quot;&gt;
   &lt;u&gt;
    Agentforce Voice
   &lt;/u&gt;
  &lt;/a&gt;
  , now generally available, transforms traditional IVR systems into natural conversations that can update CRM records, trigger workflows, and seamlessly hand off to human agents.
 &lt;/p&gt;
 &lt;p&gt;
  The IT Service offering represents Salesforce&#x27;s most direct challenge to
  &lt;a href=&quot;https://www.servicenow.com/&quot;&gt;
   &lt;u&gt;
    ServiceNow
   &lt;/u&gt;
  &lt;/a&gt;
  , the market leader. Mudhu Sudhakar, who joined Salesforce two months ago as senior vice president for IT and HR Service, positioned the product as a fundamental reimagining of employee support.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Legacy IT service management is very portals, forms, tickets focused, manual process,&quot; Sudhakar said. &quot;What we had a few key tenets: conversation first and agent first, really focused on having a conversational experience for the people requesting the support and for the people providing the support.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The IT Service platform includes what Salesforce describes as 25+ specialized agents and 100+ pre-built workflows and connectors that can handle everything from password resets to complex incident management.
 &lt;/p&gt;
 &lt;h2&gt;
  Early customers report dramatic efficiency gains
 &lt;/h2&gt;
 &lt;p&gt;
  Customer results suggest the approach is gaining traction.
  &lt;a href=&quot;https://www.reddit.com/&quot;&gt;
   &lt;u&gt;
    Reddit
   &lt;/u&gt;
  &lt;/a&gt;
  reduced average support resolution time from 8.9 minutes to 1.4 minutes — an 84% improvement — while deflecting 46% of cases entirely to AI agents. &quot;This efficiency has allowed us to provide on-demand help for complex tasks and boost advertiser satisfaction scores by 20%,&quot; said John Thompson, Reddit&#x27;s VP of sales strategy and operations, in a statement.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://engine.com/&quot;&gt;
   &lt;u&gt;
    Engine
   &lt;/u&gt;
  &lt;/a&gt;
  , a travel management company, reduced average handle time by 15%, saving over $2 million annually.
  &lt;a href=&quot;https://www.opentable.com/&quot;&gt;
   &lt;u&gt;
    OpenTable
   &lt;/u&gt;
  &lt;/a&gt;
  resolved 70% of restaurant and diner inquiries autonomously. And 1-800Accountant achieved a 90% case deflection rate during the critical tax week period.
 &lt;/p&gt;
 &lt;p&gt;
  Salesforce&#x27;s own internal deployments may be most telling. Tallapragada&#x27;s customer success organization now handles 1.8 million AI-powered conversations weekly, with metrics published at
  &lt;a href=&quot;http://help.salesforce.com&quot;&gt;
   &lt;u&gt;
    help.salesforce.com
   &lt;/u&gt;
  &lt;/a&gt;
  showing how many agents answer versus escalating to humans.
 &lt;/p&gt;
 &lt;p&gt;
  Even more significantly, Salesforce has deployed AI-powered sales development representatives to follow up on leads that would previously have gone uncontacted due to cost constraints. &quot;Now, Agentforce has an SDR which is doing thousands of leads following up,&quot; Tallapragada explained. The company also increased proactive customer outreach by 40% by shifting staff from reactive support.
 &lt;/p&gt;
 &lt;h2&gt;
  The trust layer problem enterprises can&#x27;t ignore
 &lt;/h2&gt;
 &lt;p&gt;
  Given enterprise concerns about AI reliability, Salesforce has invested heavily in what it calls the &quot;trust layer&quot; — audit trails, compliance checks, and observability tools that let organizations monitor agent behavior at scale.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;You should think of an agent as a human. Digital labor. You need to manage performance just like a human. And you need these audit trails,&quot; Tallapragada explained.
 &lt;/p&gt;
 &lt;p&gt;
  The company encountered this challenge firsthand when its own agent deployment scaled. &quot;When we started at Agentforce at Salesforce, we would track every message, which is great until 1,000, 3,000,&quot; Tallapragada said. &quot;Once you have a million chats, there&#x27;s no human, we cannot do it.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The platform now includes &quot;
  &lt;a href=&quot;https://www.cxtoday.com/crm/salesforce-teases-a-new-agentforce-builder-announces-more-additions-to-the-platform/&quot;&gt;
   &lt;u&gt;
    Agentforce Grid
   &lt;/u&gt;
  &lt;/a&gt;
  &quot; for searching across millions of conversations to identify and fix problematic patterns. The company also introduced Agent Script, a new scripting language that allows developers to define precise guardrails and deterministic controls for agent behavior.
 &lt;/p&gt;
 &lt;h2&gt;
  Data infrastructure gets a major upgrade
 &lt;/h2&gt;
 &lt;p&gt;
  Underlying the agent capabilities is significant infrastructure investment. Salesforce&#x27;s
  &lt;a href=&quot;https://www.salesforce.com/blog/what-exactly-is-salesforce-customer-360/&quot;&gt;
   &lt;u&gt;
    Data 360
   &lt;/u&gt;
  &lt;/a&gt;
  includes &quot;Intelligent Context,&quot; which automatically extracts structured information from unstructured content like PDFs, diagrams, and flowcharts using what the company describes as &quot;AI-powered unstructured data pipelines.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The company is also collaborating with
  &lt;a href=&quot;https://www.databricks.com/&quot;&gt;
   &lt;u&gt;
    Databricks
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.getdbt.com/&quot;&gt;
   &lt;u&gt;
    dbt Labs
   &lt;/u&gt;
  &lt;/a&gt;
  , and
  &lt;a href=&quot;https://www.snowflake.com/en/&quot;&gt;
   &lt;u&gt;
    Snowflake
   &lt;/u&gt;
  &lt;/a&gt;
  on the &quot;Universal Semantic Interchange,&quot; an attempt to standardize how different platforms define business metrics. The pending $8 billion acquisition of Informatica, expected to close soon, will expand metadata management capabilities across the enterprise.
 &lt;/p&gt;
 &lt;h2&gt;
  The competitive landscape keeps intensifying
 &lt;/h2&gt;
 &lt;p&gt;
  Salesforce&#x27;s aggressive AI agent push comes as virtually every major enterprise software vendor pursues similar strategies. Microsoft has embedded Copilot across its product line, Google offers agent capabilities through Vertex AI and Gemini, and ServiceNow has launched its own agentic offerings.
 &lt;/p&gt;
 &lt;p&gt;
  When asked how Salesforce&#x27;s announcement compared to
  &lt;a href=&quot;https://venturebeat.com/ai/openai-dev-day-2025-chatgpt-becomes-the-new-app-store-and-hardware-is-coming&quot;&gt;
   &lt;u&gt;
    OpenAI&#x27;s recent releases
   &lt;/u&gt;
  &lt;/a&gt;
  , Tallapragada emphasized that customers will use multiple AI tools simultaneously. &quot;Most of the time I&#x27;m seeing they&#x27;re using OpenAI, they&#x27;re using Gemini, they&#x27;re using Anthropic, just like Salesforce, we use all three,&quot; he said.
 &lt;/p&gt;
 &lt;p&gt;
  The real differentiation, executives argued, lies not in the AI models but in the integration with business processes and data. Harris framed the competition in terms familiar from Salesforce&#x27;s founding: &quot;26 years ago, we just said, let&#x27;s make Salesforce automation as easy as buying a book on Amazon.com. We&#x27;re doing that same thing. We want to make agentic AI as easy as buying a book on Amazon.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The company&#x27;s customer success stories are impressive but remain a small fraction of its customer base. With 150,000 Salesforce customers and one million Slack customers, the 12,000 Agentforce deployments represent roughly 8% penetration — strong for a one-year-old product line, but hardly ubiquitous.
 &lt;/p&gt;
 &lt;p&gt;
  The company&#x27;s stock, down
  &lt;a href=&quot;https://finance.yahoo.com/news/salesforce-stock-trades-near-52-132500685.html&quot;&gt;
   &lt;u&gt;
    roughly 28% year to date
   &lt;/u&gt;
  &lt;/a&gt;
  with a
  &lt;a href=&quot;https://www.investors.com/news/technology/salesforce-stock-crm-ai-dreamforce/&quot;&gt;
   &lt;u&gt;
    Relative Strength rating of just 15
   &lt;/u&gt;
  &lt;/a&gt;
  , suggests investors remain skeptical. This week&#x27;s Dreamforce demonstrations — and the months of customer deployments that follow — will begin to provide answers to whether Salesforce can finally move enterprise AI from pilots to production at scale, or whether the &quot;$7 billion business&quot; remains more aspiration than reality.
 &lt;/p&gt;
 &lt;p&gt;
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Visa just launched a protocol to secure the AI shopping boom — here’s what it means for merchants </title>
<link>https://venturebeat.com/data-infrastructure/visa-just-launched-a-protocol-to-secure-the-ai-shopping-boom-heres-what-it</link>
<pubDate>Mon, 22 Dec 2025 12:51:44 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;Credit: VentureBeat made with Midjourney&quot; data-nimg=&quot;1&quot; height=&quot;599&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/4TWzzYHcsJXmxU7VYnIlKV/896cc598ae137fe841c13309d6aae3df/nuneybits_Vector_art_of_a_Visa_credit_card_c3c9580a-d8ce-4402-9763-bd56dc26549e.webp?w=1000&quot; width=&quot;1069&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://usa.visa.com/&quot;&gt;
   &lt;u&gt;
    Visa
   &lt;/u&gt;
  &lt;/a&gt;
  is introducing a new security framework designed to solve one of the thorniest problems emerging in artificial intelligence-powered commerce: how retailers can tell the difference between legitimate AI shopping assistants and the malicious bots that plague their websites.
 &lt;/p&gt;
 &lt;p&gt;
  The payments giant unveiled its
  &lt;a href=&quot;https://developer.visa.com/capabilities/trusted-agent-protocol/docs#:~:text=The%20Trusted%20Agent%20Protocol%3A%20This,for%20validating%20an%20agent&#x27;s%20intent.&quot;&gt;
   &lt;u&gt;
    Trusted Agent Protocol
   &lt;/u&gt;
  &lt;/a&gt;
  on Tuesday, establishing what it describes as foundational infrastructure for &quot;agentic commerce&quot; — a term for the rapidly growing practice of consumers delegating shopping tasks to AI agents that can search products, compare prices, and complete purchases autonomously.
 &lt;/p&gt;
 &lt;p&gt;
  The protocol enables merchants to cryptographically verify that an AI agent browsing their site is authorized and trustworthy, rather than a bot designed to scrape pricing data, test stolen credit cards, or carry out other fraudulent activities.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  The launch comes as AI-driven traffic to U.S. retail websites has
  &lt;a href=&quot;https://business.adobe.com/resources/holiday-shopping-report.html&quot;&gt;
   &lt;u&gt;
    exploded by more than 4,700%
   &lt;/u&gt;
  &lt;/a&gt;
  over the past year, according to data from Adobe cited by Visa. That dramatic surge has created an acute challenge for merchants whose existing bot detection systems — designed to block automated traffic — now risk accidentally blocking legitimate AI shoppers along with bad actors.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Merchants need additional tools that provide them with greater insight and transparency into agentic commerce activities to ensure they can participate safely,&quot; said Rubail Birwadker, Visa&#x27;s Global Head of Growth, in an exclusive interview with VentureBeat. &quot;Without common standards, potential risks include ecosystem fragmentation and the proliferation of closed loop models.&quot;
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  The stakes are substantial. While 85% of shoppers who have used AI to shop report improved experiences, merchants face the prospect of either turning away legitimate AI-powered customers or exposing themselves to sophisticated bot attacks. Visa&#x27;s own data shows the company
  &lt;a href=&quot;https://usa.visa.com/about-visa/newsroom/press-releases.releaseId.20661.html&quot;&gt;
   &lt;u&gt;
    prevented $40 billion in fraudulent activity
   &lt;/u&gt;
  &lt;/a&gt;
  between October 2022 and September 2023, nearly double the previous year, much of it involving AI-powered enumeration attacks where bots systematically test combinations of card numbers until finding valid credentials.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Inside the cryptographic handshake: How Visa verifies AI shopping agents
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Visa&#x27;s
  &lt;a href=&quot;https://developer.visa.com/capabilities/trusted-agent-protocol/docs#:~:text=The%20Trusted%20Agent%20Protocol%3A%20This,for%20validating%20an%20agent%27s%20intent.&quot;&gt;
   &lt;u&gt;
    Trusted Agent Protocol
   &lt;/u&gt;
  &lt;/a&gt;
  operates through what Birwadker describes as a &quot;cryptographic trust handshake&quot; between merchants and approved AI agents. The system works in three steps:
 &lt;/p&gt;
 &lt;p&gt;
  First, AI agents must be approved and onboarded through Visa&#x27;s
  &lt;a href=&quot;https://developer.visa.com/capabilities/visa-intelligent-commerce&quot;&gt;
   &lt;u&gt;
    Intelligent Commerce
   &lt;/u&gt;
  &lt;/a&gt;
  program, where they undergo vetting to meet trust and reliability standards. Each approved agent receives a unique digital signature key — essentially a cryptographic credential that proves its identity.
 &lt;/p&gt;
 &lt;p&gt;
  When an approved agent visits a merchant&#x27;s website, it creates a digital signature using its key and transmits three categories of information: Agent Intent (indicating the agent is trusted and intends to retrieve product details or make a purchase), Consumer Recognition (data showing whether the underlying consumer has an existing account with the merchant), and Payment Information (optional payment data to support checkout).
 &lt;/p&gt;
 &lt;p&gt;
  Merchants or their infrastructure providers, such as content delivery networks, then validate these digital signatures against Visa&#x27;s registry of approved agents. &quot;Upon proper validation of these fields, the merchant can confirm the signature is a trusted agent,&quot; Birwadker explained.
 &lt;/p&gt;
 &lt;p&gt;
  Crucially, Visa designed the protocol to require minimal changes to existing merchant infrastructure. Built on the
  &lt;a href=&quot;https://www.rfc-editor.org/rfc/rfc9421&quot;&gt;
   &lt;u&gt;
    HTTP Message Signature standard
   &lt;/u&gt;
  &lt;/a&gt;
  and aligned with
  &lt;a href=&quot;https://developers.cloudflare.com/bots/reference/bot-verification/web-bot-auth/&quot;&gt;
   &lt;u&gt;
    Web Both Auth
   &lt;/u&gt;
  &lt;/a&gt;
  , the protocol works with existing web infrastructure without requiring merchants to overhaul their checkout pages. &quot;This is no-code functionality,&quot; Birwadker emphasized, though merchants may need to integrate with Visa&#x27;s Developer Center to access the verification system.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   The race for AI commerce standards: Visa faces competition from Google, OpenAI, and Stripe
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Visa developed the protocol in collaboration with
  &lt;a href=&quot;https://www.cloudflare.com/&quot;&gt;
   &lt;u&gt;
    Cloudflare
   &lt;/u&gt;
  &lt;/a&gt;
  , the web infrastructure and security company that already provides bot management services to millions of websites. The partnership reflects Visa&#x27;s recognition that solving bot verification requires cooperation across the entire web stack, not just the payments layer.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Trusted Agent Protocol supplements traditional bot management by providing merchants insights that enable agentic commerce,&quot; Birwadker said. &quot;Agents are providing additional context they otherwise would not, including what it intends to do, who the underlying consumer is, and payment information.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The protocol arrives as multiple technology giants race to establish competing standards for AI commerce. Google recently introduced its
  &lt;a href=&quot;https://cloud.google.com/blog/products/ai-machine-learning/announcing-agents-to-payments-ap2-protocol&quot;&gt;
   &lt;u&gt;
    Agent Protocol for Payments (AP2)
   &lt;/u&gt;
  &lt;/a&gt;
  , while
  &lt;a href=&quot;https://openai.com/&quot;&gt;
   &lt;u&gt;
    OpenAI
   &lt;/u&gt;
  &lt;/a&gt;
  and
  &lt;a href=&quot;https://stripe.com/&quot;&gt;
   &lt;u&gt;
    Stripe
   &lt;/u&gt;
  &lt;/a&gt;
  have discussed their own approaches to enabling AI agents to make purchases. Microsoft, Shopify, Adyen, Ant International, Checkout.com, Cybersource, Elavon, Fiserv, Nuvei, and Worldpay provided feedback during Trusted Agent Protocol&#x27;s development, according to Visa.
 &lt;/p&gt;
 &lt;p&gt;
  When asked how Visa&#x27;s protocol relates to these competing efforts, Birwadker struck a collaborative tone. &quot;Both Google&#x27;s AP2 and Visa&#x27;s Trusted Agent Protocol are working toward the same goal of building trust in agent-initiated payments,&quot; he said. &quot;We are engaged with Google, OpenAI, and Stripe and are looking to create compatibility across the ecosystem.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Visa says it is working with global standards bodies including the
  &lt;a href=&quot;https://www.ietf.org/&quot;&gt;
   &lt;u&gt;
    Internet Engineering Task Force (IETF)
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://openid.net/foundation/&quot;&gt;
   &lt;u&gt;
    OpenID Foundation
   &lt;/u&gt;
  &lt;/a&gt;
  , and
  &lt;a href=&quot;https://www.emvco.com/&quot;&gt;
   &lt;u&gt;
    EMVCo
   &lt;/u&gt;
  &lt;/a&gt;
  to ensure the protocol can eventually become interoperable with other emerging standards. &quot;While these specifications apply to the Visa network in this initial phase, enabling agents to safely and securely act on a consumer&#x27;s behalf requires an open, ecosystem-wide approach,&quot; Birwadker noted.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Who pays when AI agents go rogue? Unanswered questions about liability and authorization
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The protocol raises important questions about authorization and liability when AI agents make purchases on behalf of consumers. If an agent completes an unauthorized transaction — perhaps misunderstanding a user&#x27;s intent or exceeding its delegated authority — who bears responsibility?
 &lt;/p&gt;
 &lt;p&gt;
  Birwadker emphasized that the protocol helps merchants &quot;leverage this information to enable experiences tied to existing consumer relationships and more secure checkout,&quot; but he did not provide specific details about how disputes would be handled when agents make unauthorized purchases. Visa&#x27;s existing fraud protection and chargeback systems would presumably apply, though the company has not yet published detailed guidance on agent-initiated transaction disputes.
 &lt;/p&gt;
 &lt;p&gt;
  The protocol also places Visa in the position of gatekeeper for the emerging agentic commerce ecosystem. Because Visa determines which AI agents get approved for the
  &lt;a href=&quot;https://developer.visa.com/capabilities/visa-intelligent-commerce&quot;&gt;
   &lt;u&gt;
    Intelligent Commerce
   &lt;/u&gt;
  &lt;/a&gt;
  program and receive cryptographic credentials, the company effectively controls which agents merchants can easily trust. &quot;Agents are approved and onboarded through the Visa Intelligent Commerce program, ensuring they meet our standards for trust and reliability,&quot; Birwadker said, though he did not detail the specific criteria agents must meet or whether Visa charges fees for approval.
 &lt;/p&gt;
 &lt;p&gt;
  This gatekeeping role could prove contentious, particularly if Visa&#x27;s approval process favors large technology companies over startups, or if the company faces pressure to block agents from competitors or politically controversial entities. Visa declined to provide details about how many agents it has approved so far or how long the vetting process typically takes.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Visa&#x27;s legal battles and the long road to merchant adoption
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The protocol launch comes at a complex moment for Visa, which continues to navigate significant legal and regulatory challenges even as its core business remains robust. The company&#x27;s latest
  &lt;a href=&quot;https://investor.visa.com/financial-information/quarterly-earnings/&quot;&gt;
   &lt;u&gt;
    earnings report
   &lt;/u&gt;
  &lt;/a&gt;
  for the third quarter of fiscal year 2025 showed a 10% increase in net revenues to $9.2 billion, driven by resilient consumer spending and strong growth in cross-border transaction volume. For the full fiscal year ending September 30, 2024, Visa processed 289 billion transactions, with a total payments volume of $15.2 trillion.
 &lt;/p&gt;
 &lt;p&gt;
 &lt;/p&gt;
 &lt;p&gt;
  However, the company&#x27;s legal headwinds have intensified. In July 2025, a federal judge rejected a landmark
  &lt;a href=&quot;https://www.reuters.com/legal/us-judge-rejects-visa-mastercard-30-bln-swipe-fee-settlement-2024-06-25/&quot;&gt;
   &lt;u&gt;
    $30 billion settlement
   &lt;/u&gt;
  &lt;/a&gt;
  that Visa and Mastercard had reached with merchants over long-disputed credit card swipe fees, sending the parties back to the negotiating table and extending the long-running legal battle.
 &lt;/p&gt;
 &lt;p&gt;
  Simultaneously,
  &lt;a href=&quot;https://www.justice.gov/archives/opa/pr/justice-department-sues-visa-monopolizing-debit-markets&quot;&gt;
   &lt;u&gt;
    Visa remains under investigation by the Department of Justice
   &lt;/u&gt;
  &lt;/a&gt;
  over its rules for routing debit card transactions, with regulators scrutinizing whether the company&#x27;s practices unlawfully limit merchant choice and stifle competition. These domestic challenges are mirrored abroad, where European regulators have continued their own antitrust investigations into the fee structures of both Visa and its primary competitor, Mastercard.
 &lt;/p&gt;
 &lt;p&gt;
  Against this backdrop of regulatory pressure, Birwadker acknowledged that adoption of the Trusted Agent Protocol will take time. &quot;As agentic commerce continues to rise, we recognize that consumer trust is still in its early stages,&quot; he said. &quot;That&#x27;s why our focus through 2025 is on building foundational credibility and demonstrating real-world value.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The protocol is available immediately in
  &lt;a href=&quot;https://developer.visa.com/&quot;&gt;
   &lt;u&gt;
    Visa&#x27;s Developer Center
   &lt;/u&gt;
  &lt;/a&gt;
  and on
  &lt;a href=&quot;https://github.com/visa&quot;&gt;
   &lt;u&gt;
    GitHub
   &lt;/u&gt;
  &lt;/a&gt;
  , with agent onboarding already active and merchant integration resources available. But Birwadker declined to provide specific targets for how many merchants might adopt the protocol by the end of 2026. &quot;Adoption is aligned with the momentum we&#x27;re already seeing,&quot; he said. &quot;The launch of our protocol marks another big step — it&#x27;s not just a technical milestone, but a signal that the industry is beginning to unify.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Industry analysts say merchant adoption will likely depend on how quickly agentic commerce grows as a percentage of overall e-commerce. While AI-driven traffic has surged dramatically, much of that consists of agents browsing and researching rather than completing purchases. If AI agents begin accounting for a significant share of completed transactions, merchants will face stronger incentives to adopt verification systems like Visa&#x27;s protocol.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   From fraud detection to AI gatekeeping: Visa&#x27;s $10 billion bet on artificial intelligence
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Visa&#x27;s move reflects broader strategic bets on AI across the financial services industry. The company has
  &lt;a href=&quot;https://www.cnbc.com/2024/07/26/ai-and-machine-learning-helped-visa-combat-40-billion-in-fraud-activity.html&quot;&gt;
   &lt;u&gt;
    invested $10 billion in technology
   &lt;/u&gt;
  &lt;/a&gt;
  over the past five years to reduce fraud and increase network security, with AI and machine learning central to those efforts. Visa&#x27;s fraud detection system analyzes over 500 different attributes for each transaction, using AI models to assign real-time risk scores to the 300 billion annual transactions flowing through its network.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Every single one of those transactions has been processed by AI,&quot; James Mirfin, Visa&#x27;s global head of risk and identity solutions, said in a
  &lt;a href=&quot;https://www.cnbc.com/2024/07/26/ai-and-machine-learning-helped-visa-combat-40-billion-in-fraud-activity.html&quot;&gt;
   &lt;u&gt;
    July 2024 CNBC interview
   &lt;/u&gt;
  &lt;/a&gt;
  discussing the company&#x27;s fraud prevention efforts. &quot;If you see a new type of fraud happening, our model will see that, it will catch it, it will score those transactions as high risk and then our customers can decide not to approve those transactions.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The company has also moved aggressively into new payment territories beyond its core card business. In January 2025,
  &lt;a href=&quot;https://www.cnbc.com/2025/01/28/elon-musk-x-visa-digital-wallet.html&quot;&gt;
   &lt;u&gt;
    Visa partnered with Elon Musk&#x27;s X
   &lt;/u&gt;
  &lt;/a&gt;
  (formerly Twitter) to provide the infrastructure for a digital wallet and peer-to-peer payment service called the X Money Account, competing with services like Venmo and Zelle. That deal marked Visa&#x27;s first major partnership in the social media payments space and reflected the company&#x27;s recognition that payment flows are increasingly happening outside traditional e-commerce channels.
 &lt;/p&gt;
 &lt;p&gt;
  The agentic commerce protocol represents an extension of this strategy — an attempt to ensure Visa remains central to payment flows even as the mechanics of shopping shift from direct human interaction to AI intermediation.
  &lt;a href=&quot;https://venturebeat.com/ai/visa-launches-intelligent-commerce-platform-letting-ai-agents-swipe-your-card-safely-it-says&quot;&gt;
   &lt;u&gt;
    Jack Forestell
   &lt;/u&gt;
  &lt;/a&gt;
  , Visa&#x27;s Chief Product &amp; Strategy Officer, framed the protocol in expansive terms: &quot;We believe the entire payments ecosystem has a responsibility to ensure sellers trust AI agents with the same confidence they place in their most valued customers and networks.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   The coming battle for control of AI shopping
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The real test for Visa&#x27;s protocol won&#x27;t be technical — it will be political. As AI agents become a larger force in retail, whoever controls the verification infrastructure controls access to hundreds of billions of dollars in commerce. Visa&#x27;s position as gatekeeper gives it enormous leverage, but also makes it a target.
 &lt;/p&gt;
 &lt;p&gt;
  Merchants chafing under Visa&#x27;s existing fee structure and facing multiple antitrust investigations may resist ceding even more power to the payments giant. Competitors like Google and OpenAI, each with their own ambitions in commerce, have little incentive to let Visa dictate standards. Regulators already scrutinizing Visa&#x27;s market dominance will surely examine whether its agent approval process unfairly advantages certain players.
 &lt;/p&gt;
 &lt;p&gt;
  And there&#x27;s a deeper question lurking beneath the technical specifications and corporate partnerships: In an economy increasingly mediated by AI, who decides which algorithms get to spend our money? Visa is making an aggressive bid to be that arbiter, wrapping its answer in the language of security and interoperability. Whether merchants, consumers, and regulators accept that proposition will determine not just the fate of the Trusted Agent Protocol, but the structure of AI-powered commerce itself.
 &lt;/p&gt;
 &lt;p&gt;
  For now, Visa is moving forward with the confidence of a company that has weathered disruption before. But in the emerging world of agentic commerce, being too trusted might prove just as dangerous as not being trusted enough.
 &lt;/p&gt;
 &lt;p&gt;
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Kai-Fu Lee&#x27;s brutal assessment: America is already losing the AI hardware war to China </title>
<link>https://venturebeat.com/data-infrastructure/kai-fu-lees-brutal-assessment-america-is-already-losing-the-ai-hardware-war</link>
<pubDate>Mon, 22 Dec 2025 12:51:42 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;Credit: VentureBeat made with Midjourney&quot; data-nimg=&quot;1&quot; height=&quot;599&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/ayDtsYfCFDVHHKnTvWKwk/04173bcfce3f9d53ecd9fe3ecfd14d5c/nuneybits_Vector_art_of_Chinese_flag-coded_AI_chip_6c9fcafc-8614-4d3b-858f-d64bede8c2df.webp?w=1000&quot; width=&quot;1069&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
    &lt;p&gt;
     Credit: VentureBeat made with Midjourney
    &lt;/p&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  China is on track to dominate consumer artificial intelligence applications and robotics manufacturing within years, but the United States will maintain its substantial lead in enterprise AI adoption and cutting-edge research, according to
  &lt;a href=&quot;https://en.wikipedia.org/wiki/Kai-Fu_Lee&quot;&gt;
   &lt;u&gt;
    Kai-Fu Lee
   &lt;/u&gt;
  &lt;/a&gt;
  , one of the world&#x27;s most prominent AI scientists and investors.
 &lt;/p&gt;
 &lt;p&gt;
  In a rare, unvarnished assessment delivered via video link from Beijing to the
  &lt;a href=&quot;https://tedai-sanfrancisco.ted.com/&quot;&gt;
   &lt;u&gt;
    TED AI conference
   &lt;/u&gt;
  &lt;/a&gt;
  in San Francisco Tuesday, Lee — a former executive at Apple, Microsoft, and Google who now runs both a major venture capital firm and his own AI company — laid out a technology landscape splitting along geographic and economic lines, with profound implications for both commercial competition and national security.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  &quot;China&#x27;s robotics has the advantage of having integrated AI into much lower costs, better supply chain and fast turnaround, so companies like
  &lt;a href=&quot;https://www.unitree.com/&quot;&gt;
   &lt;u&gt;
    Unitree
   &lt;/u&gt;
  &lt;/a&gt;
  are actually the farthest ahead in the world in terms of building affordable, embodied humanoid AI,&quot; Lee said, referring to a Chinese robotics manufacturer that has undercut Western competitors on price while advancing capabilities.
 &lt;/p&gt;
 &lt;p&gt;
  The comments, made to a room filled with Silicon Valley executives, investors, and researchers, represented one of the most detailed public assessments from Lee about the comparative strengths and weaknesses of the world&#x27;s two AI superpowers — and suggested that the race for artificial intelligence leadership is becoming less a single contest than a series of parallel competitions with different winners.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Why venture capital is flowing in opposite directions in the U.S. and China
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  At the heart of Lee&#x27;s analysis lies a fundamental difference in how capital flows in the two countries&#x27; innovation ecosystems. American venture capitalists, Lee said, are pouring money into generative AI companies building large language models and enterprise software, while Chinese investors are betting heavily on robotics and hardware.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;The VCs in the US don&#x27;t fund robotics the way the VCs do in China,&quot; Lee said. &quot;Just like the VCs in China don&#x27;t fund generative AI the way the VCs do in the US.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  This investment divergence reflects different economic incentives and market structures. In the United States, where companies have grown accustomed to paying for software subscriptions and where labor costs are high, enterprise AI tools that boost white-collar productivity command premium prices. In China, where software subscription models have historically struggled to gain traction but manufacturing dominates the economy, robotics offers a clearer path to commercialization.
 &lt;/p&gt;
 &lt;p&gt;
  The result, Lee suggested, is that each country is pulling ahead in different domains — and may continue to do so.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;China&#x27;s got some challenges to overcome in getting a company funded as well as OpenAI or Anthropic,&quot; Lee acknowledged, referring to the leading American AI labs. &quot;But I think U.S., on the flip side, will have trouble developing the investment interest and value creation in the robotics&quot; sector.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Why American companies dominate enterprise AI while Chinese firms struggle with subscriptions
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Lee was explicit about one area where the United States maintains what appears to be a durable advantage: getting businesses to actually adopt and pay for AI software.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;The enterprise adoption will clearly be led by the United States,&quot; Lee said. &quot;The Chinese companies have not yet developed a habit of paying for software on a subscription.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  This seemingly mundane difference in business culture — whether companies will pay monthly fees for software — has become a critical factor in the AI race. The explosion of spending on tools like
  &lt;a href=&quot;https://github.com/features/copilot&quot;&gt;
   &lt;u&gt;
    GitHub Copilot
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://chatgpt.com/business/enterprise?utm_source=google&amp;utm_medium=paidsearch_brand&amp;utm_campaign=GOOG_B_SEM_GBR_Core_ENT_BAU_ACQ_PER_BRD_ALL_NAMER_US_EN_080625&amp;utm_term=chatgpt%20enterprise&amp;utm_content=182507886919&amp;utm_ad=779434575256&amp;utm_match=b&amp;gad_source=1&amp;gad_campaignid=22855802308&amp;gbraid=0AAAAA-I0E5deWS9iAj-S2JPixEaUT67Un&amp;gclid=CjwKCAjwgeLHBhBuEiwAL5gNEQgjDKgZm5up9BDA-oZ1HLMAECMm5XlfJerkJ9BbJgtkYf9GcAAQUhoCrskQAvD_BwE&quot;&gt;
   &lt;u&gt;
    ChatGPT Enterprise
   &lt;/u&gt;
  &lt;/a&gt;
  , and other AI-powered productivity software has fueled American companies&#x27; ability to invest billions in further research and development.
 &lt;/p&gt;
 &lt;p&gt;
  Lee noted that China has historically overcome similar challenges in consumer technology by developing alternative business models. &quot;In the early days of internet software, China was also well behind because people weren&#x27;t willing to pay for software,&quot; he said. &quot;But then advertising models, e-commerce models really propelled China forward.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Still, he suggested, someone will need to &quot;find a new business model that isn&#x27;t just pay per software per use or per month basis. That&#x27;s going to not happen in China anytime soon.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The implication: American companies building enterprise AI tools have a window — perhaps a substantial one — where they can generate revenue and reinvest in R&amp;D without facing serious Chinese competition in their core market.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   How ByteDance, Alibaba and Tencent will outpace Meta and Google in consumer AI
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Where Lee sees China pulling ahead decisively is in consumer-facing AI applications — the kind embedded in social media, e-commerce, and entertainment platforms that billions of people use daily.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;In terms of consumer usage, that&#x27;s likely to happen,&quot; Lee said, referring to China matching or surpassing the United States in AI deployment. &quot;The Chinese giants, like
  &lt;a href=&quot;https://www.bytedance.com/en/&quot;&gt;
   &lt;u&gt;
    ByteDance
   &lt;/u&gt;
  &lt;/a&gt;
  and
  &lt;a href=&quot;https://www.alibaba.com/&quot;&gt;
   &lt;u&gt;
    Alibaba
   &lt;/u&gt;
  &lt;/a&gt;
  and
  &lt;a href=&quot;https://www.tencent.com/&quot;&gt;
   &lt;u&gt;
    Tencent
   &lt;/u&gt;
  &lt;/a&gt;
  , will definitely move a lot faster than their equivalent in the United States, companies like
  &lt;a href=&quot;https://www.meta.com/&quot;&gt;
   &lt;u&gt;
    Meta
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.youtube.com/&quot;&gt;
   &lt;u&gt;
    YouTube
   &lt;/u&gt;
  &lt;/a&gt;
  and so on.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Lee pointed to a cultural advantage: Chinese technology companies have spent the past decade obsessively optimizing for user engagement and product-market fit in brutally competitive markets. &quot;The Chinese giants really work tenaciously, and they have mastered the art of figuring out product market fit,&quot; he said. &quot;Now they have to add technology to it. So that is inevitably going to happen.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  This assessment aligns with recent industry observations. ByteDance&#x27;s
  &lt;a href=&quot;https://www.tiktok.com/en/&quot;&gt;
   &lt;u&gt;
    TikTok
   &lt;/u&gt;
  &lt;/a&gt;
  became the world&#x27;s most downloaded app through sophisticated AI-driven content recommendation, and Chinese companies have pioneered AI-powered features in areas like live-streaming commerce and short-form video that Western companies later copied.
 &lt;/p&gt;
 &lt;p&gt;
  Lee also noted that China has already deployed AI more widely in certain domains. &quot;There are a lot of areas where China has also done a great job, such as using computer vision, speech recognition, and translation more widely,&quot; he said.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   The surprising open-source shift that has Chinese models beating Meta&#x27;s Llama
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Perhaps Lee&#x27;s most striking data point concerned
  &lt;a href=&quot;https://venturebeat.com/ai/why-open-source-ai-became-an-american-national-priority&quot;&gt;
   &lt;u&gt;
    open-source AI development
   &lt;/u&gt;
  &lt;/a&gt;
  — an area where China appears to have seized leadership from American companies in a remarkably short time.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;The 10 highest rated open source [models] are from China,&quot; Lee said. &quot;These companies have now eclipsed Meta&#x27;s Llama, which used to be number one.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  This represents a significant shift. Meta&#x27;s
  &lt;a href=&quot;https://venturebeat.com/ai/metas-answer-to-deepseek-is-here-llama-4-launches-with-long-context-scout-and-maverick-models-and-2t-parameter-behemoth-on-the-way&quot;&gt;
   &lt;u&gt;
    Llama models
   &lt;/u&gt;
  &lt;/a&gt;
  were widely viewed as the gold standard for open-source large language models as recently as early 2024. But Chinese companies — including Lee&#x27;s own firm,
  &lt;a href=&quot;http://01.ai&quot;&gt;
   &lt;u&gt;
    01.AI
   &lt;/u&gt;
  &lt;/a&gt;
  , along with
  &lt;a href=&quot;https://www.alibaba.com/&quot;&gt;
   &lt;u&gt;
    Alibaba
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.baidu.com/&quot;&gt;
   &lt;u&gt;
    Baidu
   &lt;/u&gt;
  &lt;/a&gt;
  , and others — have released a flood of open-source models that, according to various benchmarks, now outperform their American counterparts.
 &lt;/p&gt;
 &lt;p&gt;
  The open-source question has become a flashpoint in AI development. Lee made an extensive case for why open-source models will prove essential to the technology&#x27;s future, even as closed models from companies like OpenAI command higher prices and, often, superior performance.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;I think open source has a number of major advantages,&quot; Lee argued. With open-source models, &quot;you can examine it, tune it, improve it. It&#x27;s yours, and it&#x27;s free, and it&#x27;s important for building if you want to build an application or tune the model to do something specific.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  He drew an analogy to operating systems: &quot;People who work in operating systems loved Linux, and that&#x27;s why its adoption went through the roof. And I think in the future, open source will also allow people to tune a sovereign model for a country, make it work better for a particular language.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Still, Lee predicted both approaches will coexist. &quot;I don&#x27;t think open source models will win,&quot; he said. &quot;I think just like we have Apple, which is closed, but provides a somewhat better experience than Android... I think we&#x27;re going to see more apps using open-source models, more engineers wanting to build open-source models, but I think more money will remain in the closed model.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Why China&#x27;s manufacturing advantage makes the robotics race &#x27;not over, but&#x27; nearly decided
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  On robotics, Lee&#x27;s message was blunt: the combination of China&#x27;s manufacturing prowess, lower costs, and aggressive investment has created an advantage that will be difficult for American companies to overcome.
 &lt;/p&gt;
 &lt;p&gt;
  When asked directly whether the robotics race was already over with China victorious, Lee hedged only slightly. &quot;It&#x27;s not over, but I think the U.S. is still capable of coming up with the best robotic research ideas,&quot; he said. &quot;But the VCs in the U.S. don&#x27;t fund robotics the way the VCs do in China.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The challenge is structural. Building robots requires not just software and AI, but hardware manufacturing at scale — precisely the kind of integrated supply chain and low-cost production that China has spent decades perfecting. While American labs at universities and companies like
  &lt;a href=&quot;https://bostondynamics.com/&quot;&gt;
   &lt;u&gt;
    Boston Dynamics
   &lt;/u&gt;
  &lt;/a&gt;
  continue to produce impressive research prototypes, turning those prototypes into affordable commercial products requires the manufacturing ecosystem that China possesses.
 &lt;/p&gt;
 &lt;p&gt;
  Companies like
  &lt;a href=&quot;https://www.unitree.com/&quot;&gt;
   &lt;u&gt;
    Unitree
   &lt;/u&gt;
  &lt;/a&gt;
  have demonstrated this advantage concretely. The company&#x27;s humanoid robots and quadrupedal robots cost a fraction of their American-made equivalents while offering comparable or superior capabilities — a price-to-performance ratio that could prove decisive in commercial markets.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   What worries Lee most: not AGI, but the race itself
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Despite his generally measured tone about China&#x27;s AI development, Lee expressed concern about one area where he believes the global AI community faces real danger — not the far-future risk of superintelligent AI, but the near-term consequences of moving too fast.
 &lt;/p&gt;
 &lt;p&gt;
  When asked about
  &lt;a href=&quot;https://venturebeat.com/ai/study-warns-of-security-risks-as-os-agents-gain-control-of-computers-and-phones&quot;&gt;
   &lt;u&gt;
    AGI risks
   &lt;/u&gt;
  &lt;/a&gt;
  , Lee reframed the question. &quot;I&#x27;m less afraid of AI becoming self-aware and causing danger for humans in the short term,&quot; he said, &quot;but more worried about it being used by bad people to do terrible things, or by the AI race pushing people to work so hard, so fast and furious and move fast and break things that they build products that have problems and holes to be exploited.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  He continued: &quot;I&#x27;m very worried about that. In fact, I think some terrible event will happen that will be a wake up call from this sort of problem.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Lee&#x27;s perspective carries unusual weight because of his unique vantage point spanning both Chinese and American AI development. Over a career spanning more than three decades, he has held senior positions at
  &lt;a href=&quot;https://www.apple.com/&quot;&gt;
   &lt;u&gt;
    Apple
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.microsoft.com/en-us/&quot;&gt;
   &lt;u&gt;
    Microsoft
   &lt;/u&gt;
  &lt;/a&gt;
  , and
  &lt;a href=&quot;https://www.google.com/?zx=1761178473681&amp;no_sw_cr=1&quot;&gt;
   &lt;u&gt;
    Google
   &lt;/u&gt;
  &lt;/a&gt;
  , while also founding
  &lt;a href=&quot;https://www.sinovationventures.com/&quot;&gt;
   &lt;u&gt;
    Sinovation Ventures
   &lt;/u&gt;
  &lt;/a&gt;
  , which has invested in more than 400 companies across both countries. His AI company,
  &lt;a href=&quot;http://01.ai&quot;&gt;
   &lt;u&gt;
    01.AI
   &lt;/u&gt;
  &lt;/a&gt;
  , founded in 2023, has released several
  &lt;a href=&quot;https://huggingface.co/01-ai&quot;&gt;
   &lt;u&gt;
    open-source models
   &lt;/u&gt;
  &lt;/a&gt;
  that rank among the most capable in the world.
 &lt;/p&gt;
 &lt;p&gt;
  For American companies and policymakers, Lee&#x27;s analysis presents a complex strategic picture. The United States appears to have clear advantages in enterprise AI software, fundamental research, and computing infrastructure. But China is moving faster in consumer applications, manufacturing robotics at lower costs, and potentially pulling ahead in open-source model development.
 &lt;/p&gt;
 &lt;p&gt;
  The bifurcation suggests that rather than a single &quot;winner&quot; in AI, the world may be heading toward a technology landscape where different countries excel in different domains — with all the economic and geopolitical complications that implies.
 &lt;/p&gt;
 &lt;p&gt;
  As the
  &lt;a href=&quot;https://tedai-sanfrancisco.ted.com/&quot;&gt;
   &lt;u&gt;
    TED AI conference
   &lt;/u&gt;
  &lt;/a&gt;
  continued Wednesday, Lee&#x27;s assessment hung over subsequent discussions. His message seemed clear: the AI race is not one contest, but many — and the United States and China are each winning different races.
 &lt;/p&gt;
 &lt;p&gt;
  Standing in the conference hall afterward, one venture capitalist, who asked not to be named, summed up the mood in the room: &quot;We&#x27;re not competing with China anymore. We&#x27;re competing on parallel tracks.&quot; Whether those tracks eventually converge — or diverge into entirely separate technology ecosystems — may be the defining question of the next decade.
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Thinking Machines challenges OpenAI&#x27;s AI scaling strategy: &#x27;First superintelligence will be a superhuman learner&#x27; </title>
<link>https://venturebeat.com/data-infrastructure/thinking-machines-challenges-openais-ai-scaling-strategy-first</link>
<pubDate>Mon, 22 Dec 2025 12:51:39 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;nuneybits A retro glowing computer terminal on gradient backgro b5f91633-1cc9-42d7-9d6f-e497887b2ff3&quot; data-nimg=&quot;1&quot; height=&quot;599&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/6gnj4yPgIqEF3Y4cLtYWL9/3a8c4c8b409b763704f9f4dd0ad67fd3/nuneybits_A_retro_glowing_computer_terminal_on_gradient_backgro_b5f91633-1cc9-42d7-9d6f-e497887b2ff3.webp?w=1000&quot; width=&quot;1069&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
    &lt;p&gt;
     Credit: VentureBeat made with Midjourney
    &lt;/p&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  While the world&#x27;s leading artificial intelligence companies race to build ever-larger models, betting billions that scale alone will unlock artificial general intelligence, a researcher at one of the industry&#x27;s most secretive and valuable startups delivered a pointed challenge to that orthodoxy this week: The path forward isn&#x27;t about training bigger — it&#x27;s about learning better.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;I believe that the first superintelligence will be a superhuman learner,&quot;
  &lt;a href=&quot;https://rmrafailov.github.io/&quot;&gt;
   &lt;u&gt;
    Rafael Rafailov
   &lt;/u&gt;
  &lt;/a&gt;
  , a reinforcement learning researcher at
  &lt;a href=&quot;https://thinkingmachines.ai/&quot;&gt;
   &lt;u&gt;
    Thinking Machines Lab
   &lt;/u&gt;
  &lt;/a&gt;
  , told an audience at TED AI San Francisco on Tuesday. &quot;It will be able to very efficiently figure out and adapt, propose its own theories, propose experiments, use the environment to verify that, get information, and iterate that process.&quot;
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  This breaks sharply with the approach pursued by
  &lt;a href=&quot;https://openai.com/&quot;&gt;
   &lt;u&gt;
    OpenAI
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://anthropic.com/&quot;&gt;
   &lt;u&gt;
    Anthropic
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://deepmind.google/&quot;&gt;
   &lt;u&gt;
    Google DeepMind
   &lt;/u&gt;
  &lt;/a&gt;
  , and other leading laboratories, which have bet billions on scaling up model size, data, and compute to achieve increasingly sophisticated reasoning capabilities. Rafailov argues these companies have the strategy backwards: what&#x27;s missing from today&#x27;s most advanced AI systems isn&#x27;t more scale — it&#x27;s the ability to actually learn from experience.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Learning is something an intelligent being does,&quot; Rafailov said, citing a quote he described as recently compelling. &quot;Training is something that&#x27;s being done to it.&quot;
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  The distinction cuts to the core of how AI systems improve — and whether the industry&#x27;s current trajectory can deliver on its most ambitious promises. Rafailov&#x27;s comments offer a rare window into the thinking at
  &lt;a href=&quot;https://thinkingmachines.ai/&quot;&gt;
   &lt;u&gt;
    Thinking Machines Lab
   &lt;/u&gt;
  &lt;/a&gt;
  , the startup co-founded in February by former OpenAI chief technology officer
  &lt;a href=&quot;https://x.com/miramurati?lang=en&quot;&gt;
   &lt;u&gt;
    Mira Murati
   &lt;/u&gt;
  &lt;/a&gt;
  that raised a record-breaking
  &lt;a href=&quot;https://www.reuters.com/technology/mira-muratis-ai-startup-thinking-machines-raises-2-billion-a16z-led-round-2025-07-15/&quot;&gt;
   &lt;u&gt;
    $2 billion in seed funding
   &lt;/u&gt;
  &lt;/a&gt;
  at a $12 billion valuation.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Why today&#x27;s AI coding assistants forget everything they learned yesterday
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  To illustrate the problem with current AI systems, Rafailov offered a scenario familiar to anyone who has worked with today&#x27;s most advanced coding assistants.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;If you use a coding agent, ask it to do something really difficult — to implement a feature, go read your code, try to understand your code, reason about your code, implement something, iterate — it might be successful,&quot; he explained. &quot;And then come back the next day and ask it to implement the next feature, and it will do the same thing.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The issue, he argued, is that these systems don&#x27;t internalize what they learn. &quot;In a sense, for the models we have today, every day is their first day of the job,&quot; Rafailov said. &quot;But an intelligent being should be able to internalize information. It should be able to adapt. It should be able to modify its behavior so every day it becomes better, every day it knows more, every day it works faster — the way a human you hire gets better at the job.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   The duct tape problem: How current training methods teach AI to take shortcuts instead of solving problems
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Rafailov pointed to a specific behavior in coding agents that reveals the deeper problem: their tendency to wrap uncertain code in
  &lt;a href=&quot;https://www.w3schools.com/python/python_try_except.asp&quot;&gt;
   &lt;u&gt;
    try/except blocks
   &lt;/u&gt;
  &lt;/a&gt;
  — a programming construct that catches errors and allows a program to continue running.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;If you use coding agents, you might have observed a very annoying tendency of them to use try/except pass,&quot; he said. &quot;And in general, that is basically just like duct tape to save the entire program from a single error.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Why do agents do this? &quot;They do this because they understand that part of the code might not be right,&quot; Rafailov explained. &quot;They understand there might be something wrong, that it might be risky. But under the limited constraint—they have a limited amount of time solving the problem, limited amount of interaction—they must only focus on their objective, which is implement this feature and solve this bug.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The result: &quot;They&#x27;re kicking the can down the road.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  This behavior stems from training systems that optimize for immediate task completion. &quot;The only thing that matters to our current generation is solving the task,&quot; he said. &quot;And anything that&#x27;s general, anything that&#x27;s not related to just that one objective, is a waste of computation.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Why throwing more compute at AI won&#x27;t create superintelligence, according to Thinking Machines researcher
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Rafailov&#x27;s most direct challenge to the industry came in his assertion that continued scaling won&#x27;t be sufficient to reach AGI.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;I don&#x27;t believe we&#x27;re hitting any sort of saturation points,&quot; he clarified. &quot;I think we&#x27;re just at the beginning of the next paradigm—the scale of reinforcement learning, in which we move from teaching our models how to think, how to explore thinking space, into endowing them with the capability of general agents.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  In other words, current approaches will produce increasingly capable systems that can interact with the world, browse the web, write code. &quot;I believe a year or two from now, we&#x27;ll look at our coding agents today, research agents or browsing agents, the way we look at summarization models or translation models from several years ago,&quot; he said.
 &lt;/p&gt;
 &lt;p&gt;
  But general agency, he argued, is not the same as general intelligence. &quot;The much more interesting question is: Is that going to be AGI? And are we done — do we just need one more round of scaling, one more round of environments, one more round of RL, one more round of compute, and we&#x27;re kind of done?&quot;
 &lt;/p&gt;
 &lt;p&gt;
  His answer was unequivocal: &quot;I don&#x27;t believe this is the case. I believe that under our current paradigms, under any scale, we are not enough to deal with artificial general intelligence and artificial superintelligence. And I believe that under our current paradigms, our current models will lack one core capability, and that is learning.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Teaching AI like students, not calculators: The textbook approach to machine learning
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  To explain the alternative approach, Rafailov turned to an analogy from mathematics education.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Think about how we train our current generation of reasoning models,&quot; he said. &quot;We take a particular math problem, make it very hard, and try to solve it, rewarding the model for solving it. And that&#x27;s it. Once that experience is done, the model submits a solution. Anything it discovers—any abstractions it learned, any theorems—we discard, and then we ask it to solve a new problem, and it has to come up with the same abstractions all over again.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  That approach misunderstands how knowledge accumulates. &quot;This is not how science or mathematics works,&quot; he said. &quot;We build abstractions not necessarily because they solve our current problems, but because they&#x27;re important. For example, we developed the field of topology to extend Euclidean geometry — not to solve a particular problem that Euclidean geometry couldn&#x27;t handle, but because mathematicians and physicists understood these concepts were fundamentally important.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The solution: &quot;Instead of giving our models a single problem, we might give them a textbook. Imagine a very advanced graduate-level textbook, and we ask our models to work through the first chapter, then the first exercise, the second exercise, the third, the fourth, then move to the second chapter, and so on—the way a real student might teach themselves a topic.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The objective would fundamentally change: &quot;Instead of rewarding their success — how many problems they solved — we need to reward their progress, their ability to learn, and their ability to improve.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  This approach, known as &quot;
  &lt;a href=&quot;https://en.wikipedia.org/wiki/Meta-learning_(computer_science)&quot;&gt;
   &lt;u&gt;
    meta-learning
   &lt;/u&gt;
  &lt;/a&gt;
  &quot; or &quot;
  &lt;a href=&quot;https://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/&quot;&gt;
   &lt;u&gt;
    learning to learn
   &lt;/u&gt;
  &lt;/a&gt;
  ,&quot; has precedents in earlier AI systems. &quot;Just like the ideas of scaling test-time compute and search and test-time exploration played out in the domain of games first&quot; — in systems like
  &lt;a href=&quot;https://deepmind.google/research/projects/alphago/&quot;&gt;
   &lt;u&gt;
    DeepMind&#x27;s AlphaGo
   &lt;/u&gt;
  &lt;/a&gt;
  — &quot;the same is true for meta learning. We know that these ideas do work at a small scale, but we need to adapt them to the scale and the capability of foundation models.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   The missing ingredients for AI that truly learns aren&#x27;t new architectures—they&#x27;re better data and smarter objectives
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  When Rafailov addressed why current models lack this learning capability, he offered a surprisingly straightforward answer.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Unfortunately, I think the answer is quite prosaic,&quot; he said. &quot;I think we just don&#x27;t have the right data, and we don&#x27;t have the right objectives. I fundamentally believe a lot of the core architectural engineering design is in place.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Rather than arguing for entirely new model architectures, Rafailov suggested the path forward lies in redesigning the
  &lt;a href=&quot;https://julius.ai/glossary/data-distribution&quot;&gt;
   &lt;u&gt;
    data distributions
   &lt;/u&gt;
  &lt;/a&gt;
  and
  &lt;a href=&quot;https://arxiv.org/html/2408.10215v1&quot;&gt;
   &lt;u&gt;
    reward structures
   &lt;/u&gt;
  &lt;/a&gt;
  used to train models.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Learning, in of itself, is an algorithm,&quot; he explained. &quot;It has inputs — the current state of the model. It has data and compute. You process it through some sort of structure, choose your favorite optimization algorithm, and you produce, hopefully, a stronger model.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The question: &quot;If reasoning models are able to learn general reasoning algorithms, general search algorithms, and agent models are able to learn general agency, can the next generation of AI learn a learning algorithm itself?&quot;
 &lt;/p&gt;
 &lt;p&gt;
  His answer: &quot;I strongly believe that the answer to this question is yes.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The technical approach would involve creating training environments where &quot;learning, adaptation, exploration, and self-improvement, as well as generalization, are necessary for success.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  &quot;I believe that under enough computational resources and with broad enough coverage, general purpose learning algorithms can emerge from large scale training,&quot; Rafailov said. &quot;The way we train our models to reason in general over just math and code, and potentially act in general domains, we might be able to teach them how to learn efficiently across many different applications.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Forget god-like reasoners: The first superintelligence will be a master student
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  This vision leads to a fundamentally different conception of what artificial superintelligence might look like.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;I believe that if this is possible, that&#x27;s the final missing piece to achieve truly efficient general intelligence,&quot; Rafailov said. &quot;Now imagine such an intelligence with the core objective of exploring, learning, acquiring information, self-improving, equipped with general agency capability—the ability to understand and explore the external world, the ability to use computers, ability to do research, ability to manage and control robots.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Such a system would constitute artificial superintelligence. But not the kind often imagined in science fiction.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;I believe that intelligence is not going to be a single god model that&#x27;s a god-level reasoner or a god-level mathematical problem solver,&quot; Rafailov said. &quot;I believe that the first superintelligence will be a superhuman learner, and it will be able to very efficiently figure out and adapt, propose its own theories, propose experiments, use the environment to verify that, get information, and iterate that process.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  This vision stands in contrast to OpenAI&#x27;s emphasis on building
  &lt;a href=&quot;https://www.nytimes.com/2025/04/16/technology/openai-reasoning-models-o3-o4-mini.html&quot;&gt;
   &lt;u&gt;
    increasingly powerful reasoning systems
   &lt;/u&gt;
  &lt;/a&gt;
  , or Anthropic&#x27;s focus on &quot;
  &lt;a href=&quot;https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback&quot;&gt;
   &lt;u&gt;
    constitutional AI
   &lt;/u&gt;
  &lt;/a&gt;
  .&quot; Instead, Thinking Machines Lab appears to be betting that the path to superintelligence runs through systems that can continuously improve themselves through interaction with their environment.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   The $12 billion bet on learning over scaling faces formidable challenges
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Rafailov&#x27;s appearance comes at a complex moment for
  &lt;a href=&quot;https://thinkingmachines.ai/&quot;&gt;
   &lt;u&gt;
    Thinking Machines Lab
   &lt;/u&gt;
  &lt;/a&gt;
  . The company has assembled an impressive team of approximately 30 researchers from
  &lt;a href=&quot;https://openai.com/&quot;&gt;
   &lt;u&gt;
    OpenAI
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.google.com/&quot;&gt;
   &lt;u&gt;
    Google
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.meta.com/&quot;&gt;
   &lt;u&gt;
    Meta
   &lt;/u&gt;
  &lt;/a&gt;
  , and other leading labs. But it suffered a setback in early October when Andrew Tulloch, a co-founder and machine learning expert, departed to return to Meta after the company launched what The Wall Street Journal called a &quot;
  &lt;a href=&quot;https://www.wsj.com/tech/ai/meta-zuckerberg-ai-recruiting-fail-e6107555?gaa_at=eafs&amp;gaa_n=AWEtsqc_-cB9wl3ZPgtqZ__eBCeYWyT9I0pNgGVMy4Y898FrhtFnq3tSx4HFZHBFSzU%3D&amp;gaa_ts=68fbf024&amp;gaa_sig=rxhAZjpOFkPvuz6hDIoRcezY0lcbtglzljasLalVhtZWykfDMjIa_V4IS4mobhEUfRRXwH_qaEixofFop4Ec3g%3D%3D&quot;&gt;
   &lt;u&gt;
    full-scale raid
   &lt;/u&gt;
  &lt;/a&gt;
  &quot; on the startup, approaching more than a dozen employees with compensation packages ranging from $200 million to $1.5 billion over multiple years.
 &lt;/p&gt;
 &lt;p&gt;
  Despite these pressures, Rafailov&#x27;s comments suggest the company remains committed to its differentiated technical approach. The company launched its first product,
  &lt;a href=&quot;https://venturebeat.com/ai/thinking-machines-first-official-product-is-here-meet-tinker-an-api-for&quot;&gt;
   &lt;u&gt;
    Tinker
   &lt;/u&gt;
  &lt;/a&gt;
  , an API for fine-tuning open-source language models, in October. But Rafailov&#x27;s talk suggests Tinker is just the foundation for a much more ambitious research agenda focused on meta-learning and self-improving systems.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;This is not easy. This is going to be very difficult,&quot; Rafailov acknowledged. &quot;We&#x27;ll need a lot of breakthroughs in memory and engineering and data and optimization, but I think it&#x27;s fundamentally possible.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  He concluded with a play on words: &quot;The world is not enough, but we need the right experiences, and we need the right type of rewards for learning.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The question for
  &lt;a href=&quot;https://thinkingmachines.ai/&quot;&gt;
   &lt;u&gt;
    Thinking Machines Lab
   &lt;/u&gt;
  &lt;/a&gt;
  — and the broader AI industry — is whether this vision can be realized, and on what timeline. Rafailov notably did not offer specific predictions about when such systems might emerge.
 &lt;/p&gt;
 &lt;p&gt;
  In an industry where executives routinely make bold predictions about AGI arriving within years or even months, that restraint is notable. It suggests either unusual scientific humility — or an acknowledgment that Thinking Machines Lab is pursuing a much longer, harder path than its competitors.
 &lt;/p&gt;
 &lt;p&gt;
  For now, the most revealing detail may be what Rafailov didn&#x27;t say during his TED AI presentation. No timeline for when superhuman learners might emerge. No prediction about when the technical breakthroughs would arrive. Just a conviction that the capability was &quot;fundamentally possible&quot; — and that without it, all the scaling in the world won&#x27;t be enough.
 &lt;/p&gt;
 &lt;p&gt;
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Intuit learned to build AI agents for finance the hard way: Trust lost in buckets, earned back in spoonfuls </title>
<link>https://venturebeat.com/data-infrastructure/intuit-learned-to-build-ai-agents-for-finance-the-hard-way-trust-lost-in</link>
<pubDate>Mon, 22 Dec 2025 12:51:37 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;AI trust in a bucket&quot; data-nimg=&quot;1&quot; height=&quot;720&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/26uFKCJx7guEmpRjNxJdWl/bee15b7153fa921dc410f50175781a25/ai_trust_in_a_bucket-SMK.png?w=1000&quot; width=&quot;1280&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
    &lt;p&gt;
     Credit: Image generated by VentureBeat with Ideogram v3.0
    &lt;/p&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  Building AI for financial software requires a different playbook than consumer AI, and
  &lt;a href=&quot;https://www.intuit.com/&quot;&gt;
   &lt;u&gt;
    Intuit&#x27;s
   &lt;/u&gt;
  &lt;/a&gt;
  latest QuickBooks release provides an example.
 &lt;/p&gt;
 &lt;p&gt;
  The company has announced Intuit Intelligence, a system that orchestrates specialized AI agents across its QuickBooks platform to handle tasks including sales tax compliance and payroll processing. These new agents augment existing accounting and project management agents (which have also been updated) as well as a unified interface that lets users query data across QuickBooks, third-party systems and uploaded files using natural language.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  The new development follow years of investment and improvement in Intuit&#x27;s
  &lt;a href=&quot;https://venturebeat.com/ai/inside-intuits-genos-update-why-prompt-optimization-and-intelligent-data-cognition-are-critical-to-enterprise-agentic-ai-success&quot;&gt;
   &lt;u&gt;
    GenOS
   &lt;/u&gt;
  &lt;/a&gt;
  , allowing the company to build AI capabilities that reduce
  &lt;a href=&quot;https://venturebeat.com/ai/how-intuit-built-custom-financial-llms-that-cut-latency-50-while-boosting&quot;&gt;
   &lt;u&gt;
    latency and improve accuracy
   &lt;/u&gt;
  &lt;/a&gt;
  .
 &lt;/p&gt;
 &lt;p&gt;
  But the real news isn&#x27;t what Intuit built — it&#x27;s how they built it and why their design decisions will make AI more usable. The company&#x27;s latest AI rollout represents an evolution built on hard-won lessons about what works and what doesn&#x27;t when deploying AI in financial contexts.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  What the company learned is sobering: Even when its accounting agent improved transaction categorization accuracy by 20 percentage points on average, they still received complaints about errors.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;The use cases that we&#x27;re trying to solve for customers include tax and finance; if you make a mistake in this world, you lose trust with customers in buckets and we only get it back in spoonfuls,&quot; Joe Preston, Intuit&#x27;s VP of product and design, told VentureBeat.
 &lt;/p&gt;
 &lt;h2&gt;
  The architecture of trust: Real data queries over generative responses
 &lt;/h2&gt;
 &lt;p&gt;
  Intuit&#x27;s technical strategy centers on a fundamental design decision. For financial queries and business intelligence, the system queries actual data, rather than generating responses through large language models (LLMs).
 &lt;/p&gt;
 &lt;p&gt;
  Also critically important: That data isn&#x27;t all in one place. Intuit&#x27;s technical implementation allows QuickBooks to ingest data from multiple distinct sources: native Intuit data, OAuth-connected third-party systems like Square for payments and user-uploaded files such as spreadsheets containing vendor pricing lists or marketing campaign data. This creates a unified data layer that AI agents can query reliably.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;We&#x27;re actually querying your real data,&quot; Preston explained. &quot;That&#x27;s very different than if you were to just copy, paste out a spreadsheet or a PDF and paste into ChatGPT.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  This architectural choice means that the Intuit Intelligence system functions more as an orchestration layer. It&#x27;s a natural language interface to structured data operations. When a user asks about projected profitability or wants to run payroll, the system translates the natural language query into database operations against verified financial data.
 &lt;/p&gt;
 &lt;p&gt;
  This matters because Intuit&#x27;s internal research has uncovered widespread shadow AI usage. When surveyed, 25% of accountants using QuickBooks admitted they were already copying and pasting data into ChatGPT or Google Gemini for analysis.
 &lt;/p&gt;
 &lt;p&gt;
  Intuit&#x27;s approach treats AI as a query translation and orchestration mechanism, not a content generator. This reduces the hallucination risk that has plagued AI deployments in financial contexts.
 &lt;/p&gt;
 &lt;h2&gt;
  Explainability as a design requirement, not an afterthought
 &lt;/h2&gt;
 &lt;p&gt;
  Beyond the technical architecture, Intuit has made explainability a core user experience across its AI agents. This goes beyond simply providing correct answers: It means showing users the reasoning behind automated decisions.
 &lt;/p&gt;
 &lt;p&gt;
  When Intuit&#x27;s accounting agent categorizes a transaction, it doesn&#x27;t just display the result; it shows the reasoning. This isn&#x27;t marketing copy about explainable AI, it&#x27;s actual UI displaying data points and logic.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;It&#x27;s about closing that trust loop and making sure customers understand the why,&quot; Alastair Simpson, Intuit&#x27;s VP of design, told VentureBeat.
 &lt;/p&gt;
 &lt;p&gt;
  This becomes particularly critical when you consider Intuit&#x27;s user research: While half of small businesses describe AI as helpful, nearly a quarter haven&#x27;t used AI at all. The explanation layer serves both populations: Building confidence for newcomers, while giving experienced users the context to verify accuracy.
 &lt;/p&gt;
 &lt;p&gt;
  The design also enforces human control at critical decision points. This approach extends beyond the interface. Intuit connects users directly with human experts, embedded in the same workflows, when automation reaches its limits or when users want validation.
 &lt;/p&gt;
 &lt;h2&gt;
  Navigating the transition from forms to conversations
 &lt;/h2&gt;
 &lt;p&gt;
  One of Intuit&#x27;s more interesting challenges involves managing a fundamental shift in user interfaces. Preston described it as having one foot in the past and one foot in the future.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;This isn&#x27;t just Intuit, this is the market as a whole,&quot; said Preston. &quot;Today we still have a lot of customers filling out forms and going through tables full of data. We&#x27;re investing a lot into leaning in and questioning the ways that we do it across our products today, where you&#x27;re basically just filling out, form after form, or table after table, because we see where the world is headed, which is really a different form of interacting with these products.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  This creates a product design challenge: How do you serve users who are comfortable with traditional interfaces while gradually introducing conversational and agentic capabilities?
 &lt;/p&gt;
 &lt;p&gt;
  Intuit&#x27;s approach has been to embed AI agents directly into existing workflows. This means not forcing users to adopt entirely new interaction patterns. The payments agent appears alongside invoicing workflows; the accounting agent enhances the existing reconciliation process rather than replacing it. This incremental approach lets users experience AI benefits without abandoning familiar processes.
 &lt;/p&gt;
 &lt;h2&gt;
  What enterprise AI builders can learn from Intuit&#x27;s approach
 &lt;/h2&gt;
 &lt;p&gt;
  Intuit&#x27;s experience deploying AI in financial contexts surfaces several principles that apply broadly to enterprise AI initiatives.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Architecture matters for trust:
  &lt;/b&gt;
  In domains where accuracy is critical, consider whether you need content generation or data query translation. Intuit&#x27;s decision to treat AI as an orchestration and natural language interface layer dramatically reduces hallucination risk and avoids using AI as a generative system.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Explainability must be designed in, not bolted on:
  &lt;/b&gt;
  Showing users why the AI made a decision isn&#x27;t optional when trust is at stake. This requires deliberate UX design. It may constrain model choices.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   User control preserves trust during accuracy improvements:
  &lt;/b&gt;
  Intuit&#x27;s accounting agent improved categorization accuracy by 20 percentage points. Yet, maintaining user override capabilities was essential for adoption.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Transition gradually from familiar interfaces:
  &lt;/b&gt;
  Don&#x27;t force users to abandon forms for conversations. Embed AI capabilities into existing workflows first. Let users experience benefits before asking them to change behavior.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Be honest about what&#x27;s reactive versus proactive:
  &lt;/b&gt;
  Current AI agents primarily respond to prompts and automate defined tasks. True proactive intelligence that makes unprompted strategic recommendations remains an evolving capability.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;b&gt;
   Address workforce concerns with tooling, not just messaging:
  &lt;/b&gt;
  If AI is meant to augment rather than replace workers, provide workers with AI tools. Show them how to leverage the technology.
 &lt;/p&gt;
 &lt;p&gt;
  For enterprises navigating AI adoption, Intuit&#x27;s journey offers a clear directive. The winning approach prioritizes trustworthiness over capability demonstrations. In domains where mistakes have real consequences, that means investing in accuracy, transparency and human oversight before pursuing conversational sophistication or autonomous action.
 &lt;/p&gt;
 &lt;p&gt;
  Simpson frames the challenge succinctly: &quot;We didn&#x27;t want it to be a bolted-on layer. We wanted customers to be in their natural workflow, and have agents doing work for customers, embedded in the workflow.&quot;
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Moving past speculation: How deterministic CPUs deliver predictable AI performance </title>
<link>https://venturebeat.com/data-infrastructure/moving-past-speculation-how-deterministic-cpus-deliver-predictable-ai</link>
<pubDate>Mon, 22 Dec 2025 12:51:34 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;Deterministic execution&quot; data-nimg=&quot;1&quot; height=&quot;816&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/7xDQkK3UJNPCfHY5rmlmLW/4b5264fdd5c1156b8c4863814660dadd/Modern_data_infrastructure.png?w=1000&quot; width=&quot;1456&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  For more than three decades, modern CPUs have relied on speculative execution to keep pipelines full. When it emerged in the 1990s, speculation was hailed as a breakthrough — just as pipelining and superscalar execution had been in earlier decades. Each marked a generational leap in microarchitecture. By predicting the outcomes of branches and memory loads, processors could avoid stalls and keep execution units busy.
 &lt;/p&gt;
 &lt;p&gt;
  But this architectural shift came at a cost: Wasted energy when predictions failed, increased complexity and vulnerabilities such as Spectre and Meltdown. These challenges set the stage for an alternative: A deterministic, time-based execution model. As David Patterson
  &lt;a href=&quot;https://people.eecs.berkeley.edu/~kubitron/courses/cs252-F00/handouts/papers/patterson80.pdf&quot;&gt;
   observed in 1980
  &lt;/a&gt;
  , “A RISC potentially gains in speed merely from a simpler design.” Patterson’s principle of simplicity underpins a new alternative to speculation: A deterministic, time-based execution model.&quot;
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  For the first time since speculative execution became the dominant paradigm, a fundamentally new approach has been invented. This breakthrough is embodied in a series of six recently issued U.S. patents, sailing through the U.S. Patent and Trademark Office (USPTO). Together, they introduce a
  &lt;a href=&quot;https://patents.google.com/patent/US11829187B2/en&quot;&gt;
   radically different
  &lt;/a&gt;
  instruction execution model. Departing sharply from conventional speculative techniques, this novel deterministic framework replaces guesswork with a time-based, latency-tolerant mechanism. Each instruction is assigned a precise execution slot within the pipeline, resulting in a rigorously ordered and predictable flow of execution. This reimagined model redefines how modern processors can handle latency and concurrency with greater efficiency and reliability.
 &lt;/p&gt;
 &lt;p&gt;
  A simple time counter is used to deterministically set the exact time of when instructions should be executed in the future. Each instruction is dispatched to an execution queue with a preset execution time based on resolving its data dependencies and availability of resources — read buses, execution units and the write bus to the register file. Each instruction remains queued until its scheduled execution slot arrives. This new deterministic approach may represent the first major architectural challenge to speculation since it
  &lt;a href=&quot;https://patents.google.com/patent/US11829187B2/en&quot;&gt;
   became the standard
  &lt;/a&gt;
  .
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  The architecture extends naturally into matrix computation, with a RISC-V instruction set proposal under community review. Configurable general matrix multiply (GEMM) units, ranging from 8×8 to 64×64, can operate using either register-based or direct-memory acceess (DMA)-fed operands. This flexibility supports a wide range of AI and high-performance computing (HPC) workloads. Early analysis suggests scalability that rivals Google’s TPU cores, while maintaining significantly lower cost and power requirements.
 &lt;/p&gt;
 &lt;p&gt;
  Rather than a direct comparison with general-purpose CPUs, the more accurate reference point is vector and matrix engines: Traditional CPUs still depend on speculation and branch prediction, whereas this design applies deterministic scheduling directly to GEMM and vector units. This efficiency stems not only from the configurable GEMM blocks but also from the time-based execution model, where instructions are decoded and assigned precise execution slots based on operand readiness and resource availability.
 &lt;/p&gt;
 &lt;p&gt;
  Execution is never a random or heuristic choice among many candidates, but a predictable, pre-planned flow that keeps compute resources continuously busy. Planned matrix benchmarks will provide direct comparisons with TPU GEMM implementations, highlighting the ability to deliver datacenter-class performance without datacenter-class overhead.
 &lt;/p&gt;
 &lt;p&gt;
  Critics may argue that static scheduling introduces latency into instruction execution. In reality, the latency already exists — waiting on data dependencies or memory fetches. Conventional CPUs attempt to hide it with speculation, but when predictions fail, the resulting pipeline flush introduces delay and wastes power.
 &lt;/p&gt;
 &lt;p&gt;
  The time-counter approach acknowledges this latency and fills it deterministically with useful work, avoiding rollbacks. As the first patent notes, instructions retain out-of-order efficiency: “A
  &lt;a href=&quot;https://patents.google.com/patent/US11829187B2/en&quot;&gt;
   microprocessor
  &lt;/a&gt;
  with a time counter for statically dispatching instructions enables execution based on predicted timing rather than speculative issue and recovery,&quot; with preset execution times but without the overhead of register renaming or speculative comparators.
 &lt;/p&gt;
 &lt;h2&gt;
  Why speculation stalled
 &lt;/h2&gt;
 &lt;p&gt;
  Speculative execution boosts performance by predicting outcomes before they’re known — executing instructions ahead of time and discarding them if the guess was wrong. While this approach can accelerate workloads, it also introduces unpredictability and power inefficiency. Mispredictions inject “No Ops” into the pipeline, stalling progress and wasting energy on work that never completes.
 &lt;/p&gt;
 &lt;p&gt;
  These issues are magnified in modern
  &lt;a href=&quot;https://venturebeat.com/ai/large-reasoning-models-almost-certainly-can-think&quot;&gt;
   AI and machine learning (ML)
  &lt;/a&gt;
  workloads, where vector and matrix operations dominate and memory access patterns are irregular. Long fetches, non-cacheable loads and misaligned vectors frequently trigger pipeline flushes in speculative architectures.
 &lt;/p&gt;
 &lt;p&gt;
  The result is performance cliffs that vary wildly across datasets and problem sizes, making consistent tuning nearly impossible. Worse still, speculative side effects have exposed vulnerabilities that led to high-profile security exploits. As data intensity grows and memory systems strain, speculation struggles to keep pace — undermining its original promise of seamless acceleration.
 &lt;/p&gt;
 &lt;h2&gt;
  Time-based execution and deterministic scheduling
 &lt;/h2&gt;
 &lt;p&gt;
  At the core of this invention is a
  &lt;a href=&quot;https://patents.google.com/patent/US12112172B2/en?oq=U.S.+Patent+No.+12%2c112%2c172&quot;&gt;
   vector coprocessor
  &lt;/a&gt;
  with a time counter for statically dispatching instructions. Rather than relying on speculation, instructions are issued only when data dependencies and latency windows are fully known. This eliminates guesswork and costly pipeline flushes while preserving the throughput advantages of out-of-order execution. Architectures built on this patented framework feature deep pipelines — typically spanning 12 stages — combined with wide front ends supporting up to 8-way decode and large reorder buffers exceeding 250 entries
 &lt;/p&gt;
 &lt;p&gt;
  As illustrated in Figure 1, the architecture mirrors a conventional RISC-V processor at the top level, with instruction fetch and decode stages feeding into execution units. The innovation emerges in the integration of a
  &lt;a href=&quot;https://patents.google.com/patent/US12112172B2/en?oq=U.S.+Patent+No.+12%2c112%2c172&quot;&gt;
   time counter and register scoreboard
  &lt;/a&gt;
  , strategically positioned between fetch/decode and the vector execution units. Instead of relying on speculative comparators or register renaming, they utilize a Register Scoreboard and
  &lt;a href=&quot;https://patents.google.com/patent/US12112172B2/en?oq=U.S.+Patent+No.+12%2c112%2c172&quot;&gt;
   Time Resource Matrix
  &lt;/a&gt;
  (TRM) to deterministically schedule instructions based on operand readiness and resource availability.
 &lt;/p&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;Deterministic&quot; data-nimg=&quot;1&quot; height=&quot;868&quot; loading=&quot;lazy&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/2KPd1xiGcoow3JAyQXlb20/4f7da9f9f4cddc926f7569132b7dc24e/Deterministic.jpeg?w=1000&quot; width=&quot;2080&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
   &lt;/figcaption&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  &lt;i&gt;
   Figure 1: High-level block diagram of deterministic processor. A time counter and scoreboard sit between fetch/decode and vector execution units, ensuring instructions issue only when operands are ready.
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;p&gt;
  A typical program running on the deterministic processor begins much like it does on any conventional RISC-V system: Instructions are fetched from memory and decoded to determine whether they are scalar, vector, matrix or custom extensions. The difference emerges at the point of dispatch. Instead of issuing instructions speculatively, the processor employs a cycle-accurate time counter, working with a register scoreboard, to decide exactly when each instruction can be executed. This mechanism provides a deterministic execution contract, ensuring instructions complete at predictable cycles and reducing wasted issue slots.
 &lt;/p&gt;
 &lt;p&gt;
  In conjunction with a register scoreboard, the time-resource matrix associates instructions with execution cycles, allowing the processor to plan dispatch deterministically across available resources. The scoreboard tracks operand readiness and hazard information, enabling scheduling without register renaming or speculative comparators. By monitoring dependencies such as read-after-write (RAW) and write-after-read, it ensures hazards are resolved without costly pipeline flushes. As noted
  &lt;a href=&quot;https://patents.google.com/patent/US12112172B2/en?oq=U.S.+Patent+No.+12%2c112%2c172&quot;&gt;
   in the patent
  &lt;/a&gt;
  , “in a multi-threaded microprocessor, the time counter and scoreboard permit rescheduling around cache misses, branch flushes, and RAW hazards without speculative rollback.”
 &lt;/p&gt;
 &lt;p&gt;
  Once operands are ready, the instruction is dispatched to the appropriate execution unit. Scalar operations use standard artithmetic logic units (ALUs), while vector and matrix instructions execute in wide execution units connected to a
  &lt;a href=&quot;https://venturebeat.com/ai/abstract-or-die-why-ai-enterprises-cant-afford-rigid-vector-stacks&quot;&gt;
   large vector
  &lt;/a&gt;
  register file. Because instructions launch only when conditions are safe, these units stay highly utilized without the wasted work or recovery cycles caused by mis-predicted speculation.
 &lt;/p&gt;
 &lt;p&gt;
  The key enabler of this approach is a simple time counter that orchestrates execution according to data readiness and resource availability, ensuring instructions advance only when operands are ready and resources available. The same principle applies to memory operations: The interface predicts latency windows for loads and stores, allowing the processor to fill those slots with independent instructions and keep execution flowing.
 &lt;/p&gt;
 &lt;h2&gt;
  Programming model differences
 &lt;/h2&gt;
 &lt;p&gt;
  From the programmer’s perspective, the flow remains familiar — RISC-V code compiles and executes in the usual way. The crucial difference lies in the execution contract: Rather than relying on dynamic speculation to hide latency, the processor guarantees predictable dispatch and completion times. This eliminates the performance cliffs and wasted energy of speculation while still providing the throughput benefits of out-of-order execution.
 &lt;/p&gt;
 &lt;p&gt;
  This perspective underscores how deterministic execution preserves the familiar RISC-V programming model while eliminating the unpredictability and wasted effort of speculation. As
  &lt;a href=&quot;https://cs.stanford.edu/people/eroberts/courses/soco/projects/risc/about/interview.html&quot;&gt;
   John Hennessy put it
  &lt;/a&gt;
  : &quot;It’s stupid to do work in run time that you can do in compile time”— a remark reflecting the foundations of RISC and its forward-looking design philosophy.
 &lt;/p&gt;
 &lt;p&gt;
  The RISC-V ISA provides opcodes for custom and extension instructions, including floating-point, DSP, and vector operations. The result is a processor that executes instructions deterministically while retaining the benefits of out-of-order performance. By eliminating speculation, the design simplifies hardware, reduces power consumption and avoids pipeline flushes.
 &lt;/p&gt;
 &lt;p&gt;
  These efficiency gains grow even more significant in vector and matrix operations, where wide execution units require consistent utilization to reach peak performance. Vector extensions require wide register files and large execution units, which in speculative processors necessitate expensive register renaming to recover from branch mispredictions. In the deterministic design, vector instructions are executed only after commit, eliminating the need for renaming.
 &lt;/p&gt;
 &lt;p&gt;
  Each instruction is scheduled against a
  &lt;a href=&quot;https://patents.google.com/patent/US12001848B2/en?oq=U.S.+Patent+No.+12%2c001%2c848&quot;&gt;
   cycle-accurate time counter
  &lt;/a&gt;
  : “The time counter provides a deterministic execution contract, ensuring instructions complete at predictable cycles and reducing wasted issue slots.” The vector register scoreboard resolves data dependency before issuing instructions to execution pipeline.  Instructions are dispatched in a known order at the correct cycle, making execution both predictable and efficient.
 &lt;/p&gt;
 &lt;p&gt;
  Vector execution units (integer and floating point) connect directly to a large vector register file. Because instructions are never flushed, there is no renaming overhead. The scoreboard ensures safe access, while the time counter aligns execution with memory readiness. A dedicated memory block predicts the return cycle of loads. Instead of stalling or speculating, the processor schedules independent instructions into latency slots, keeping
  &lt;a href=&quot;https://patents.google.com/patent/US12001848B2/en?oq=U.S.+Patent+No.+12%2c001%2c848&quot;&gt;
   execution units busy
  &lt;/a&gt;
  . “A vector coprocessor with a time counter for statically dispatching instructions ensures high utilization of wide execution units while avoiding misprediction penalties.”
 &lt;/p&gt;
 &lt;p&gt;
  In today’s CPUs, compilers and programmers write code assuming the hardware will dynamically reorder instructions and speculatively execute branches. The hardware handles hazards with register renaming, branch prediction and recovery mechanisms. Programmers benefit from performance, but at the cost of unpredictability and power consumption.
 &lt;/p&gt;
 &lt;p&gt;
  In the deterministic time-based architecture, instructions are dispatched only when the time counter indicates their operands will be ready. This means the compiler (or runtime system) doesn’t need to insert guard code for misprediction recovery. Instead, compiler scheduling becomes simpler, as instructions are guaranteed to issue at the correct cycle without rollbacks. For programmers, the ISA remains RISC-V compatible, but deterministic extensions reduce reliance on speculative safety nets.
 &lt;/p&gt;
 &lt;h2&gt;
  Application in AI and ML
 &lt;/h2&gt;
 &lt;p&gt;
  In
  &lt;a href=&quot;https://venturebeat.com/ai/under-the-hood-of-ai-agents-a-technical-guide-to-the-next-frontier-of-gen-ai&quot;&gt;
   AI/ML kernels
  &lt;/a&gt;
  , vector loads and matrix operations often dominate runtime. On a speculative CPU, misaligned or non-cacheable loads can trigger stalls or flushes, starving wide vector and matrix units and wasting energy on discarded work. A deterministic design instead issues these operations with cycle-accurate timing, ensuring high utilization and steady throughput. For programmers, this means fewer performance cliffs and more predictable scaling across problem sizes. And because the patents extend the RISC-V ISA rather than replace it, deterministic processors remain fully compatible with the RVA23 profile and mainstream toolchains such as GCC, LLVM, FreeRTOS, and Zephyr.
 &lt;/p&gt;
 &lt;p&gt;
  In practice, the deterministic model doesn’t change how code is written — it remains RISC-V assembly or high-level languages compiled to RISC-V instructions. What changes is the execution contract: Rather than relying on speculative guesswork, programmers can expect predictable latency behavior and higher efficiency without tuning code around microarchitectural quirks.
 &lt;/p&gt;
 &lt;p&gt;
  The industry is at an inflection point. AI/ML workloads are dominated by vector and matrix math, where GPUs and TPUs excel — but only by consuming massive power and adding architectural complexity. In contrast, general-purpose CPUs, still tied to speculative execution models, lag behind.
 &lt;/p&gt;
 &lt;p&gt;
  A deterministic processor delivers predictable performance across a wide range of workloads, ensuring consistent behavior regardless of task complexity. Eliminating speculative execution enhances energy efficiency and avoids unnecessary computational overhead. Furthermore, deterministic design scales naturally to vector and matrix operations, making it especially well-suited for AI workloads that rely on high-throughput parallelism. This new deterministic approach may represent the next such leap: The first major architectural challenge to speculation since speculation itself became the standard.
 &lt;/p&gt;
 &lt;p&gt;
  Will deterministic CPUs replace speculation in mainstream computing? That remains to be seen. But with issued patents, proven novelty and growing pressure from AI workloads, the timing is right for a paradigm shift. Taken together, these advances signal deterministic execution as the next architectural leap — redefining performance and efficiency just as speculation once did.
 &lt;/p&gt;
 &lt;p&gt;
  Speculation marked the last revolution in CPU design; determinism may well represent the next.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;i&gt;
   Thang Tran is the founder and CTO of Simplex Micro.
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;p&gt;
  &lt;i&gt;
   Read more from our
  &lt;/i&gt;
  &lt;a href=&quot;https://venturebeat.com/datadecisionmakers&quot;&gt;
   &lt;i&gt;
    guest writers
   &lt;/i&gt;
  &lt;/a&gt;
  &lt;i&gt;
   . Or, consider submitting a post of your own! See our
  &lt;/i&gt;
  &lt;a href=&quot;https://r39crwmcu9m.typeform.com/to/NEzWFTji&quot;&gt;
   &lt;i&gt;
    guidelines here
   &lt;/i&gt;
  &lt;/a&gt;
  &lt;i&gt;
   .
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;br/&gt;
 &lt;br/&gt;
 &lt;p&gt;
  Welcome to the VentureBeat community!
 &lt;/p&gt;
 &lt;p&gt;
  Our guest posting program is where technical experts share insights and provide neutral, non-vested deep dives on AI, data infrastructure, cybersecurity and other cutting-edge technologies shaping the future of enterprise.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;a href=&quot;/category/DataDecisionMakers&quot;&gt;
   Read more
  &lt;/a&gt;
  from our guest post program — and check out our
  &lt;a href=&quot;/guest-posts&quot;&gt;
   guidelines
  &lt;/a&gt;
  if you’re interested in contributing an article of your own!
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Google debuts AI chips with 4X performance boost, secures Anthropic megadeal worth billions </title>
<link>https://venturebeat.com/data-infrastructure/google-debuts-ai-chips-with-4x-performance-boost-secures-anthropic-megadeal</link>
<pubDate>Mon, 22 Dec 2025 12:51:31 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;Ironwood board&quot; data-nimg=&quot;1&quot; height=&quot;4672&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/3wiaJuUTbBrUaBp8cSXtO4/81095c7817da6a2967a961ed60356ed4/Ironwood_board.jpg?w=1000&quot; width=&quot;7008&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
    &lt;p&gt;
     Image Credit: Google
    &lt;/p&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://cloud.google.com/?hl=en&quot;&gt;
   &lt;u&gt;
    Google Cloud
   &lt;/u&gt;
  &lt;/a&gt;
  is introducing what it calls its most powerful artificial intelligence infrastructure to date, unveiling a seventh-generation
  &lt;a href=&quot;https://cloud.google.com/tpu?hl=en&quot;&gt;
   &lt;u&gt;
    Tensor Processing Unit
   &lt;/u&gt;
  &lt;/a&gt;
  and expanded
  &lt;a href=&quot;https://cloud.google.com/discover/what-are-arm-based-processors?hl=en&quot;&gt;
   &lt;u&gt;
    Arm-based computing options
   &lt;/u&gt;
  &lt;/a&gt;
  designed to meet surging demand for AI model deployment — what the company characterizes as a fundamental industry shift from training models to serving them to billions of users.
 &lt;/p&gt;
 &lt;p&gt;
  The announcement, made Thursday, centers on
  &lt;a href=&quot;https://cloud.google.com/resources/ironwood-tpu-interest?utm_source=cgc-blog&amp;utm_medium=blog&amp;utm_campaign=FY25-Q2-global-ENT33820-website-cs-ironwood-tpu-interest&amp;utm_content=ironwood_announcement_blog&amp;utm_term=ironwood&amp;hl=en&quot;&gt;
   &lt;u&gt;
    Ironwood
   &lt;/u&gt;
  &lt;/a&gt;
  , Google&#x27;s latest custom AI accelerator chip, which will become generally available in the coming weeks. In a striking validation of the technology,
  &lt;a href=&quot;https://www.anthropic.com/&quot;&gt;
   &lt;u&gt;
    Anthropic
   &lt;/u&gt;
  &lt;/a&gt;
  , the AI safety company behind the Claude family of models, disclosed plans to access up to
  &lt;a href=&quot;https://www.googlecloudpresscorner.com/2025-10-23-Anthropic-to-Expand-Use-of-Google-Cloud-TPUs-and-Services&quot;&gt;
   &lt;u&gt;
    one million of these TPU chips
   &lt;/u&gt;
  &lt;/a&gt;
  — a commitment worth tens of billions of dollars and among the largest known AI infrastructure deals to date.
 &lt;/p&gt;
 &lt;p&gt;
  The move underscores an intensifying competition among cloud providers to control the infrastructure layer powering artificial intelligence, even as questions mount about whether the industry can sustain its current pace of capital expenditure. Google&#x27;s approach — building custom silicon rather than relying solely on
  &lt;a href=&quot;https://www.reuters.com/business/nvidia-poised-record-5-trillion-market-valuation-2025-10-29/&quot;&gt;
   &lt;u&gt;
    Nvidia&#x27;s dominant GPU chips
   &lt;/u&gt;
  &lt;/a&gt;
  — amounts to a long-term bet that vertical integration from chip design through software will deliver superior economics and performance.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;h3&gt;
  &lt;b&gt;
   Why companies are racing to serve AI models, not just train them
  &lt;/b&gt;
 &lt;/h3&gt;
 &lt;p&gt;
  Google executives framed the announcements around what they call &quot;the age of inference&quot; — a transition point where companies shift resources from training frontier AI models to deploying them in production applications serving millions or billions of requests daily.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Today&#x27;s frontier models, including Google&#x27;s Gemini, Veo, and Imagen and Anthropic&#x27;s Claude train and serve on Tensor Processing Units,&quot; said Amin Vahdat, vice president and general manager of AI and Infrastructure at Google Cloud. &quot;For many organizations, the focus is shifting from training these models to powering useful, responsive interactions with them.&quot;
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  This transition has profound implications for infrastructure requirements. Where training workloads can often tolerate batch processing and longer completion times, inference — the process of actually running a trained model to generate responses — demands consistently low latency, high throughput, and unwavering reliability. A chatbot that takes 30 seconds to respond, or a coding assistant that frequently times out, becomes unusable regardless of the underlying model&#x27;s capabilities.
 &lt;/p&gt;
 &lt;p&gt;
  Agentic workflows — where AI systems take autonomous actions rather than simply responding to prompts — create particularly complex infrastructure challenges, requiring tight coordination between specialized AI accelerators and general-purpose computing.
 &lt;/p&gt;
 &lt;h3&gt;
  &lt;b&gt;
   Inside Ironwood&#x27;s architecture: 9,216 chips working as one supercomputer
  &lt;/b&gt;
 &lt;/h3&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://cloud.google.com/resources/ironwood-tpu-interest?utm_source=cgc-blog&amp;utm_medium=blog&amp;utm_campaign=FY25-Q2-global-ENT33820-website-cs-ironwood-tpu-interest&amp;utm_content=ironwood_announcement_blog&amp;utm_term=ironwood&amp;hl=en&quot;&gt;
   &lt;u&gt;
    Ironwood
   &lt;/u&gt;
  &lt;/a&gt;
  is more than incremental improvement over Google&#x27;s sixth-generation TPUs. According to technical specifications shared by the company, it delivers more than four times better performance for both training and inference workloads compared to its predecessor — gains that Google attributes to a system-level co-design approach rather than simply increasing transistor counts.
 &lt;/p&gt;
 &lt;p&gt;
  The architecture&#x27;s most striking feature is its scale. A single Ironwood &quot;pod&quot; — a tightly integrated unit of TPU chips functioning as one supercomputer — can connect up to 9,216 individual chips through Google&#x27;s proprietary
  &lt;a href=&quot;https://blog.google/products/google-cloud/ironwood-tpu-age-of-inference/&quot;&gt;
   &lt;u&gt;
    Inter-Chip Interconnect network
   &lt;/u&gt;
  &lt;/a&gt;
  operating at 9.6 terabits per second. To put that bandwidth in perspective, it&#x27;s roughly equivalent to downloading the entire Library of Congress in under two seconds.
 &lt;/p&gt;
 &lt;p&gt;
  This massive interconnect fabric allows the 9,216 chips to share access to 1.77 petabytes of
  &lt;a href=&quot;https://blog.google/products/google-cloud/ironwood-tpu-age-of-inference/&quot;&gt;
   &lt;u&gt;
    High Bandwidth Memory
   &lt;/u&gt;
  &lt;/a&gt;
  — memory fast enough to keep pace with the chips&#x27; processing speeds. That&#x27;s approximately 40,000 high-definition Blu-ray movies&#x27; worth of working memory, instantly accessible by thousands of processors simultaneously. &quot;For context, that means Ironwood Pods can deliver 118x more FP8 ExaFLOPS versus the next closest competitor,&quot; Google stated in technical documentation.
 &lt;/p&gt;
 &lt;p&gt;
  The system employs
  &lt;a href=&quot;https://www.opencompute.org/projects/optical-circuit-switching&quot;&gt;
   &lt;u&gt;
    Optical Circuit Switching
   &lt;/u&gt;
  &lt;/a&gt;
  technology that acts as a &quot;dynamic, reconfigurable fabric.&quot; When individual components fail or require maintenance — inevitable at this scale — the OCS technology automatically reroutes data traffic around the interruption within milliseconds, allowing workloads to continue running without user-visible disruption.
 &lt;/p&gt;
 &lt;p&gt;
  This reliability focus reflects lessons learned from deploying five previous TPU generations. Google reported that its fleet-wide uptime for liquid-cooled systems has maintained approximately 99.999% availability since 2020 — equivalent to less than six minutes of downtime per year.
 &lt;/p&gt;
 &lt;h3&gt;
  &lt;b&gt;
   Anthropic&#x27;s billion-dollar bet validates Google&#x27;s custom silicon strategy
  &lt;/b&gt;
 &lt;/h3&gt;
 &lt;p&gt;
  Perhaps the most significant external validation of Ironwood&#x27;s capabilities comes from
  &lt;a href=&quot;https://www.googlecloudpresscorner.com/2025-10-23-Anthropic-to-Expand-Use-of-Google-Cloud-TPUs-and-Services&quot;&gt;
   &lt;u&gt;
    Anthropic&#x27;s commitment to access up to one million TPU chips
   &lt;/u&gt;
  &lt;/a&gt;
  — a staggering figure in an industry where even clusters of 10,000 to 50,000 accelerators are considered massive.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Anthropic and Google have a longstanding partnership and this latest expansion will help us continue to grow the compute we need to define the frontier of AI,&quot; said Krishna Rao, Anthropic&#x27;s chief financial officer, in the official partnership agreement. &quot;Our customers — from Fortune 500 companies to AI-native startups — depend on Claude for their most important work, and this expanded capacity ensures we can meet our exponentially growing demand.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  According to a separate statement, Anthropic will have access to &quot;well over a gigawatt of capacity coming online in 2026&quot; — enough electricity to power a small city. The company specifically cited TPUs&#x27; &quot;price-performance and efficiency&quot; as key factors in the decision, along with &quot;existing experience in training and serving its models with TPUs.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Industry analysts estimate that a commitment to access one million TPU chips, with associated infrastructure, networking, power, and cooling, likely represents a
  &lt;a href=&quot;https://www.reuters.com/technology/anthropic-expand-use-google-clouds-tpu-chips-2025-10-23/&quot;&gt;
   &lt;u&gt;
    multi-year contract worth tens of billions of dollars
   &lt;/u&gt;
  &lt;/a&gt;
  — among the largest known cloud infrastructure commitments in history.
 &lt;/p&gt;
 &lt;p&gt;
  James Bradbury, Anthropic&#x27;s head of compute, elaborated on the inference focus: &quot;Ironwood&#x27;s improvements in both inference performance and training scalability will help us scale efficiently while maintaining the speed and reliability our customers expect.&quot;
 &lt;/p&gt;
 &lt;h3&gt;
  &lt;b&gt;
   Google&#x27;s Axion processors target the computing workloads that make AI possible
  &lt;/b&gt;
 &lt;/h3&gt;
 &lt;p&gt;
  Alongside
  &lt;a href=&quot;https://cloud.google.com/resources/ironwood-tpu-interest?utm_source=cgc-blog&amp;utm_medium=blog&amp;utm_campaign=FY25-Q2-global-ENT33820-website-cs-ironwood-tpu-interest&amp;utm_content=ironwood_announcement_blog&amp;utm_term=ironwood&amp;hl=en&quot;&gt;
   &lt;u&gt;
    Ironwood
   &lt;/u&gt;
  &lt;/a&gt;
  , Google introduced expanded options for its
  &lt;a href=&quot;https://cloud.google.com/products/axion?hl=en&quot;&gt;
   &lt;u&gt;
    Axion processor family
   &lt;/u&gt;
  &lt;/a&gt;
  — custom Arm-based CPUs designed for general-purpose workloads that support AI applications but don&#x27;t require specialized accelerators.
 &lt;/p&gt;
 &lt;p&gt;
  The
  &lt;a href=&quot;http://forms.gle/HYY5FWRKewYuDMB27&quot;&gt;
   &lt;u&gt;
    N4A instance type
   &lt;/u&gt;
  &lt;/a&gt;
  , now entering preview, targets what Google describes as &quot;microservices, containerized applications, open-source databases, batch, data analytics, development environments, experimentation, data preparation and web serving jobs that make AI applications possible.&quot; The company claims N4A delivers up to 2X better price-performance than comparable current-generation x86-based virtual machines.
 &lt;/p&gt;
 &lt;p&gt;
  Google is also
  &lt;a href=&quot;https://docs.google.com/forms/d/e/1FAIpQLSd14sMYz79SeRI665dM7lnUbsAg7zilVPdDfK2_6u1vBmiUfg/viewform?usp=send_form&quot;&gt;
   &lt;u&gt;
    previewing C4A metal
   &lt;/u&gt;
  &lt;/a&gt;
  , its first bare-metal Arm instance, which provides dedicated physical servers for specialized workloads such as Android development, automotive systems, and software with strict licensing requirements.
 &lt;/p&gt;
 &lt;p&gt;
  The Axion strategy reflects a growing conviction that the future of computing infrastructure requires both specialized AI accelerators and highly efficient general-purpose processors. While a TPU handles the computationally intensive task of running an AI model, Axion-class processors manage data ingestion, preprocessing, application logic, API serving, and countless other tasks in a modern AI application stack.
 &lt;/p&gt;
 &lt;p&gt;
  Early customer results suggest the approach delivers measurable economic benefits. Vimeo reported observing &quot;a 30% improvement in performance for our core transcoding workload compared to comparable x86 VMs&quot; in initial N4A tests. ZoomInfo measured &quot;a 60% improvement in price-performance&quot; for data processing pipelines running on Java services, according to Sergei Koren, the company&#x27;s chief infrastructure architect.
 &lt;/p&gt;
 &lt;h3&gt;
  &lt;b&gt;
   Software tools turn raw silicon performance into developer productivity
  &lt;/b&gt;
 &lt;/h3&gt;
 &lt;p&gt;
  Hardware performance means little if developers cannot easily harness it. Google emphasized that
  &lt;a href=&quot;https://cloud.google.com/resources/ironwood-tpu-interest?utm_source=cgc-blog&amp;utm_medium=blog&amp;utm_campaign=FY25-Q2-global-ENT33820-website-cs-ironwood-tpu-interest&amp;utm_content=ironwood_announcement_blog&amp;utm_term=ironwood&amp;hl=en&quot;&gt;
   &lt;u&gt;
    Ironwood
   &lt;/u&gt;
  &lt;/a&gt;
  and
  &lt;a href=&quot;https://cloud.google.com/products/axion?hl=en&quot;&gt;
   &lt;u&gt;
    Axion
   &lt;/u&gt;
  &lt;/a&gt;
  are integrated into what it calls
  &lt;a href=&quot;https://cloud.google.com/solutions/ai-hypercomputer&quot;&gt;
   &lt;u&gt;
    AI Hypercomputer
   &lt;/u&gt;
  &lt;/a&gt;
  — &quot;an integrated supercomputing system that brings together compute, networking, storage, and software to improve system-level performance and efficiency.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  According to an October 2025 IDC Business Value Snapshot study, AI Hypercomputer customers achieved on average 353% three-year return on investment, 28% lower IT costs, and 55% more efficient IT teams.
 &lt;/p&gt;
 &lt;p&gt;
  Google disclosed several software enhancements designed to maximize Ironwood utilization.
  &lt;a href=&quot;https://cloud.google.com/kubernetes-engine?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=na-US-all-en-dr-bkws-all-all-trial-e-dr-1710134&amp;utm_content=text-ad-none-any-DEV_c-CRE_772251321321-ADGP_Hybrid+%7C+BKWS+-+EXA+%7C+Txt-AppMod-GKE-Kubernetes+Engine-KWID_369526655975-kwd-369526655975&amp;utm_term=KW_google+kubernetes+engine-ST_google+kubernetes+engine&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=23052915519&amp;gclid=Cj0KCQiAiKzIBhCOARIsAKpKLAMMFmNaZgmWnQ3CYrziXElfmMXmQphYqoSvICvf6jfUjLqR9XqFt3oaArkYEALw_wcB&amp;hl=en&quot;&gt;
   &lt;u&gt;
    Google Kubernetes Engine
   &lt;/u&gt;
  &lt;/a&gt;
  now offers advanced maintenance and topology awareness for TPU clusters, enabling intelligent scheduling and highly resilient deployments. The company&#x27;s
  &lt;a href=&quot;https://github.com/AI-Hypercomputer/maxtext&quot;&gt;
   &lt;u&gt;
    open-source MaxText framework
   &lt;/u&gt;
  &lt;/a&gt;
  now supports advanced training techniques including Supervised Fine-Tuning and Generative Reinforcement Policy Optimization.
 &lt;/p&gt;
 &lt;p&gt;
  Perhaps most significant for production deployments, Google&#x27;s
  &lt;a href=&quot;https://docs.cloud.google.com/kubernetes-engine/docs/concepts/about-gke-inference-gateway&quot;&gt;
   &lt;u&gt;
    Inference Gateway
   &lt;/u&gt;
  &lt;/a&gt;
  intelligently load-balances requests across model servers to optimize critical metrics. According to Google, it can reduce time-to-first-token latency by 96% and serving costs by up to 30% through techniques like prefix-cache-aware routing.
 &lt;/p&gt;
 &lt;p&gt;
  The
  &lt;a href=&quot;https://docs.cloud.google.com/kubernetes-engine/docs/concepts/about-gke-inference-gateway&quot;&gt;
   &lt;u&gt;
    Inference Gateway
   &lt;/u&gt;
  &lt;/a&gt;
  monitors key metrics including KV cache hits, GPU or TPU utilization, and request queue length, then routes incoming requests to the optimal replica. For conversational AI applications where multiple requests might share context, routing requests with shared prefixes to the same server instance can dramatically reduce redundant computation.
 &lt;/p&gt;
 &lt;h3&gt;
  &lt;b&gt;
   The hidden challenge: powering and cooling one-megawatt server racks
  &lt;/b&gt;
 &lt;/h3&gt;
 &lt;p&gt;
  Behind these announcements lies a massive physical infrastructure challenge that Google addressed at the recent
  &lt;a href=&quot;https://www.opencompute.org/summit/emea-summit&quot;&gt;
   &lt;u&gt;
    Open Compute Project EMEA Summit
   &lt;/u&gt;
  &lt;/a&gt;
  . The company disclosed that it&#x27;s implementing +/-400 volt direct current power delivery capable of supporting up to one megawatt per rack — a tenfold increase from typical deployments.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;The AI era requires even greater power delivery capabilities,&quot; explained Madhusudan Iyengar and Amber Huffman, Google principal engineers, in an
  &lt;a href=&quot;https://cloud.google.com/blog/topics/systems/enabling-1-mw-it-racks-and-liquid-cooling-at-ocp-emea-summit&quot;&gt;
   &lt;u&gt;
    April 2025 blog post
   &lt;/u&gt;
  &lt;/a&gt;
  . &quot;ML will require more than 500 kW per IT rack before 2030.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Google is collaborating with Meta and Microsoft to standardize electrical and mechanical interfaces for high-voltage DC distribution. The company selected
  &lt;a href=&quot;https://www.opencompute.org/files/OCP18-400VDC-Efficiency-02.pdf&quot;&gt;
   &lt;u&gt;
    400 VDC
   &lt;/u&gt;
  &lt;/a&gt;
  specifically to leverage the supply chain established by electric vehicles, &quot;for greater economies of scale, more efficient manufacturing, and improved quality and scale.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  On cooling, Google revealed it will contribute its fifth-generation cooling distribution unit design to the Open Compute Project. The company has deployed liquid cooling &quot;at GigaWatt scale across more than 2,000 TPU Pods in the past seven years&quot; with fleet-wide availability of approximately 99.999%.
 &lt;/p&gt;
 &lt;p&gt;
  Water can transport approximately 4,000 times more heat per unit volume than air for a given temperature change — critical as individual AI accelerator chips increasingly dissipate 1,000 watts or more.
 &lt;/p&gt;
 &lt;h3&gt;
  &lt;b&gt;
   Custom silicon gambit challenges Nvidia&#x27;s AI accelerator dominance
  &lt;/b&gt;
 &lt;/h3&gt;
 &lt;p&gt;
  Google&#x27;s announcements come as the AI infrastructure market reaches an inflection point. While Nvidia maintains overwhelming dominance in AI accelerators — holding an estimated 80-95% market share — cloud providers are increasingly investing in custom silicon to differentiate their offerings and improve unit economics.
 &lt;/p&gt;
 &lt;p&gt;
  Amazon Web Services pioneered this approach with
  &lt;a href=&quot;https://aws.amazon.com/ec2/graviton/&quot;&gt;
   &lt;u&gt;
    Graviton Arm-based CPUs
   &lt;/u&gt;
  &lt;/a&gt;
  and
  &lt;a href=&quot;https://aws.amazon.com/ai/machine-learning/inferentia/&quot;&gt;
   &lt;u&gt;
    Inferentia
   &lt;/u&gt;
  &lt;/a&gt;
  /
  &lt;a href=&quot;https://aws.amazon.com/ai/machine-learning/trainium/&quot;&gt;
   &lt;u&gt;
    Trainium
   &lt;/u&gt;
  &lt;/a&gt;
  AI chips. Microsoft has developed
  &lt;a href=&quot;https://learn.microsoft.com/en-us/azure/virtual-machines/sizes/cobalt-overview&quot;&gt;
   &lt;u&gt;
    Cobalt processors
   &lt;/u&gt;
  &lt;/a&gt;
  and is reportedly working on AI accelerators. Google now offers the most comprehensive custom silicon portfolio among major cloud providers.
 &lt;/p&gt;
 &lt;p&gt;
  The strategy faces inherent challenges. Custom chip development requires enormous upfront investment — often billions of dollars. The software ecosystem for specialized accelerators lags behind Nvidia&#x27;s
  &lt;a href=&quot;https://developer.nvidia.com/about-cuda&quot;&gt;
   &lt;u&gt;
    CUDA platform
   &lt;/u&gt;
  &lt;/a&gt;
  , which benefits from 15+ years of developer tools. And rapid AI model architecture evolution creates risk that custom silicon optimized for today&#x27;s models becomes less relevant as new techniques emerge.
 &lt;/p&gt;
 &lt;p&gt;
  Yet Google argues its approach delivers unique advantages. &quot;This is how we built the first TPU ten years ago, which in turn unlocked the invention of the Transformer eight years ago — the very architecture that powers most of modern AI,&quot; the company noted, referring to the seminal
  &lt;a href=&quot;https://arxiv.org/abs/1706.03762&quot;&gt;
   &lt;u&gt;
    &quot;Attention Is All You Need&quot; paper
   &lt;/u&gt;
  &lt;/a&gt;
  from Google researchers in 2017.
 &lt;/p&gt;
 &lt;p&gt;
  The argument is that tight integration — &quot;model research, software, and hardware development under one roof&quot; — enables optimizations impossible with off-the-shelf components.
 &lt;/p&gt;
 &lt;p&gt;
  Beyond Anthropic, several other customers provided early feedback. Lightricks, which develops creative AI tools, reported that early Ironwood testing &quot;makes us highly enthusiastic&quot; about creating &quot;more nuanced, precise, and higher-fidelity image and video generation for our millions of global customers,&quot; said Yoav HaCohen, the company&#x27;s research director.
 &lt;/p&gt;
 &lt;p&gt;
  Google&#x27;s announcements raise questions that will play out over coming quarters. Can the industry sustain current infrastructure spending, with major AI companies collectively committing hundreds of billions of dollars? Will custom silicon prove economically superior to Nvidia GPUs? How will model architectures evolve?
 &lt;/p&gt;
 &lt;p&gt;
  For now, Google appears committed to a strategy that has defined the company for decades: building custom infrastructure to enable applications impossible on commodity hardware, then making that infrastructure available to customers who want similar capabilities without the capital investment.
 &lt;/p&gt;
 &lt;p&gt;
  As the AI industry transitions from research labs to production deployments serving billions of users, that infrastructure layer — the silicon, software, networking, power, and cooling that make it all run — may prove as important as the models themselves.
 &lt;/p&gt;
 &lt;p&gt;
  And if Anthropic&#x27;s willingness to commit to accessing up to one million chips is any indication, Google&#x27;s bet on custom silicon designed specifically for the age of inference may be paying off just as demand reaches its inflection point.
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Baseten takes on hyperscalers with new AI training platform that lets you own your model weights </title>
<link>https://venturebeat.com/data-infrastructure/baseten-takes-on-hyperscalers-with-new-ai-training-platform-that-lets-you</link>
<pubDate>Mon, 22 Dec 2025 12:51:29 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;nuneybits Vector art of multi-cloud nodes interconnected global df5a72fb-1f71-4b95-8b12-94c1e8def7d6&quot; data-nimg=&quot;1&quot; height=&quot;712&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/789u1ePM0udlJqqwgxRkPd/6fd3661185f8285972d95d68249faa03/nuneybits_Vector_art_of_multi-cloud_nodes_interconnected_global_df5a72fb-1f71-4b95-8b12-94c1e8def7d6.webp?w=1000&quot; width=&quot;1270&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
    &lt;p&gt;
     Credit: VentureBeat made with Midjourney
    &lt;/p&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://www.baseten.co/&quot;&gt;
   &lt;u&gt;
    Baseten
   &lt;/u&gt;
  &lt;/a&gt;
  , the AI infrastructure company recently valued at $2.15 billion, is making its most significant product pivot yet: a full-scale push into model training that could reshape how enterprises wean themselves off dependence on OpenAI and other closed-source AI providers.
 &lt;/p&gt;
 &lt;p&gt;
  The San Francisco-based company announced Thursday the general availability of
  &lt;a href=&quot;https://www.baseten.co/products/training/&quot;&gt;
   &lt;u&gt;
    Baseten Training
   &lt;/u&gt;
  &lt;/a&gt;
  , an infrastructure platform designed to help companies fine-tune open-source AI models without the operational headaches of managing GPU clusters, multi-node orchestration, or cloud capacity planning. The move is a calculated expansion beyond Baseten&#x27;s core inference business, driven by what CTO Amir Haghighat describes as relentless customer demand and a strategic imperative to capture the full lifecycle of AI deployment.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;We had a captive audience of customers who kept coming to us saying, &#x27;Hey, I hate this problem,&#x27;&quot; Haghighat said in an interview. &quot;One of them told me, &#x27;Look, I bought a bunch of H100s from a cloud provider. I have to SSH in on Friday, run my fine-tuning job, then check on Monday to see if it worked. Sometimes I realize it just hasn&#x27;t been working all along.&#x27;&quot;
 &lt;/p&gt;
 &lt;div&gt;
  &lt;div data-exs-config=&#x27;{&quot;customParams&quot;:{&quot;post-type&quot;:&quot;article&quot;,&quot;post_id&quot;:&quot;4UOKzkyQ3Rxp6ogmiLzDYl&quot;,&quot;post_cat&quot;:&quot;data-infrastructure&quot;}}&#x27;&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  The launch comes at a critical inflection point in enterprise AI adoption. As open-source models from
  &lt;a href=&quot;https://huggingface.co/meta-llama&quot;&gt;
   &lt;u&gt;
    Meta
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://huggingface.co/Alibaba-NLP&quot;&gt;
   &lt;u&gt;
    Alibaba
   &lt;/u&gt;
  &lt;/a&gt;
  , and others increasingly rival proprietary systems in performance, companies face mounting pressure to reduce their reliance on expensive API calls to services like OpenAI&#x27;s
  &lt;a href=&quot;https://openai.com/index/introducing-gpt-5/&quot;&gt;
   &lt;u&gt;
    GPT-5
   &lt;/u&gt;
  &lt;/a&gt;
  or Anthropic&#x27;s
  &lt;a href=&quot;https://claude.ai/&quot;&gt;
   &lt;u&gt;
    Claude
   &lt;/u&gt;
  &lt;/a&gt;
  . But the path from off-the-shelf open-source model to production-ready custom AI remains treacherous, requiring specialized expertise in machine learning operations, infrastructure management, and performance optimization.
 &lt;/p&gt;
 &lt;p&gt;
  Baseten&#x27;s answer: provide the infrastructure rails while letting companies retain full control over their training code, data, and model weights. It&#x27;s a deliberately low-level approach born from hard-won lessons.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;h2&gt;
  &lt;b&gt;
   How a failed product taught Baseten what AI training infrastructure really needs
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  This isn&#x27;t Baseten&#x27;s first foray into training. The company&#x27;s previous attempt, a product called Blueprints launched roughly two and a half years ago, failed spectacularly — a failure Haghighat now embraces as instructive.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;We had created the abstraction layer a little too high,&quot; he explained. &quot;We were trying to create a magical experience, where as a user, you come in and programmatically choose a base model, choose your data and some hyperparameters, and magically out comes a model.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The problem? Users didn&#x27;t have the intuition to make the right choices about base models, data quality, or hyperparameters. When their models underperformed, they blamed the product. Baseten found itself in the consulting business rather than the infrastructure business, helping customers debug everything from dataset deduplication to model selection.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;We became consultants,&quot; Haghighat said. &quot;And that&#x27;s not what we had set out to do.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://www.baseten.co/&quot;&gt;
   &lt;u&gt;
    Baseten
   &lt;/u&gt;
  &lt;/a&gt;
  killed Blueprints and refocused entirely on inference, vowing to &quot;earn the right&quot; to expand again. That moment arrived earlier this year, driven by two market realities: the vast majority of Baseten&#x27;s inference revenue comes from custom models that customers train elsewhere, and competing training platforms were using restrictive terms of service to lock customers into their inference products.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Multiple companies who were building fine-tuning products had in their terms of service that you as a customer cannot take the weights of the fine-tuned model with you somewhere else,&quot; Haghighat said. &quot;I understand why from their perspective — I still don&#x27;t think there is a big company to be made purely on just training or fine-tuning. The sticky part is in inference, the valuable part where value is unlocked is in inference, and ultimately the revenue is in inference.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Baseten took the opposite approach: customers own their weights and can download them at will. The bet is that superior inference performance will keep them on the platform anyway.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Multi-cloud GPU orchestration and sub-minute scheduling set Baseten apart from hyperscalers
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The new
  &lt;a href=&quot;https://www.baseten.co/products/training/&quot;&gt;
   &lt;u&gt;
    Baseten Training
   &lt;/u&gt;
  &lt;/a&gt;
  product operates at what Haghighat calls &quot;the infrastructure layer&quot; — lower-level than the failed Blueprints experiment, but with opinionated tooling around reliability, observability, and integration with Baseten&#x27;s inference stack.
 &lt;/p&gt;
 &lt;p&gt;
  Key technical capabilities include multi-node training support across clusters of
  &lt;a href=&quot;https://www.nvidia.com/en-us/data-center/h100/&quot;&gt;
   &lt;u&gt;
    NVIDIA H100
   &lt;/u&gt;
  &lt;/a&gt;
  or
  &lt;a href=&quot;https://www.baseten.co/blog/accelerating-inference-nvidia-b200-gpus/?utm_term=b200%20gpu&amp;utm_campaign=Search+-Hosting+Inference&amp;utm_source=adwords&amp;utm_medium=ppc&amp;hsa_acc=9990356727&amp;hsa_cam=21607833837&amp;hsa_grp=179204207220&amp;hsa_ad=747940377782&amp;hsa_src=g&amp;hsa_tgt=kwd-2402895176571&amp;hsa_kw=b200%20gpu&amp;hsa_mt=e&amp;hsa_net=adwords&amp;hsa_ver=3&amp;gad_source=1&amp;gad_campaignid=21607833837&amp;gbraid=0AAAAAqCKh1tBBfE-A9FM_fms6m5z6IuPk&amp;gclid=CjwKCAiAt8bIBhBpEiwAzH1w6S_fxqaV-EfbGshbTKib8rt2sQl81yPs6M0y40aoYf1Zy5mV_ECflBoCjPsQAvD_BwE&quot;&gt;
   &lt;u&gt;
    B200 GPUs
   &lt;/u&gt;
  &lt;/a&gt;
  , automated checkpointing to protect against node failures, sub-minute job scheduling, and integration with Baseten&#x27;s proprietary
  &lt;a href=&quot;https://www.baseten.co/blog/how-we-built-multi-cloud-capacity-management/&quot;&gt;
   &lt;u&gt;
    Multi-Cloud Management (MCM)
   &lt;/u&gt;
  &lt;/a&gt;
  system. That last piece is critical: MCM allows Baseten to dynamically provision GPU capacity across multiple cloud providers and regions, passing cost savings to customers while avoiding the capacity constraints and multi-year contracts typical of hyperscaler deals.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;With hyperscalers, you don&#x27;t get to say, &#x27;Hey, give me three or four B200 nodes while my job is running, and then take it back from me and don&#x27;t charge me for it,&#x27;&quot; Haghighat said. &quot;They say, &#x27;No, you need to sign a three-year contract.&#x27; We don&#x27;t do that.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Baseten&#x27;s approach mirrors broader trends in cloud infrastructure, where abstraction layers increasingly allow workloads to move fluidly across providers. When AWS experienced a major outage several weeks ago, Baseten&#x27;s inference services remained operational by automatically routing traffic to other cloud providers — a capability now extended to training workloads.
 &lt;/p&gt;
 &lt;p&gt;
  The technical differentiation extends to Baseten&#x27;s observability tooling, which provides per-GPU metrics for multi-node jobs, granular checkpoint tracking, and a refreshed UI that surfaces infrastructure-level events. The company also introduced an &quot;
  &lt;a href=&quot;https://github.com/basetenlabs/ml-cookbook&quot;&gt;
   &lt;u&gt;
    ML Cookbook
   &lt;/u&gt;
  &lt;/a&gt;
  &quot; of open-source training recipes for popular models like Gemma, GPT OSS, and Qwen, designed to help users reach &quot;training success&quot; faster.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Early adopters report 84% cost savings and 50% latency improvements with custom models
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Two early customers illustrate the market Baseten is targeting: AI-native companies building specialized vertical solutions that require custom models.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://www.oxen.ai/&quot;&gt;
   &lt;u&gt;
    Oxen AI
   &lt;/u&gt;
  &lt;/a&gt;
  , a platform focused on dataset management and model fine-tuning, exemplifies the partnership model Baseten envisions. CEO Greg Schoeninger articulated a common strategic calculus, telling VentureBeat: &quot;Whenever I&#x27;ve seen a platform try to do both hardware and software, they usually fail at one of them. That&#x27;s why partnering with Baseten to handle infrastructure was the obvious choice.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Oxen built its customer experience entirely on top of Baseten&#x27;s infrastructure, using the
  &lt;a href=&quot;https://www.baseten.co/resources/changelog/authenticate-from-cli-with-truss-login/&quot;&gt;
   &lt;u&gt;
    Baseten CLI
   &lt;/u&gt;
  &lt;/a&gt;
  to programmatically orchestrate training jobs. The system automatically provisions and deprovisions GPUs, fully concealing Baseten&#x27;s interface behind Oxen&#x27;s own. For one Oxen customer,
  &lt;a href=&quot;https://alliumai.com/&quot;&gt;
   &lt;u&gt;
    AlliumAI
   &lt;/u&gt;
  &lt;/a&gt;
  — a startup bringing structure to messy retail data — the integration delivered 84% cost savings compared to previous approaches, reducing total inference costs from $46,800 to $7,530.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Training custom LoRAs has always been one of the most effective ways to leverage open-source models, but it often came with infrastructure headaches,&quot; said Daniel Demillard, CEO of AlliumAI. &quot;With Oxen and Baseten, that complexity disappears. We can train and deploy models at massive scale without ever worrying about CUDA, which GPU to choose, or shutting down servers after training.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://parsed.com/&quot;&gt;
   &lt;u&gt;
    Parsed
   &lt;/u&gt;
  &lt;/a&gt;
  , another early customer, tackles a different pain point: helping enterprises reduce dependence on OpenAI by creating specialized models that outperform generalist LLMs on domain-specific tasks. The company works in mission-critical sectors like healthcare, finance, and legal services, where model performance and reliability aren&#x27;t negotiable.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Prior to switching to Baseten, we were seeing repetitive and degraded performance on our fine-tuned models due to bugs with our previous training provider,&quot; said Charles O&#x27;Neill, Parsed&#x27;s co-founder and chief science officer. &quot;On top of that, we were struggling to easily download and checkpoint weights after training runs.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  With Baseten, Parsed achieved 50% lower end-to-end latency for transcription use cases, spun up HIPAA-compliant EU deployments for testing within 48 hours, and kicked off more than 500 training jobs. The company also leveraged Baseten&#x27;s modified
  &lt;a href=&quot;https://docs.baseten.co/examples/vllm&quot;&gt;
   &lt;u&gt;
    vLLM inference framework
   &lt;/u&gt;
  &lt;/a&gt;
  and
  &lt;a href=&quot;https://www.baseten.co/blog/a-quick-introduction-to-speculative-decoding/&quot;&gt;
   &lt;u&gt;
    speculative decoding
   &lt;/u&gt;
  &lt;/a&gt;
  — a technique that generates draft tokens to accelerate language model output — to cut latency in half for custom models.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Fast models matter,&quot; O&#x27;Neill said. &quot;But fast models that get better over time matter more. A model that&#x27;s 2x faster but static loses to one that&#x27;s slightly slower but improving 10% monthly. Baseten gives us both — the performance edge today and the infrastructure for continuous improvement.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Why training and inference are more interconnected than the industry realizes
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The Parsed example illuminates a deeper strategic rationale for Baseten&#x27;s training expansion: the boundary between training and inference is blurrier than conventional wisdom suggests.
 &lt;/p&gt;
 &lt;p&gt;
  Baseten&#x27;s model performance team uses the training platform extensively to create &quot;draft models&quot; for speculative decoding, a cutting-edge technique that can dramatically accelerate inference. The company recently announced it achieved 650+ tokens per second on OpenAI&#x27;s
  &lt;a href=&quot;https://huggingface.co/openai/gpt-oss-120b&quot;&gt;
   &lt;u&gt;
    GPT OSS 120B model
   &lt;/u&gt;
  &lt;/a&gt;
  — a 60% improvement over its launch performance — using
  &lt;a href=&quot;https://arxiv.org/abs/2503.01840&quot;&gt;
   &lt;u&gt;
    EAGLE-3
   &lt;/u&gt;
  &lt;/a&gt;
  speculative decoding, which requires training specialized small models to work alongside larger target models.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Ultimately, inference and training plug in more ways than one might think,&quot; Haghighat said. &quot;When you do speculative decoding in inference, you need to train the draft model. Our model performance team is a big customer of the training product to train these EAGLE heads on a continuous basis.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  This technical interdependence reinforces Baseten&#x27;s thesis that owning both training and inference creates defensible value. The company can optimize the entire lifecycle: a model trained on Baseten can be deployed with a single click to inference endpoints pre-optimized for that architecture, with deployment-from-checkpoint support for chat completion and audio transcription workloads.
 &lt;/p&gt;
 &lt;p&gt;
  The approach contrasts sharply with vertically integrated competitors like
  &lt;a href=&quot;https://replicate.com/&quot;&gt;
   &lt;u&gt;
    Replicate
   &lt;/u&gt;
  &lt;/a&gt;
  or
  &lt;a href=&quot;https://modal.com/&quot;&gt;
   &lt;u&gt;
    Modal
   &lt;/u&gt;
  &lt;/a&gt;
  , which also offer training and inference but with different architectural tradeoffs. Baseten&#x27;s bet is on lower-level infrastructure flexibility and performance optimization, particularly for companies running custom models at scale.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   As open-source AI models improve, enterprises see fine-tuning as the path away from OpenAI dependency
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Underpinning Baseten&#x27;s entire strategy is a conviction about the trajectory of open-source AI models — namely, that they&#x27;re getting good enough, fast enough, to unlock massive enterprise adoption through fine-tuning.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Both closed and open-source models are getting better and better in terms of quality,&quot; Haghighat said. &quot;We don&#x27;t even need open source to surpass closed models, because as both of them are getting better, they unlock all these invisible lines of usefulness for different use cases.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  He pointed to the proliferation of reinforcement learning and supervised fine-tuning techniques that allow companies to take an open-source model and make it &quot;as good as the closed model, not at everything, but at this narrow band of capability that they want.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  That trend is already visible in Baseten&#x27;s
  &lt;a href=&quot;https://www.baseten.co/products/model-apis/&quot;&gt;
   &lt;u&gt;
    Model APIs business
   &lt;/u&gt;
  &lt;/a&gt;
  , launched alongside Training earlier this year to provide production-grade access to open-source models. The company was the first provider to offer access to
  &lt;a href=&quot;https://api-docs.deepseek.com/news/news1226&quot;&gt;
   &lt;u&gt;
    DeepSeek V3
   &lt;/u&gt;
  &lt;/a&gt;
  and
  &lt;a href=&quot;https://api-docs.deepseek.com/news/news250120&quot;&gt;
   &lt;u&gt;
    R1
   &lt;/u&gt;
  &lt;/a&gt;
  , and has since added models like
  &lt;a href=&quot;https://ai.meta.com/blog/llama-4-multimodal-intelligence/&quot;&gt;
   &lt;u&gt;
    Llama 4
   &lt;/u&gt;
  &lt;/a&gt;
  and
  &lt;a href=&quot;https://qwen.ai/research&quot;&gt;
   &lt;u&gt;
    Qwen 3
   &lt;/u&gt;
  &lt;/a&gt;
  , optimized for performance and reliability. Model APIs serves as a top-of-funnel product: companies start with off-the-shelf open-source models, realize they need customization, move to Training for fine-tuning, and ultimately deploy on Baseten&#x27;s
  &lt;a href=&quot;https://www.baseten.co/products/dedicated-deployments/&quot;&gt;
   &lt;u&gt;
    Dedicated Deployments
   &lt;/u&gt;
  &lt;/a&gt;
  infrastructure.
 &lt;/p&gt;
 &lt;p&gt;
  Yet Haghighat acknowledged the market remains &quot;fuzzy&quot; around which training techniques will dominate. Baseten is hedging by staying close to the bleeding edge through its
  &lt;a href=&quot;https://www.baseten.co/blog/forward-deployed-engineering/&quot;&gt;
   &lt;u&gt;
    Forward Deployed Engineering team
   &lt;/u&gt;
  &lt;/a&gt;
  , which works hands-on with select customers on reinforcement learning, supervised fine-tuning, and other advanced techniques.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;As we do that, we will see patterns emerge about what a productized training product can look like that really addresses the user&#x27;s needs without them having to learn too much about how RL works,&quot; he said. &quot;Are we there as an industry? I would say not quite. I see some attempts at that, but they all seem like almost falling to the same trap that Blueprints fell into—a bit of a walled garden that ties the hands of AI folks behind their back.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The roadmap ahead includes potential abstractions for common training patterns, expansion into image, audio, and video fine-tuning, and deeper integration of advanced techniques like prefill-decode disaggregation, which separates the initial processing of prompts from token generation to improve efficiency.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Baseten faces crowded field but bets developer experience and performance will win enterprise customers
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Baseten enters an increasingly crowded market for AI infrastructure. Hyperscalers like
  &lt;a href=&quot;https://aws.amazon.com/&quot;&gt;
   &lt;u&gt;
    AWS
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://cloud.google.com/?hl=en&quot;&gt;
   &lt;u&gt;
    Google Cloud
   &lt;/u&gt;
  &lt;/a&gt;
  , and
  &lt;a href=&quot;https://azure.microsoft.com/en-us/&quot;&gt;
   &lt;u&gt;
    Microsoft Azure
   &lt;/u&gt;
  &lt;/a&gt;
  offer GPU compute for training, while specialized providers like Lambda Labs, CoreWeave, and Together AI compete on price, performance, or ease of use. Then there are vertically integrated platforms like
  &lt;a href=&quot;https://huggingface.co/&quot;&gt;
   &lt;u&gt;
    Hugging Face
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://replicate.com/&quot;&gt;
   &lt;u&gt;
    Replicate
   &lt;/u&gt;
  &lt;/a&gt;
  , and
  &lt;a href=&quot;https://modal.com/&quot;&gt;
   &lt;u&gt;
    Modal
   &lt;/u&gt;
  &lt;/a&gt;
  that bundle training, inference, and model hosting.
 &lt;/p&gt;
 &lt;p&gt;
  Baseten&#x27;s differentiation rests on three pillars: its MCM system for multi-cloud capacity management, deep performance optimization expertise built from its inference business, and a developer experience tailored for production deployments rather than experimentation.
 &lt;/p&gt;
 &lt;p&gt;
  The company&#x27;s recent
  &lt;a href=&quot;https://www.baseten.co/blog/announcing-baseten-150m-series-d/&quot;&gt;
   &lt;u&gt;
    $150 million Series D
   &lt;/u&gt;
  &lt;/a&gt;
  and
  &lt;a href=&quot;https://www.baseten.co/blog/announcing-baseten-150m-series-d/&quot;&gt;
   &lt;u&gt;
    $2.15 billion valuation
   &lt;/u&gt;
  &lt;/a&gt;
  provide runway to invest in both products simultaneously. Major customers include
  &lt;a href=&quot;https://www.descript.com/&quot;&gt;
   &lt;u&gt;
    Descript
   &lt;/u&gt;
  &lt;/a&gt;
  , which uses Baseten for transcription workloads;
  &lt;a href=&quot;https://decagon.ai/&quot;&gt;
   &lt;u&gt;
    Decagon
   &lt;/u&gt;
  &lt;/a&gt;
  , which runs customer service AI; and
  &lt;a href=&quot;https://sourcegraph.com/&quot;&gt;
   &lt;u&gt;
    Sourcegraph
   &lt;/u&gt;
  &lt;/a&gt;
  , which powers coding assistants. All three operate in domains where model customization and performance are competitive advantages.
 &lt;/p&gt;
 &lt;p&gt;
  Timing may be Baseten&#x27;s biggest asset. The confluence of improving open-source models, enterprise discomfort with dependence on proprietary AI providers, and growing sophistication around fine-tuning techniques creates what Haghighat sees as a sustainable market shift.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;There is a lot of use cases for which closed models have gotten there and open ones have not,&quot; he said. &quot;Where I&#x27;m seeing in the market is people using different training techniques — more recently, a lot of reinforcement learning and SFT — to be able to get this open model to be as good as the closed model, not at everything, but at this narrow band of capability that they want. That&#x27;s very palpable in the market.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  For enterprises navigating the complex transition from closed to open AI models, Baseten&#x27;s positioning offers a clear value proposition: infrastructure that handles the messy middle of fine-tuning while optimizing for the ultimate goal of performant, reliable, cost-effective inference at scale. The company&#x27;s insistence that customers own their model weights — a stark contrast to competitors using training as a lock-in mechanism — reflects confidence that technical excellence, not contractual restrictions, will drive retention.
 &lt;/p&gt;
 &lt;p&gt;
  Whether Baseten can execute on this vision depends on navigating tensions inherent in its strategy: staying at the infrastructure layer without becoming consultants, providing power and flexibility without overwhelming users with complexity, and building abstractions at exactly the right level as the market matures. The company&#x27;s willingness to kill Blueprints when it failed suggests a pragmatism that could prove decisive in a market where many infrastructure providers over-promise and under-deliver.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Through and through, we&#x27;re an inference company,&quot; Haghighat emphasized. &quot;The reason that we did training is at the service of inference.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  That clarity of purpose — treating training as a means to an end rather than an end in itself—may be Baseten&#x27;s most important strategic asset. As AI deployment matures from experimentation to production, the companies that solve the full stack stand to capture outsized value. But only if they avoid the trap of technology in search of a problem.
 &lt;/p&gt;
 &lt;p&gt;
  At least Baseten&#x27;s customers no longer have to SSH into boxes on Friday and pray their training jobs complete by Monday. In the infrastructure business, sometimes the best innovation is simply making the painful parts disappear.
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Deductive AI projects 1,000+ annual engineering hours saved at DoorDash </title>
<link>https://venturebeat.com/data-infrastructure/how-deductive-ai-saved-doordash-1-000-engineering-hours-by-automating</link>
<pubDate>Mon, 22 Dec 2025 12:51:27 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;nuneybits Vector art of robot holding blueprint 193c9fc5-bbb5-46ea-9ff6-1a08bb03716e&quot; data-nimg=&quot;1&quot; height=&quot;712&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/7mfhEiM01EDWrgDZYpDbte/23713914379b94e43303f9965ccc40ae/nuneybits_Vector_art_of_robot_holding_blueprint_193c9fc5-bbb5-46ea-9ff6-1a08bb03716e.webp?w=1000&quot; width=&quot;1270&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
    &lt;p&gt;
     Credit: VentureBeat made with Midjourney
    &lt;/p&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  As software systems grow more complex and AI tools generate code faster than ever, a fundamental problem is getting worse:
  &lt;a href=&quot;https://algocademy.com/blog/why-debugging-takes-longer-than-writing-the-actual-code/&quot;&gt;
   &lt;u&gt;
    Engineers are drowning in debugging work
   &lt;/u&gt;
  &lt;/a&gt;
  , spending up to half their time hunting down the causes of software failures instead of building new products. The challenge has become so acute that it&#x27;s creating a new category of tooling — AI agents that can diagnose production failures in minutes instead of hours.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://www.deductive.ai/&quot;&gt;
   &lt;u&gt;
    Deductive AI
   &lt;/u&gt;
  &lt;/a&gt;
  , a startup emerging from stealth mode Wednesday, believes it has found a solution by applying reinforcement learning — the same technology that powers game-playing AI systems — to the messy, high-stakes world of production software incidents. The company announced it has raised $7.5 million in seed funding led by
  &lt;a href=&quot;https://www.crv.com/&quot;&gt;
   &lt;u&gt;
    CRV
   &lt;/u&gt;
  &lt;/a&gt;
  , with participation from
  &lt;a href=&quot;https://www.databricks.com/databricks-ventures&quot;&gt;
   &lt;u&gt;
    Databricks Ventures
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.thomvest.com/&quot;&gt;
   &lt;u&gt;
    Thomvest Ventures
   &lt;/u&gt;
  &lt;/a&gt;
  , and
  &lt;a href=&quot;https://www.primeset.com/&quot;&gt;
   &lt;u&gt;
    PrimeSet
   &lt;/u&gt;
  &lt;/a&gt;
  , to commercialize what it calls &quot;
  &lt;a href=&quot;https://www.deductive.ai/product&quot;&gt;
   &lt;u&gt;
    AI SRE agents
   &lt;/u&gt;
  &lt;/a&gt;
  &quot; that can diagnose and help fix software failures at machine speed.
 &lt;/p&gt;
 &lt;p&gt;
  The pitch resonates with a growing frustration inside engineering organizations: Modern observability tools can show that something broke, but they rarely explain why. When a production system fails at 3 a.m., engineers still face hours of manual detective work, cross-referencing logs, metrics, deployment histories, and code changes across dozens of interconnected services to identify the root cause.
 &lt;/p&gt;
 &lt;div&gt;
  &lt;div data-exs-config=&#x27;{&quot;customParams&quot;:{&quot;post-type&quot;:&quot;article&quot;,&quot;post_id&quot;:&quot;5eB6WWAPJjU76ZCvwit306&quot;,&quot;post_cat&quot;:&quot;data-infrastructure&quot;}}&#x27;&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  &quot;The complexities and inter-dependencies of modern infrastructure means that investigating the root cause of an outage or incident can feel like searching for a needle in a haystack, except the haystack is the size of a football field, it&#x27;s made of a million other needles, it&#x27;s constantly reshuffling itself, and is on fire — and every second you don&#x27;t find it equals lost revenue,&quot; said Sameer Agarwal, Deductive&#x27;s co-founder and chief technology officer, in an exclusive interview with VentureBeat.
 &lt;/p&gt;
 &lt;p&gt;
  Deductive&#x27;s system builds what the company calls a &quot;knowledge graph&quot; that maps relationships across codebases, telemetry data, engineering discussions, and internal documentation. When an incident occurs, multiple AI agents work together to form hypotheses, test them against live system evidence, and converge on a root cause — mimicking the investigative workflow of experienced site reliability engineers, but completing the process in minutes rather than hours.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  The technology has already shown measurable impact at some of the world&#x27;s most demanding production environments.
  &lt;a href=&quot;https://www.deductive.ai/blogs/how-doordash-powers-a-reliable-high-performance-ad-platform-with-deductive-ai&quot;&gt;
   &lt;u&gt;
    DoorDash&#x27;s advertising platform
   &lt;/u&gt;
  &lt;/a&gt;
  , which runs real-time auctions that must complete in under 100 milliseconds, has integrated Deductive into its incident response workflow. The company has set an ambitious 2026 goal of resolving production incidents within 10 minutes.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Our Ads Platform operates at a pace where manual, slow-moving investigations are no longer viable. Every minute of downtime directly affects company revenue,&quot; said Shahrooz Ansari, Senior Director of Engineering at DoorDash, in an interview with VentureBeat. &quot;Deductive has become a critical extension of our team, rapidly synthesizing signals across dozens of services and surfacing the insights that matter—within minutes.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://www.deductive.ai/&quot;&gt;
   &lt;u&gt;
    Deductive
   &lt;/u&gt;
  &lt;/a&gt;
  has root-caused approximately 100 production incidents at
  &lt;a href=&quot;https://www.doordash.com/&quot;&gt;
   &lt;u&gt;
    DoorDash
   &lt;/u&gt;
  &lt;/a&gt;
  over the past few months, with its accuracy improving with each investigation. For an organization of DoorDash&#x27;s size, the company estimates this will translate to more than 1,000 hours of annual engineering productivity savings, with an estimated full revenue impact &quot;in millions of dollars,&quot; according to Ansari. At location intelligence company
  &lt;a href=&quot;https://foursquare.com/&quot;&gt;
   &lt;u&gt;
    Foursquare
   &lt;/u&gt;
  &lt;/a&gt;
  , Deductive reduced the time to diagnose Apache Spark job failures by 90% —t urning a process that previously took hours or days into one that completes in under 10 minutes — while generating over $275,000 in annual savings.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Why AI-generated code is creating a debugging crisis
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The timing of Deductive&#x27;s launch reflects a brewing tension in software development: AI coding assistants are enabling engineers to generate code faster than ever, but the resulting software is often harder to understand and maintain.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;
  &lt;a href=&quot;https://x.com/karpathy/status/1886192184808149383?lang=en&quot;&gt;
   &lt;u&gt;
    Vibe coding
   &lt;/u&gt;
  &lt;/a&gt;
  ,&quot; a term popularized by AI researcher
  &lt;a href=&quot;https://karpathy.ai/&quot;&gt;
   &lt;u&gt;
    Andrej Karpathy
   &lt;/u&gt;
  &lt;/a&gt;
  , refers to using natural-language prompts to generate code through AI assistants. While these tools accelerate development, they can introduce what Agarwal describes as &quot;redundancies, breaks in architectural boundaries, assumptions, or ignored design patterns&quot; that accumulate over time.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Most AI-generated code still introduces redundancies, breaks architectural boundaries, makes assumptions, or ignores established design patterns,&quot; Agarwal told Venturebeat. &quot;In many ways, we now need AI to help clean up the mess that AI itself is creating.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The claim that engineers spend roughly half their time on debugging isn&#x27;t hyperbole. The Association for Computing Machinery reports that developers spend
  &lt;a href=&quot;https://queue.acm.org/detail.cfm?id=3404974&quot;&gt;
   &lt;u&gt;
    35% to 50% of their time validating and debugging software
   &lt;/u&gt;
  &lt;/a&gt;
  . More recently,
  &lt;a href=&quot;https://www.harness.io/blog/announcing-harness-ai&quot;&gt;
   &lt;u&gt;
    Harness&#x27;s State of Software Delivery 2025
   &lt;/u&gt;
  &lt;/a&gt;
  report found that 67% of developers are spending more time debugging AI-generated code.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;We&#x27;ve seen world-class engineers spending half of their time debugging instead of building,&quot; said Rakesh Kothari, Deductive&#x27;s co-founder and CEO. &quot;And as vibe coding generates new code at a rate we&#x27;ve never seen, this problem is only going to get worse.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   How Deductive&#x27;s AI agents actually investigate production failures
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Deductive&#x27;s technical approach differs substantially from the AI features being added to existing observability platforms like
  &lt;a href=&quot;https://www.datadoghq.com/&quot;&gt;
   &lt;u&gt;
    Datadog
   &lt;/u&gt;
  &lt;/a&gt;
  or
  &lt;a href=&quot;https://newrelic.com/&quot;&gt;
   &lt;u&gt;
    New Relic
   &lt;/u&gt;
  &lt;/a&gt;
  . Most of those systems use large language models to summarize data or identify correlations, but they lack what Agarwal calls &quot;code-aware reasoning&quot;—the ability to understand not just that something broke, but why the code behaves the way it does.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Most enterprises use multiple observability tools across different teams and services, so no vendor has a single holistic view of how their systems behave, fail, and recover—nor are they able to pair that with an understanding of the code that defines system behavior,&quot; Agarwal explained. &quot;These are key ingredients to resolving software incidents and it is exactly the gap Deductive fills.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The system connects to existing infrastructure using read-only API access to observability platforms, code repositories, incident management tools, and chat systems. It then continuously builds and updates its knowledge graph, mapping dependencies between services and tracking deployment histories.
 &lt;/p&gt;
 &lt;p&gt;
  When an alert fires, Deductive launches what the company describes as a multi-agent investigation. Different agents specialize in different aspects of the problem: one might analyze recent code changes, another examines trace data, while a third correlates the timing of the incident with recent deployments. The agents share findings and iteratively refine their hypotheses.
 &lt;/p&gt;
 &lt;p&gt;
  The critical difference from rule-based automation is Deductive&#x27;s use of reinforcement learning. The system learns from every incident which investigative steps led to correct diagnoses and which were dead ends. When engineers provide feedback, the system incorporates that signal into its learning model.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Each time it observes an investigation, it learns which steps, data sources, and decisions led to the right outcome,&quot; Agarwal said. &quot;It learns how to think through problems, not just point them out.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  At DoorDash, a recent latency spike in an API initially appeared to be an isolated service issue. Deductive&#x27;s investigation revealed that the root cause was actually timeout errors from a downstream machine learning platform undergoing a deployment. The system connected these dots by analyzing log volumes, traces, and deployment metadata across multiple services.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Without Deductive, our team would have had to manually correlate the latency spike across all logs, traces, and deployment histories,&quot; Ansari said. &quot;Deductive was able to explain not just what changed, but how and why it impacted production behavior.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   The company keeps humans in the loop—for now
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  While Deductive&#x27;s technology could theoretically push fixes directly to production systems, the company has deliberately chosen to keep humans in the loop—at least for now.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;While our system is capable of deeper automation and could push fixes to production, currently, we recommend precise fixes and mitigations that engineers can review, validate, and apply,&quot; Agarwal said. &quot;We believe maintaining a human in the loop is essential for trust, transparency and operational safety.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  However, he acknowledged that &quot;over time, we do think that deeper automation will come and how humans operate in the loop will evolve.&quot;
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Databricks and ThoughtSpot veterans bet on reasoning over observability
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The founding team brings deep expertise from building some of Silicon Valley&#x27;s most successful data infrastructure platforms. Agarwal earned his Ph.D. at UC Berkeley, where he created
  &lt;a href=&quot;https://arxiv.org/abs/1203.5485&quot;&gt;
   &lt;u&gt;
    BlinkDB
   &lt;/u&gt;
  &lt;/a&gt;
  , an influential system for approximate query processing. He was among the first engineers at
  &lt;a href=&quot;https://www.databricks.com/&quot;&gt;
   &lt;u&gt;
    Databricks
   &lt;/u&gt;
  &lt;/a&gt;
  , where he helped build
  &lt;a href=&quot;https://docs.databricks.com/gcp/en/spark/?scid=701Vp000004h4b1IAA&amp;utm_medium=paid+search&amp;utm_source=google&amp;utm_campaign=23156677199&amp;utm_adgroup=189768475320&amp;utm_content=aimax&amp;utm_offer=aimax&amp;utm_ad=779965794184&amp;utm_term=apache%20iceberg%20spark&amp;gad_source=1&amp;gad_campaignid=23156677199&amp;gbraid=0AAAAABYBeAhSzbWjXCf1Ok8HU2XzyuNAb&amp;gclid=CjwKCAiA_dDIBhB6EiwAvzc1cN1MnT40-rmesA_-YwBm870Sksy-DQYqWaR9mqQLAIQjzo7yRJpIfBoC7GsQAvD_BwE&quot;&gt;
   &lt;u&gt;
    Apache Spark
   &lt;/u&gt;
  &lt;/a&gt;
  . Kothari was an early engineer at
  &lt;a href=&quot;https://www.thoughtspot.com/&quot;&gt;
   &lt;u&gt;
    ThoughtSpot
   &lt;/u&gt;
  &lt;/a&gt;
  , where he led teams focused on distributed query processing and large-scale system optimization.
 &lt;/p&gt;
 &lt;p&gt;
  The investor syndicate reflects both the technical credibility and market opportunity. Beyond CRV&#x27;s
  &lt;a href=&quot;https://www.crv.com/team/max-gazor&quot;&gt;
   &lt;u&gt;
    Max Gazor
   &lt;/u&gt;
  &lt;/a&gt;
  , the round included participation from
  &lt;a href=&quot;https://sequoiacap.com/podcast/training-data-ion-stoica/&quot;&gt;
   &lt;u&gt;
    Ion Stoica
   &lt;/u&gt;
  &lt;/a&gt;
  , founder of Databricks and Anyscale;
  &lt;a href=&quot;https://www.thoughtspot.com/author/ajeet-singh&quot;&gt;
   &lt;u&gt;
    Ajeet Singh
   &lt;/u&gt;
  &lt;/a&gt;
  , founder of Nutanix and ThoughtSpot; and
  &lt;a href=&quot;http://bensigelman.org/&quot;&gt;
   &lt;u&gt;
    Ben Sigelman
   &lt;/u&gt;
  &lt;/a&gt;
  , founder of Lightstep.
 &lt;/p&gt;
 &lt;p&gt;
  Rather than competing with platforms like
  &lt;a href=&quot;https://www.datadoghq.com/&quot;&gt;
   &lt;u&gt;
    Datadog
   &lt;/u&gt;
  &lt;/a&gt;
  or
  &lt;a href=&quot;https://www.pagerduty.com/&quot;&gt;
   &lt;u&gt;
    PagerDuty
   &lt;/u&gt;
  &lt;/a&gt;
  , Deductive positions itself as a complementary layer that sits on top of existing tools. The pricing model reflects this: Instead of charging based on data volume, Deductive charges based on the number of incidents investigated, plus a base platform fee.
 &lt;/p&gt;
 &lt;p&gt;
  The company offers both cloud-hosted and self-hosted deployment options and emphasizes that it doesn&#x27;t store customer data on its servers or use it to train models for other customers — a critical assurance given the proprietary nature of both code and production system behavior.
 &lt;/p&gt;
 &lt;p&gt;
  With fresh capital and early customer traction at companies like
  &lt;a href=&quot;https://www.doordash.com/&quot;&gt;
   &lt;u&gt;
    DoorDash
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://foursquare.com/&quot;&gt;
   &lt;u&gt;
    Foursquare
   &lt;/u&gt;
  &lt;/a&gt;
  , and
  &lt;a href=&quot;https://kumo.ai/&quot;&gt;
   &lt;u&gt;
    Kumo AI
   &lt;/u&gt;
  &lt;/a&gt;
  , Deductive plans to expand its team and deepen the system&#x27;s reasoning capabilities from reactive incident analysis to proactive prevention. The near-term vision: helping teams predict problems before they occur.
 &lt;/p&gt;
 &lt;p&gt;
  DoorDash&#x27;s Ansari offers a pragmatic endorsement of where the technology stands today: &quot;Investigations that were previously manual and time-consuming are now automated, allowing engineers to shift their energy toward prevention, business impact, and innovation.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  In an industry where every second of downtime translates to lost revenue, that shift from firefighting to building increasingly looks less like a luxury and more like table stakes.
 &lt;/p&gt;
 &lt;p&gt;
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Inside LinkedIn’s generative AI cookbook: How it scaled people search to 1.3 billion users </title>
<link>https://venturebeat.com/data-infrastructure/inside-linkedins-generative-ai-cookbook-how-it-scaled-people-search-to-1-3</link>
<pubDate>Mon, 22 Dec 2025 12:51:25 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;LinkedIn&#x27;s generative AI cookbook&quot; data-nimg=&quot;1&quot; height=&quot;800&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/lgGMZPiCCaW1DNedEGAbm/a05d0e3b39eea0fae4e58895fad8d198/Screenshot_2025-11-12_at_4.53.46â__PM.png?w=1000&quot; width=&quot;1600&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  LinkedIn is launching its new AI-powered people search this week, after what seems like a very long wait for what should have been a natural offering for generative AI.
 &lt;/p&gt;
 &lt;p&gt;
  It comes a full three years after the launch of ChatGPT and six months after LinkedIn launched its AI job search offering. For technical leaders, this timeline illustrates a key enterprise lesson: Deploying generative AI in real enterprise settings is challenging, especially at a scale of 1.3 billion users. It’s a slow, brutal process of pragmatic optimization.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  The following account is based on several exclusive interviews with the LinkedIn product and engineering team behind the launch.
 &lt;/p&gt;
 &lt;p&gt;
  First, here’s how the product works: A user can now type a natural language query like,
  &lt;b&gt;
   &quot;Who is knowledgeable about curing cancer?&quot;
  &lt;/b&gt;
  into LinkedIn’s search bar.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  LinkedIn&#x27;s old search, based on keywords, would have been stumped. It would have looked only for references to &quot;cancer&quot;. If a user wanted to get sophisticated, they would have had to run separate, rigid keyword searches for &quot;cancer&quot; and then &quot;oncology&quot; and manually try to piece the results together.
 &lt;/p&gt;
 &lt;p&gt;
  The new AI-powered system, however, understands the
  &lt;i&gt;
   intent
  &lt;/i&gt;
  of the search because the LLM under the hood grasps semantic meaning. It recognizes, for example, that &quot;cancer&quot; is conceptually related to &quot;oncology&quot; and even less directly, to &quot;genomics research.&quot; As a result, it surfaces a far more relevant list of people, including oncology leaders and researchers, even if their profiles don&#x27;t use the exact word &quot;cancer.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The system also balances this relevance with
  &lt;i&gt;
   usefulness
  &lt;/i&gt;
  . Instead of just showing the world&#x27;s top oncologist (who might be an unreachable third-degree connection), it will also weigh who in your immediate network — like a first-degree connection — is &quot;pretty relevant&quot; and can serve as a crucial bridge to that expert.
 &lt;/p&gt;
 &lt;p&gt;
  See the video below for an example.
 &lt;/p&gt;
 &lt;figure&gt;
  &lt;video controls=&quot;&quot;&gt;
   &lt;source src=&quot;https://videos.ctfassets.net/jdtwqhzvc2n1/44gqdaTVm7rAtukCIyRKdq/2c3aa473939107ea22aa3af8dc2b6688/01D_Investors_with_FDA_experience_for_a_biotech_startup.mp4&quot;/&gt;
  &lt;/video&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  Arguably, though, the more important lesson for enterprise practitioners is the &quot;cookbook&quot; LinkedIn has developed: a replicable, multi-stage pipeline of distillation, co-design, and relentless optimization. LinkedIn had to perfect this on one product before attempting it on another.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Don&#x27;t try to do everything all at once,&quot; writes Wenjing Zhang, LinkedIn&#x27;s VP of Engineering,
  &lt;a href=&quot;https://www.linkedin.com/pulse/rebuilding-how-linkedin-members-connect-discover-ai-powered-zhang-rpbsc/?trackingId=jbJ518JQ2%2BAZa3Aiq7WOFQ%3D%3D&quot;&gt;
   in a post
  &lt;/a&gt;
  about the product launch, and who also spoke with VentureBeat last week in an interview. She notes that an earlier &quot;sprawling ambition&quot; to build a unified system for all of LinkedIn&#x27;s products &quot;stalled progress.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Instead, LinkedIn focused on winning one vertical first. The success of its previously launched AI Job Search — which led to job seekers without a four-year degree being
  &lt;b&gt;
   10% more likely to get hired
  &lt;/b&gt;
  , according to VP of Product Engineering Erran Berger — provided the blueprint.
 &lt;/p&gt;
 &lt;p&gt;
  Now, the company is applying that blueprint to a far larger challenge. &quot;It&#x27;s one thing to be able to do this across tens of millions of jobs,&quot; Berger told VentureBeat. &quot;It&#x27;s another thing to do this across north of a billion members.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  For enterprise AI builders, LinkedIn&#x27;s journey provides a technical playbook for what it
  &lt;i&gt;
   actually
  &lt;/i&gt;
  takes to move from a successful pilot to a billion-user-scale product.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   The new challenge: a 1.3 billion-member graph
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The job search product created a robust recipe that the new people search product could build upon, Berger explained.
 &lt;/p&gt;
 &lt;p&gt;
  The recipe started with with a &quot;golden data set&quot; of just a few hundred to a thousand real query-profile pairs, meticulously scored against a detailed 20- to 30-page &quot;product policy&quot; document. To scale this for training, LinkedIn used this small golden set to prompt a large foundation model to generate a massive volume of
  &lt;i&gt;
   synthetic
  &lt;/i&gt;
  training data. This synthetic data was used to train a
  &lt;b&gt;
   7-billion-parameter
  &lt;/b&gt;
  &quot;Product Policy&quot; model — a high-fidelity judge of relevance that was too slow for live production but perfect for teaching smaller models.
 &lt;/p&gt;
 &lt;p&gt;
  However, the team hit a wall early on. For six to nine months, they struggled to train a single model that could balance strict policy adherence (relevance) against user engagement signals. The &quot;aha moment&quot; came when they realized they needed to break the problem down. They distilled the 7B policy model into a
  &lt;b&gt;
   1.7B teacher model
  &lt;/b&gt;
  focused solely on relevance. They then paired it with separate teacher models trained to predict specific member actions, such as job applications for the jobs product, or connecting and following for people search. This &quot;multi-teacher&quot; ensemble produced soft probability scores that the final student model learned to mimic via KL divergence loss.
 &lt;/p&gt;
 &lt;p&gt;
  The resulting architecture operates as a two-stage pipeline. First, a larger
  &lt;b&gt;
   8B parameter model
  &lt;/b&gt;
  handles broad retrieval, casting a wide net to pull candidates from the graph. Then, the highly distilled student model takes over for fine-grained ranking. While the job search product successfully deployed a
  &lt;b&gt;
   0.6B (600-million)
  &lt;/b&gt;
  parameter student, the new people search product required even more aggressive compression. As Zhang notes, the team pruned their new student model from 440M down to just
  &lt;b&gt;
   220M parameters
  &lt;/b&gt;
  , achieving the necessary speed for 1.3 billion users with less than 1% relevance loss.
 &lt;/p&gt;
 &lt;p&gt;
  But applying this to people search broke the old architecture. The new problem included not just
  &lt;i&gt;
   ranking
  &lt;/i&gt;
  but also
  &lt;i&gt;
   retrieval
  &lt;/i&gt;
  .
 &lt;/p&gt;
 &lt;p&gt;
  “A billion records,&quot; Berger said, is a &quot;different beast.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  The team’s prior retrieval stack was built on CPUs. To handle the new scale and the latency demands of a &quot;snappy&quot; search experience, the team had to move its indexing to
  &lt;b&gt;
   GPU-based infrastructure
  &lt;/b&gt;
  . This was a foundational architectural shift that the job search product did not require.
 &lt;/p&gt;
 &lt;p&gt;
  Organizationally, LinkedIn benefited from multiple approaches. For a time, LinkedIn had two separate teams — job search and people search — attempting to solve the problem in parallel. But once the job search team achieved its breakthrough using the policy-driven distillation method, Berger and his leadership team intervened. They brought over the architects of the job search win —  product lead Rohan Rajiv and engineering lead Wenjing Zhang — to transplant their &#x27;cookbook&#x27; directly to the new domain.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Distilling for a 10x throughput gain
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  With the retrieval problem solved, the team faced the ranking and efficiency challenge. This is where the cookbook was adapted with new, aggressive optimization techniques.
 &lt;/p&gt;
 &lt;p&gt;
  Zhang’s
  &lt;a href=&quot;https://www.linkedin.com/pulse/rebuilding-how-linkedin-members-connect-discover-ai-powered-zhang-rpbsc/?trackingId=jbJ518JQ2%2BAZa3Aiq7WOFQ%3D%3D&quot;&gt;
   technical post
  &lt;/a&gt;
  provides the specific details our audience of AI engineers will appreciate. One of the more significant optimizations was input size.
 &lt;/p&gt;
 &lt;p&gt;
  To feed the model, the team trained
  &lt;i&gt;
   another
  &lt;/i&gt;
  LLM with reinforcement learning (RL) for a single purpose: to summarize the input context. This &quot;summarizer&quot; model was able to reduce the model&#x27;s input size by
  &lt;b&gt;
   20-fold
  &lt;/b&gt;
  with minimal information loss.
 &lt;/p&gt;
 &lt;p&gt;
  The combined result of the 220M-parameter model and the 20x input reduction? A
  &lt;b&gt;
   10x increase in ranking throughput
  &lt;/b&gt;
  , allowing the team to serve the model efficiently to its massive user base.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Pragmatism over hype: building tools, not agents
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Throughout our discussions, Berger was adamant about something else that might catch peoples’ attention: The real value for enterprises today lies in perfecting recommender systems, not in chasing &quot;agentic hype.&quot; He also refused to talk about the specific models that the company used for the searches, suggesting it almost doesn&#x27;t matter. The company selects models based on which one it finds the most efficient for the task.
 &lt;/p&gt;
 &lt;p&gt;
  The new AI-powered people search is a manifestation of Berger’s philosophy that it’s best to optimize the recommender system first. The architecture includes a new &quot;intelligent query routing layer,&quot; as Berger explained, that itself is LLM-powered. This router pragmatically decides if a user&#x27;s query — like &quot;trust expert&quot; — should go to the new semantic, natural-language stack or to the old, reliable lexical search.
 &lt;/p&gt;
 &lt;p&gt;
  This entire, complex system is designed to be a &quot;tool&quot; that a
  &lt;i&gt;
   future
  &lt;/i&gt;
  agent will use, not the agent itself.
 &lt;/p&gt;
 &lt;p&gt;
  &quot;Agentic products are only as good as the tools that they use to accomplish tasks for people,&quot; Berger said. &quot;You can have the world&#x27;s best reasoning model, and if you&#x27;re trying to use an agent to do people search but the people search engine is not very good, you&#x27;re not going to be able to deliver.&quot;
 &lt;/p&gt;
 &lt;p&gt;
  Now that the people search is available, Berger suggested that one day the company will be offering agents to use it. But he didn’t provide details on timing. He also said the recipe used for job and people search will be spread across the company’s other products.
 &lt;/p&gt;
 &lt;p&gt;
  For enterprises building their own AI roadmaps, LinkedIn&#x27;s playbook is clear:
 &lt;/p&gt;
 &lt;ol&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Be pragmatic:
    &lt;/b&gt;
    Don&#x27;t try to boil the ocean. Win one vertical, even if it takes 18 months.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Codify the &quot;cookbook&quot;:
    &lt;/b&gt;
    Turn that win into a repeatable process (policy docs, distillation pipelines, co-design).
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Optimize relentlessly:
    &lt;/b&gt;
    The real 10x gains come
    &lt;i&gt;
     after
    &lt;/i&gt;
    the initial model, in pruning, distillation, and creative optimizations like an RL-trained summarizer.
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ol&gt;
 &lt;p&gt;
  LinkedIn&#x27;s journey shows that for real-world enterprise AI, emphasis on specific models or cool agentic systems should take a back seat. The durable, strategic advantage comes from mastering the
  &lt;i&gt;
   pipeline
  &lt;/i&gt;
  — the &#x27;AI-native&#x27; cookbook of co-design, distillation, and ruthless optimization.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;i&gt;
   (Editor&#x27;s note: We will be publishing a full-length podcast with LinkedIn&#x27;s Erran Berger, which will dive deeper into these technical details, on the VentureBeat podcast feed soon.)
  &lt;/i&gt;
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> From shiny object to sober reality: The vector database story, two years later </title>
<link>https://venturebeat.com/data-infrastructure/from-shiny-object-to-sober-reality-the-vector-database-story-two-years-later</link>
<pubDate>Mon, 22 Dec 2025 12:51:22 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;Vector databases&quot; data-nimg=&quot;1&quot; height=&quot;816&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/SGaUQ51tBkvFJOC9u2V3c/30aeb16db2c0f1e0cb0a488908910f9e/u7277289442_A_multi-tiered_data_stack_lit_in_neon_emanates_st_cc2e0a2c-336d-4d1b-928c-76caecb59444_1.png?w=1000&quot; width=&quot;1456&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  When I first wrote
  &lt;i&gt;
   “
  &lt;/i&gt;
  &lt;a href=&quot;https://venturebeat.com/ai/vector-databases-shiny-object-syndrome-and-the-case-of-a-missing-unicorn&quot;&gt;
   &lt;i&gt;
    &lt;u&gt;
     Vector databases: Shiny object syndrome and the case of a missing unicorn
    &lt;/u&gt;
   &lt;/i&gt;
  &lt;/a&gt;
  &lt;i&gt;
   ”
  &lt;/i&gt;
  in March 2024, the industry was awash in hype. Vector databases were positioned as the
  &lt;b&gt;
   next big thing
  &lt;/b&gt;
  — a must-have infrastructure layer for the gen AI era. Billions of venture dollars flowed, developers rushed to integrate embeddings into their pipelines and analysts breathlessly tracked funding rounds for
  &lt;a href=&quot;https://www.pinecone.io/&quot;&gt;
   &lt;u&gt;
    Pinecone
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://weaviate.io/&quot;&gt;
   &lt;u&gt;
    Weaviate
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.trychroma.com/&quot;&gt;
   &lt;u&gt;
    Chroma
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://milvus.io/&quot;&gt;
   &lt;u&gt;
    Milvus
   &lt;/u&gt;
  &lt;/a&gt;
  and a dozen others.
 &lt;/p&gt;
 &lt;p&gt;
  The promise was intoxicating: Finally, a way to search by meaning rather than by brittle keywords. Just dump your enterprise knowledge into a vector store, connect an LLM and watch magic happen.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  Except the magic never fully materialized.
 &lt;/p&gt;
 &lt;p&gt;
  Two years on, the
  &lt;a href=&quot;https://venturebeat.com/ai/how-ai-product-teams-are-rethinking-impact-risk-feasibility&quot;&gt;
   &lt;b&gt;
    &lt;u&gt;
     reality check
    &lt;/u&gt;
   &lt;/b&gt;
  &lt;/a&gt;
  has arrived: 95% of organizations invested in gen AI initiatives are seeing zero measurable returns. And, many of the warnings I raised back then — about the limits of vectors, the crowded vendor landscape and the risks of treating vector databases as silver bullets — have played out almost exactly as predicted.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Prediction 1: The missing unicorn
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Back then, I questioned whether Pinecone — the poster child of the category — would achieve unicorn status or whether it would become the “missing unicorn” of the database world. Today, that question has been answered in the most telling way possible: Pinecone is
  &lt;a href=&quot;https://www.calcalistech.com/ctechnews/article/rz31q82b5&quot;&gt;
   &lt;b&gt;
    &lt;u&gt;
     reportedly exploring a sale
    &lt;/u&gt;
   &lt;/b&gt;
  &lt;/a&gt;
  , struggling to break out amid fierce competition and customer churn.
 &lt;/p&gt;
 &lt;p&gt;
  Yes, Pinecone raised big rounds and signed marquee logos. But in practice, differentiation was thin. Open-source players like Milvus, Qdrant and Chroma undercut them on cost. Incumbents like Postgres (with
  &lt;a href=&quot;https://github.com/pgvector/pgvector&quot;&gt;
   &lt;u&gt;
    pgVector
   &lt;/u&gt;
  &lt;/a&gt;
  ) and Elasticsearch simply added vector support as a feature. And customers increasingly asked:
  &lt;i&gt;
   “Why introduce a whole new database when my existing stack already does vectors well enough?”
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;p&gt;
  The result: Pinecone, once valued near a billion dollars, is now looking for a home. The missing unicorn indeed. In September 2025,
  &lt;a href=&quot;https://venturebeat.com/data-infrastructure/pinecone-founder-edo-liberty-appoints-googler-ash-as-ceo&quot;&gt;
   &lt;u&gt;
    Pinecone appointed Ash Ashutosh
   &lt;/u&gt;
  &lt;/a&gt;
  as CEO, with founder Edo Liberty moving to a chief scientist role.  The timing is telling: The leadership change comes amid increasing pressure and questions over its long-term independence.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Prediction 2: Vectors alone won’t cut it
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  I also argued that vector databases by themselves were not an end solution. If your use case required exactness —  l ike searching for “Error 221” in a manual—a pure vector search would gleefully serve up “Error 222” as “close enough.” Cute in a demo, catastrophic in production.
 &lt;/p&gt;
 &lt;p&gt;
  That tension between similarity and relevance has proven fatal to the myth of vector databases as all-purpose engines.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;i&gt;
   “Enterprises discovered the hard way that semantic ≠ correct.”
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;p&gt;
  Developers who gleefully swapped out lexical search for vectors quickly reintroduced… lexical search in conjunction with vectors. Teams that expected vectors to “just work” ended up bolting on metadata filtering,
  &lt;a href=&quot;https://www.mongodb.com/resources/basics/artificial-intelligence/reranking-models&quot;&gt;
   &lt;u&gt;
    rerankers
   &lt;/u&gt;
  &lt;/a&gt;
  and hand-tuned rules. By 2025, the consensus is clear: Vectors are powerful, but only as part of a hybrid stack.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Prediction 3: A crowded field becomes commoditized
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The explosion of vector database startups was never sustainable. Weaviate, Milvus (via Zilliz), Chroma, Vespa, Qdrant — each claimed subtle differentiators, but to most buyers they all did the same thing: store vectors and retrieve nearest neighbors.
 &lt;/p&gt;
 &lt;p&gt;
  Today, very few of these players are breaking out. The market has fragmented, commoditized and in many ways been swallowed by incumbents. Vector search is now a checkbox feature in cloud data platforms, not a standalone moat.
 &lt;/p&gt;
 &lt;p&gt;
  Just as I wrote then: Distinguishing one vector DB from another will pose an increasing challenge. That challenge has only grown harder.
  &lt;a href=&quot;https://vald.vdaas.org/&quot;&gt;
   &lt;u&gt;
    Vald
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.marqo.ai/&quot;&gt;
   &lt;u&gt;
    Marqo
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://lancedb.com/&quot;&gt;
   &lt;u&gt;
    LanceDB
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://github.com/pgvector/pgvector&quot;&gt;
   &lt;u&gt;
    PostgresSQL
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.oracle.com/heatwave/&quot;&gt;
   &lt;u&gt;
    MySQL HeatWave
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.oracle.com/database/23ai/&quot;&gt;
   &lt;u&gt;
    Oracle 23c
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://azure.microsoft.com/en-us/products/azure-sql/database&quot;&gt;
   &lt;u&gt;
    Azure SQL
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://cassandra.apache.org/_/index.html&quot;&gt;
   &lt;u&gt;
    Cassandra
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://redis.io/docs/latest/develop/clients/redis-py/vecsearch/&quot;&gt;
   &lt;u&gt;
    Redis
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://neo4j.com/docs/cypher-manual/current/indexes/semantic-indexes/vector-indexes/&quot;&gt;
   &lt;u&gt;
    Neo4j
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://neo4j.com/docs/cypher-manual/current/indexes/semantic-indexes/vector-indexes/&quot;&gt;
   &lt;u&gt;
    SingleStore
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://www.elastic.co/docs/solutions/search/vector/knn&quot;&gt;
   &lt;u&gt;
    ElasticSearch
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://docs.opensearch.org/latest/vector-search/vector-search-techniques/index/&quot;&gt;
   &lt;u&gt;
    OpenSearch
   &lt;/u&gt;
  &lt;/a&gt;
  ,
  &lt;a href=&quot;https://solr.apache.org/guide/solr/latest/query-guide/dense-vector-search.html&quot;&gt;
   &lt;u&gt;
    Apahce Solr
   &lt;/u&gt;
  &lt;/a&gt;
  … the list goes on.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   The new reality: Hybrid and GraphRAG
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  But this isn’t just a story of decline — it’s a story of evolution. Out of the ashes of vector hype, new paradigms are emerging that combine the best of multiple approaches.
 &lt;/p&gt;
 &lt;p&gt;
  Hybrid Search: Keyword + vector is now the default for serious applications. Companies learned that you need both precision and fuzziness, exactness and semantics. Tools like Apache Solr, Elasticsearch, pgVector and Pinecone’s own “cascading retrieval” embrace this.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://arxiv.org/abs/2501.00309&quot;&gt;
   &lt;u&gt;
    GraphRAG
   &lt;/u&gt;
  &lt;/a&gt;
  : The hottest buzzword of late 2024/2025 is GraphRAG — graph-enhanced retrieval augmented generation. By marrying vectors with knowledge graphs, GraphRAG encodes the relationships between entities that embeddings alone flatten away. The payoff is dramatic.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Benchmarks and evidence
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;a href=&quot;https://aws.amazon.com/blogs/machine-learning/improving-retrieval-augmented-generation-accuracy-with-graphrag/&quot;&gt;
     &lt;u&gt;
      Amazon’s AI blog
     &lt;/u&gt;
    &lt;/a&gt;
    cites benchmarks from
    &lt;b&gt;
     Lettria
    &lt;/b&gt;
    , where hybrid GraphRAG boosted answer correctness from ~50% to 80%-plus in test datasets across finance, healthcare, industry, and law.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    The
    &lt;a href=&quot;https://arxiv.org/pdf/2506.02404&quot;&gt;
     &lt;b&gt;
      &lt;u&gt;
       GraphRAG-Bench
      &lt;/u&gt;
     &lt;/b&gt;
    &lt;/a&gt;
    benchmark (released May 2025) provides a rigorous evaluation of GraphRAG vs. vanilla RAG across reasoning tasks, multi-hop queries and domain challenges.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    An
    &lt;a href=&quot;https://openreview.net/forum?id=NOK8g6AxRI&quot;&gt;
     &lt;u&gt;
      OpenReview evaluation of RAG vs GraphRAG
     &lt;/u&gt;
    &lt;/a&gt;
    found that each approach has strengths depending on task — but hybrid combinations often perform best.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;a href=&quot;https://www.falkordb.com/blog/graphrag-accuracy-diffbot-falkordb/&quot;&gt;
     &lt;u&gt;
      FalkorDB’s blog reports
     &lt;/u&gt;
    &lt;/a&gt;
    that when schema precision matters (structured domains), GraphRAG can outperform vector retrieval by a factor of ~3.4x on certain benchmarks.
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;p&gt;
  The rise of GraphRAG underscores the larger point: Retrieval is not about any single shiny object. It’s about building
  &lt;b&gt;
   retrieval systems
  &lt;/b&gt;
  — layered, hybrid, context-aware pipelines that give LLMs the right information, with the right precision, at the right time.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   What this means going forward
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The verdict is in: Vector databases were never the miracle. They were a step — an important one — in the evolution of search and retrieval. But they are not, and never were, the endgame.
 &lt;/p&gt;
 &lt;p&gt;
  The winners in this space won’t be those who sell vectors as a standalone database. They will be the ones who embed vector search into broader ecosystems — integrating graphs, metadata, rules and context engineering into cohesive platforms.
 &lt;/p&gt;
 &lt;p&gt;
  In other words: The unicorn isn’t the vector database. The unicorn is the retrieval stack.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Looking ahead: What’s next
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Unified data platforms will subsume vector + graph:
    &lt;/b&gt;
    Expect major DB and cloud vendors to offer integrated retrieval stacks (vector + graph + full-text) as built-in capabilities.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     “Retrieval engineering” will emerge as a distinct discipline:
    &lt;/b&gt;
    Just as MLOps matured, so too will practices around embedding tuning, hybrid ranking and graph construction.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Meta-models learning to query better:
    &lt;/b&gt;
    Future LLMs may
    &lt;i&gt;
     learn
    &lt;/i&gt;
    to orchestrate which retrieval method to use per query, dynamically adjusting weighting.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Temporal and multimodal GraphRAG:
    &lt;/b&gt;
    Already, researchers are extending GraphRAG to be time-aware (
    &lt;a href=&quot;https://arxiv.org/pdf/2508.01680&quot;&gt;
     &lt;u&gt;
      T-GRAG
     &lt;/u&gt;
    &lt;/a&gt;
    ) and multimodally unified (e.g. connecting images, text, video).
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    &lt;b&gt;
     Open benchmarks and abstraction layers:
    &lt;/b&gt;
    Tools like
    &lt;a href=&quot;https://www.microsoft.com/en-us/research/blog/benchmarkqed-automated-benchmarking-of-rag-systems/&quot;&gt;
     &lt;u&gt;
      BenchmarkQED
     &lt;/u&gt;
    &lt;/a&gt;
    (for RAG benchmarking) and GraphRAG-Bench will push the community toward fairer, comparably measured systems.
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;h2&gt;
  &lt;b&gt;
   From shiny objects to essential infrastructure
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The arc of the vector database story has followed a classic path: A pervasive hype cycle, followed by introspection, correction and maturation. In 2025, vector search is no longer the shiny object everyone pursues blindly — it’s now a critical building block within a more sophisticated, multi-pronged retrieval architecture.
 &lt;/p&gt;
 &lt;p&gt;
  The original warnings were right. Pure vector-based hopes often crash on the shoals of precision, relational complexity and enterprise constraints. Yet the technology was never wasted: It forced the industry to rethink retrieval, blending semantic, lexical and relational strategies.
 &lt;/p&gt;
 &lt;p&gt;
  If I were to write a sequel in 2027, I suspect it would frame vector databases not as unicorns, but as legacy infrastructure — foundational, but eclipsed by smarter orchestration layers, adaptive retrieval controllers and AI systems that dynamically choose
  &lt;i&gt;
   which
  &lt;/i&gt;
  retrieval tool fits the query.
 &lt;/p&gt;
 &lt;p&gt;
  As of now, the real battle is not vector vs keyword — it’s the indirection, blending and discipline in building retrieval pipelines that reliably ground gen AI in facts and domain knowledge. That’s the unicorn we should be chasing now.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;i&gt;
   Amit Verma is head of engineering and AI Labs at
  &lt;/i&gt;
  &lt;a href=&quot;https://www.neuron7.ai/&quot;&gt;
   &lt;i&gt;
    Neuron7
   &lt;/i&gt;
  &lt;/a&gt;
  &lt;i&gt;
   .
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;p&gt;
  &lt;i&gt;
   Read more from our
  &lt;/i&gt;
  &lt;a href=&quot;https://venturebeat.com/datadecisionmakers&quot;&gt;
   &lt;i&gt;
    guest writers
   &lt;/i&gt;
  &lt;/a&gt;
  &lt;i&gt;
   . Or, consider submitting a post of your own! See our
  &lt;/i&gt;
  &lt;a href=&quot;https://venturebeat.com/guest-posts&quot;&gt;
   &lt;i&gt;
    guidelines here
   &lt;/i&gt;
  &lt;/a&gt;
  &lt;i&gt;
   .
  &lt;/i&gt;
 &lt;/p&gt;
 &lt;br/&gt;
 &lt;br/&gt;
 &lt;p&gt;
  Welcome to the VentureBeat community!
 &lt;/p&gt;
 &lt;p&gt;
  Our guest posting program is where technical experts share insights and provide neutral, non-vested deep dives on AI, data infrastructure, cybersecurity and other cutting-edge technologies shaping the future of enterprise.
 &lt;/p&gt;
 &lt;p&gt;
  &lt;a href=&quot;/category/DataDecisionMakers&quot;&gt;
   Read more
  &lt;/a&gt;
  from our guest post program — and check out our
  &lt;a href=&quot;/guest-posts&quot;&gt;
   guidelines
  &lt;/a&gt;
  if you’re interested in contributing an article of your own!
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> ScaleOps&#x27; new AI Infra Product slashes GPU costs for self-hosted enterprise LLMs by 50% for early adopters </title>
<link>https://venturebeat.com/data-infrastructure/scaleops-new-ai-infra-product-slashes-gpu-costs-for-self-hosted-enterprise</link>
<pubDate>Mon, 22 Dec 2025 12:51:20 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;figure&gt;
  &lt;img alt=&quot;Flat illustration isometric view of people working in lab surrounded by computers and GPUs&quot; data-nimg=&quot;1&quot; height=&quot;1152&quot; src=&quot;https://images.ctfassets.net/jdtwqhzvc2n1/3bOnH3W9t1HN5Ha6WoxYDq/00f40013d88e7f450f365f14c433c6d1/e6e653a5878841beaf1a3cb76e2bce67.png?w=1000&quot; width=&quot;2048&quot;/&gt;
  &lt;div&gt;
   &lt;figcaption&gt;
   &lt;/figcaption&gt;
   &lt;div&gt;
    &lt;button aria-label=&quot;Copy link&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;20&quot; viewbox=&quot;0 0 20 20&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M2.22196 17.778C2.68584 18.2425 3.23693 18.6108 3.84358 18.8617C4.45023 19.1126 5.10048 19.2411 5.75696 19.24C6.41359 19.2411 7.06398 19.1125 7.67079 18.8617C8.2776 18.6108 8.82887 18.2425 9.29296 17.778L12.121 14.949L10.707 13.535L7.87896 16.364C7.31543 16.925 6.55263 17.2399 5.75746 17.2399C4.96229 17.2399 4.19949 16.925 3.63596 16.364C3.07447 15.8007 2.75917 15.0378 2.75917 14.2425C2.75917 13.4471 3.07447 12.6842 3.63596 12.121L6.46496 9.29296L5.05096 7.87896L2.22196 10.707C1.28577 11.6454 0.76001 12.9169 0.76001 14.2425C0.76001 15.568 1.28577 16.8395 2.22196 17.778ZM17.778 9.29296C18.7137 8.35425 19.2391 7.08288 19.2391 5.75746C19.2391 4.43204 18.7137 3.16068 17.778 2.22196C16.8395 1.28577 15.568 0.76001 14.2425 0.76001C12.9169 0.76001 11.6454 1.28577 10.707 2.22196L7.87896 5.05096L9.29296 6.46496L12.121 3.63596C12.6845 3.07495 13.4473 2.75999 14.2425 2.75999C15.0376 2.75999 15.8004 3.07495 16.364 3.63596C16.9255 4.19923 17.2408 4.96213 17.2408 5.75746C17.2408 6.55279 16.9255 7.31569 16.364 7.87896L13.535 10.707L14.949 12.121L17.778 9.29296Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
      &lt;path d=&quot;M6.46395 14.95L5.04895 13.536L13.536 5.05005L14.95 6.46505L6.46395 14.95Z&quot; fill=&quot;black&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on LinkedIn&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;19&quot; viewbox=&quot;0 0 18 19&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.5 0.119141C0.67157 0.119141 0 0.790711 0 1.61914V16.6191C0 17.4475 0.67157 18.1191 1.5 18.1191H16.5C17.3284 18.1191 18 17.4475 18 16.6191V1.61914C18 0.790711 17.3284 0.119141 16.5 0.119141H1.5ZM5.52076 4.12186C5.52639 5.07811 4.81061 5.66733 3.96123 5.66311C3.16107 5.65889 2.46357 5.02186 2.46779 4.12327C2.47201 3.27811 3.13998 2.59889 4.00764 2.61858C4.88795 2.63827 5.52639 3.28374 5.52076 4.12186ZM9.2797 6.8809H6.75971H6.7583V15.4407H9.4217V15.241C9.4217 14.8611 9.4214 14.4811 9.4211 14.101C9.4203 13.0872 9.4194 12.0723 9.4246 11.0588C9.426 10.8127 9.4372 10.5568 9.5005 10.3219C9.7381 9.44444 10.5271 8.87774 11.4074 9.01704C11.9727 9.10554 12.3467 9.43324 12.5042 9.96624C12.6013 10.2994 12.6449 10.658 12.6491 11.0054C12.6605 12.053 12.6589 13.1006 12.6573 14.1483C12.6567 14.5181 12.6561 14.8881 12.6561 15.2579V15.4393H15.328V15.234C15.328 14.782 15.3278 14.3301 15.3275 13.8782C15.327 12.7487 15.3264 11.6192 15.3294 10.4893C15.3308 9.97884 15.276 9.47544 15.1508 8.98184C14.9638 8.24774 14.5771 7.64024 13.9485 7.20154C13.5027 6.88933 13.0133 6.68824 12.4663 6.66574C12.404 6.66315 12.3412 6.65976 12.2781 6.65635C11.9984 6.64123 11.7141 6.62587 11.4467 6.6798C10.6817 6.83308 10.0096 7.18324 9.5019 7.80054C9.4429 7.87134 9.3852 7.94324 9.2991 8.05054L9.2797 8.07484V6.8809ZM2.68164 15.4435H5.33242V6.88647H2.68164V15.4435Z&quot; fill=&quot;currentColor&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on X&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;17&quot; viewbox=&quot;0 0 18 17&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M14.1761 0.119141H16.9362L10.9061 6.89654L18 16.1191H12.4456L8.0951 10.5257L3.11723 16.1191H0.35544L6.80517 8.86994L0 0.119141H5.69545L9.6279 5.23176L14.1761 0.119141ZM13.2073 14.4945H14.7368L4.86441 1.65842H3.2232L13.2073 14.4945Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;button aria-label=&quot;Share on Facebook&quot; type=&quot;button&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;21&quot; viewbox=&quot;0 0 20 21&quot; width=&quot;20&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path d=&quot;M20 10.1802C20 4.62365 15.5229 0.119141 10 0.119141C4.47715 0.119141 0 4.62365 0 10.1802C0 15.2019 3.65684 19.3643 8.4375 20.1191V13.0885H5.89844V10.1802H8.4375V7.96366C8.4375 5.4421 9.9305 4.04926 12.2146 4.04926C13.3088 4.04926 14.4531 4.24577 14.4531 4.24577V6.72175H13.1922C11.95 6.72175 11.5625 7.49736 11.5625 8.29304V10.1802H14.3359L13.8926 13.0885H11.5625V20.1191C16.3432 19.3643 20 15.2021 20 10.1802Z&quot; fill=&quot;currentColor&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/button&gt;
    &lt;a href=&quot;https://www.google.com/preferences/source?q=venturebeat.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot; title=&quot;Add to Google Preferred Source&quot;&gt;
     &lt;svg fill=&quot;none&quot; height=&quot;18&quot; viewbox=&quot;0 0 18 18&quot; width=&quot;18&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;&gt;
      &lt;path clip-rule=&quot;evenodd&quot; d=&quot;M1.99998 0C1.132 0 0.744805 0.255172 0.499981 0.500014C0.255179 0.744855 0 1.13202 0 2V16C0 16.868 0.187717 17.1878 0.499962 17.5C0.78474 17.7848 1.132 18 1.99998 18H16C16.868 18 17.1639 17.8361 17.5 17.5C17.8361 17.1639 18 16.868 18 16V2C18 1.13202 17.7982 0.798195 17.5 0.500012C17.2018 0.201815 16.868 0 16 0H1.99998ZM13.2226 3.57136V6.03655L10.3377 5.39509C10.2238 5.37001 10.105 5.37853 9.99573 5.41964L9.67009 4.76755C9.56532 4.55809 9.38342 4.39741 9.16264 4.31929C8.94185 4.24117 8.69937 4.25169 8.48618 4.34864L4.77818 6.03409V3.57136C4.77818 3.40445 4.91318 3.26945 5.08009 3.26945H12.9215C13.0876 3.26945 13.2226 3.40445 13.2226 3.57136ZM4.47627 7.49209H10.3574L9.13009 5.03755C9.09502 4.96794 9.03439 4.91459 8.96089 4.88867C8.88739 4.86275 8.80671 4.86625 8.73573 4.89846L2.63209 7.67209C2.56052 7.70438 2.50435 7.76327 2.47548 7.83628C2.44661 7.9093 2.44732 7.99068 2.47745 8.06318L3.57218 10.6887V8.397C3.57218 7.89791 3.97718 7.49209 4.47627 7.49209ZM11.0324 7.49209H13.5245C14.0236 7.49209 14.4295 7.89709 14.4295 8.397V10.809L15.5299 7.50764C15.5432 7.46758 15.5479 7.4252 15.5437 7.38322C15.5396 7.34124 15.5267 7.30059 15.5059 7.26389C15.4851 7.2272 15.4568 7.19527 15.4229 7.17018C15.389 7.14508 15.3502 7.12737 15.309 7.11818L10.287 6.00218L11.0324 7.49209ZM4.47627 8.09509H13.5245C13.6906 8.09509 13.8256 8.23009 13.8256 8.397V14.4286C13.8256 14.5086 13.7939 14.5852 13.7375 14.6418C13.6811 14.6984 13.6045 14.7303 13.5245 14.7305H4.47545C4.39553 14.7303 4.31894 14.6984 4.2625 14.6418C4.20606 14.5852 4.17436 14.5086 4.17436 14.4286V8.397C4.17436 8.23009 4.31018 8.09509 4.47627 8.09509ZM6.88991 10.314C6.69039 10.3139 6.49461 10.3682 6.32359 10.471C6.15257 10.5737 6.01275 10.7211 5.91915 10.8973C5.82554 11.0735 5.78168 11.2719 5.79227 11.4711C5.80285 11.6704 5.86749 11.863 5.97924 12.0282C6.09098 12.1935 6.24563 12.3253 6.42658 12.4093C6.60753 12.4934 6.80795 12.5266 7.00634 12.5054C7.20473 12.4842 7.3936 12.4094 7.55269 12.289C7.71178 12.1685 7.83508 12.0071 7.90936 11.8219H6.88909V11.0037H8.80691V11.4128C8.80688 11.8378 8.66563 12.2508 8.40534 12.5867C8.14506 12.9227 7.78051 13.1626 7.369 13.2689C6.95749 13.3751 6.52235 13.3415 6.13198 13.1735C5.74162 13.0055 5.41815 12.7125 5.21244 12.3406C5.00673 11.9687 4.93043 11.539 4.99554 11.119C5.06065 10.699 5.26348 10.3126 5.57214 10.0204C5.8808 9.72829 6.2778 9.547 6.70072 9.50505C7.12364 9.46311 7.54851 9.5629 7.90855 9.78873L7.47327 10.4809C7.29827 10.3711 7.09651 10.3132 6.88991 10.314ZM12.3177 10.314H9.60382V9.49582H12.3177V10.314ZM9.60382 11.8219H12.9215V11.0037H9.60382V11.8219ZM12.3177 13.3298H9.60382V12.5116H12.3177V13.3298Z&quot; fill=&quot;black&quot; fill-rule=&quot;evenodd&quot;&gt;
      &lt;/path&gt;
     &lt;/svg&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/figure&gt;
 &lt;p&gt;
  &lt;a href=&quot;https://scaleops.com/&quot;&gt;
   ScaleOps
  &lt;/a&gt;
  has expanded its cloud resource management platform with a new product aimed at enterprises operating self-hosted large language models (LLMs) and GPU-based AI applications.
 &lt;/p&gt;
 &lt;p&gt;
  The
  &lt;a href=&quot;https://www.prnewswire.com/il/news-releases/scaleops-launches-ai-infrastructure-resource-management-product-to-power-self-hosted-ai-at-scale-302621807.html&quot;&gt;
   AI Infra Product announced today
  &lt;/a&gt;
  , extends the company’s existing automation capabilities to address a growing need for efficient GPU utilization, predictable performance, and reduced operational burden in large-scale AI deployments.
 &lt;/p&gt;
 &lt;p&gt;
  The company said the system is already running in enterprise production environments and delivering major efficiency gains for early adopters, reducing GPU costs by between 50% and 70%, according to the company. The company does not publicly list enterprise pricing for this solution and instead invites interested customers to receive a custom quote based on their operation size and needs
  &lt;a href=&quot;https://scaleops.com/pricing/&quot;&gt;
   here
  &lt;/a&gt;
  .
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;p&gt;
  In explaining how the system behaves under heavy load, Yodar Shafrir, CEO and Co-Founder of ScaleOps, said in an email to VentureBeat that the platform uses “proactive and reactive mechanisms to handle sudden spikes without performance impact,” noting that its workload rightsizing policies “automatically manage capacity to keep resources available.”
 &lt;/p&gt;
 &lt;p&gt;
  He added that minimizing GPU cold-start delays was a priority, emphasizing that the system “ensures instant response when traffic surges,” particularly for AI workloads where model load times are substantial.
 &lt;/p&gt;
 &lt;div&gt;
 &lt;/div&gt;
 &lt;div&gt;
  &lt;div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Expanding Resource Automation to AI Infrastructure
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  Enterprises deploying self-hosted AI models face performance variability, long load times, and persistent underutilization of GPU resources. ScaleOps positioned the new AI Infra Product as a direct response to these issues.
 &lt;/p&gt;
 &lt;p&gt;
  The platform allocates and scales GPU resources in real time and adapts to changes in traffic demand without requiring alterations to existing model deployment pipelines or application code.
 &lt;/p&gt;
 &lt;p&gt;
  According to ScaleOps, the system manages production environments for organizations including Wiz, DocuSign, Rubrik, Coupa, Alkami, Vantor, Grubhub, Island, Chewy, and several Fortune 500 companies.
 &lt;/p&gt;
 &lt;p&gt;
  The AI Infra Product introduces workload-aware scaling policies that proactively and reactively adjust capacity to maintain performance during demand spikes. The company stated that these policies reduce the cold-start delays associated with loading large AI models, which improves responsiveness when traffic increases.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Technical Integration and Platform Compatibility
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The product is designed for compatibility with common enterprise infrastructure patterns. It works across all Kubernetes distributions, major cloud platforms, on-premises data centers, and air-gapped environments. ScaleOps emphasized that deployment does not require code changes, infrastructure rewrites, or modifications to existing manifests.
 &lt;/p&gt;
 &lt;p&gt;
  Shafrir said the platform “integrates seamlessly into existing model deployment pipelines without requiring any code or infrastructure changes,” and he added that teams can begin optimizing immediately with their existing GitOps, CI/CD, monitoring, and deployment tooling.
 &lt;/p&gt;
 &lt;p&gt;
  Shafrir also addressed how the automation interacts with existing systems. He said the platform operates without disrupting workflows or creating conflicts with custom scheduling or scaling logic, explaining that the system “doesn’t change manifests or deployment logic” and instead enhances schedulers, autoscalers, and custom policies by incorporating real-time operational context while respecting existing configuration boundaries.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Performance, Visibility, and User Control
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The platform provides full visibility into GPU utilization, model behavior, performance metrics, and scaling decisions at multiple levels, including pods, workloads, nodes, and clusters. While the system applies default workload scaling policies, ScaleOps noted that engineering teams retain the ability to tune these policies as needed.
 &lt;/p&gt;
 &lt;p&gt;
  In practice, the company aims to reduce or eliminate the manual tuning that DevOps and AIOps teams typically perform to manage AI workloads. Installation is intended to require minimal effort, described by ScaleOps as a two-minute process using a single helm flag, after which optimization can be enabled through a single action.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Cost Savings and Enterprise Case Studies
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  ScaleOps reported that early deployments of the AI Infra Product have achieved GPU cost reductions of 50–70% in customer environments. The company cited two examples:
 &lt;/p&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    A major creative software company operating thousands of GPUs averaged 20% utilization before adopting ScaleOps. The product increased utilization, consolidated underused capacity, and enabled GPU nodes to scale down. These changes reduced overall GPU spending by more than half. The company also reported a 35% reduction in latency for key workloads.
   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
   &lt;p&gt;
    A global gaming company used the platform to optimize a dynamic LLM workload running on hundreds of GPUs. According to ScaleOps, the product increased utilization by a factor of seven while maintaining service-level performance. The customer projected $1.4 million in annual savings from this workload alone.
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;p&gt;
  ScaleOps stated that the expected GPU savings typically outweigh the cost of adopting and operating the platform, and that customers with limited infrastructure budgets have reported fast returns on investment.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   Industry Context and Company Perspective
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  The rapid adoption of self-hosted AI models has created new operational challenges for enterprises, particularly around GPU efficiency and the complexity of managing large-scale workloads. Shafrir described the broader landscape as one in which “cloud-native AI infrastructure is reaching a breaking point.”
 &lt;/p&gt;
 &lt;p&gt;
  “Cloud-native architectures unlocked great flexibility and control, but they also introduced a new level of complexity,” he said in the announcement. “Managing GPU resources at scale has become chaotic—waste, performance issues, and skyrocketing costs are now the norm. The ScaleOps platform was built to fix this. It delivers the complete solution for managing and optimizing GPU resources in cloud-native environments, enabling enterprises to run LLMs and AI applications efficiently, cost-effectively, and while improving performance.”
 &lt;/p&gt;
 &lt;p&gt;
  Shafrir added that the product brings together the full set of cloud resource management functions needed to manage diverse workloads at scale. The company positioned the platform as a holistic system for continuous, automated optimization.
 &lt;/p&gt;
 &lt;h2&gt;
  &lt;b&gt;
   A Unified Approach for the Future
  &lt;/b&gt;
 &lt;/h2&gt;
 &lt;p&gt;
  With the addition of the AI Infra Product, ScaleOps aims to establish a unified approach to GPU and AI workload management that integrates with existing enterprise infrastructure.
 &lt;/p&gt;
 &lt;p&gt;
  The platform’s early performance metrics and reported cost savings suggest a focus on measurable efficiency improvements within the expanding ecosystem of self-hosted AI deployments.
 &lt;/p&gt;
&lt;/div&gt;

</description>
</item>
</channel>
</rss>
