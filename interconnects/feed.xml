<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0" version="2.0">
<channel><title>Interconnects</title>
<lastBuildDate>Sun, 01 Mar 2026 23:21:01 -0000</lastBuildDate>
<item>
<title> How much does distillation really matter for Chinese LLMs? </title>
<link>https://www.interconnects.ai/p/how-much-does-distillation-really</link>
<pubDate>Tue, 24 Feb 2026 16:06:43 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    Distillation has been one of the most frequent topics of discussion in the broader US-China and technological diffusion story for AI. Distillation is a term with many definitions — the colloquial one today is using a stronger AI model’s outputs to teach a weaker model. The word itself is derived from a more technical and specific definition of
   &lt;/span&gt;
   &lt;em&gt;
    &lt;a href=&quot;https://arxiv.org/abs/1503.02531&quot; rel=&quot;&quot;&gt;
     knowledge distillation
    &lt;/a&gt;
   &lt;/em&gt;
   &lt;span&gt;
    (Hinton, Vinyals, &amp; Dean 2015), which involves a specific way of learning to match the probability distribution of a teacher model.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The distillation of today is better described generally as synthetic data. You take outputs from a stronger model, usually via an API, and you train your model to predict those. The technical form of knowledge distillation is not actually possible from API models because they don’t expose the right information to the user.
  &lt;/p&gt;
  &lt;p&gt;
   Synthetic data is arguably the single most useful method that an AI researcher today uses to improve the models on a day to day basis. Yes, architecture is crucial, some data still needs exclusively human inputs, and new ideas like reinforcement learning with verifiable rewards at scale can transform the industry, but so much of the day to day life in improving models today is figuring out how to properly capture and scale up synthetic data.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    To flesh out the point from the start of this piece, the argument has repeatedly been that the leading Chinese labs are using distillation for their models to steal  capabilities from the best American API-based counterparts. The most prominent case to date was surrounding the
   &lt;/span&gt;
   &lt;a href=&quot;https://fortune.com/2025/01/29/deepseek-openais-what-is-distillation-david-sacks/&quot; rel=&quot;&quot;&gt;
    release
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;a href=&quot;https://techcrunch.com/2025/01/29/microsoft-probing-whether-deepseek-improperly-used-openais-api/&quot; rel=&quot;&quot;&gt;
    of
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;a href=&quot;https://www.scmp.com/tech/big-tech/article/3296827/deepseeks-ai-distillation-theft-openai-seeks-answers-over-chinas-breakthrough&quot; rel=&quot;&quot;&gt;
    DeepSeek
   &lt;/a&gt;
   &lt;span&gt;
    R1 — where
   &lt;/span&gt;
   &lt;a href=&quot;https://www.bloomberg.com/news/articles/2026-02-12/openai-accuses-deepseek-of-distilling-us-models-to-gain-an-edge&quot; rel=&quot;&quot;&gt;
    OpenAI accused DeepSeek of stealing their reasoning traces
   &lt;/a&gt;
   &lt;span&gt;
    by jailbreaking the API (they’re not exposed by default — for context, a reasoning trace is a colloquial word of art referring to the internal reasoning process, such as what open weight reasoning models expose to the user). Fear of distillation is also likely why Gemini quickly flipped from exposing the reasoning traces to users to hiding them. There was even very prominent, early
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2501.19393&quot; rel=&quot;&quot;&gt;
    reasoning research that built on Gemini
   &lt;/a&gt;
   &lt;span&gt;
    !
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    This all leads us to today’s news, where
   &lt;/span&gt;
   &lt;a href=&quot;https://www.anthropic.com/news/detecting-and-preventing-distillation-attacks&quot; rel=&quot;&quot;&gt;
    Anthropic named and directly accused a series of Chinese labs
   &lt;/a&gt;
   &lt;span&gt;
    for elaborate distillation campaigns on their Claude models. This is a complex issue. In this post we unpack a series of questions, beginning with the impact, and ending with politics. The core question is — how much of a performance benefit do Chinese labs get from distilling from American models.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects AI is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    To start, let’s review what Anthropic shared. From the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.anthropic.com/news/detecting-and-preventing-distillation-attacks&quot; rel=&quot;&quot;&gt;
    blog post
   &lt;/a&gt;
   &lt;span&gt;
    , emphasis mine:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    We have identified industrial-scale campaigns by three AI laboratories—DeepSeek, Moonshot, and MiniMax—to illicitly extract Claude’s capabilities to improve their own models. These labs generated over 16 million exchanges with Claude through approximately 24,000 fraudulent accounts, in violation of our terms of service and regional access restrictions.
   &lt;/p&gt;
   &lt;p&gt;
    &lt;span&gt;
     These labs used a technique called “distillation,” which involves training a less capable model on the outputs of a stronger one.
    &lt;/span&gt;
    &lt;strong&gt;
     Distillation is a widely used and legitimate training method.
    &lt;/strong&gt;
    &lt;span&gt;
     For example, frontier AI labs routinely distill their own models to create smaller, cheaper versions for their customers. But distillation can also be used for illicit purposes: competitors can use it to acquire powerful capabilities from other labs in a fraction of the time, and at a fraction of the cost, that it would take to develop them independently.
    &lt;/span&gt;
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   Much like the models themselves, the benefits of distillation are very jagged. For some capabilities, particularly if you don’t have a full training pipeline setup for it, quickly distilling some data from the leading frontier model in that area can yield massive performance boosts. This can definitely help the lab distilling from the API catch up much more quickly than they otherwise would. Most distillation is rather benign, using many tokens of an LLM to help process and refine existing data — putting a lot of compute into getting a few, high quality training tokens out. This sort of raw data processing work can be done on many different APIs, but one tends to be best.
  &lt;/p&gt;
  &lt;p&gt;
   When we go into what Anthropic says the three Chinese LLM builders actually used the Claude API for — as an aside, Anthropic didn’t confirm that the attack was done through the API, the chat app, or Claude Code — the actual impact of the operations is very mixed. It’s hard to know how much untracked usage these labs deployed for other projects (or other American models).
  &lt;/p&gt;
  &lt;p&gt;
   To start, Anthropic puts DeepSeek first in their blog post because they’re the household name in the US for Chinese AI. The extent of their use is actually quite small, showing how this post is more about the big picture than the details:
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    &lt;strong&gt;
     DeepSeek
    &lt;/strong&gt;
   &lt;/p&gt;
   &lt;p&gt;
    &lt;em&gt;
     Scale: Over 150,000 exchanges
    &lt;/em&gt;
   &lt;/p&gt;
   &lt;p&gt;
    The operation targeted:
   &lt;/p&gt;
   &lt;ul&gt;
    &lt;li&gt;
     &lt;p&gt;
      Reasoning capabilities across diverse tasks
     &lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
     &lt;p&gt;
      Rubric-based grading tasks that made Claude function as a reward model for reinforcement learning
     &lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
     &lt;p&gt;
      Creating censorship-safe alternatives to policy sensitive queries
     &lt;/p&gt;
    &lt;/li&gt;
   &lt;/ul&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   In the scale of training a language model, 150K samples is only scratching the surface as a substantive experiment. It looks like they were experimenting with some rubrics, which could’ve been for an online RL run, but that’s extremely unlikely with how distributed the access was, and then some minor stuff on completions for sensitive queries. This usage of Anthropic’s API will have a negligible impact on DeepSeek’s long-rumored V4 model (or whichever model the data here contributed to). This was also very likely a small team at DeepSeek and unknown to much of the broader training organization.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The other two labs, Moonshot AI (makers of the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/kimi-k2-thinking-what-it-means&quot; rel=&quot;&quot;&gt;
    Kimi
   &lt;/a&gt;
   &lt;span&gt;
    models) and MiniMax reflected much broader usage.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    &lt;strong&gt;
     Moonshot AI
    &lt;/strong&gt;
   &lt;/p&gt;
   &lt;p&gt;
    &lt;em&gt;
     Scale: Over 3.4 million exchanges
    &lt;/em&gt;
   &lt;/p&gt;
   &lt;p&gt;
    The operation targeted:
   &lt;/p&gt;
   &lt;ul&gt;
    &lt;li&gt;
     &lt;p&gt;
      Agentic reasoning and tool use
     &lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
     &lt;p&gt;
      Coding and data analysis
     &lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
     &lt;p&gt;
      Computer-use agent development
     &lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
     &lt;p&gt;
      Computer vision
     &lt;/p&gt;
    &lt;/li&gt;
   &lt;/ul&gt;
   &lt;p&gt;
    &lt;strong&gt;
     MiniMax
    &lt;/strong&gt;
   &lt;/p&gt;
   &lt;p&gt;
    &lt;em&gt;
     Scale: Over 13 million exchanges
    &lt;/em&gt;
   &lt;/p&gt;
   &lt;p&gt;
    The operation targeted:
   &lt;/p&gt;
   &lt;ul&gt;
    &lt;li&gt;
     &lt;p&gt;
      Agentic coding
     &lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
     &lt;p&gt;
      Tool use and orchestration
     &lt;/p&gt;
    &lt;/li&gt;
   &lt;/ul&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   The role of distillation is constantly changing. Distilling from Claude today for its agentic behavior is much more valuable than versions of Claude have been as a teacher in the past. Claude Opus 4.6 has a well-rounded agentic navigation that none of the other models quite match. Why not try training on some of the model outputs to see if your model absorbs it? Over the next few months, that’ll be less differentiated. It’s sort of like how all the models are way better at math today than most people need — there are plenty of places to distill from.
  &lt;/p&gt;
  &lt;p&gt;
   Estimates will vary, but if each response had 10-25K tokens per exchange, the total tokens across these two labs, mostly with MiniMax, would be 150-400 billion tokens. This is a substantial amount, which could meaningfully improve a models’ post-training. For example, in Olmo 3 we had an SFT dataset of 20 billion tokens that could be built like this, and increasing it by 10X would be very reasonable.
  &lt;/p&gt;
  &lt;p&gt;
   These numbers are just scratching the surface of total synthetic data generation across APIs hosted by US companies. At the same time, quantity is a pretty crude way to measure impact. Just taking the outputs from Claude and figuring out how to add them to your model pipeline isn’t easy. The research community has seen many cases where taking outputs from a certain teacher model unexpectedly makes the student worse — subtle interactions between the data make it variable and tricky to do this type of distillation. It’s fundamentally a research problem.
  &lt;/p&gt;
  &lt;p&gt;
   This is what I’m sure the Chinese labs are innovating at. There’s an argument that Chinese frontier labs are substantially more efficient than their Western counterparts — this is misleading.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The labs operate under different constraints. The Chinese labs are likely slightly more efficient out of necessity in being lower on resources, but overall the picture of talent access is very similar. The Chinese labs also approach benchmarks differently, making it appear that they’re a bit closer than they really are (and
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/open-models-in-perpetual-catch-up&quot; rel=&quot;&quot;&gt;
    appearing as if they’re potentially surpassing
   &lt;/a&gt;
   &lt;span&gt;
    ). This is needed to get momentum and brand recognition in the AI market.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The Chinese labs likely innovate greatly on distilling from leading API models, due to their restricted access to GPUs. GPUs could be used to construct synthetic data, but for organizations with more funding than they can spend on research compute (being supply limited), using API-based models is one of the few other options for effectively getting more compute. It’s way easier to figure out getting access to “banned” API models than it is to smuggle tens of thousands of physical GPUs and get them set up.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/how-much-does-distillation-really?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/how-much-does-distillation-really?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    It’s not only the Chinese labs that operate like this. Synthetic data from a model you don’t own is all arguably distillation. Distillation is a shortcut to more compute for anyone. It’s also a far less risky cost, as having a big cluster for research requires a very large financial commitment, where APIs are pay-as-you-go. For example, in
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2512.13961&quot; rel=&quot;&quot;&gt;
    Olmo 3
   &lt;/a&gt;
   &lt;span&gt;
    we used millions of GPU hours on the
   &lt;/span&gt;
   &lt;a href=&quot;https://en.wikipedia.org/wiki/Frontier_(supercomputer)&quot; rel=&quot;&quot;&gt;
    Frontier supercomputer
   &lt;/a&gt;
   &lt;span&gt;
    and Azure credits through
   &lt;/span&gt;
   &lt;a href=&quot;https://nairrpilot.org/&quot; rel=&quot;&quot;&gt;
    NAIRR
   &lt;/a&gt;
   &lt;span&gt;
    for synthetic data. We didn’t have the equivalent in GPUs (or really the cash, thank you research credits!).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    All together, it’s very fair for Anthropic to be concerned about this. I still wouldn’t say it is a
   &lt;/span&gt;
   &lt;em&gt;
    crucial
   &lt;/em&gt;
   &lt;span&gt;
    factor in these Chinese labs post-training capabilities, especially not one that’ll be easy to measure in a time gap to matching the model they’re distilling from a la the US-China performance lag.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    If we take a step back, there was even a time when Claude Sonnet was the flagship model ahead of Opus (I think this was with  Sonnet 3.5), much of this comes from it being
   &lt;/span&gt;
   &lt;em&gt;
    well distilled
   &lt;/em&gt;
   &lt;span&gt;
    internally from Opus checkpoints. Fast iteration and high-quality data can go very far, letting student models surpass the teacher. Frontier labs use this to their advantage, by having internal-only models for generating synthetic data, but saying that Chinese models could never pass the US frontier due to data distillation is like saying that Claude Sonnet could never beat Opus. It&#x27;s unlikely, and it depends a lot on release times, but with AI models making dramatic progress, weirder things like this have already literally happened.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The biggest factor unaddressed here is how distillation from stronger teacher models is harder in an era when reinforcement learning at scale is needed to train the best models. You can spend compute carefully crafting and filtering prompts, but you still need to train the model yourself with substantial, on-policy inference — generation is the majority of the compute cost for RL and it can’t be generations from another model. For this reason, I expected this story to die down a bit. It’s clear from their
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2501.12948&quot; rel=&quot;&quot;&gt;
    open
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2506.13585&quot; rel=&quot;&quot;&gt;
    research
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2507.20534&quot; rel=&quot;&quot;&gt;
    that
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2602.15763&quot; rel=&quot;&quot;&gt;
    Chinese
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2512.02556&quot; rel=&quot;&quot;&gt;
    labs
   &lt;/a&gt;
   &lt;span&gt;
    have excellent RL infrastructure, despite the compute shortages.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The reason I expected it to fade is that not being allowed to distill models for “competitive purposes” has violated the terms of service for API models for quite some time. Academics and open model builders in the US used to greatly worry about and debate this (and I’ve written about it multiple times in
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/ml-moats&quot; rel=&quot;&quot;&gt;
    2022
   &lt;/a&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/llm-synthetic-data&quot; rel=&quot;&quot;&gt;
    2023
   &lt;/a&gt;
   &lt;span&gt;
    ). Only later in 2024 did that worry die down in the community (and no action has been taken against any smaller model builders).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   This action from Anthropic represents another continued step ratcheting up the AI geopolitical tension. Kneecapping model distillation will be far harder than restricting the shipments of physical goods like GPUs. In many ways it seems like fully restricting distillation through distributed access methods seems almost impossible, and restricting GPU sales would be far more impactful.
  &lt;/p&gt;
  &lt;p&gt;
   Anthropic and the AI industry should choose their battles. When API endpoints are available for the best models, other entities will use that to train variants of said model. This is a natural evolution of AI models. If AI models are so precious that distillation is an extreme risk, then the models will be restricted to first-party products. Anthropic has a choice to do this with their latest models. The market for API-based model alternatives may be so competitive that some companies go this path — likely in part due to Chinese models undercutting on price — but an API is a fundamental offering that no leading lab will risk walking back from anytime soon.
  &lt;/p&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Open models in perpetual catch-up </title>
<link>https://www.interconnects.ai/p/open-models-in-perpetual-catch-up</link>
<pubDate>Tue, 17 Feb 2026 17:27:36 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    Every 4-6 months a new open-weights model comes out that causes a clamor of discussion on how open models are closer than they ever have been to the best closed, frontier models. The most recent is Z.ai’s
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/zai-org/GLM-5&quot; rel=&quot;&quot;&gt;
    GLM 5
   &lt;/a&gt;
   &lt;span&gt;
    model, which is the latest, leading open weights model from a Chinese company. In the last 12 months the new part of this story is that all of the open models of discussion are coming from China, where previously they were almost always Meta’s Llamas. These moments of discussion are always reflective for me — for, despite being one of open models’ biggest advocates, I always find the narrative to be overblown — open models are not meaningfully accelerating towards matching the best closed models in absolute performance. The ~6month gap is holding steady.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   At the same time, it’s worth discussing what happens as open models keep getting way better. Open models are staying far closer on the heels of the best closed models than I, and many other experts following the ecosystem, would expect. On paper the top three American labs — in Anthropic, OpenAI, and Google — have vastly more resources at play for training in research. In this world, many would have expected a more obviously growing margin between the best open and closed models. Raw research compute, data purchases, user data, etc. all are providing relatively fine margins. Maybe it’s the scaling laws log-linear relationship from compute to performance coming into play?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The plot of the day is ArtificialAnalysis Intelligence Index for
   &lt;/span&gt;
   &lt;a href=&quot;https://artificialanalysis.ai/models/open-source&quot; rel=&quot;&quot;&gt;
    open vs. closed models over time
   &lt;/a&gt;
   &lt;span&gt;
    . The point of this post isn’t to nitpick this index’s many limitations, or any other, but to reflect on what this chart doesn’t represent and what it means for the AI world for open weights to keep pace year in and year out.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!oyTU!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2cad176-f718-4046-8486-161c1111435e_2680x1366.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!oyTU!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2cad176-f718-4046-8486-161c1111435e_2680x1366.png 424w, https://substackcdn.com/image/fetch/$s_!oyTU!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2cad176-f718-4046-8486-161c1111435e_2680x1366.png 848w, https://substackcdn.com/image/fetch/$s_!oyTU!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2cad176-f718-4046-8486-161c1111435e_2680x1366.png 1272w, https://substackcdn.com/image/fetch/$s_!oyTU!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2cad176-f718-4046-8486-161c1111435e_2680x1366.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c2cad176-f718-4046-8486-161c1111435e_2680x1366.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:742,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:592365,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/188211391?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2cad176-f718-4046-8486-161c1111435e_2680x1366.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;742&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!oyTU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2cad176-f718-4046-8486-161c1111435e_2680x1366.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!oyTU!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2cad176-f718-4046-8486-161c1111435e_2680x1366.png 424w, https://substackcdn.com/image/fetch/$s_!oyTU!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2cad176-f718-4046-8486-161c1111435e_2680x1366.png 848w, https://substackcdn.com/image/fetch/$s_!oyTU!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2cad176-f718-4046-8486-161c1111435e_2680x1366.png 1272w, https://substackcdn.com/image/fetch/$s_!oyTU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc2cad176-f718-4046-8486-161c1111435e_2680x1366.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    The benchmark mixes a ton of factors into 1 score that judges model “quality.” This compresses far too many error bars, stories, and weaknesses into one metric. These metrics will always be used to inform policy and help more people understand the high-level trends of AI, but they do a poor job of capturing the
   &lt;/span&gt;
   &lt;em&gt;
    frontier
   &lt;/em&gt;
   &lt;span&gt;
    of AI progress.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The frontier of AI has
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/opus-46-vs-codex-53&quot; rel=&quot;&quot;&gt;
    never been harder to capture in public benchmarks
   &lt;/a&gt;
   &lt;span&gt;
    . Building benchmarks is now super expensive and requires extreme knowledge regarding the latest models and what they do and do not excel at. Well known issues like SWE-Bench being almost 3/4 Django or Terminal Bench 2 being crowdsourced and a bit noisy will never be captured here.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Time and time again it has been shown that the leading frontier labs in the U.S. have a better read on the capabilities that actually matter, and the public benchmarks tend to be a bit easier to overfit to. Qwen’s recent flagship v3.5 model has been plagued again with numerous complaints of benchmaxing (while some out-of-distribution weirdness is debatably implementation errors, on Alibaba’s own API).
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The combination of all these factors has pushed me to advocate for “no averaging across our evaluation suite” when communicating the value of our latest Olmo models at Ai2 (see my
   &lt;/span&gt;
   &lt;a href=&quot;https://youtu.be/uaZ3yRdYg8A?si=31zxbDFqqqXHwJIR&amp;t=2465&quot; rel=&quot;&quot;&gt;
    recent talk
   &lt;/a&gt;
   &lt;span&gt;
    on evals). The best models are indeed very close together, but averages can totally hide a single eval being dramatically different from an unscrupulous reader.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   All together, I’d bet that the current Artificial Analysis Intelligence Index is a bit unrepresentative of the true frontier, rather than open models being closer to the closed models than ever before (yes, I know, it’s not like I am offering any obvious ways to improve it). The one domain where I foresee open models staying close behind is coding, where public GitHub data and clever verifiable rewards present a ton of potential performance gains.
  &lt;/p&gt;
  &lt;p&gt;
   The overall balance in the ecosystem is in between the value of the most intelligent model — which many people like myself still pay for despite open models’ improvements — and the incredible cost-reductions that come once a given task is achievable by a permissively licensed open model. The best closed models keep unlocking even more valuable tasks, keeping open models in a state of perpetual catch-up. The industry continues to reinvent itself at a blistering pace.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/open-models-in-perpetual-catch-up?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/open-models-in-perpetual-catch-up?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Onto the 7 biggest other trends in open models.
  &lt;/p&gt;
  &lt;h3&gt;
   1. The open model frontier is brutally competitive
  &lt;/h3&gt;
  &lt;p&gt;
   2025 witnessed a sort of “Cambrian Explosion” of open weight models with very impressive benchmark scores. This market is far more populated than closed, API based models (where there are 4 substantive providers), so open model adoption is brutally concentrated. Only the most-successful models ever get any adoption. This is going to push many small and mid-sized model builders across the ecosystem to shift to a specific niche or a different business plan over the coming months or years.
  &lt;/p&gt;
  &lt;p&gt;
   As a model builder, I feel this super close to home. Even though models are fairly sticky (at least more sticky than the general coverage would indicate) — many open models are set up once if performance is good enough, and never replaced – the likelihood for most models to even get tried once goes down month over month with the ecosystem getting more competitive.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    In my
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/8-plots-that-explain-the-state-of&quot; rel=&quot;&quot;&gt;
    post
   &lt;/a&gt;
   &lt;span&gt;
    on the state of open models earlier this year, I even learned that Qwen gets dominated on adoption metrics at the biggest scale of models. This continues to surprise me!
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!L-lz!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a16175-d9e6-4ca9-ae31-46c84f25d693_1872x1156.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!L-lz!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a16175-d9e6-4ca9-ae31-46c84f25d693_1872x1156.png 424w, https://substackcdn.com/image/fetch/$s_!L-lz!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a16175-d9e6-4ca9-ae31-46c84f25d693_1872x1156.png 848w, https://substackcdn.com/image/fetch/$s_!L-lz!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a16175-d9e6-4ca9-ae31-46c84f25d693_1872x1156.png 1272w, https://substackcdn.com/image/fetch/$s_!L-lz!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a16175-d9e6-4ca9-ae31-46c84f25d693_1872x1156.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/26a16175-d9e6-4ca9-ae31-46c84f25d693_1872x1156.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:899,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;899&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!L-lz!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a16175-d9e6-4ca9-ae31-46c84f25d693_1872x1156.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!L-lz!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a16175-d9e6-4ca9-ae31-46c84f25d693_1872x1156.png 424w, https://substackcdn.com/image/fetch/$s_!L-lz!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a16175-d9e6-4ca9-ae31-46c84f25d693_1872x1156.png 848w, https://substackcdn.com/image/fetch/$s_!L-lz!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a16175-d9e6-4ca9-ae31-46c84f25d693_1872x1156.png 1272w, https://substackcdn.com/image/fetch/$s_!L-lz!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a16175-d9e6-4ca9-ae31-46c84f25d693_1872x1156.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   The upshot is that competition at the frontier of performance for models is most concentrated in the popular benchmarks of the day, especially with large MoE models — this will drive exploration and innovation towards other cases where open models can actually win on overall business value.
  &lt;/p&gt;
  &lt;h3&gt;
   2. Specialized, small, fast, and cheap open models are missing
  &lt;/h3&gt;
  &lt;p&gt;
   There’s a large underserved market in specialized models for the enterprise, particularly with tools (maybe GPT OSS’s success is somewhat related to this). Generally, the idea would be to either release the weights, or the method for creating them, that are excellent in valuable, repetitive tasks. With agents becoming more prominent, these models should be able to perform repetitive, agent sub-tasks at small percentages of the cost of large frontier models, while being faster, private, and directly owned. For example, what if one open weight model is deployed with multiple PEFT-adapters per skill, allowing high-utilization and extensibility.
  &lt;/p&gt;
  &lt;p&gt;
   I’ve specifically heard this request from multiple enterprises building agents. While the Qwen models are fantastic at small sizes, open models tend to be very jagged in performance, so multiple options would likely be needed to get this off the ground. It’s also limited by a general lack of frontier-quality, post-training recipes, especially when it comes to adapting a model to specific domain or set of tasks not covered in academic benchmarks. In this view, most of the domain-specific models of today, like math or biology models, are actually not specialized enough.
  &lt;/p&gt;
  &lt;p&gt;
   This is one of many issues that I see repeatedly in how the open model ecosystem has major blind spots. The biggest reason that the open model ecosystem seems a bit misunderstood externally, or confused in itself, is that open models take a long time to figure out and get into the world.
  &lt;/p&gt;
  &lt;h3&gt;
   3. Understanding open models is massively under-indexed on
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;span&gt;
    There should be more research organizations fully dedicated to understanding how open models work technically and geopolitically. There could be entire think-tanks in DC informing the public on what is happening, and uncovering information buried in hackathons and new research labs in San Francisco. For Interconnects and
   &lt;/span&gt;
   &lt;a href=&quot;https://atomproject.ai/&quot; rel=&quot;&quot;&gt;
    The ATOM Project
   &lt;/a&gt;
   &lt;span&gt;
    I’m at the frontier of this work, which often entails
   &lt;/span&gt;
   &lt;em&gt;
    uncovering new raw data
   &lt;/em&gt;
   &lt;span&gt;
    on how open models are used. This data is always messy and imperfect, and often flat out confusing. Understanding open models is how we keep track of the direction of global diffusion for the most important technology in decades, and it feels like there is almost no public work doing so.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Here’s some new data on open model
   &lt;/span&gt;
   &lt;em&gt;
    usage
   &lt;/em&gt;
   &lt;span&gt;
    courtesy of
   &lt;/span&gt;
   &lt;a href=&quot;http://openrouter.ai/&quot; rel=&quot;&quot;&gt;
    OpenRouter
   &lt;/a&gt;
   &lt;span&gt;
    , which largely mirrors the adoption trends we’ve been seeing. While HuggingFace downloads are obviously very noisy, almost every other adoption metric over time looks strongly correlated with them, especially on U.S. vs. China issues.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!P0Nw!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2b13721-7a67-46c9-b83f-1ea16f4cff7c_1806x1218.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!P0Nw!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2b13721-7a67-46c9-b83f-1ea16f4cff7c_1806x1218.jpeg 424w, https://substackcdn.com/image/fetch/$s_!P0Nw!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2b13721-7a67-46c9-b83f-1ea16f4cff7c_1806x1218.jpeg 848w, https://substackcdn.com/image/fetch/$s_!P0Nw!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2b13721-7a67-46c9-b83f-1ea16f4cff7c_1806x1218.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!P0Nw!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2b13721-7a67-46c9-b83f-1ea16f4cff7c_1806x1218.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;Image&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d2b13721-7a67-46c9-b83f-1ea16f4cff7c_1806x1218.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:982,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;982&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!P0Nw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2b13721-7a67-46c9-b83f-1ea16f4cff7c_1806x1218.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!P0Nw!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2b13721-7a67-46c9-b83f-1ea16f4cff7c_1806x1218.jpeg 424w, https://substackcdn.com/image/fetch/$s_!P0Nw!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2b13721-7a67-46c9-b83f-1ea16f4cff7c_1806x1218.jpeg 848w, https://substackcdn.com/image/fetch/$s_!P0Nw!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2b13721-7a67-46c9-b83f-1ea16f4cff7c_1806x1218.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!P0Nw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2b13721-7a67-46c9-b83f-1ea16f4cff7c_1806x1218.jpeg 1456w&quot; title=&quot;Image&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;em&gt;
    As an aside, if this work monitoring the open ecosystem sounds appealing to you, please reach out or leave a comment — I’m thinking about how to scale up our impact in this area!
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects AI is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;h3&gt;
   4. Nations will turn to open models as the only way to get an initial foothold in sovereign AI (and sovereign AI is the real deal)
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;span&gt;
    Sovereign AI has largely been unfolding slowly in the background of frontier AI discussions and the U.S.-China arms race, but it’ll only become more prevalent as AI becomes more deeply embedded in our technological
   &lt;/span&gt;
   &lt;em&gt;
    reality
   &lt;/em&gt;
   &lt;span&gt;
    . Every wealthy nation will see AI as a direction for influence in addition to a necessity for national security. Open models will likely be the only way to get this off the ground as a real effort, in order to have the local AI community and economy seamlessly integrate with it.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   5. Futures where open-source wins the frontier are still possible, but seemingly less likely
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;span&gt;
    The most likely (by far) outcome is for the status quo to continue and for the best open models to lag the best closed models by 6-9months. A large portion of the perpetual catch-up is likely due to the best open model builders constantly distilling their models on the strongest, currently available closed API models, but this direction seems less relevant with the rise of RL. Post-training today is more about the model undergoing
   &lt;/span&gt;
   &lt;em&gt;
    experience
   &lt;/em&gt;
   &lt;span&gt;
    rather than directly learning from the smartest teacher you can find. The paths to open models winning come through fundamental innovation. This looks like the ability to merge, rotate, and share expert models, a dramatic (100X+) cost reduction in the cost of training, etc. Predicting this before it happens is more of a sci-fi story than a faithful science, as then I’d just go build the damn thing.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/open-models-in-perpetual-catch-up?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/open-models-in-perpetual-catch-up?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   6. China’s open model “ecosystem” makes it the most likely place for a discovery around who wins
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;span&gt;
    China has
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/2025-open-models-year-in-review&quot; rel=&quot;&quot;&gt;
    many labs
   &lt;/a&gt;
   &lt;span&gt;
    building models on top of their peers’ innovations. This intentional sharing of ideas provides immense benefits relative to Silicon Valley’s quid pro quo where it’s accepted that people go home at the end of their day and chat with some of their friends on the latest technical secrets of their models. The sort of sharing the Chinese companies do, especially considering more of them have closer ties to the nation’s scientific and academic institutions, is the sort of setup that lets new standards converge much faster and breakthroughs be shared. This is another unknown factor, like potential innovation where open models “win,” but it’s important because China has created their own conditions of potential, massive success, and the U.S. has no answer. This divergence in how the ecosystems operate could be nothing in the long-term, but U.S. AI companies cannot do much to compete with it if it takes off.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   7. Open models dictate science and diffusion — slower trends than the frontier of AI
  &lt;/h3&gt;
  &lt;p&gt;
   The biggest impact in AI in terms of transforming day to day life, and even the world’s power structures, will obviously come from the most powerful and intelligent models. It is fairly obvious then that the open models that end up in closest proximity to this capture the headlines — if an open-weights model does, somehow, happen to claim that title as “the world’s most powerful model,” there will be extreme economic consequences.
  &lt;/p&gt;
  &lt;p&gt;
   In the real world, the one with the highest probability of occurring, open models’ biggest influence will be in two, very slow-moving sectors: 1) fundamental research/innovation and 2) global technological diffusion. I’ve personally realized how much of the excitement I can have for open models is a bit misguided — I’m trying to understand the frontier of AI through the lens of these models, missing the bigger story in how technology slowly reshapes the world’s biggest companies.
  &lt;/p&gt;
  &lt;p&gt;
   Consider when Llama was the open SOTA model, everyone in the U.S. and China did science on Llama, which then impacted subsequent models — even if we didn’t hear directly from Meta on how-so. Now this default is Qwen. Qwen is the anchor of the Chinese ecosystem. Language model research is proceeding extremely fast, which could make the fundamental improvements made in research labs impact the frontier of the technology much faster than usual.
  &lt;/p&gt;
  &lt;p&gt;
   At the same time, the global default for using AI outside of the wealthiest few nations will be to use either free applications like ChatGPT or open weight models. ChatGPT doesn’t fit a lot of business use-cases, so open weight models are a melting pot for innovation that we largely have no visibility into. When we zoom out to a timeline closer to decades, open model’s global adoption seems like a top trend to follow in AI.
  &lt;/p&gt;
  &lt;h2&gt;
   Conclusion
  &lt;/h2&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Opus 4.6 vs. Codex 5.3 </title>
<link>https://www.interconnects.ai/p/opus-46-vs-codex-53</link>
<pubDate>Mon, 09 Feb 2026 14:03:12 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    Last Thursday, February 5th, both OpenAI and Anthropic unveiled the next iterations of their models designed as coding assistants,
   &lt;/span&gt;
   &lt;a href=&quot;https://openai.com/index/introducing-gpt-5-3-codex/&quot; rel=&quot;&quot;&gt;
    GPT-5.3-Codex
   &lt;/a&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;a href=&quot;https://www.anthropic.com/news/claude-opus-4-6&quot; rel=&quot;&quot;&gt;
    Claude Opus 4.6
   &lt;/a&gt;
   &lt;span&gt;
    , respectively. Ahead of this, Anthropic had a firm grasp of the mindshare as everyone collectively
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/get-good-at-agents&quot; rel=&quot;&quot;&gt;
    grappled with the new world of agents
   &lt;/a&gt;
   &lt;span&gt;
    , primarily driven by a
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/claude-code-hits-different&quot; rel=&quot;&quot;&gt;
    Claude Code with Opus 4.5
   &lt;/a&gt;
   &lt;span&gt;
    -induced step change in performance. This post doesn’t unpack how software is changing forever,
   &lt;/span&gt;
   &lt;a href=&quot;https://thezvi.substack.com/p/welcome-to-moltbook&quot; rel=&quot;&quot;&gt;
    Moltbook
   &lt;/a&gt;
   &lt;span&gt;
    is showcasing the future, ML research is accelerating, and the many broader implications, but rather how to assess, live with, and prepare for new models. The fine margins between Opus 4.6 and Codex 5.3 will be felt in many model versions this year, with Opus ahead in this matchup on usability.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/opus-46-vs-codex-53?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/opus-46-vs-codex-53?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Going into these releases I’d been using Claude Code extensively as a general computer agent, with some software engineering and a lot of data analysis, automation, etc. I had dabbled with Codex 5.2 (usually on xhigh, maximum thinking effort), but found it not to quite work for me among my broad, horizontal set of tasks.
  &lt;/p&gt;
  &lt;p&gt;
   For the last few days, I’ve been using both of the models much more evenly. I mean this as a great compliment, but Codex 5.3 feels much more Claude-like, where it’s much faster in its feedback and much more capable in a broad suite of tasks from git to data analysis (previous versions of Codex, including up to 5.2, regularly failed basic git operations like creating a fresh branch). Codex 5.3 takes a very important step towards Claude’s territory by having better product-market fit. This is a very important move for OpenAI and between the two models, Codex 5.3 feels far more different than its predecessors.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    OpenAI’s latest GPT, with this context, keeps an edge as a better
   &lt;/span&gt;
   &lt;em&gt;
    coding model
   &lt;/em&gt;
   &lt;span&gt;
    . It’s hard to describe this general statement precisely, and a lot of it is based on reading others’ work, but it seems to be a bit better at finding bugs and fixing things in codebases, such as the
   &lt;/span&gt;
   &lt;a href=&quot;https://github.com/natolambert/rlhf-book/pull/243&quot; rel=&quot;&quot;&gt;
    minimal algorithmic examples
   &lt;/a&gt;
   &lt;span&gt;
    for my RLHF Book. In my experience, this is a minor edge, and the community thinks that this is most apparent in complex situations (i.e. not most vibe-coded apps).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   As users become better at supervising these new agents, having the best top-end ability in software understanding and creation could become a meaningful edge for Codex 5.3, but it is not an obvious advantage today. Many of my most trusted friends in the AI space swear by Codex because it can be just this tiny bit better. I haven’t been able to unlock it.
  &lt;/p&gt;
  &lt;p&gt;
   Switching from Opus 4.6 to Codex 5.3 feels like I need to babysit the model in terms of more detailed descriptions when doing somewhat mundane tasks like “clean up this branch and push the PR.” I can trust Claude to understand the context of the fix and generally get it right, where Codex can skip files, put stuff in weird places, etc.
  &lt;/p&gt;
  &lt;p&gt;
   Both of these releases feel like the companies pushing for capabilities and speed of execution in the models, but at the cost of some ease of use. I’ve found both Opus 4.6 and Codex 5.3 ignoring an instruction if I queue up multiple things to do — they’re really best when given well-scoped, clear problems (especially Codex). Claude Code’s harness has a terrible bug that makes subagents brick the terminal, where new messages say you must compact or clear, but compaction fails.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Despite the massive step by Codex, they still have a large gap to close to Claude on the product side. Opus 4.6 is another step in the right direction, where Claude Code feels like a great experience. It’s approachable, it tends to work in the wide range of tasks I throw at it, and this’ll help them gain much broader adoption than Codex. If I’m going to recommend a coding agent to an audience who has limited-to-no software experience, it’s certainly going to be Claude. At a time when agents are just emerging into general use, this is a massive advantage, both in mindshare and feedback in terms of usage data.
   &lt;/span&gt;
   &lt;span data-state=&quot;closed&quot;&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/opus-46-vs-codex-53#footnote-1-187332712&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     1
    &lt;/a&gt;
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    In the meantime, there’s no cut-and-dried guideline on which agent you need to use for any use-case, you need to
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/use-multiple-models&quot; rel=&quot;&quot;&gt;
    use multiple models
   &lt;/a&gt;
   &lt;span&gt;
    all the time and keep up with the skill that is managing agents.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects AI is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   Assessing models in 2026
  &lt;/h2&gt;
  &lt;p&gt;
   There have been many hints through 2025 that we were heading toward an AI world where benchmarks associated with model releases no longer convey meaningful signal to users. Back in the time of the GPT-4 or Gemini 2.5 Pro releases, the benchmark deltas could be easily felt within the chatbot form factor of the day — models were more reliable, could do more tasks, etc. This continued through models like OpenAI’s o3. During this phase of AI’s buildout, roughly from 2023 to 2025, we were assembling the core functionality of modern language models: tool-use, extended reasoning, basic scaling, etc. The gains were obvious.
  &lt;/p&gt;
  &lt;p&gt;
   It should be clear with the releases of both Opus 4.6 and Codex 5.3 that benchmark-based release reactions barely matter. For this release, I barely looked at the evaluation scores. I saw that Opus 4.6 had a bit better search scores and Codex 5.3 used far fewer tokens per answer, but neither of these were going to make me sure they were much better models.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Each of the AI laboratories, and the media ecosystems covering them, have been on this transition away from standard evaluations at their own pace. The most telling example is the Gemini 3 Pro release in November of 2025. The collective vibe was Google is back in the lead. Kevin Roose, self-proclaimed “
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/kevinroose/status/1900535165874827379&quot; rel=&quot;&quot;&gt;
    AGI-pilled
   &lt;/a&gt;
   &lt;span&gt;
    ” NYTimes reporter in SF
   &lt;/span&gt;
   &lt;a href=&quot;https://www.infoq.com/news/2025/11/google-gemini-3/&quot; rel=&quot;&quot;&gt;
    said
   &lt;/a&gt;
   &lt;span&gt;
    :
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    &lt;span&gt;
     There&#x27;s sort of this feeling that Google, which kind of struggled in AI for a couple of years there — they had the launch of Bard and the first versions of Gemini, which had some issues — and I think they were seen as sort of catching up to the state of the art. And now the question is:
    &lt;/span&gt;
    &lt;strong&gt;
     is this them taking their crown back?
    &lt;/strong&gt;
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   We don’t need to dwell on the depths of Gemini’s current crisis, but they have effectively no impact at the frontier of coding agents, which as an area feels the most likely for dramatic strides in performance — dare I say, even many commonly accepted definitions of AGI that center around the notion of a “remote worker?” The timeline has left them behind 2 months after their coronation, showing Gemini 3 was hailed as a false king.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    On the other end of the spectrum is Anthropic. With Anthropic’s release of Claude 4 in May of 2025, I was
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/claude-4-and-anthropics-bet-on-code&quot; rel=&quot;&quot;&gt;
    skeptical of their bet on code
   &lt;/a&gt;
   &lt;span&gt;
    — I was distracted by the glitz of OpenAI and Gemini trading blows with announcements like models achieving
   &lt;/span&gt;
   &lt;a href=&quot;https://deepmind.google/blog/advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad/&quot; rel=&quot;&quot;&gt;
    IMO Gold medals
   &lt;/a&gt;
   &lt;span&gt;
    in mathematics or other evaluation breakthroughs.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Anthropic deserves serious credit for the focus of its vision. They were likely not the only AI lab to note the coming role of agents, but they were by far the first to shift their messaging and prioritization towards this. In my
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/summertime-outlook-o3s-novelty-coming&quot; rel=&quot;&quot;&gt;
    post in June of 2025
   &lt;/a&gt;
   &lt;span&gt;
    , a month after Claude 4 was released, I was coming around to them being right to deprioritize standard benchmarks:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    &lt;span&gt;
     This is a different path for the industry and will take a different form of messaging than we’re used to. More releases are going to look like
    &lt;/span&gt;
    &lt;a href=&quot;https://www.interconnects.ai/p/claude-4-and-anthropics-bet-on-code&quot; rel=&quot;&quot;&gt;
     Anthropic’s Claude 4
    &lt;/a&gt;
    &lt;span&gt;
     , where the benchmark gains are minor and the real world gains are a big step. There are plenty of more implications for policy, evaluation, and transparency that come with this. It is going to take much more nuance to understand if the pace of progress is continuing, especially as critics of AI are going to seize the opportunity of evaluations flatlining to say that AI is no longer working.
    &lt;/span&gt;
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   This leaves me reflecting on the role of Interconnects’ model reviews in 2026. 2025 was characterized by many dramatic, day-of model release blog posts, with the entry of many new Chinese open model builders, OpenAI’s first open language model since GPT-2, and of course the infinitely hyped GPT-5. These timely release posts still have great value — they center the conversation around the current snapshot of a company vis-a-vis the broader industry, but if models remain similar, they’ll do little to disentangle the complexity in mapping the current frontier of AI.
  &lt;/p&gt;
  &lt;p&gt;
   In order to serve my role as an independent voice tracking the frontier models, I need to keep providing regular updates on how I’m using models, why, and why not. Over time, the industry is going to develop better ways of articulating the differences in agentic models. For the next few months, maybe even years, I expect the pace of progress to be so fast and uneven in agentic capabilities, that consistent testing and clear articulation will be the only way to monitor it.
  &lt;/p&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/opus-46-vs-codex-53#footnote-anchor-1-187332712&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     &lt;span&gt;
      The emerging frontier of coding agents is in the use of subagents (or “
     &lt;/span&gt;
     &lt;a href=&quot;https://code.claude.com/docs/en/agent-teams&quot; rel=&quot;&quot;&gt;
      agent teams
     &lt;/a&gt;
     &lt;span&gt;
      ”, which are subagents that can work together), where the primary orchestration agent sends off copies of itself to work on pieces of the problem. Claude is slightly ahead here with more polished features, but the space will evolve quickly, and maybe OpenAI can take their experiences with products like GPT-Pro to make a Pro agent.
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;p&gt;
     The GPT-Pro line of models is a major advantage OpenAI has over Anthropic. I use them all the time. As we learn to use these agents for more complex, long-term tasks, harnessing more compute on a single problem will be a crucial differentiator.
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Why Nvidia builds open models with Bryan Catanzaro </title>
<link>https://www.interconnects.ai/p/why-nvidia-builds-open-models-with</link>
<pubDate>Wed, 04 Feb 2026 18:00:28 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   One of the big stories of 2025 for me was how Nvidia massively stepped up their open model program — more releases, higher quality models, joining a small handful of companies releasing datasets, etc. In this interview, I sat down with one of the 3 VP’s leading the effort of 500+ technical staff, Bryan Catanzaro, to discuss:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     Their very impressive Nemotron 3 Nano model released in Dec. 2025, and the bigger Super and Ultra variants coming soon,
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Why Nvidia’s business clearly benefits from them building open models,
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     How the Nemotron team culture was crafted in pursuit of better models,
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Megatron-LM and the current state of open-source training software,
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Career reflections and paths into AI research,
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     And other topics.
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   The biggest takeaway I had from this interview is how Nvidia understands their unique roll as a company that and both build and directly capture the value they get from building open language models, giving them a uniquely sustainable advantage.
  &lt;/p&gt;
  &lt;p&gt;
   Bryan has a beautiful analogy for open models this early in AI’s development, and how they are a process of creating “potential energy” for AI’s future applications.
  &lt;/p&gt;
  &lt;p&gt;
   I hope you enjoy it!
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/why-nvidia-builds-open-models-with?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/why-nvidia-builds-open-models-with?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Guest:
   &lt;/span&gt;
   &lt;strong&gt;
    Bryan Catanzaro
   &lt;/strong&gt;
   &lt;span&gt;
    , VP Applied Deep Learning Research (ADLR), NVIDIA. X:
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/ctnzr&quot; rel=&quot;&quot;&gt;
    @ctnzr
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.linkedin.com/in/bryancatanzaro/&quot; rel=&quot;&quot;&gt;
    LinkedIn
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://scholar.google.com/citations?user=UZ6kI2AAAAAJ&quot; rel=&quot;&quot;&gt;
    Google Scholar
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Listen on
   &lt;/span&gt;
   &lt;a href=&quot;https://podcasts.apple.com/us/podcast/interconnects-audio/id1719552353&quot; rel=&quot;&quot;&gt;
    Apple Podcasts
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://open.spotify.com/show/6XNzfJULeVxR7SneeesDUs&quot; rel=&quot;&quot;&gt;
    Spotify
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.youtube.com/@interconnects&quot; rel=&quot;&quot;&gt;
    YouTube
   &lt;/a&gt;
   &lt;span&gt;
    , and
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/podcast&quot; rel=&quot;&quot;&gt;
    where ever you get your podcasts
   &lt;/a&gt;
   &lt;span&gt;
    . For other Interconnects interviews,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/t/interviews&quot; rel=&quot;&quot;&gt;
    go here
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div data-attrs=&#x27;{&quot;videoId&quot;:&quot;Y3Vb6ecvfpU&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}&#x27; data-component-name=&quot;Youtube2ToDOM&quot;&gt;
   &lt;div&gt;
    &lt;iframe allow=&quot;autoplay; fullscreen&quot; allowautoplay=&quot;true&quot; allowfullscreen=&quot;true&quot; frameborder=&quot;0&quot; gesture=&quot;media&quot; height=&quot;409&quot; loading=&quot;lazy&quot; src=&quot;https://www.youtube-nocookie.com/embed/Y3Vb6ecvfpU?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0&quot; width=&quot;728&quot;&gt;
    &lt;/iframe&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;h3&gt;
   Nemotron Model Timeline
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;strong&gt;
    2019–2022 — Foundational Work
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://arxiv.org/abs/1909.08053&quot; rel=&quot;&quot;&gt;
      Megatron-LM
     &lt;/a&gt;
     &lt;span&gt;
      (model parallelism framework that has become very popular again recently; alternatives:
     &lt;/span&gt;
     &lt;a href=&quot;https://github.com/deepspeedai/DeepSpeed&quot; rel=&quot;&quot;&gt;
      DeepSpeed
     &lt;/a&gt;
     &lt;span&gt;
      , PyTorch FSDP).
     &lt;/span&gt;
     &lt;a href=&quot;https://github.com/NVIDIA/NeMo&quot; rel=&quot;&quot;&gt;
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://github.com/NVIDIA/NeMo&quot; rel=&quot;&quot;&gt;
      NeMo Framework
     &lt;/a&gt;
     &lt;span&gt;
      (NVIDIA’s end-to-end LLM stack: training recipes, data pipelines, evaluation, deployment).
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nov 2023 — Nemotron-3 8B:
   &lt;/strong&gt;
   &lt;span&gt;
    Enterprise-ready NeMo models
   &lt;/span&gt;
   &lt;em&gt;
    .
   &lt;/em&gt;
   &lt;span&gt;
    Models:
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/nvidia/nemotron-3-8b-base-4k&quot; rel=&quot;&quot;&gt;
    base
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/nvidia/nemotron-3-8b-chat-4k-sft&quot; rel=&quot;&quot;&gt;
    chat-sft
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/nvidia/nemotron-3-8b-chat-4k-rlhf&quot; rel=&quot;&quot;&gt;
    chat-rlhf
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/collections/nvidia/nemotron-3-8b&quot; rel=&quot;&quot;&gt;
    collection
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
   &lt;a href=&quot;https://developer.nvidia.com/blog/nvidia-ai-foundation-models-build-custom-enterprise-chatbots-and-co-pilots-with-production-ready-llms/&quot; rel=&quot;&quot;&gt;
    Blog
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Feb 2024 — Nemotron-4 15B:
   &lt;/strong&gt;
   &lt;span&gt;
    Multilingual LLM trained to 8T tokens.
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2402.16819&quot; rel=&quot;&quot;&gt;
    Paper
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Jun 2024 — Nemotron-4 340B:
   &lt;/strong&gt;
   &lt;span&gt;
    Major open release detailing their synthetic data pipeline.
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2406.11704&quot; rel=&quot;&quot;&gt;
    Paper
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://blogs.nvidia.com/blog/nemotron-4-synthetic-data-generation-llm-training/&quot; rel=&quot;&quot;&gt;
    blog
   &lt;/a&gt;
   &lt;span&gt;
    . Models:
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/nvidia/Nemotron-4-340B-Instruct&quot; rel=&quot;&quot;&gt;
    Instruct
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/nemotron-4-340b-reward&quot; rel=&quot;&quot;&gt;
    Reward
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Jul–Sep 2024 — Minitron / Nemotron-Mini:
   &lt;/strong&gt;
   &lt;span&gt;
    First of their pruned models, pruned from 15B
   &lt;/span&gt;
   &lt;em&gt;
    .
   &lt;/em&gt;
   &lt;a href=&quot;https://huggingface.co/nvidia/Minitron-4B-Base&quot; rel=&quot;&quot;&gt;
    Minitron-4B
   &lt;/a&gt;
   &lt;span&gt;
    (base model),
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/nvidia/Nemotron-Mini-4B-Instruct&quot; rel=&quot;&quot;&gt;
    Nemotron-Mini-4B-Instruct
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2407.14679&quot; rel=&quot;&quot;&gt;
    Paper
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://github.com/NVlabs/Minitron&quot; rel=&quot;&quot;&gt;
    code
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Oct 2024 — Llama-3.1-Nemotron-70B:
   &lt;/strong&gt;
   &lt;span&gt;
    Strong post-training on Llama 3.1 70B.
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Instruct-HF&quot; rel=&quot;&quot;&gt;
    Model
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/collections/nvidia/llama-31-nemotron-70b&quot; rel=&quot;&quot;&gt;
    collection
   &lt;/a&gt;
   &lt;span&gt;
    . Key dataset —
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/datasets/nvidia/HelpSteer2&quot; rel=&quot;&quot;&gt;
    HelpSteer2
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2410.01257&quot; rel=&quot;&quot;&gt;
    paper
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Mar–Jun 2025 — Nemotron-H:
   &lt;/strong&gt;
   &lt;span&gt;
    First hybrid Mamba-Transformer models for inference efficiency
   &lt;/span&gt;
   &lt;em&gt;
    .
   &lt;/em&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2504.03624&quot; rel=&quot;&quot;&gt;
    Paper
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://research.nvidia.com/labs/adlr/nemotronh/&quot; rel=&quot;&quot;&gt;
    research page
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://developer.nvidia.com/blog/nemotron-h-reasoning-enabling-throughput-gains-with-no-compromises/&quot; rel=&quot;&quot;&gt;
    blog
   &lt;/a&gt;
   &lt;span&gt;
    . Models:
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/nvidia/Nemotron-H-8B-Base-8K&quot; rel=&quot;&quot;&gt;
    8B
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/nvidia/Nemotron-H-47B-Base-8K&quot; rel=&quot;&quot;&gt;
    47B
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/nvidia/Nemotron-H-4B-Instruct-128K&quot; rel=&quot;&quot;&gt;
    4B-128K
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    May 2025 — Llama-Nemotron:
   &lt;/strong&gt;
   &lt;span&gt;
    Efficient reasoning models built ontop of Llama (
   &lt;/span&gt;
   &lt;em&gt;
    still!).
   &lt;/em&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2505.00949&quot; rel=&quot;&quot;&gt;
    Paper
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Sep 2025 — Nemotron Nano 2:
   &lt;/strong&gt;
   &lt;span&gt;
    9B hybrid for reasoning, continuing to improve in performance
   &lt;/span&gt;
   &lt;em&gt;
    .
   &lt;/em&gt;
   &lt;span&gt;
    12B base on 20T tokens (FP8 training) pruned to 9B for post-training.
   &lt;/span&gt;
   &lt;a href=&quot;https://research.nvidia.com/labs/adlr/files/NVIDIA-Nemotron-Nano-2-Technical-Report.pdf&quot; rel=&quot;&quot;&gt;
    Report
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/collections/nvidia/nvidia-nemotron-v2&quot; rel=&quot;&quot;&gt;
    V2 collection
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nov 2025 — Nemotron Nano V2 VL:
   &lt;/strong&gt;
   &lt;span&gt;
    12B VLM
   &lt;/span&gt;
   &lt;em&gt;
    .
   &lt;/em&gt;
   &lt;a href=&quot;https://research.nvidia.com/labs/adlr/files/NVIDIA-Nemotron-Nano-V2-VL-report.pdf&quot; rel=&quot;&quot;&gt;
    Report
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dec 2025 — Nemotron 3:
   &lt;/strong&gt;
   &lt;span&gt;
    Nano/Super/Ultra family, hybrid MoE, up to 1M context. Super/Ultra H1 2026.
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    Nano: 25T tokens, 31.6B total / ~3.2B active, releases recipes + code + datasets.
   &lt;/span&gt;
   &lt;a href=&quot;https://nvidianews.nvidia.com/news/nvidia-debuts-nemotron-3-family-of-open-models&quot; rel=&quot;&quot;&gt;
   &lt;/a&gt;
   &lt;span&gt;
    Papers:
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2512.20856&quot; rel=&quot;&quot;&gt;
    White Paper
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2512.20848&quot; rel=&quot;&quot;&gt;
    Technical Report
   &lt;/a&gt;
   &lt;span&gt;
    . Models:
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16&quot; rel=&quot;&quot;&gt;
    Nano-30B-BF16
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-Base-BF16&quot; rel=&quot;&quot;&gt;
    Base
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-FP8&quot; rel=&quot;&quot;&gt;
    FP8
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   Nemotron’s Recent Datasets
  &lt;/h3&gt;
  &lt;p&gt;
   NVIDIA began releasing substantially more data in 2025, including pretraining datasets — making them one of few organizations releasing high-quality pretraining data at scale (which comes with non-negligible legal risk).
  &lt;/p&gt;
  &lt;h4&gt;
   Pretraining Data
  &lt;/h4&gt;
  &lt;p&gt;
   &lt;a href=&quot;https://huggingface.co/collections/nvidia/nemotron-pre-training-datasets&quot; rel=&quot;&quot;&gt;
    Collection
   &lt;/a&gt;
   &lt;span&gt;
    —
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/datasets/nvidia/Nemotron-CC-v2&quot; rel=&quot;&quot;&gt;
    CC-v2
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/datasets/nvidia/Nemotron-CC-v2.1&quot; rel=&quot;&quot;&gt;
    CC-v2.1
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/datasets/nvidia/Nemotron-CC-Code-v1&quot; rel=&quot;&quot;&gt;
    CC-Code-v1
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/datasets/nvidia/Nemotron-Pretraining-Code-v2&quot; rel=&quot;&quot;&gt;
    Code-v2
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/datasets/nvidia/Nemotron-Pretraining-Specialized-v1&quot; rel=&quot;&quot;&gt;
    Specialized-v1
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/datasets/nvidia/Nemotron-CC-Math-v1&quot; rel=&quot;&quot;&gt;
    CC-Math-v1
   &lt;/a&gt;
   &lt;span&gt;
    . Math paper:
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2508.15096&quot; rel=&quot;&quot;&gt;
    arXiv:2508.15096
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h4&gt;
   Post-Training Data
  &lt;/h4&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Core post-training dumps (SFT/RL blends):
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://huggingface.co/datasets/nvidia/Llama-Nemotron-Post-Training-Dataset&quot; rel=&quot;&quot;&gt;
      Llama Nemotron Post-Training v1.1
     &lt;/a&gt;
     &lt;span&gt;
      (Apr 2025)
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://huggingface.co/datasets/nvidia/Nemotron-Post-Training-Dataset-v1&quot; rel=&quot;&quot;&gt;
      Nemotron Post-Training v1
     &lt;/a&gt;
     &lt;span&gt;
      (Jul 2025)
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://huggingface.co/datasets/nvidia/Nemotron-Post-Training-Dataset-v2&quot; rel=&quot;&quot;&gt;
      Nemotron Post-Training v2
     &lt;/a&gt;
     &lt;span&gt;
      (Aug 2025)
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   &lt;strong&gt;
    2025 reasoning/code SFT corpora:
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://huggingface.co/datasets/nvidia/OpenMathReasoning&quot; rel=&quot;&quot;&gt;
      OpenMathReasoning
     &lt;/a&gt;
     &lt;span&gt;
      (Apr 2025)
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://huggingface.co/datasets/nvidia/OpenCodeReasoning&quot; rel=&quot;&quot;&gt;
      OpenCodeReasoning
     &lt;/a&gt;
     &lt;span&gt;
      (Apr 2025),
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/datasets/nvidia/OpenCodeReasoning-2&quot; rel=&quot;&quot;&gt;
      OpenCodeReasoning-2
     &lt;/a&gt;
     &lt;span&gt;
      (May 2025)
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://huggingface.co/datasets/nvidia/AceReason-1.1-SFT&quot; rel=&quot;&quot;&gt;
      AceReason-1.1-SFT
     &lt;/a&gt;
     &lt;span&gt;
      (Jun 2025)
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://huggingface.co/datasets/nvidia/Nemotron-Math-HumanReasoning&quot; rel=&quot;&quot;&gt;
      Nemotron-Math-HumanReasoning
     &lt;/a&gt;
     &lt;span&gt;
      (Jun 2025),
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/datasets/nvidia/Nemotron-PrismMath&quot; rel=&quot;&quot;&gt;
      Nemotron-PrismMath
     &lt;/a&gt;
     &lt;span&gt;
      (Apr 2025)
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   &lt;strong&gt;
    NeMo Gym RLVR datasets:
   &lt;/strong&gt;
   &lt;a href=&quot;https://huggingface.co/collections/nvidia/nemo-gym&quot; rel=&quot;&quot;&gt;
    Collection
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nemotron v3 post-training (Dec 2025):
   &lt;/strong&gt;
   &lt;a href=&quot;https://huggingface.co/collections/nvidia/nemotron-post-training-v3&quot; rel=&quot;&quot;&gt;
    Collection
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    HelpSteer (human feedback/preference):
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://huggingface.co/datasets/nvidia/HelpSteer&quot; rel=&quot;&quot;&gt;
      HelpSteer
     &lt;/a&gt;
     &lt;span&gt;
      (Nov 2023)
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://huggingface.co/datasets/nvidia/HelpSteer2&quot; rel=&quot;&quot;&gt;
      HelpSteer2
     &lt;/a&gt;
     &lt;span&gt;
      (Jun 2024)
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://huggingface.co/datasets/nvidia/HelpSteer3&quot; rel=&quot;&quot;&gt;
      HelpSteer3
     &lt;/a&gt;
     &lt;span&gt;
      (Mar 2025)
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   And others, not linked here.
  &lt;/p&gt;
  &lt;h2&gt;
   Chapters
  &lt;/h2&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:00:00 Intro &amp; Why NVIDIA Releases Open Models
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:05:17 Nemotron’s two jobs: systems R&amp;D + ecosystem support
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:15:23 Releasing datasets, not just models
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:22:25 Organizing 500+ people with “invitation, not control”
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     0:37:29 Scaling Nemotron &amp; The Evolution of Megatron
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:48:26 Career Reflections: From SVMs to DLSS
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:54:12 Lessons from the Baidu Silicon Valley AI Lab
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:57:25 Building an Applied Research Lab with Jensen Huang
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     01:00:44 Advice for Researchers &amp; Predictions for 2026
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h2&gt;
   Transcript
  &lt;/h2&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:00:06 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Okay. Hey, Bryan. I’m very excited to talk about Nemotron. I think low-key, one of the biggest evolving stories in twenty-five of open models, outside the obvious things in China that everybody talks about, that gets a ton of attention. So th- thanks for coming on the pod.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:00:22 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    Oh, yeah, it’s my honor.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:00:23 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    So I wanted to start, and some of these questions are honestly fulfilling my curiosity as a fan. As like, why does NVIDIA, at a basic level, release Nemotron as open models?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:00:39 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    Well, we know that it’s an opportunity for NVIDIA to grow our market whenever AI grows, and we know that having access to open AI models is really important for a lot of developers and researchers that are trying to push AI forward. you know, we were really excited by efforts from some other companies around the industry to push openly developed AI forward. You know, Meta did some amazing work, obviously, with Llama and you know OpenAI released GPT OSS, which was exciting. And the Allen Institute, of course, has been, you know, really leading the charge for research, open research and, you know, also things like the Marin Project and OpenAthena. You know, like there’s, there’s a bunch of things that we’re always excited to see develop.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And, you know, as we think about where AI is gonna go, you know, NVIDIA believes that AI is a form of infrastructure. it’s.. AI is a very useful technology when it’s applied, but on its own you know, it’s kind of a foundation and infrastructure. We think that technology generally works better when there’s openness to the infrastructure so that people can build things in different ways. You know, you think about the way that the internet transformed every aspect of the world economy is pretty profound, and we’re not done yet.
  &lt;/p&gt;
  &lt;p&gt;
   But the way that, for example, retail uses the internet is different from the way that healthcare uses the internet. And the fact that you know, different sectors of the economy were able to figure out how to incorporate the internet into the beating heart of their businesses in different ways was possible because the internet was built on open technologies that, you know, allowed people to try different things. And we think AI is gonna evolve in a similar way, that organizations across every sector of the world economy are gonna find new and surprising and fun, and important things to do with AI, and they’ll be able to do that better if they have the ability to customize AI and incorporate it directly into the work that they do. and so -- and by the way, this is not to detract from any of the you know, more closed approaches to AI, you know, the APIs that we see from a number of leading labs that, you know, are just extraordinary and have amazing capabilities. We’re excited about those, too.
  &lt;/p&gt;
  &lt;p&gt;
   You know, NVIDIA loves to support AI in all of its manifestations, but we feel like right now the sort of closed approaches to deploying AI are doing pretty well but we, you know, could use some more energy in the openly developed AI ecosystem, and so that’s why we’ve been putting more effort into it this past year.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:03:42 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. So I’m definitely gonna dig into this a lot ‘cause I have seen this. We’re sitting here recording in January twenty-six, which is in the midst of the rollout of these Nemotron three models. There’s the-- I think the Nano has released in the fall, which was probably one of the biggest splashes the org has made, and everybody’s eagerly awaiting these super and ultra-larger variants.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And it’s like how far are you, how far are you willing to push this Nemotron platform? Like, is it just depending on the users and the uptake and the ecosystem? Like, like, what is the-- is there a North Star in this? Or you hear a lot of.. if you listen to a lot of other open labs, they’re like: “We want to build open AGI,” which is like, I don’t necessarily think grounded, but there’s like a very unifying vision.
  &lt;/p&gt;
  &lt;p&gt;
   Is there something that you try to set the tone for it that goes through the organization? I mean, AI too, it’s like-
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:04:31 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    You know, my North-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:04:32 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    .. academics is so-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:04:34 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    For Nemotron.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:04:36 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Okay, go ahead.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:04:37 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    Oh, sorry. Go ahead.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:04:39 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    I was just, like, gonna compare to, like, AI too, where we can have such a-- like, we have a very specific vision, being so open that it’s like, I think, like, research is so needed, and there’s so little recipes to build on, like, with really credible research. So there’s, like, a research infrastructure, and then when you have something like Llama, it was, like, built on Zuckerberg’s vision, and he changed his mind, which I actually thought his vision was ex- was excellent, the way he articulated the need for open models, and it kind of faded. So it’s like, is there a way to set a vision for an org that, like, permeates every- everyone and is really compelling and exciting?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:05:17 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    Right. Well, we built Nemotron for two main reasons. The first is because we need to for our main product line. So what I mean by that?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Well, accelerated computing, what NVIDIA does, we build fast computers, right? But the point of building fast computers is to help people do new things. and actually every fast computer is also a slow computer. you know, the observation that it would be nice if computers were faster and could do more things isn’t new. that’s been around since the beginning of computing. So what makes accelerated computing different from standard computing is that we’re prioritizing, you know, we’re focusing, we’re deciding we’re gonna accelerate this workload. This other workload, which is like ninety-nine percent of all of the workloads, we’re gonna let somebody else do that, right?
  &lt;/p&gt;
  &lt;p&gt;
   So, like, you do not buy NVIDIA systems to do any general purpose computation. You buy them for a purpose, right? Which is these days, all about AI. But when you think about the workload, the compute workloads involved in AI there’s a, there’s a lot of diversity and there’s a lot of really important -.. parameters, hyperparameters, or algorithmic approaches that all have enormous imp- impacts on the systems that we need to build for AI.
  &lt;/p&gt;
  &lt;p&gt;
   So things like numeric precision MoE architecture, which of course, influence net-- it influences network design. you know, we’re dreaming about sparsity. We, you know, we’ve had, we’ve had sparse neural network acceleration in the GPU since Ampere. I don’t think that it’s being used enough. you know, so how do we, how do we figure out how to use that? These, these sorts of things have an enormous impact on the future of NVIDIA’s main product line, and we have to understand the answers to those questions deeply ourselves in order to know what we’re going to build.
  &lt;/p&gt;
  &lt;p&gt;
   We can’t just go to our customers and do a survey and say, “Hey “ you know, Meta, for example, since we were just talking about them, “what would you like to see in a future product line from NVIDIA?” Of course, Meta’s always trying to help us as much as they can, but there’s limits to what they can tell us because, you know a lot of the information that influences the design of these systems, it’s very expensive to derive, and so therefore, it’s, it’s very closely held. And so we need to be able to understand these questions very deeply in order to understand what kind of systems to build, in order to understand what we’re accelerating in AI and what we’re not gonna worry about. and so that’s kind of the first job for Nemotron models, is to make it possible for NVIDIA to continue to exist as a company. And I think it’s important that the community knows that because that’s the reason why NVIDIA is making the investments in Nemotron, is because we believe it’s essential for the future of our company. and so this isn’t-- and although as much, as much as it feels good to say, you know, NVIDIA believes in open openly developed AI because you know, we’re so charitable, but actually, that’s not the case. This is actually a business decision-
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:08:34 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    It’s smart
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:08:34 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    .. like, for NVIDIA, our business needs us to know about AI very deeply. And and so, you know, the amount of investment that is justified to carry on NVIDIA’s ongoing business, I think, is large. and so that’s that’s job number one for Nemotron. Now job number two for Nemotron is to support the ecosystem more broadly outside of NVIDIA. and, you know, NVIDIA has a special position in the AI landscape. of all of the big AI companies I think we’re the one that works with the most other companies. We support every company small and large, AI native company to old established enterprise.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   We work with hyperscalers, we work with tiny little startups, we work with countries around the world. so we have this unique position and I think also a uni- unique responsibility and al- maybe also a unique opportunity, that whenever AI is able to grow in any sort of direction, in any capability, then you know, that’s an opportunity for us to grow our business. Obviously, it’s not automatic, right? you know, the AI market is diverse, and it’s getting more diverse, and it should be, ‘cause it’s the most important market in the history of humanity. So so we acknowledge that, and at the same time, we know that it’s in our interest to develop the AI ecosystem. The more people that are building, inventing, and deploying AI, the more opportunity that we have as a company.
  &lt;/p&gt;
  &lt;p&gt;
   So that’s job number two for Nemotron.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:10:17 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. I really appreciate you saying it so directly ‘cause it’s like we’ve worked.. We- I launched this thing, the Adam Project, last summer, which is trying to get more investment in the US open models, and it’s like the only company that has an obvious business model for open models is something like NVIDIA, where you need to make sure that the open models and the research ecosystem plays nicely on CUDA, because then you’re gonna be able to be one-- You’re so many steps closer to research that’s happening. If not, like, if it like- There’s such an advantage to have research happen mostly on GPUs relative to AMD or anything like this, so.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:10:49 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    Well, you know, we are-- we’re, we’re not thinking about how to prevent competition. You know, we welcome competition. There’s lots of competition. There should be more competition in this space, but we are very self-interested in staying engaged with the community.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   You know, it’s very important. You know, CUDA not many people remember this because it happened so long ago, but you know, CUDA started out with a lot of outreach from NVIDIA to the academic and industrial community saying, “Hey, we have this new way of doing computing. we’d love to see what you can do with it.” In fact, you know, I started using CUDA in 2006 when I was a grad student at Berkeley because David Kirk, who was the chief scientist of NVIDIA at the time, came over to Berkeley and said, “Hey we just released this new GPU, and it has this new programming model called CUDA. You should give it a try.” And I was-- at the time, I was working on machine learning on FPGAs, and I had been working on this one particular piece of support vector machine training on the FPGA, and I decided to take that little piece and write it in CUDA, and it took me like fifteen minutes, and then I ran it, and it was like two hundred times faster than my single-threaded CPU code, and I was like: “Whoa, that was way easier than what I was doing before. I’m just gonna go do that,” right?
  &lt;/p&gt;
  &lt;p&gt;
   So, like, my own personal involvement with CUDA and NVIDIA came about because of this outreach that NVIDIA conducted right from the beginning of CUDA. you know, of course, that led to a lot of great things for NVIDIA, including AlexNet, which was another academic project, you know, where Alex Krizhevsky and Ilya Sutskever were thinking about: “How do we train larger neural networks on more data? we’re gonna go write a bunch of GPU code that uses the GPU in a, in a kinda new and clever way, so that we can train a better image classification model.” And, you know, that had such astonishing results, it kicked off the deep learning era for the whole community. and again, not something that-.. could have been done top-down. That was a, that was a very much a result of NVIDIA supporting open development and re- research in parallel computing and artificial intelligence. And so we remember that, and we’re thinking about in twenty-six, what does it look like to help, you know, the Alex Krizhevsky of the future, who’s, who’s a grad student in a lab somewhere, invent the next technology that changes the world? It seems really difficult to do that without something like Nemotron or, or the other openly developed AI projects out there. yeah, I also wanna say in regards to this Nemotron is not trying to be the only project out there.
  &lt;/p&gt;
  &lt;p&gt;
   We’re part of the community. We love other people doing great work in openly developed AI. We learn from things that other people do and you know, so we’re, we’re trying to support the community because it’s in our interest, but we you know, we’re very happy to see other people contributing as well.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:13:57 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, I mean, I can transition into something I wanted to ask about is like, I see multiple ways, twenty-five Nemotron mat-- in, I don’t wanna use the word maturing ‘cause I wanna ask you about how it feels in the org, but just like the output reached levels that were more noticed by the community and people building with models. And there’s a lot of ways that can happen, but one of them is like, in my niche community, I’ve been using Nemotron datasets a lot. Like we-- when we redo our post-training recipe, one of the only people we look at is like, okay, NVIDIA, Nemotron has released a lot of high-quality, openly licensed post-training data. this year, you also started releasing some pre-training data, which among AI2 got a lot of notice. Like, what is that? is that like a distinct shift within Nemotron?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Is that something that you’ve wanted to do for a while and finally just did? But it’s ‘cause it’s like-- it is just like a zero to one moment where releasing pre-training data comes with legal risk for any company, but so few people do it, where on my side of the world, it’s like pretty easy to normally say what the best pre-training dataset is, and it had, for a long time, oscillated between like Hugging Face, AI2, DCLM, and there was like literally only two or three options. So in terms of fundamental research, like I think that’s a big step from an org to support the community and take on some risk. So if you have any story you can tell and or just say like, I appreciate it, that’s, that’s all.. that’s all I got.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:15:23 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    Well, yeah. I mean, so I think it’d be great if more people could understand that Nemotron is not just a model, right? Like, what we’re trying to do with Nemotron is to support openly developed AI, because, again, that’s our big opportunity, right? Now, there’s a lot of organizations that are incentivized to build a model, and the model is maybe the thing that runs their business, right?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   But at NVIDIA, the model is not the thing that runs our business, it’s the systems. So when we’re thinking about how do we support the ecosystem, it’s clear to us that the ecosystem needs more than just a model. There’s a lot of models out there already, you know? And of course, we want Nemotron to be awesome, but you know, if Nemotron can convince other people to work on AI because of a dataset or a technique, you know, we’re, we’re trying to be very open with all of the things we learn, you know, including..
  &lt;/p&gt;
  &lt;p&gt;
   I mean, we do a lot of expensive experiments in order to figure out how to do blending for our datasets or to figure out, you know, optimize our settings and, you know, these sorts of things. we’re very happy for other people to pick that up and run with it if it’s useful to them, you know. And so that makes Nemotron a different kind of AI effort. Of course, there is a model component, and that’s a tangible thing, and it’s, it’s easy to focus on that, but we see Nemotron as you know, an effort that includes models, but also includes datasets, techniques, all of all of the research that goes into Nemotron. And again we’re a unique kind of AI organization because of the way that we work with AI companies around the industry and because of the way that our business works, we can afford to be more open with some of these things than maybe some other organizations could be.
  &lt;/p&gt;
  &lt;p&gt;
   Now to your question about, like, does it take some courage in order to be open? Yeah, absolutely it does. and you know, I think there’s been-- one of the things that’s happened in twenty-five is that there’s been an evolving understanding within NVIDIA about the benefits of openness, and that has really enabled the company to make some investments that perhaps it was a little gun-shy to make in the past. And so that’s really encouraging for me. it’s something that I’ve you know, advocated for a while, and so it’s, it’s great to see the company kind of lining up behind it. I also, you know, to your point about like twenty-five being a, a year where Nemotron really made some strides, I want to say thank you for noticing that, and then maybe tell you a little bit about how that happened, because I think it’s instructive for me about how I think the work is gonna go forward in the future.
  &lt;/p&gt;
  &lt;p&gt;
   So you know, NVIDIA is a very decentralized company with a lot of volunteers. You know, everybody that works at NVIDIA is a volunteer. And what do I mean by that? Well, I mean, look, the industry is moving quick.
  &lt;/p&gt;
  &lt;p&gt;
   You know, people can always move from one job to the next. So the way that we think about the work that we do is like, it’s very decentralized, it’s very much let smart people figure out what they should be doing and then kind of self-organize. Now one of the challenges of self-organization in a field that’s moving quickly is that sometimes a whole bunch of people decide to-.. do similar kind of overlapping things but aren’t really coordinated. and that’s okay at the beginning because, you know in a place like NVIDIA, it’s just great to have some energy. It, it took us a while, I think, as a company to figure out that Nemotron was better together.
  &lt;/p&gt;
  &lt;p&gt;
   That rather than having, like, this group has a, has a model and that group has a dataset, and like, you know, then we end up publishing papers that kind of you know don’t really acknowledge each other and aren’t really coordinated. And then, of course along with that, we need to have k times the GPUs, where k is the number of independent efforts. we realized that, you know building AI, you really do need to figure out how to collaborate. the AI efforts that are built from teams of people focused on the overall effort succeeding rather than their own particular piece of the project succeeding, those are the ones that, you know, really change the world. And, you know, of course, NVIDIA works that way for the systems that we build, right? So, like, the people working on the memory controller on the GPU know that they also have to work with the people working on the SM that does the math, right?
  &lt;/p&gt;
  &lt;p&gt;
   Like, you can’t, you can’t make a GPU where it’s just like, “Well, we’ve got an awesome memory controller,” if the math doesn’t work, right? It all has to, has to kinda work together. And so that coordination, I think in the field of AI, it took us a little bit longer to do maybe than you could imagine that it could have. and I think that slowed the progress for Nemotron. so I give a lot of credit to the Nemotron team for realizing over the past, I don’t know, year and a half or so, that it was really time to join up and build one thing and make it awesome, and deeply understand that the success of the Nemotron project was more important than the success of any individual piece of that project. And the reason why I’m telling you all of this is because I think that’s actually true more broadly than just inside NVIDIA, and I think it’s, it’s difficult. you know, researchers like those of us with PhDs, for example, we are taught how to be independent, you know, and how to, how to build up our Google Scholar profile, and there’s, like, an incentive to go ahead and focus on that.
  &lt;/p&gt;
  &lt;p&gt;
   And a lot of successful academics and people researchers you know, they manage to push that pretty far and get some pretty amazing results. But, you know, I do believe that in 2020- in the 2020s you know, that the best research is done as part of a larger team. so how do we figure out how to work together? You know, how do we figure out how to put the success of the team first? That is a thing that is challenging to do but if we can achieve it, I think yield significant results.
  &lt;/p&gt;
  &lt;p&gt;
   And, you know, to the extent that we made progress in that part of the organization, I think we also saw progress in the technology. and that’s.. That gives me great hope for 2026 for Nemotron because the way the team is working together, I think is you know, pretty extraordinary. There’s just an enormous number of brilliant people that have decided that they’re gonna volunteer to make Nemotron awesome, and we’re, we’re starting to see some pretty great things come together.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:22:25 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    I agree with everything you said. Do you have any advice for making the orgs come together? I think we’ve seen big-- Wait, I’ve seen two class-- there’s two classes of AI companies right now. One is startup, does everything, and you have a model in six months, but you’re building from zero, and you have-- you p-- everybody agrees when they start that they do this. And then you have Google’s famous long-winded reorgs, which they actually eventually got right. Like, they got it very right with what’s going on with Gemini and Google DeepMind-.. right now. And it’s like, do you have any advice on doing this? I think, like, I’m, AI too, also advocating for this, but it’s very hard. I think personally-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:22:58 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    It’s-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:22:58 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    .. it’s like, I mean, I’m, I’m a special case ‘cause I’m also visible, where it’s e-- very easy for me to turn internet activity into, like, reputation points because of algorithms and size. But it’s very hard to do bottom-up technical work and get all of this and get all the culture alignment. So do you have any advice on actually, like, what works in this domain?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:23:20 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    You know what’s worked for us is invitation and not control. so you know, one way that, like, for a while I kinda wanted to try to implement was, like, nobody gets to publish any papers in AI unless they’re clearly part of Nemotron. So this is kind of a top-down, like, we’re gonna make you do it, right? I came to the realization that which we never implemented this, by the way, but I came to realization that this was a bad idea because it would just breed resentment, and, you know, NVIDIA is a company of volunteers. Everybody here is a volunteer.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So what we need to do is create the conditions by which it makes sense for people to volunteer to be part of Nemotron. And so the way that we went about doing that first of all it involved like, some top-level agreements between me and some of the other leaders of Nemotron, for example, John Cohen and Kerry Briski. I work very closely with the two of them. And you know, that hadn’t always been the case.
  &lt;/p&gt;
  &lt;p&gt;
   Like, we kind of had all come to this place independently. but we realized, like, Nemotron, better together, all three of us, and then we started telling our teams that: “You know, we really think Nemotron is gonna be better together.” so that top-down alignment, I think was really helpful. We-- again, we weren’t telling people exactly what to do, but we were just sending a con constant message like, you know, “Nemotron’s better together.” And then we built some structures that facilitated collaboration. So in the past decisions in the Nemotron project tended to be made in kind of a an opaque way. and the reason for that is just, you know-.. it’s hard to tell everybody about the middle of the sausage-making process. You know, it’s, like, messy and dif- difficult, and so, like, you know, it’s natural.
  &lt;/p&gt;
  &lt;p&gt;
   Like, researchers, we’re used to doing this, right? It’s a fait accompli. Like, “Here’s my ICML paper,” and like, you know, the fact that you spent, like, two years failing at that task before you finally succeeded, and then you tied a bow around it and gave it to the ICML committee, you don’t really talk about that, right? And so it’s difficult for researchers to, to be open about the middle of the process of research.
  &lt;/p&gt;
  &lt;p&gt;
   There’s a lot of failure, and it’s hard for people to feel like they’re, they’re not looking amazing. But what we, what we decided to do is we structured the project with.. There’s about twenty different areas for the project. Each of them has a clear leader, what we call a pilot in command.
  &lt;/p&gt;
  &lt;p&gt;
   Their job is to-- the job of the pilot in command is to land the airplane. You know, you just want the airplane to land, okay? So somebody, if you’re landing an airplane, there might be multiple pilots on board, but only one of them is gonna land the airplane at any time, right? Because it would be chaos if two of them tried to land at the same time, people would die.
  &lt;/p&gt;
  &lt;p&gt;
   So so this is not a committee structure; it is a delineated responsibility structure. And then the purpose of that pilot in command for each of these sections is to gather together all the best ideas, help the group of people that are interested in working on that space to come up with data-driven answers to what we should do, what technical decisions we should make, and then document that, you know, in a, in a way that other people can review. and you know, the thing that’s been really great about that is that it is inviting to people because when they see, like, okay, here’s the group of volunteers that are working on this area of Nemotron and then they want to contribute, it’s much clearer about how they could go about doing that, and it’s also clearer what the group needs because you know, these meetings are being held in the open. and we have-- we actually have a website where all of the ideas are submitted. they each get, like, a unique identifier, and then they get engaged with, you know, the PIC is trying to understand what the implications are, what kinds of experiments need to be run in order to prove or disprove the idea? how do we do what I call integration studies? You know, I, integration studies are so key for bringing researchers together, and they’re so opposite of what we are taught when we’re learning how to do ablations as a graduate student. You know, rather than, like, isolating the particular contribution of one idea, integration studies are about putting a hundred ideas together and seeing if they’re better than what we had before. so this kind of thing, doing that in a structured way and in a, in an open way internally has then made it possible for more people to volunteer, and that has then generally raised the rigor of the experiments and also the I think the outcome of the work.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:28:15 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, this is great. I think that over the last few years, there’s been more consensus on things that work for research. And I think the- we also do integration tests very regularly of like, is this feature gonna land for the model? And that’s kind of a..
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   It’s a good- it’s a nice mirror to ablations, where we know research is changing so much. There’s a lot of turmoil in the academic research community, and it’s nice to have things that are tangible as ways that are a little bit different when you’re doing these large-scale projects. So people that underst- like, you still need to do ablations. But then it needs to survive, like, an additional test in order to land into the model.
  &lt;/p&gt;
  &lt;p&gt;
   So it’s like an additional type of work that needs to be done, and I just like to have words to describe what is actually happening. I think on the Nemotron-3 Nano front, I do a lot of analysis on just looking at basic adoption metrics and Nemotron we created this, what we called like a relative adoption metric, which is essentially looking at downloads over time for models, because it’s easy to know which models have a ton of downloads that are released a while ago. But to, like, look at the trajectory of downloads changing over time, this is a lot-- this is a mouthful. It’s kind of an aside, but, like, Nemotron Nano 3 was in the thirty B size range, like, on track to be one of the top ten models downloaded of all time.
  &lt;/p&gt;
  &lt;p&gt;
   The point that I bring this up, other than to just flatter you, is like, do you think last mile adoption takes a substantial amount of work other than making, like, a very functional model? Or does adoption-- like, do you need to, like, change the recipe that you’re making and put a lot of focus and evaluation and, like, change this over time so that you actually get people to really use the model, rather than, like, “Oh, the benchmarks are good,” look at NVIDIA flying high?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:30:03 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    Right. Yeah, I mean, wow, it has taken the whole company coming together in order to make Nano V3 have more of an impact than the models that we released before. and there’s so many different aspects to that. obviously, there’s a lot of technical aspects which frankly, I think we have more work to do. So, like you know, making sure that on day zero, when we release something, that the quantizations, all the quantizations, the best quantizations are out there, that the speed on all of the important inference frameworks is out there, that it runs on all of the edge devices that we care about fla- flawlessly, that the install experience is great. You know, this kind of work is extraordinarily important because you know, it’s a crowded world.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   There’s so many different things that people could choose to work with, and any amount of friction that gets in the way of people even evaluating something that you do is gonna blunt the results, no matter how good that technology is.. I don’t think that we’re amazing at this yet, so this is something that I anticipate we’re gonna see a lot more investment in as the, you know more people at NVIDIA from all over the company, from marketing, from developer relations, from software engineering, you know as they-- as we all come together in support of this effort. so yeah, so it does, it does take an enormous amount of work. and then, you know, something that I’m particularly interested in is you know, how do we work engage-- i-in a new way, sort of engage with the community to make future Nemotron models even stronger? You know if the only things that we were to optimize for with a Nemotron model would be kind of academic benchmarks that are, you know, highly cited it’s likely the case that the model wouldn’t be general enough to really be useful. And so what we’re trying to build is a technology that other people can extend and deploy, and that means we need to have, like, other ways of understanding the strength of a model besides you know, a handful of academic benchmarks.
  &lt;/p&gt;
  &lt;p&gt;
   I think we have a lot of room to grow here. I’m hoping over time that we develop the muscle of being able to engage with the community and learn from them. Like, you know, okay, this particular thing that I tried to do with Nemotron, it didn’t work. It did this other thing that, you know, I wasn’t expecting, it was wrong. well, that can become feedback that then is used to make the next version better.
  &lt;/p&gt;
  &lt;p&gt;
   I think we’ve got a lot of work to do in that regard.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:33:10 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Do you think there’s any magic to it? I’ve-- I’m blown away by how successful OpenAI’s two open-source models are. Like, yes, they’re obviously the number one name brand in AI, but on the same metric that I see you guys, like, overperforming, like, what I would expect. I’m like, “Wow, great job, NVIDIA.” They’re, like, totally off the charts, like, on track to like, beat Llama’s, like, most downloaded numbers ever with these two GPT OSS models.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And I feel like what they-- like, even on release, they had hiccups where people were pretty negative on it. But for whatever reason, it has just like.. People figured it out, and it just clicked, and then just, like, for a company to say so little about it. Like, we-- Meta put so much effort into Llama being adopted, and you obviously are putting a lot of effort into this.
  &lt;/p&gt;
  &lt;p&gt;
   Like, I’m just like, did OpenAI just crack the code, or is there sometimes a bit of luck?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:33:59 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    Well, I don’t think I, I don’t think about OpenAI as a, as a lucky company. I think of them as a visionary company that works incredibly hard and you know, I think their success is well deserved. I love the GPT OSS models. You know definitely they’re an inspiration for us here at Nemotron. and yeah, so I think OpenAI also has, like, some other ways of engaging with the community just because of the large number of people that use their services, and that helps them learn things about what are people trying to do with AI, that then they can address when they’re building models, and you know, obviously, you know, people talk about that as a flywheel. you know, I think that’s really interesting and really important.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   NVIDIA is never going to have the same kind of flywheel as OpenAI does. We’re not trying to build a service like ChatGPT. What we’re trying to do is help the ecosystem, you know, be strong and enduring. we think that it’s important for there to be this openly developed AI ecosystem, and also we’re, we’re trying to build our next generation of systems, and so we have our own reasons for doing this. But we’re not ever going to have the same exact user base or flywheel that OpenAI does.
  &lt;/p&gt;
  &lt;p&gt;
   On the other hand, you know, we are able to work with institutions around the world in our own way, that I think offers us different opportunities and hopefully, that helps us make things that are, that are useful, too.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:35:38 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, this makes me realize, I’m having a lot of conversations on.. There are many open model efforts, especially even among people that are fully open, and it’s like, how do we better coordinate? So especially at the smaller scale, it’s like AI2 and Hugging Face. So they’re not big teams.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Like, how do we make sure we’re not doing the same data project at the same-- the same exact thing at the same time? And it’s like, I wonder if there’s opportunities for open companies, like LM Arena has historically released a lot of user data to, like, better help us close this kind of what are people using models for flywheel. And but it’s just-- it’s very hard to build cross-organizational model improvement pipelines, is something that I think. I think models become pretty vertical in terms of somebody at NVIDIA getting the feedback and the model making better.
  &lt;/p&gt;
  &lt;p&gt;
   So that’s what would be something I would like to see this year, but I don’t have ideas for doing it well.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:36:28 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. You know at NVIDIA, we have a tradition of working really closely with, you know, organizations that use our technology. and, you know, we really-- we have, we have teams of engineers that their job is to enable success for our customers. in fact, there’s more people at NVIDIA that care about the success of people outside of NVIDIA than I feel like sometimes there are people that care about the success of things inside NVIDIA. So, like, sometimes I’m like, I’m like: “Hey, could we use a little bit of that e-energy to support Nemotron?” And, and the answer is yes, and NVIDIA is doing that. But I think as Nemotron matures, we’re gonna find that you know, the organizations that work with NVIDIA to make Nemotron awesome for their business, for their use case are gonna have a say in how Nemotron evolves and hopefully, that helps Nemotron address their needs.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:37:29 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    .. Yeah, a basic question: how many people, like, how many employees does it take to build all the different versions of Nemotron? I haven’t brought this up because you also have other great types of models. I think our, like, open model analyst, Florian, is obsessed with the Parakeet model, ‘cause- Much faster at typing and is much faster at speaking than typing.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So there’s a lot of other-- I don’t know-- I don’t have the full list of other NVIDIA models off the top of my head, but you are releasing a lot of varieties of models. So I think it’s a bit of a there’s more context to my original question, which is I think about language models ‘cause I’m a n-- like, I just think of AI’s progress is gonna continue to go very fast, so I focus as that as the engine. So but it’s like, how many people is putting this kind of movement into place?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:38:16 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. Well, it’s, it’s, it’s hard to know exactly, and as I said, NVIDIA is a company of volunteers. But and also these days, things are changing, right? Like, so the Parakeet team, which is an excellent team, by the way they I would say a year ago wouldn’t have really considered themselves so much part of the core Nemotron effort, but these days they absolutely are. for the obvious reason that, you know, LLMs these days need to be able to consume all sorts of data, right?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Including audio data. And so you know, as the pro-- as the characteristics, the capabilities of Nemotron models expand obviously, the number of people contributing is gonna expand. I’d say right now there’s about five hundred people that are working pretty much full-time on Nemotron technologies in different ways. This is everything from numerics quantization recipes to speech recognition or image understanding or, you know, pre-training, post-training, RL systems inference software. you know, there’s, there’s a, there’s a whole bunch of different dimensions, right?
  &lt;/p&gt;
  &lt;p&gt;
   So I’d say it’s about five hundred people. but also we’re having our Nemotron all-hands meeting this week, and so I took a look to see how many people were invited to that all-hands meeting, and it was about two thousand. so those are people around the company that are interested in working with Nemotron and either expanding its capabilities or helping its adoption. and so I think you know, the number is somewhere in between and it’s hopefully gonna keep growing as, as Nemotron matures.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:40:07 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, I mean, that’s one of the greatest attestations to what you’re saying is like, if the interest outside the company-- inside the company is four times as big as the people doing it, you’re gonna, you’re gonna keep scaling up, it seems. People are gonna-.. find ways to help. - One of the other things I’m interested in, I don’t know, like, on the point of five hundred, it’s like, it sounds like a lot of people, but with how many things you have going on, it seems also very few. ‘Cause I’m transitioning to thinking about the long-standing, like, open-source software that you’ve had for NeMo, and I think Megatron, and it’s like they’ve been around for a long time. I think Megatron has gone through many eras. I have a note here.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   It’s like these softwares have been going around since, like, twenty nineteen in some form. And it’s, it-
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:40:51 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    Publicly. We had our first public release in twenty nineteen, but we started earlier.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:40:56 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    And it’s something that I’ve found is that when I started doing lang- language models, so I was a late bloomer, and we’ll transition to some career talk in a few minutes at Hugging Face. Like Megatron had, like, a bad rap of being very hard to use. But now, like three years later, I hear from anyone that’s founding a new language modeling startup, they’re like, “Just use Megatron.” like, do you pick up on things like this? Is it just, like, random-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:41:22 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    Well, we-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:41:22 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    .. but it’s like-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:41:22 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    We hard on it. You know, we’re trying really hard to make Megatron easier to use. It’s difficult. Megatron is a complicated piece of technology, and, you know, when we originally started Megatron, the point was to show the community that you could make state-of-the-art large transformer language models with NVIDIA.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I don’t know if you recall, but it-- there was some assertions by some other companies back in twenty seventeen when the transformer was invented, that they could only be made without NVIDIA. in fact, there were statements to that effect on bl-- on official blog posts, which I think got redacted later on. But it was important for NVIDIA to show up and say, “We love language models. We love transformers. Let’s see what we could do, you know, if we partitioned the work properly on lots of GPUs with an amazing interconnect, what kinds of models could we train?” And so that’s where the Megatron project started.
  &lt;/p&gt;
  &lt;p&gt;
   You know, I actually came up with the name Megatron. one of my proudest moments, I suppose. I was thinking about it, I was like: This is a really big transformer. What’s the biggest and baddest transformer? Oh, it’s Megatron.
  &lt;/p&gt;
  &lt;p&gt;
   So that’s, you know, where the name came from. but you’ll think about that had nothing to do with usability, right? Like, I wasn’t, I wasn’t thinking about, like, how do we make a platform that’s really easy for other people to use? I was just trying to show the world that, like, NVIDIA systems could be awesome for transformers. You know, that was, that was my goal.
  &lt;/p&gt;
  &lt;p&gt;
   Over the years, you know, it has evolved. We have a lot more people trying to use Megatron. We got a lot of complaints about how hard it was to use, and then we did a lot of work to try to improve the software engineering around Megatron. You know, these days Megatron software engineering is actually shared between about four different teams at NVIDIA. and we have to coordinate that work very closely.
  &lt;/p&gt;
  &lt;p&gt;
   That has also not been easy. There has been times when you know, people wanted to fork Megatron, and then there were times when we, like, had to bring it back together, and it’s like: Look, I know forking things is always tempting, but look, better together. It’s better for all of us to keep working together.. and so I feel like Megatron the-- and especially Megatron Core, which is like a subset of Megatron that’s, like, especially protected, and we try to put more software engineering into that that has gotten dramatically better since we started paying more attention to it as a company. are we done yet? No, there’s a lot, a lot, a lot more work.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:43:52 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    a ba-- a basic question: Is is Megatron or Megatron Core, like, this is what Nemotron is trained on? And also-- And it’s also something that many of the hottest, like, AI startups are training their models on. I would guess that there’s nothing else that does that. So, like, could you summarize why it’s so hard?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:44:11 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    Well, you know, there’s a, there’s a lot of other great frameworks out there. Megatron’s not the only one. and you know, we’re happy about that. NVIDIA doesn’t need to control the space. What we, what we do wanna do is make sure that we’re putting our products forward in the best light, you know, and it’s a challenging problem.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   We’ve got so many things going on with precision and you know, the networking. Like, those questions, like, the software is so complicated. these days, you know, we’re pre-training our Nemotron-3 Super and Ultra models using FP4 which is a thing that, you know, hasn’t been done publicly anyway and something that, you know, we’re pretty excited about because our GPUs have really awesome FP4 throughput. But obviously, the numerical challenges of, like, trying to train a state-of-the-art language model using four bits is non-trivial. So, like, you know, all of that work has to go into Megatron, into Transformer Engine which is a, another open-source project that Megatron relies on and, you know coordinating all of that making sure that, you know, we can actually deliver the benefits of NVIDIA systems to people that are trying to make state-of-the-art models, that’s really important to us.
  &lt;/p&gt;
  &lt;p&gt;
   And, you know, of the five hundred or so people working on Megatron, like, a pretty good fraction.. or on Nemotron, a pretty good fraction of them are working on these kinds of systems issues, right? Because NVIDIA at its core, is a systems company. and Megatron, you know, Nemotron’s first job really is about systems, you know, and so we, we care, we care deeply about that.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:45:51 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. I mean, from my perspective, I was at Hugging Face before AI2, and Hugging Face is, like, the best company at doing public work. But also, and switching to AI2 and focusing on, like, we’re focused on the output artifact the most. Seeing the different type-- Like, it’s such a different type of work, going from you’re trying to build a tool that’s good for training models, to build a tool that’s good for everybody else and whatever heck use case they are.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:46:13 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    It’s different.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:46:13 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    So I think-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:46:13 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. Different work.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:46:14 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    To do both is like.. I’m, I’m happy that AI2’s repos aren’t that popular in terms-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:46:21 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    Oh,
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:46:21 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    .. of open-source adoption because, like, we can’t handle it. We just can’t. It’s, like, so hard because it’s people-- it’s, like, it ends up being researchers that are supporting it, and we don’t have the ability to scale the organization structure. So I just think, like, that’s a, that’s a very fun turnaround for me to think of all these things happening at once.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:46:39 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. Well, thanks for noticing we’re putting effort in. I would say Megatron is still not nearly as user-friendly as Hugging Face libraries. Like-.. Hugging Face libraries are legendary, and I admire the work they’ve done to make the community so productive. people, you know, are able to get so much research done thanks to the work that, you know, Hugging Face has put into to their library. So you know, my hat’s off to them as well.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:47:06 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. One of my hot takes, you don’t have to reply, is that Hugging Face and NVIDIA have been very good partners.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:47:10 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    Oh, absolutely.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:47:10 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    And it’s like bringing that Hugging Face culture to the NVIDIA stuff would be so good. It’s just so hard, so I don’t know how that would work, but-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:47:17 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    We’re trying, you know, and you know, it is, it is challenging. NVIDIA is always a company that is gonna prioritize speed like hardware speed, above really anything else, ‘cause that’s, like, who we are. I am always trying to make the case that developer speed is important, too, right? It’s like there’s different ways of thinking about speed. and it is definitely the case that a lot of NVIDIA’s software is so cumbersome to use that you know people can’t get the actual hardware speed as fast as it should be because they just give up.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   You know, they just don’t, don’t even figure out how to use that. So I think NVIDIA’s making strides there. I think the, the company is understanding more deeply how important developer experience is, and I hope we continue to push that, so that the benefits of all of the systems technology that NVIDIA works so hard on can be more widely used. but at the same time, you know, there is gonna be a tension between those things. It’s, it’s not gonna go away, and you know, to a certain extent, I think that’s just life on planet Earth.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:48:26 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    It is. I think you’re do- you’re doing a good job, and I’m gonna kind of shift gears in this interview. So I’ve.. In becoming more back in language- in becoming a person that works in language models, I’ve seen your name more and more times.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I was like, “Bryan Catanzaro, like, where have I seen this?” And then I went and did the research of the Berkeley PhD in, like.. It says April of 2021, you gave a Berkeley EECS Colloquium titled “Applications of Deep Learning and Graphics, Conversational AI, and Systems Design.” I’m not even gonna posit that I actually went, but that’s definitely where I remembered the name from in grad school. And we both have backgrounds that aren’t traditionally in AI and end up working in language models. I just wanted to, like-- what have you learned from your path th- through NVIDIA into what, like, people should be thinking about with AI or open models today?
  &lt;/p&gt;
  &lt;p&gt;
   This could be career reflections, like technical reflections. I just think that there’s-- there are actually a lot of people that come from all over the, like, STEM field to work in AI, so giving it-
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:49:29 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    Sure
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:49:29 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    .. space to think about is-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:49:31 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    .. useful, even if it’s just like, it was the big problem, and I wanted to go solve it. Well, I think, you know I’ve, I’ve had a lot of opportunity and a lot of luck in my career. I think in hindsight, it seems like an extraordinarily lucky thing that, you know, I did my first internship at NVIDIA in 2008, and I was, like, building machine learning models on the GPU, and I went to NVIDIA, and nobody else was really doing that. And I was like, “Hey, like, we should have more people doing machine learning on the GPU.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I think this could be an opportunity.” And you know, it took a few years for me to make any headway. NVIDIA didn’t really wanna listen to me. I was a brand-new PhD. I was in the research organization, which is very independent, but, you know, sometimes struggles to change the way that the, you know, the bigger company thinks about things.
  &lt;/p&gt;
  &lt;p&gt;
   And and yet, I just had this conviction, you know, I just was following my heart about what I think is gonna be important, what do I think could really change the world? And that has been, I think, the thread that has taken me through my whole career, is that I’m constantly trying to refine my beliefs about what matters and then hold to them. And that.. I don’t know how helpful it is to say that, but I feel like sometimes people you know, tend to follow the, whatever the thing is that people are talking about on Twitter.
  &lt;/p&gt;
  &lt;p&gt;
   And like I’ve- I’ve done a lot of unpopular things during my career because I believed in them, you know? I remember I published my first paper in 2008 on, at ICML, on training support vector machines on the GPU, and I actually had somebody at the conference, it was in Helsinki at dinner, you know, we were all telling each other what we’re doing, and, and I was like: Yeah, I wanna help people train bigger models on bigger data sets with GPUs. And, and I had you know, a couple of people just say, “Well, why are you here at ICML? That just doesn’t really feel like a good thing for us.” And in 2008, ICML was momly- mainly about new mathematical frameworks for thinking about data, and you know, maybe if you trained a model at all, you would train one on your laptop.
  &lt;/p&gt;
  &lt;p&gt;
   You know, that was the state of machine learning in 2008. So for somebody to come in and say, “I think I want to focus on, like, parallel computing, new kinds of hardware for machine learning, programming frameworks for machine learning, so that, you know, we- more people can try inventing new models on complicated machines with a lot more compute throughput on bigger data sets,” that was like a, an unpopular thing. At least it felt very unpopular. I felt very marginalized at the time by the community.
  &lt;/p&gt;
  &lt;p&gt;
   But I believed in it, you know? I just felt like, look, technology.. Like I have this sense of, like, where do I think technology is going? I knew that traditional computing was running out of steam.
  &lt;/p&gt;
  &lt;p&gt;
   You know, I had, I had done a few internships at Intel, and I was trying to help Intel make processors that ran at, like, ten gigahertz back in 2001, and, you know, it was, like, clear that th- they were running into a wall. And I was thinking: Okay, so if the compute hardware is gonna have to be different, it’s gonna be more restricted. It’s not gonna be able to be so general-purpose in order to get speed. What kinds of applications are gonna have, like, an infinite need for more computing?
  &lt;/p&gt;
  &lt;p&gt;
   And I thought, well, machine learning and AI, that could really change the world if it ever actually worked. But, you know, but, you know, back then it, back then, it kinda worked inside of Google. outside of Google, it kind of didn’t work. and so I had kinda these signals, like it was possible, but it was hard. It was a little weird. It was a little niche.
  &lt;/p&gt;
  &lt;p&gt;
   I was a little bit caught in between different fields, like the systems people didn’t think I was systems enough, and the machine learning people didn’t think I was machine learning enough. But, but I believed in what I was doing, and I found a way to keep following that belief. And, you know, ultimately it was very rewarding when all of a sudden NVIDIA decided, “Hey deep learning is changing the world. What do we know about deep learning?” And then it was like: Oh, well, Bryan’s been doing that for several years, and he’s written some libraries that we could turn into a product.
  &lt;/p&gt;
  &lt;p&gt;
   Let’s go do that. And, you know, so that all happened really quickly after many years of nothing happening, you know? And that was really obviously an amazing opportunity for me. you know, an- another thing that was important to me, I left NVIDIA in 2014 to go work at the Silicon Valley AI Lab at Baidu with a group of really talented people, including Andrew Ng and Dario Amodei and Awni Hannun and Adam Coates, and you know, this was a, a really once-in-a-lifetime opportunity, I think for me, to learn some things that would have been hard for me to learn on my own. you know, I felt at the time at NVIDIA that although I had this great opportunity to help NVIDIA become an AI company, and I was doing that, and I was succeeding at that back in 2013 2014, I also felt like I really wanted to learn from a broader community of people applying machine learning and AI to solve really important business problems. And so going to work at Baidu really gave me that chance. and I was there for a couple of years, learned a ton. very grateful to the team there especially to Andrew Ng, who, who encouraged me to, to join with him on that. and then, you know, I ran into limits of what I could do in California, working for a Chinese company.
  &lt;/p&gt;
  &lt;p&gt;
   I was thinking about, you know, what should I do next? And Jensen asked me to come back and build an applied research lab at NVIDIA in 2016. and -.. I wasn’t sure, like, if that was a good idea. I thought NVIDIA’s already grown so much, you know.
  &lt;/p&gt;
  &lt;p&gt;
   The, the years from twenty fourteen to twenty sixteen, NVIDIA actually grew a lot. these days you look back at it, and you’re like: It was still really tiny. But, but back then, I was like: I don’t know, maybe NVIDIA’s already tapped out. I don’t know if you recall, in twenty sixteen, there was already, like, ten different companies making GPU competitors, right? The TPU had already been out for a while and you know, it, it wasn’t clear that NVIDIA was gonna become as large as it, as it has.
  &lt;/p&gt;
  &lt;p&gt;
   But I believed in the opportunity. I believed in the people. you know, one of the things I loved about NVIDIA was that it’s a very stable organization. So Jensen, he’s been running it since he founded it in nineteen ninety-three. my boss, Jonah Alben, who’s an absolutely extraordinary person has been here for you know quite a, quite a long time, almost since the very beginning of NVIDIA. And these people a lot of the leadership at NVIDIA they love the work.
  &lt;/p&gt;
  &lt;p&gt;
   Their heart is in the work. Jensen and Jonah and many other leaders at NVIDIA, they don’t need to be doing this, right? They, they have earned the right to go sit on a beach and drink mai tais all day, but their heart is in the work, and they work incredibly hard. you know, the.. I feel like if there was an Olympics for email, you know Jensen would get the gold medal.
  &lt;/p&gt;
  &lt;p&gt;
   You know, like it’s, it’s unfathomable to me, like, how much information he’s able to process. and it’s a skill that he’s built up over a long time running this company, but it’s also a reflection of his commitment to the work. And I felt like working at a place where we’ve got this very stable organization that loves the work, that really wants to change the world. You know, why does, why does Jensen get up in the morning? Well, it’s-- this is his chance to do something meaningful.
  &lt;/p&gt;
  &lt;p&gt;
   I thought, associating with these people, you know, I could do worse. I could-- I think I could learn from this as well. And so I came to NVIDIA, and back then it was really hard to explain to people why I was trying to build an AI lab inside of NVIDIA. At, at the time, NVIDIA wasn’t doing very much AI, and so I had to kind of develop a vision for that and then explain it to people. that’s ended up being a really good idea for me as well.
  &lt;/p&gt;
  &lt;p&gt;
   You know, the lab, I think, has really helped NVIDIA. you know, Megatron, I think, has really shown the industry, like, how valuable NVIDIA systems can be for language modeling, which is, which is awesome. DLSS, you know I’m continuing to, to push DLSS forward. Very excited about making graphics, you know more efficient with AI. These days, you know, fifteen out of every sixteen pixels a gamer sees are rendered by AI models that, you know, my team developed, and that then makes the GPU ten times more power efficient.
  &lt;/p&gt;
  &lt;p&gt;
   This is a really exciting you know, thing for me to be involved with, something that I’ve, you know, dreamed about for years. So, so that’s the kind of thing that continues to push me forward, is that I have strong beliefs about what I think is possible, where I think technology’s going, and I’m willing to do things that are we- weird and unpopular but, you know, basically following my convictions. I’m very much always thinking about the people I’m working with, the tribe. You know, I think tribes matter enormously. like you know if I..
  &lt;/p&gt;
  &lt;p&gt;
   So, so back when I was a grad student, I was working on programming models for machine learning. I joined the Python tribe. There are other people that were in the Scala tribe, and the people that did their work in the Scala tribe, trying to make programming models for machine learning in, like, two thousand and ten you know, that work, although a lot of it was technically excellent, didn’t matter to the community as much as the people who were in the Python tribe. It ended up.. and, you know, it kind of sucks sometimes that the world is tribal like this, but it’s just the case.
  &lt;/p&gt;
  &lt;p&gt;
   You know, that like the people that you work with, the community that you work with has a big impact on the problems you think about and then the impact that your work has. So I think a lot about the people and the tribes that I’m collaborating with or that I’m part of. and you know, that’s, that’s kind of been the thread that has carried me through my career.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:59:56 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. Than- thanks for sharing this full arc. I think you’ve said things that I tell people but in different languages, and the first one, the early days, it seems like there can be space in between fields, where people-- two fields will have their way of describing things, but both of them are probably incomplete, and there can be space there, which is a lot of what I was doing transitioning from novel robots to model-based RL, where I, like, didn’t sit and bear in the actual AI lab, but I started doing AI with my, like, total electrical engineering friends. And then the second thing is, like, I’d wholeheartedly recommend this to people, is, like, choose your work based on the people and people that sincerely are in it for-.. the, what they want to do, and a lot of-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:00:41 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    And follow your beliefs. You know, think about it. What do you believe in? And it’s okay to change your mind, you know, but, like, figure out what is it that you believe in.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Ask yourself every day: Do I still believe in that? If I do, what next? You know. If I don’t, well, what do I believe in?
  &lt;/p&gt;
  &lt;p&gt;
   You know, that’s been really important to me. I think too many people end up kind of just following trends. That’s not usually helpful because the trends are too late. So if you wanna, if you wanna change the world, you need to be ahead of the trends, and you need to know, you know, it-- trends-- I don’t think trends in computing are just fashion.
  &lt;/p&gt;
  &lt;p&gt;
   I think there’s truth that drives those trends. Not always, but often. You know, it’s just-- this is, it’s there’s kind of an inevitable force of gravity. It just can be really hard to par- parse out the noise and figure out what is the truth that is gonna push the industry forward, and how can you push that with it.
  &lt;/p&gt;
  &lt;p&gt;
   You know, if you can join with that, you can accomplish great things.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:01:36 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, I agree. I think in building language models, it’s like you want to build a model that the community wants in six months. I think if you’re building a model to compete-.. with the models that are already out, you’re not gonna keep up. And I think that it’s like, what is the right thing is building open language models in six months, and like, where do you need to try to steer things is one of the hardest problems that I think about. So I don’t-- if you want to close with any predictions where you see, like, open models, like, if we’re-- if you’re gonna be here at the end of twenty-six, if there’s anything you think will be far more obvious than it is today, or any bets that you want to make, I think it’s kind of a good place to wrap.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:02:18 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    Well predictions are always hard, and I don’t feel like I’m very good at making predictions. But I am-- I feel like I am good at identifying what I believe in, and what I believe in right now is that compute remains one of the fundamental challenges behind AI. It has been that way for a very long time and I think it continues to be. I think as we find new ways to apply compute to AI, we discover new forms of scaling laws that help AI become more useful and therefore, it becomes more widespread.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So I’m gonna keep thinking about compute. I continue to believe that the fastest-- that, you know, the way to think about AI is not just in terms of absolute intelligence, but rather intelligence per second. You know, there’s some sort of normalization in there that relates to how fast a model can think, how fast a model can be trained or post-trained. You know, that models that kind of incorporate this compute acceleration characteristic, where they’re thinking about intelligence per unit time, those are gonna end up winning because they end up getting trained on more data, they end up getting post-trained with more cycles, they end up with more iterations during thinking when they’re deployed. and you know, of course, if they happen to fit the hardware really well whatever hardware that is then, you know, that can have a pretty non-trivial effect on the intelligence as well.
  &lt;/p&gt;
  &lt;p&gt;
   So that’s something that I really believe in. I really believe in AI as an infrastructure. You know, there’s, there’s different ways of thinking about AI. I think some people believe AI is more like the singularity, like once AGI has been declared, then the whole world is different forever, and all humans have lost their jobs and, you know, there’s a lot of like-- there’s a lot of things about AI that people believe that I personally don’t believe.
  &lt;/p&gt;
  &lt;p&gt;
   You know, I believe, first of all, that intelligence is very multifaceted that it is not easy to pin down, that as soon as we try to pin down intelligence, we find that there’s very many more forms of intelligence that aren’t covered by that. So, for example, a model that achieves gold medal status on the International Math Olympiad, that’s an extraordinary achievement, but it doesn’t make me have no job, right? Like, I’m actually not solving math problems all day, even though, like, having the ability to solve math problems is clearly very useful. And you know, it’s also the case that intelligence is, you know, is kind of like a potential energy it’s not a kinetic energy, right?
  &lt;/p&gt;
  &lt;p&gt;
   In order to transform intelligence into kinetic energy, it needs to have a platform. It needs to be applied in the proper way. and you know, that is why I believe in open models and open- openly developed and deployed intelligence. I believe every company, every organization, has secrets that only they know. They have special data, they have special ways of thinking about their problems, their customers, their solutions, and they’re gonna know how to apply AI better than anyone else.
  &lt;/p&gt;
  &lt;p&gt;
   And so AI as infrastructure that transforms companies, turbocharges them, allows them to take the things they know and multiply their impact, that’s something that I believe in more than AI as an event, that one day, when it happens, makes everyone obsolete. I don’t.. I just don’t believe in that. you know, I often joke that, like if, for example, the CEO were to retire at some point, and we needed to find a replacement you know, handing out an IQ test or asking, you know, who has the highest SAT score that would not be a very good way of finding a replacement, you know? intelligence is just far too complex for that. And so you know, so this, these beliefs, you know, you can disagree with me about anything that I just said, and I’m not offended by that.
  &lt;/p&gt;
  &lt;p&gt;
   I have a lot of friends that do. but you know, I’m asking myself, well, if I believe that intelligence has these characteristics and that AI is gonna change the world by turbocharging institutions that exist a-and also creating new applications that we haven’t even dreamed of yet rather than replacing all humans, then, you know, how do I go about building that, you know? And so that’s, that’s kind of the direction that I’m on right now.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:07:00 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, I love it. I agree, I agree that we’re entering an interesting area where the open models are taking so many different shapes and sizes and have so many different strengths and trade-offs, that there can start to be interesting interplay as an ecosystem, where there’s just so many different things going on. And I think I like your idea of potential energy, and you have to build things that are kind of unclear of what-- It’s like you have to build the energy in a way, and you don’t really know what the goal is, but you have to do.. try to build these good models. So I appreciate it, and-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:07:30 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, and then let people apply it. Let it-- let them make the kinetic energy happen.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:07:35 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    I agree. Thanks for coming on.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:07:37 Bryan Catanzaro:
   &lt;/strong&gt;
   &lt;span&gt;
    Thanks so much for inviting me. It’s been a great conversation.
   &lt;/span&gt;
  &lt;/p&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Latest open artifacts (#18): Arcee&#x27;s 400B MoE, LiquidAI&#x27;s underrated 1B model, new Kimi, and anticipation of a busy month </title>
<link>https://www.interconnects.ai/p/latest-open-artifacts-18-arcees-big</link>
<pubDate>Mon, 02 Feb 2026 13:03:33 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    January was on the slower side of open model releases compared to the record-setting year that was 2025. While there were still plenty of very strong and noteworthy models, most of the AI industry is looking ahead to models coming soon. There have
   &lt;/span&gt;
   &lt;a href=&quot;https://www.bloomberg.com/news/articles/2026-01-27/china-s-moonshot-unveils-new-ai-model-ahead-of-deepseek-release?utm_source=chatgpt.com&quot; rel=&quot;&quot;&gt;
    been
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;a href=&quot;https://www.theinformation.com/articles/deepseek-release-next-flagship-ai-model-strong-coding-ability?utm_source=chatgpt.com&quot; rel=&quot;&quot;&gt;
    countless
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;a href=&quot;https://www.reuters.com/technology/deepseek-launch-new-ai-model-focused-coding-february-information-reports-2026-01-09/?utm_source=chatgpt.com&quot; rel=&quot;&quot;&gt;
    rumors
   &lt;/a&gt;
   &lt;span&gt;
    of DeepSeek V4’s looming release and impressive capabilities alongside a far more competitive open model ecosystem.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    In the general AI world,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.reddit.com/r/singularity/comments/1qtc4jg/sonnet_5_next_week/&quot; rel=&quot;&quot;&gt;
    rumors
   &lt;/a&gt;
   &lt;span&gt;
    for Claude Sonnet 5’s release potentially being
   &lt;/span&gt;
   &lt;em&gt;
    tomorrow
   &lt;/em&gt;
   &lt;span&gt;
    have been under debate all weekend. We’re excited for what comes next — for now, plenty of new open models to tinker with.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/latest-open-artifacts-18-arcees-big?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-artifacts-18-arcees-big?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   &lt;strong&gt;
    Our Picks
   &lt;/strong&gt;
  &lt;/h3&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/LiquidAI/LFM2.5-1.2B-Instruct&quot; rel=&quot;&quot;&gt;
       LFM2.5-1.2B-Instruct
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/LiquidAI&quot; rel=&quot;&quot;&gt;
      LiquidAI
     &lt;/a&gt;
     &lt;span&gt;
      : Liquid continued pretraining from 10T (of their 2.0 series) to 28T tokens and it shows! This model update really surprised us: In our vibe testing, it came very close to Qwen3 4B 2507 Instruct, which we use every day. And this model is over 3 times smaller! In a direct comparison against the (still bigger) Qwen3 1.6B, we preferred LFM2.5 basically every time. And this time, they released all the other variants at once, i.e., a
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/LiquidAI/LFM2.5-1.2B-JP&quot; rel=&quot;&quot;&gt;
      Japanese
     &lt;/a&gt;
     &lt;span&gt;
      version, a
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/LiquidAI/LFM2.5-VL-1.6B&quot; rel=&quot;&quot;&gt;
      vision
     &lt;/a&gt;
     &lt;span&gt;
      and an
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/LiquidAI/LFM2.5-Audio-1.5B&quot; rel=&quot;&quot;&gt;
      audio model
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!jthG!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff45dd0ef-1d07-4c9e-9150-55d0524114f1_1896x1334.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!jthG!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff45dd0ef-1d07-4c9e-9150-55d0524114f1_1896x1334.png 424w, https://substackcdn.com/image/fetch/$s_!jthG!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff45dd0ef-1d07-4c9e-9150-55d0524114f1_1896x1334.png 848w, https://substackcdn.com/image/fetch/$s_!jthG!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff45dd0ef-1d07-4c9e-9150-55d0524114f1_1896x1334.png 1272w, https://substackcdn.com/image/fetch/$s_!jthG!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff45dd0ef-1d07-4c9e-9150-55d0524114f1_1896x1334.png 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;image&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f45dd0ef-1d07-4c9e-9150-55d0524114f1_1896x1334.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1024,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;1024&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!jthG!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff45dd0ef-1d07-4c9e-9150-55d0524114f1_1896x1334.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!jthG!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff45dd0ef-1d07-4c9e-9150-55d0524114f1_1896x1334.png 424w, https://substackcdn.com/image/fetch/$s_!jthG!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff45dd0ef-1d07-4c9e-9150-55d0524114f1_1896x1334.png 848w, https://substackcdn.com/image/fetch/$s_!jthG!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff45dd0ef-1d07-4c9e-9150-55d0524114f1_1896x1334.png 1272w, https://substackcdn.com/image/fetch/$s_!jthG!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff45dd0ef-1d07-4c9e-9150-55d0524114f1_1896x1334.png 1456w&quot; title=&quot;image&quot; width=&quot;1456&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/arcee-ai/Trinity-Large-Preview&quot; rel=&quot;&quot;&gt;
       Trinity-Large-Preview
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/arcee-ai&quot; rel=&quot;&quot;&gt;
      arcee-ai
     &lt;/a&gt;
     &lt;span&gt;
      : An ultra-sparse MoE with 400B total and 13B active parameters, trained by an American company. They also released
     &lt;/span&gt;
     &lt;a href=&quot;https://github.com/arcee-ai/trinity-large-tech-report/blob/main/Arcee%20Trinity%20Large.pdf&quot; rel=&quot;&quot;&gt;
      a tech report
     &lt;/a&gt;
     &lt;span&gt;
      and two base models, one “true”
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/arcee-ai/Trinity-Large-TrueBase&quot; rel=&quot;&quot;&gt;
      base
     &lt;/a&gt;
     &lt;span&gt;
      model pre-annealing and the
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/arcee-ai/Trinity-Large-Base&quot; rel=&quot;&quot;&gt;
      base model
     &lt;/a&gt;
     &lt;span&gt;
      after the pre-training phase. Many more insights, including technical details and their motivation, can be found in our interview with the founders and pre-training lead:
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div data-component-name=&quot;DigestPostEmbed&quot;&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/arcee-ai-goes-all-in-on-open-models&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;
     &lt;/a&gt;
    &lt;/div&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/moonshotai/Kimi-K2.5&quot; rel=&quot;&quot;&gt;
       Kimi-K2.5
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/moonshotai&quot; rel=&quot;&quot;&gt;
      moonshotai
     &lt;/a&gt;
     &lt;span&gt;
      : A continual pre-train on 15T tokens. Furthermore, this model is also multimodal! People on Twitter have
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/thdxr/status/2017756481559339221?s=20&quot; rel=&quot;&quot;&gt;
      replaced Claude 4.5 Opus with K2.5
     &lt;/a&gt;
     &lt;span&gt;
      for tasks that need a less capable but cheaper model. However, the writing capabilities that K2 and its successor were known for have suffered in favor of coding and agentic abilities.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/zai-org/GLM-4.7-Flash&quot; rel=&quot;&quot;&gt;
       GLM-4.7-Flash
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/zai-org&quot; rel=&quot;&quot;&gt;
      zai-org
     &lt;/a&gt;
     &lt;span&gt;
      : A smaller version of GLM-4.7 which comes in the same size as the small Qwen3 MoE with 30B total, 3B active parameters.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/LLM360/K2-Think-V2&quot; rel=&quot;&quot;&gt;
       K2-Think-V2
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/LLM360&quot; rel=&quot;&quot;&gt;
      LLM360
     &lt;/a&gt;
     &lt;span&gt;
      : A truly open reasoning model building on top of their previous line of models.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h3&gt;
   &lt;strong&gt;
    Models
   &lt;/strong&gt;
  &lt;/h3&gt;
  &lt;p&gt;
   Reading through the rest of this issue, we were impressed by the quality of the “niche” small models across the ecosystem. From OCR to embeddings and song-generation, this issue has some of everything and there really tends to be open models that excel at any modality needed today — they can just be hard to find!
  &lt;/p&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Thoughts on the hiring market in the age of LLMs </title>
<link>https://www.interconnects.ai/p/thoughts-on-the-hiring-market-in</link>
<pubDate>Fri, 30 Jan 2026 15:49:25 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   There’s a pervasive, mutual challenge in the job market today for people working in (or wanting to work in) the cutting edge of AI. On the hiring side, it often feels impossible to close, or even get interest from, the candidates you want. On the individual side, it quite often feels like the opportunity cost of your current job is extremely high — even if on paper the actual work and life you’re living is extremely good — due to the crazy compensation figures.
  &lt;/p&gt;
  &lt;p&gt;
   For established tech workers, the hiring process in AI can feel like a bit of a constant fog. For junior employees, it can feel like a bit of a wall.
  &lt;/p&gt;
  &lt;p&gt;
   In my role as a bit of a hybrid research lead, individual contributor, and mentor, I spend a lot of time thinking about how to get the right people for me to work with and the right jobs for my mentees.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The advice here is shaped by the urgency of the current moment in LLMs. These are hiring practices optimized for a timeline of relevance that may need revisiting every 1-2 years as the core technology changes — which may not be best for long-term investment in people, the industry, or yourself. I’ve
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/burning-out&quot; rel=&quot;&quot;&gt;
    written separately
   &lt;/a&gt;
   &lt;span&gt;
    about the costs of this pace, and don’t intend to carry this on indefinitely.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The most defining feature of hiring in this era is the complexity and pace of progress in language models. This creates two categories. For one, senior employees are much more covetable because they have more context of how to work in and steer complex systems over time. It takes a lot of perspective to understand the right direction for a library when your team can make vastly more progress on incremental features given AI agents. Without vision, the repositories can get locked with too many small additions. With powerful AI tools I expect the impact of senior employees to grow faster than adding junior members to the team could.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    This view on the importance of key senior talent has been a recent swing,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/get-good-at-agents&quot; rel=&quot;&quot;&gt;
    given my experiences and expectations for current and future AI agents
   &lt;/a&gt;
   &lt;span&gt;
    , respectively:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    Every engineer needs to learn how to design systems. Every researcher needs to learn how to run a lab. Agents push the humans up the org chart.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   &lt;span&gt;
    On the other side, junior employees have to prove themselves in a different way. The number one defining trait I look for in a junior engineering employee is an almost fanatical obsession with making progress, both in personal understanding and in modeling performance. The only way to learn how the sausage gets made is to do it, and to catch up it takes a lot of hard work in a narrow area to cultivate ownership. With sufficient motivation, a junior employee can scale to impact quickly, but without it, it’s almost replaceable with coding agents (or will be soon). This is very hard work and hard to recruit for. The best advice I have on finding these people is “vibes,” so I am looking for advice on how to find them too!
   &lt;/span&gt;
   &lt;span data-state=&quot;closed&quot;&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/thoughts-on-the-hiring-market-in#footnote-1-186128459&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     1
    &lt;/a&gt;
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    For one, when I brought
   &lt;/span&gt;
   &lt;a href=&quot;https://substack.com/@xeophon&quot; rel=&quot;&quot;&gt;
    Florian Brand
   &lt;/a&gt;
   &lt;span&gt;
    on to help follow open models for Interconnects, when I first chatted with him he literally said “since ChatGPT came out I’ve been fully obsessed with LLMs.” You don’t need to reinvent the wheel here — if it’s honest, people notice.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   For junior researchers, there’s much more grace, but that’s due to them working in an education institution first and foremost, instead of the understatedly brutal tech economy. A defining feature that creates success here is an obsession with backing up claims. So a new idea improves models, why? So our evaluation scores are higher, what does this look like in our harness? Speed of iteration follows from executing on this practice. Too many early career researchers try to build breadth of impact (e.g. collecting contributions on many projects) before clearly demonstrating, to themselves and their advisors, depth. The best researchers then bring both clarity of results and velocity in trying new ideas.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Working in academia today is therefore likely to be a more nurturing environment for junior talent, but it comes with even greater opportunity costs financially. I’m regularly asked if one should leave a Ph.D. to get an actual job, and my decision criteria is fairly simple. If you’re not looking to become a professor and have an offer to do
   &lt;/span&gt;
   &lt;em&gt;
    modeling
   &lt;/em&gt;
   &lt;span&gt;
    research at a frontier lab (Gemini, Anthropic, OpenAI is my list) then there’s little reason to stick around and finish your Ph.D.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The little reason that keeps people often ends up being personal pride in doing something hard, which I respect. It’s difficult to square these rather direct pieces of career advice with my other recommendations of choosing jobs based on the people, as you’ll spend a ton of your life with them, more than the content of what you’ll be doing. Choosing jobs based on people is one of the best ways to choose your job based on the so-called “vibes.”
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Working in a frontier lab in
   &lt;/span&gt;
   &lt;em&gt;
    product
   &lt;/em&gt;
   &lt;span&gt;
    as an alternative to doing a Ph.D. is a path to get absorbed in the corporate machine and not stand out, reducing yourself to the standard tech career ladder. Part of what I feel like
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/my-path-into-ai&quot; rel=&quot;&quot;&gt;
    works so well for me
   &lt;/a&gt;
   &lt;span&gt;
    , and other people at Ai2, is having the winning combination of responsibility, public visibility, and execution in your work. There is something special for career progression that comes from working publicly, especially when the industry is so closed, where people often overestimate your technical abilities and output. Maybe this is just the goodwill that comes from open-source contributions paying you back.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/thoughts-on-the-hiring-market-in?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/thoughts-on-the-hiring-market-in?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   If you go to a closed lab, visibility is almost always not possible, so you rely on responsibility and execution. It doesn’t matter if you execute if you’re doing great work on a product or model that no one ever touches. Being in the core group matters.
  &lt;/p&gt;
  &lt;p&gt;
   This then all comes back to finding the people hiring pipeline.
  &lt;/p&gt;
  &lt;p&gt;
   There are many imperfect signals out there, both positive and negative. For individuals building their portfolio, it’s imperative to avoid negative signals because the competition for hiring is so high. A small but clear negative signal is a junior researcher being a middle author on too many papers. Just say no, it helps you.
  &lt;/p&gt;
  &lt;p&gt;
   The positive signals are messier, but still doable. It’s been said that you can tell someone is a genius by reading one Tweet from them, and I agree with this. The written word is still an incredibly effective and underutilized communication form. One excellent blog post can signify real, rare understanding. The opposite holds true for AI slop. One AI slop blog post will kill your application.
  &lt;/p&gt;
  &lt;p&gt;
   The other paths I often advise people who reach out asking how to establish a career in AI are open-source code contributions or open research groups (e.g. EluetherAI). I’ve seen many more success cases on the former, in open-source code. Still, it’s remarkably rare, because A) most people don’t have the hardware to add meaningful code to these popular LLM repositories and B) most people don’t stick with it long enough. Getting to the point of making meaningful contributions historically has been very hard.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Doing open-source AI contributions could be a bit easier in the age of coding agents, as a lot of the limiting factors today are just bandwidth in implementing long todo lists of features, but standing out amid the sea of AI slop PRs and Issues will be hard. That’ll take class, creativity, humanity, and patience. So, to be able to run some tiny models on a $4000 DGX Spark is an investment, but it’s at least somewhat doable to iterate on meaningful code contributions to things like HuggingFace’s ML libraries (I’ve been
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/natolambert/status/2015473455530225939?s=20&quot; rel=&quot;&quot;&gt;
    writing
   &lt;/a&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;a href=&quot;https://github.com/natolambert/dgx-spark-setup&quot; rel=&quot;&quot;&gt;
    sharing
   &lt;/a&gt;
   &lt;span&gt;
    a lot about how I’m using the DGX Spark to iterate on our codebases at Ai2).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Back to the arc of hiring, the above focused on traits, but the final piece of the puzzle is alignment. The first question to ask is “is this person good?” The second question is, “will this person thrive here?” Every organization has different constraints, but especially in small teams, the second question defines your culture. In a startup, if you grow too fast you definitely lose control of your culture. This isn’t to say that the company won’t have a strong or useful culture, it’s to say you can’t steer it. The culture of an organization is the byproduct of how all the individuals interact. You do not want to roll the dice here.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects AI is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
   Personally, I’m working on building out a few more spots in a core post-training methods team at Ai2. Post-training recipes have gotten very complicated, and we’re working on making them easier to run while doing research on fundamentals such as post-training data mixing and scaling laws. To be a little vague, getting the post-training recipes done for both Olmo 3 and Olmo 2 was... very hard on the team. At the same time, post-training hasn’t gotten much more open, so hiring through it and doing the hard work is the only way.
  &lt;/p&gt;
  &lt;p&gt;
   Ideally I would hire one engineer and one researcher, both fairly senior, meaning at least having a Ph.D. or a similar number of years working in technology. Junior engineers with some experience and the aforementioned obsession would definitely work.
  &lt;/p&gt;
  &lt;p&gt;
   This callout serves as a good lesson for hiring. It is intentional that people should self-filter for this, no one likes when you way overreach on selling yourself for a job. I also intentionally make people find my email for this as an exercise. The art of cold emailing and approaching people in the correct pipelines is essential to getting hired. Many people you look up to in AI read their emails, the reason you don’t get a response is because you didn’t format your email correctly. The best cold emails show the recipient that they learned from it or obviously benefitted from getting it. Platitudes and compliments are of course nice to receive, but the best cold emails inspire action.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Two of the most recent people I helped hire at Ai2 I learned of through these side-door job applications (i.e. not found through the pile of careers page applications). I learned of
   &lt;/span&gt;
   &lt;a href=&quot;https://finbarr.ca/&quot; rel=&quot;&quot;&gt;
    Finbarr
   &lt;/a&gt;
   &lt;span&gt;
    through his blogs and online reputation.
   &lt;/span&gt;
   &lt;a href=&quot;https://www.tylerromero.com/&quot; rel=&quot;&quot;&gt;
    Tyler
   &lt;/a&gt;
   &lt;span&gt;
    sent me an excellent cold email with high-quality blog posts relating to my obvious, current areas of interest and had meaningful open-source LLM contributions. Both have been excellent teammates (and friends), so I’m always happy to say the system works, it’s just intimidating.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   All together, I’m very torn on the AI job market. It’s obviously brutal for junior members of our industry, it obviously feels short sighted, it obviously comes with tons of opportunity costs, and so on. At the same time, it’s such a privilege to be able to contribute to such a meaningful, and exciting technology. My grounding for hiring is still going to be a reliance on my instincts and humanity, and not to get too tied down with all the noise. Like most things, it just takes time and effort.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;hr/&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    Other posts in my “
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/t/life&quot; rel=&quot;&quot;&gt;
    life thoughts
   &lt;/a&gt;
   &lt;span&gt;
    ” series include the following. I send these to people when they ask me for career advice generally, as I don’t have time to give great individual responses:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Apr 05, 2023:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/behind-the-curtain-ai&quot; rel=&quot;&quot;&gt;
      Behind the curtain: what it feels like to work in AI right now
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Oct 11, 2023:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/ai-research-job-market&quot; rel=&quot;&quot;&gt;
      The AI research job market shit show (and my experience)
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Oct 30, 2024:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/why-i-build-open-language-models&quot; rel=&quot;&quot;&gt;
      Why I build open language models
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      May 14, 2025:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/my-path-into-ai&quot; rel=&quot;&quot;&gt;
      My path into AI
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Jun 06, 2025:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/how-i-write&quot; rel=&quot;&quot;&gt;
      How I Write
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Oct 25, 2025:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/burning-out&quot; rel=&quot;&quot;&gt;
      Burning out
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/thoughts-on-the-hiring-market-in#footnote-anchor-1-186128459&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     Some companies hire heavily out of Twitter, some hire from communities such as GPU Mode or NanoGPT speedrunning.
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Arcee AI goes all-in on open models built in the U.S. </title>
<link>https://www.interconnects.ai/p/arcee-ai-goes-all-in-on-open-models</link>
<pubDate>Tue, 27 Jan 2026 22:47:24 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;a href=&quot;https://www.arcee.ai/&quot; rel=&quot;&quot;&gt;
    Arcee AI
   &lt;/a&gt;
   &lt;span&gt;
    is a the startup I’ve found to be taking the most real approach to monetizing their open models. With a bunch of experience (and revenue) in the past in post-training open models for specific customer domains, they realized they needed to both prove themselves and fill a niche by pretraining larger, higher performance open models built in the U.S.A. They’re a group of people that are most eagerly answering my call to action for
   &lt;/span&gt;
   &lt;a href=&quot;https://atomproject.ai/&quot; rel=&quot;&quot;&gt;
    The ATOM Project
   &lt;/a&gt;
   &lt;span&gt;
    , and I’ve quickly become friends with them.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Today, they’re releasing their flagship model —
   &lt;/span&gt;
   &lt;a href=&quot;https://www.arcee.ai/blog/trinity-large&quot; rel=&quot;&quot;&gt;
    Trinity Large
   &lt;/a&gt;
   &lt;span&gt;
    — as the culmination of this pivot. In anticipation of this release, I sat down with their CEO Mark McQuade, CTO Lucas Atkins, and pretraining lead, Varun Singh, to have a wide ranging conversation on:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     The state (and future) of open vs. closed models,
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     The business of selling open models for on-prem deployments,
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     The story of Arcee AI &amp; going “all-in” on this training run,
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     The ATOM project,
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Building frontier model training teams in 6 months,
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     and other great topics. I really loved this one, and think you well too.
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   &lt;span&gt;
    The blog post linked above and
   &lt;/span&gt;
   &lt;a href=&quot;https://github.com/arcee-ai/trinity-large-tech-report/blob/main/Arcee%20Trinity%20Large.pdf&quot; rel=&quot;&quot;&gt;
    technical report
   &lt;/a&gt;
   &lt;span&gt;
    have many great details on training the model that I’m still digging into. One of the great things Arcee has been doing is releasing “true base models,” which don’t contain any SFT data or learning rate annealing. The Trinity Large model, an MoE with 400B total and 13B active tokens trained to 17 trillion tokens is the first publicly shared training run at this scale on B300 Nvidia Blackwell machines.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   As a preview, they shared the scores for the underway reasoning model relative to the who’s-who of today’s open models. It’s a big step for open models built in the U.S. to scale up like this.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!LJha!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3394c20a-e9b8-4dd4-8acd-406871eb9a02_1465x961.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!LJha!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3394c20a-e9b8-4dd4-8acd-406871eb9a02_1465x961.png 424w, https://substackcdn.com/image/fetch/$s_!LJha!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3394c20a-e9b8-4dd4-8acd-406871eb9a02_1465x961.png 848w, https://substackcdn.com/image/fetch/$s_!LJha!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3394c20a-e9b8-4dd4-8acd-406871eb9a02_1465x961.png 1272w, https://substackcdn.com/image/fetch/$s_!LJha!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3394c20a-e9b8-4dd4-8acd-406871eb9a02_1465x961.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3394c20a-e9b8-4dd4-8acd-406871eb9a02_1465x961.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:955,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:207382,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/184831986?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3394c20a-e9b8-4dd4-8acd-406871eb9a02_1465x961.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;955&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!LJha!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3394c20a-e9b8-4dd4-8acd-406871eb9a02_1465x961.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!LJha!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3394c20a-e9b8-4dd4-8acd-406871eb9a02_1465x961.png 424w, https://substackcdn.com/image/fetch/$s_!LJha!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3394c20a-e9b8-4dd4-8acd-406871eb9a02_1465x961.png 848w, https://substackcdn.com/image/fetch/$s_!LJha!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3394c20a-e9b8-4dd4-8acd-406871eb9a02_1465x961.png 1272w, https://substackcdn.com/image/fetch/$s_!LJha!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3394c20a-e9b8-4dd4-8acd-406871eb9a02_1465x961.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   I won’t spoil all the details, so you still listen to the podcast, but their section of the blogpost on cost sets the tone well for the podcast, which is a very frank discussion on how and why to build open models:
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    When we started this run, we had never pretrained anything remotely like this before.
   &lt;/p&gt;
   &lt;p&gt;
    There was no guarantee this would work. Not the modeling, not the data, not the training itself, not the operational part where you wake up, and a job that costs real money is in a bad state, and you have to decide whether to restart or try to rescue it.
   &lt;/p&gt;
   &lt;p&gt;
    &lt;span&gt;
     All in—compute, salaries, data, storage, ops—we pulled off this entire effort for
    &lt;/span&gt;
    &lt;strong&gt;
     $20 million
    &lt;/strong&gt;
    &lt;span&gt;
     . 4 Models got us here in 6 months.
    &lt;/span&gt;
   &lt;/p&gt;
   &lt;p&gt;
    That number is big for us. It’s also small compared to what frontier labs spend just to keep the lights on. We don’t have infinite retries.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   Once I post this, I’m going to dive right into trying the model, and I’m curious what you find too.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/arcee-ai-goes-all-in-on-open-models?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/arcee-ai-goes-all-in-on-open-models?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Listen on
   &lt;/span&gt;
   &lt;a href=&quot;https://podcasts.apple.com/us/podcast/interconnects-audio/id1719552353&quot; rel=&quot;&quot;&gt;
    Apple Podcasts
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://open.spotify.com/show/2UE6s7wZC4kiXYOnWRuxGv&quot; rel=&quot;&quot;&gt;
    Spotify
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.youtube.com/@interconnects&quot; rel=&quot;&quot;&gt;
    YouTube
   &lt;/a&gt;
   &lt;span&gt;
    , and
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/podcast&quot; rel=&quot;&quot;&gt;
    where ever you get your podcasts
   &lt;/a&gt;
   &lt;span&gt;
    . For other Interconnects interviews,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/t/interviews&quot; rel=&quot;&quot;&gt;
    go here
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div data-attrs=&#x27;{&quot;videoId&quot;:&quot;H23MG_Iym58&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}&#x27; data-component-name=&quot;Youtube2ToDOM&quot;&gt;
   &lt;div&gt;
    &lt;iframe allow=&quot;autoplay; fullscreen&quot; allowautoplay=&quot;true&quot; allowfullscreen=&quot;true&quot; frameborder=&quot;0&quot; gesture=&quot;media&quot; height=&quot;409&quot; loading=&quot;lazy&quot; src=&quot;https://www.youtube-nocookie.com/embed/H23MG_Iym58?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0&quot; width=&quot;728&quot;&gt;
    &lt;/iframe&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   Guests
  &lt;/h2&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Lucas Atkins
   &lt;/strong&gt;
   &lt;span&gt;
    —
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/latkins&quot; rel=&quot;&quot;&gt;
    X
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.linkedin.com/in/lucas-atkins-2892482b6&quot; rel=&quot;&quot;&gt;
    LinkedIn
   &lt;/a&gt;
   &lt;span&gt;
    — CTO; leads pretraining/architecture, wrote the Trinity Manifesto.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Mark McQuade
   &lt;/strong&gt;
   &lt;span&gt;
    —
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/MarkMcQuade&quot; rel=&quot;&quot;&gt;
    X
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.linkedin.com/in/mark-mcquade/&quot; rel=&quot;&quot;&gt;
    LinkedIn
   &lt;/a&gt;
   &lt;span&gt;
    — Founder/CEO; previously at Hugging Face (monetization), Roboflow. Focused on shipping enterprise-grade open-weight models + tooling.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Varun Singh
   &lt;/strong&gt;
   &lt;span&gt;
    —
   &lt;/span&gt;
   &lt;a href=&quot;https://www.linkedin.com/in/varun-singh-cs/&quot; rel=&quot;&quot;&gt;
    LinkedIn
   &lt;/a&gt;
   &lt;span&gt;
    — pretraining lead.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Most of this interview is conducted with Lucas, but Mark and Varun make great additions at the right times.
  &lt;/p&gt;
  &lt;h2&gt;
   Links
  &lt;/h2&gt;
  &lt;p&gt;
   Core:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Trinity Large (400B total, 13B active)
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/collections/arcee-ai/trinity-large&quot; rel=&quot;&quot;&gt;
      collection
     &lt;/a&gt;
     &lt;span&gt;
      ,
     &lt;/span&gt;
     &lt;a href=&quot;https://www.arcee.ai/blog/trinity-large&quot; rel=&quot;&quot;&gt;
      blog post
     &lt;/a&gt;
     &lt;span&gt;
      . Instruct model today, reasoning models soon.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://huggingface.co/arcee-ai/Trinity-Mini&quot; rel=&quot;&quot;&gt;
      Trinity Mini
     &lt;/a&gt;
     &lt;span&gt;
      , 26B total 3B active (
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/arcee-ai/Trinity-Mini-Base&quot; rel=&quot;&quot;&gt;
      base
     &lt;/a&gt;
     &lt;span&gt;
      , including releasing
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/arcee-ai/Trinity-Mini-Base-Pre-Anneal&quot; rel=&quot;&quot;&gt;
      pre-anneal checkpoint
     &lt;/a&gt;
     &lt;span&gt;
      )
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://huggingface.co/arcee-ai/Trinity-Nano-Preview&quot; rel=&quot;&quot;&gt;
      Trinity Nano Preview
     &lt;/a&gt;
     &lt;span&gt;
      , 6B total 1B active (
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/arcee-ai/Trinity-Nano-Base&quot; rel=&quot;&quot;&gt;
      base
     &lt;/a&gt;
     &lt;span&gt;
      )
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Open Source Catalog:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.arcee.ai/open-source-catalog&quot; rel=&quot;&quot;&gt;
      https://www.arcee.ai/open-source-catalog
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      API
     &lt;/span&gt;
     &lt;a href=&quot;https://docs.arcee.ai/&quot; rel=&quot;&quot;&gt;
      Docs
     &lt;/a&gt;
     &lt;span&gt;
      and
     &lt;/span&gt;
     &lt;a href=&quot;https://chat.arcee.ai/&quot; rel=&quot;&quot;&gt;
      Playground
     &lt;/a&gt;
     &lt;span&gt;
      (demo)
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Socials:
     &lt;/span&gt;
     &lt;a href=&quot;https://github.com/arcee-ai&quot; rel=&quot;&quot;&gt;
      GitHub
     &lt;/a&gt;
     &lt;span&gt;
      ,
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/arcee-ai&quot; rel=&quot;&quot;&gt;
      Hugging Face
     &lt;/a&gt;
     &lt;span&gt;
      ,
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/arcee_ai&quot; rel=&quot;&quot;&gt;
      X
     &lt;/a&gt;
     &lt;span&gt;
      ,
     &lt;/span&gt;
     &lt;a href=&quot;https://www.linkedin.com/company/arcee-ai&quot; rel=&quot;&quot;&gt;
      LinkedIn
     &lt;/a&gt;
     &lt;span&gt;
      ,
     &lt;/span&gt;
     &lt;a href=&quot;https://www.youtube.com/channel/UCVtYdqkprxxKZyh7jlp9dFQ&quot; rel=&quot;&quot;&gt;
      YouTube
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   Trinity Models:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Trinity models page:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.arcee.ai/trinity&quot; rel=&quot;&quot;&gt;
      https://www.arcee.ai/trinity
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      The Trinity Manifesto
     &lt;/strong&gt;
     &lt;span&gt;
      (
     &lt;/span&gt;
     &lt;em&gt;
      I recommend you read it
     &lt;/em&gt;
     &lt;span&gt;
      ):
     &lt;/span&gt;
     &lt;a href=&quot;https://www.arcee.ai/blog/the-trinity-manifesto&quot; rel=&quot;&quot;&gt;
      https://www.arcee.ai/blog/the-trinity-manifesto
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://huggingface.co/collections/arcee-ai/trinity&quot; rel=&quot;&quot;&gt;
      Trinity HF collection
     &lt;/a&gt;
     &lt;span&gt;
      — (
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/arcee-ai/Trinity-Mini&quot; rel=&quot;&quot;&gt;
      Trinity Mini
     &lt;/a&gt;
     &lt;span&gt;
      &amp;
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/arcee-ai/Trinity-Nano-Preview&quot; rel=&quot;&quot;&gt;
      Trinity Nano Preview
     &lt;/a&gt;
     &lt;span&gt;
      )
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   Older models:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://huggingface.co/arcee-ai/AFM-4.5B&quot; rel=&quot;&quot;&gt;
      AFM-4.5B
     &lt;/a&gt;
     &lt;span&gt;
      (and
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/arcee-ai/AFM-4.5B-Base&quot; rel=&quot;&quot;&gt;
      base model
     &lt;/a&gt;
     &lt;span&gt;
      ) — their first open, pretrained in-house model (
     &lt;/span&gt;
     &lt;a href=&quot;https://www.arcee.ai/blog/announcing-the-arcee-foundation-model-family&quot; rel=&quot;&quot;&gt;
      blog post
     &lt;/a&gt;
     &lt;span&gt;
      ).
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Five open-weights models (
     &lt;/span&gt;
     &lt;a href=&quot;https://www.arcee.ai/blog/releasing-five-new-open-weights-models&quot; rel=&quot;&quot;&gt;
      blog
     &lt;/a&gt;
     &lt;span&gt;
      ): three production models previously exclusive to their SaaS platform plus two research models, released as they shifted focus to AFM —
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/arcee-ai/Arcee-SuperNova-v1&quot; rel=&quot;&quot;&gt;
      Arcee-SuperNova-v1
     &lt;/a&gt;
     &lt;span&gt;
      ,
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/arcee-ai/Virtuoso-Large&quot; rel=&quot;&quot;&gt;
      Virtuoso-Large
     &lt;/a&gt;
     &lt;span&gt;
      ,
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/arcee-ai/Caller&quot; rel=&quot;&quot;&gt;
      Caller
     &lt;/a&gt;
     &lt;span&gt;
      ,
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/arcee-ai/GLM-4-32B-Base-32K&quot; rel=&quot;&quot;&gt;
      GLM-4-32B-Base-32K
     &lt;/a&gt;
     &lt;span&gt;
      ,
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/arcee-ai/Homunculus&quot; rel=&quot;&quot;&gt;
      Homunculus
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   &lt;span&gt;
    Open source tools
   &lt;/span&gt;
   &lt;strong&gt;
    :
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://github.com/arcee-ai/mergekit&quot; rel=&quot;&quot;&gt;
      MergeKit
     &lt;/a&gt;
     &lt;span&gt;
      — model merging toolkit (
     &lt;/span&gt;
     &lt;a href=&quot;https://www.arcee.ai/blog/mergekit-returns-to-its-roots&quot; rel=&quot;&quot;&gt;
      LGPL license return
     &lt;/a&gt;
     &lt;span&gt;
      )
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://github.com/arcee-ai/DistillKit&quot; rel=&quot;&quot;&gt;
      DistillKit
     &lt;/a&gt;
     &lt;span&gt;
      — knowledge distillation library
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://github.com/arcee-ai/EvolKit&quot; rel=&quot;&quot;&gt;
      EvolKit
     &lt;/a&gt;
     &lt;span&gt;
      — synthetic data generation via evolutionary methods
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   &lt;span&gt;
    Related
   &lt;/span&gt;
   &lt;strong&gt;
    :
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.datologyai.com/blog/arcee-case-study&quot; rel=&quot;&quot;&gt;
      Datology case study w/ Arcee
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h2&gt;
   Chapters
  &lt;/h2&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:00:00 Intro: Arcee AI, Trinity Models &amp; Trinity Large
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:08:26 Transitioning a Company to Pre-training
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:13:00 Technical Decisions: Muon and MoE
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:18:41 Scaling and MoE Training Pain
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:23:14 Post-training and RL Strategies
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:28:09 Team Structure and Data Scaling
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:31:31 The Trinity Manifesto: US Open Weights
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:42:31 Specialized Models and Distillation
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:47:12 Infrastructure and Hosting 400B
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:50:53 Open Source as a Business Moat
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:56:31 Predictions: Best Model in 2026
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     01:02:29 Lightning Round &amp; Conclusions
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   Transcript
  &lt;/h2&gt;
  &lt;p&gt;
   &lt;em&gt;
    Transcript generated with ElevenLabs Scribe v2 and cleaned with Claude Code with Opus 4.5.
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:00:06 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    I’m here with the Arcee AI team. I personally have become a bit of a fan of Arcee, ‘cause I think what they’re doing in trying to build a company around building open models is a valiant and very reasonable way to do this, ‘cause nobody really has a good business plan for open models, and you just gotta try to figure it out, and you gotta build better models over time. And like open-source software, building in public, I think, is the best way to do this. So this kind of gives you the wheels to get the, um... You get to hit the ground running on whatever you’re doing. And this week, they’re launching their biggest model to date, which I’m very excited to see more kind of large-scale MoE open models. I think we’ve seen, I don’t know, at least ten of these from different providers from China last year, and it’s obviously a thing that’s gonna be international, and a lot of people building models, and the US kind of, for whatever reason, has fewer people building, um, open models here. And I think that wherever people are building models, they can stand on the quality of the work. But whatever. I’ll stop rambling. I’ve got Lucas, Mark, um, Varun on the, on the phone here. I’ve known some of them, and I consider us friends. We’re gonna kind of talk through this model, talk through building open models in the US, so thanks for hopping on the pod.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:01:16 Mark McQuade:
   &lt;/strong&gt;
   &lt;span&gt;
    Thanks for having us.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:01:18 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, yeah. Thanks for having us. Excited.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:01:20 Varun Singh:
   &lt;/strong&gt;
   &lt;span&gt;
    Nice to be here.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:01:20 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    What- what should people know about this Trinity Large? What’s the actual name of this model? Like, how stoked are you?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:01:29 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    So to- yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:01:29 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Like, are you, like, finally made it?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:01:32 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Uh, you know, we’re recording this a little bit before release, so it’s still like, you know, getting everything buttoned up, and inference going at that size is always a challenge, but we’re-- This has been, like, a six-month sprint since we released our first dense model, which is 4.5B, uh, in, in July of last year, 2025. So, um, it’s always been in service of releasing large. I- it’s a 400B, um, thirteen billion active sparse MoE, and, uh, yeah, we’re, we’re super excited. This has just been the entire thing the company’s focused on the last six months, so really nice to have kind of the fruits of that, uh, start to, start to be used by the people that you’re building it for.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:02:16 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, I would say, like, the realistic question: do you think this is landing in the ballpark of the models in the last six months? Like, that has to be what you shop for, is there’s a high bar- ... of open models out there and, like, on what you’re targeting. Do you feel like these hit these, and somebody that’s familiar, or like MiniMax is, like, two thirty total, something less. I, I don’t know what it is. It’s like ten to twenty B active, probably. Um, you have DeepSeeks in the six hundred range, and then you have Kimi at the one trillion range. So this is still, like, actually on the smaller side of some of the big MoEs- ... that people know, which is, like, freaking crazy, especially you said 13B active. It’s, like- ... very high on the sparsity side. So I don’t actually know how you think about comparing it among those. I was realizing that MiniMax is smaller, doing some data analysis. So I think that it’s like, actually, the comparison might be a little bit too forced, where you just have to make something that is good and figure out if people use it.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:03:06 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, I mean, if, if from raw compute, we’re, we’re roughly in the middle of MiniMax and then GLM 4.5, as far as, like, size. Right, GLM’s, like, three eighty, I believe, and, and thirty-four active. Um, so it-- you know, we go a little bit higher on the total, but we, we cut the, uh, the active in half. Um, it was definitely tricky when we decided we wanted to do this. Again, it was July when... It, it was July when we released, uh, the dense model, and then we immediately knew we wanted to kind of go, go for a really big one, and the, the tricky thing with that is knowing that it’s gonna take six months. You, you can’t really be tr-- you can’t be building the model to be competitive when you started designing it, because, you know, that, obviously, a lot happens in this industry in six months. So, um, when we threw out pre-training and, and a lot of our targets were the GLM 4.5 base model, um, because 4.6 and 4.7 have been, you know, post-training on top of that. Um, and, like, in performance-wise, it’s well within where we want it to be. Um, it’s gonna be... Technically, we’re calling it Trinity Large Preview because we just have a whole month of extra RL that we want to do. Um- But-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:04:29 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    I’ve been, I’ve been there.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:04:31 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, yeah. But i- you know, we’re, we’re in the, um, you know, mid-eighties on AIME 2025, uh, GPQA Diamonds, uh, seventy-five, um, at least with the checkpoint we’re working with right now. We’re still doing more RL on it, but, um, you know, MMLU Pro, uh, eighty-two. So we’re, we’re, we’re happy. We’re really-- Like, for it being our first big run, like, just getting it trained was, was an extreme accomplishment, but then for it to actually be, like, a, a genuinely useful model is a, a cherry on top.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:05:03 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, let’s go big picture. Uh, like, let’s recap. We have all of the... We have this full trinity of models. I think that there’s a fun note. Uh, did I put it in this doc? Yeah, on Nano Preview, which was the smallest- ... you’re, like, charming and unstable. The model card’s really funny. Um, ChatGPT, doing deep research on this, I was like, ChatGPT Pro just tagged next to it, “charming and unstable.” And I was like: Is this a hallucination? And then in the model card, you have, like: “This is a chat-tuned model with a delightful personality and charm we think users will love. Uh, we think- ... it’s pushing the boundaries, eight hundred million, um, active parameter, and as such, may be unstable in certain use cases.” This is at the smallest scale- ... which is like, I appreciate saying it as it is, and that’ll come up multiple times in the conversation. And then you have Mini, which is like, um, I think it was, like, 1B active, 6B total type thing. In my-- I, I don’t have it, the numbers right in front of me. I have it somewhere else. Um-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:05:52 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, Nano was, Nano was the 6B, uh, 1 active.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:05:55 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Oh, yeah, yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:05:55 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    And then, and the Mini was twenty-six, 3B active.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:05:58 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. So, like-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:06:00 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Um, yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:06:00 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    -are these based on more of, like, you need to build out your training chops, or are you trying to fill needs that you’ve-... heard from community, and like, I think for context, previously, your first open model was a base and post-trained model, which was Arcee 4.5B, which was a dense model- -which people like. And prior to that, you had, like, a long list of, like, post-training fine tunes that you had released. So before that, it was like a post-training shop, and I think that kind of history is i- important to fill in, ‘cause I think most people-- a lot of people are gonna meet you for the first time listening to this.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:06:34 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, it, it, um, we chose those sizes for Mini and Nano, uh, specifically Mini, um, the 26B, 3B Active, because we wanted to de-risk, uh, large. Like, th- this has all been in service of getting to a model of, of, you know, the 400B class. So, um, we, you know, learned from doing the original 4.5B, that you might have everything on paper that you need to train a model, but i- inevitably, there’s tremendous, you know, difficulties that come up, and, um, it, it’s-- we, we definitely knew we wanted to make sure that we, you know, solved some of... E- especially when it came to just doing an MoE model performance, uh, you know, like a, like an efficient, fast train of an MoE. So, um, we thought that that was a good ground where we could, you know, it wasn’t crazy expensive, uh, but gave us a lot of data, uh, going into large. And then Nano just came about because we had some extra compute time, and we really want to do more research on, like, smaller models that are very deep. Um, and we hadn’t really seen that in an MoE before, so that one was very much we started training it, and then it, you know, early benchmarks were good, so we said, “Well, we’ll just do the whole dataset.” Um, and, uh, but most of the love for those releases went into, to Mini. So I, I definitely think that long term, uh, from an ROI perspective, the smaller models are going to be where we shine, just because there’s a tremendous amount of, of cost savings a company can get from, from optimizing on a, on a smaller model. Um, but, but we, uh, w- we’re definitely gonna be trying to push the, the large frontier, too.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:08:26 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. Um, I’d like to kind of double-click on training before going back to the small model that’s useful for companies, ‘cause we’re gonna have-- we’re gonna end up talking for, like, twenty minutes plus about open ecosystem. So I kind of am curious, like, philosophically, how your company feels about, like, sharing scientific details. So if I ask you, like, what are the things you’re technically most excited about in the model, or, like, what are the pain points? Like, uh, like, are you willing to talk about these things? Like, I- Do you feel like it’s kind of orthogonal to the company? Like, I feel like a lot of it is just, like, things that happen. I think your framing of all of this is in service of getting the big model going. And particularly, of, like, you have to be thinking about your model as landing in six months, is probably... Like, for people not training models, it’s hard to think about, ‘cause even I- ... like, I’m thinking about trying to refresh our post-training stack for OLMo 3, and I’m like, the thinking model, the, um, we are pretty SFT heavy right now, and it makes it not very dynamic in terms of the thinking time. But it’s just like, I can’t see people deploying this model, or probably will have a hard time fine-tuning it. And it’s like to think about where tool use models are going in six months, like, seems pretty hard. Um, it’s a very hard task to do, so it takes a lot of gumption to actually set out and do it. So I, I would just appreciate the framing, kind of self-reflecting on what I go through. So if you have anything that you think was, like, particularly hard to actually land the six-month outlook, because you use Muon as an optimizer, or is it Muon? And some of these things. I think the data, it’s well known that Datology is cranking a lot of this, and you probably provide-- I think of it as like you’re kind of driving and working with these partners, and I’m sure you provide a lot of feedback on what’s working and what’s not. So- ... anything you’re willing to share, I think it’s useful.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:10:08 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Uh, I, I think, um, I mean, on the data side, like Datology, I-- at least for these models, that, that partnership has very much been almost an extension of our own research team. Like, we’ve worked very closely with them, and, um, obviously, our model’s doing well, you know, i- is, is, is good for them. So, um, but it, it-- there was definitely, you know, and you know this better than most, like, small-scale ablations, when you throw them at scale, sometimes, you know, uh, the-- i- it doesn’t always turn out how you want. So there was quite a lot of iterating there to at least get the dataset we used for Large. Um, I, I would say that as far as looking out six months and then figuring out how we wanted to... Obviously, the big one was compute. We don’t, um, you know, we, we never raised as, like, a foundation model company, so we’ve ne- we haven’t signed massive commits for, you know, thousands of GPUs before. Um, we didn’t have a, a, a massive cluster that was always active, uh, for a lot of our post-training. So if they came before, um, you know, we had sixty-four, uh, H100s, that was pretty sufficient for that kind of work, but obviously, this necessitated quite a bit more. Um, but the first thing was-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:11:29 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    That’s still less than people would guess. Like, you’re releasing models- ... that weren’t like, your models weren’t catching national news, but people in the community knew about them. And, like, uh, i- I think of, like, Moondream when I think about that. Like, vik has- ... such little compute, and he puts it to so use. Like, you, like, see how successful he is? And he tells you that he has, I don’t know, thirty... Like, l- it might be, like, sixty-four GPUs. Like, uh- ... there’s, uh, uh, that’s a whole separate conversation on building- ... actual good ML output on little compute. I, I should ta- I should chat with vik about this, but aside
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:12:03 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    No, it’s, it is-- I think it was... Yeah, it, it, it was very much a gift going into the pre-training side because-... we were kind of already thinking, All right, how do we do the mu- you know, the most with the, the least amount of compute? But, um, you know, we-- it took us quite a while to get the cluster that we have been training large on, which is twenty-two thousand forty-eight B300s. Um, and once we figured out when we were going to get that, get access to that cluster, everything else kind of became clear as far as, like, timelines for Mini and Nano and, and when we wanted to do that. Uh, obviously, you know, five hundred and twelve H100s was easier to come across, um, for Mini and Nano. So once we figured that out, um, it really became, uh, this game of, okay, how can we find, like, the best research on the topic of, of pre-training, and what is kind of... What are the, the, the papers and publications that are coming out, um, that have enough potential and enough precedence, either because, uh, another lab used them, it comes from a reputable team, uh, the ablations and the, the evaluation setup, like in the paper, was sufficient enough to give us confidence. Uh, and then we basically spent, I don’t know, it was probably about two months just figuring out what we wanted our architecture to be for the MoE, then figuring out, okay, now that that’s what we want to do, how do we implement all of that in the actual training pipeline? Uh, how can we-- you know, at that time, there had been many people who’d done Muon, but, um, for post-training, and, and then other-- some Chinese labs had used it, but there wasn’t, like, a widely available distributed Muon, um, to do it that scale.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:13:54 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    What do you think that, like, looks like in decision-making? ‘Cause that seems like a risky decision, if you ask me. I think for one, the ti-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:14:00 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Muon?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:14:00 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    ... the timing, the, the, like, timing sharing that you’re saying is good. Like, you said this for two months, and then, like... But, like, even Muon is like, that’s a bet that would even take-- like, somewhere like AI2, that would take some serious evidence to go with it. We would want to ablate it. So like- ... on a single track, it’s like y- you had probably had a process for becoming fairly confident in it then.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:14:24 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    It- yes, but it, it was also, like, Kimi had, had just come out, and we knew that that one used Muon, and so we knew that it, at least, if implemented correctly, could deliver a good model. There weren’t outstanding ablations done around like... You know, there wasn’t a Kimi scale model done with Adam, and then compared to Muon and see the difference. But, um, that at least gave us enough confidence that if-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:14:50 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    What does Muon give you? Does it give you, like, memory saving, uh, in-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:14:55 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    No, it’s actually a little bit more memory. It’s, it’s, it’s mostly-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:14:58 Varun Singh:
   &lt;/strong&gt;
   &lt;span&gt;
    It’s, uh-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:14:58 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    ... like the loss converges a bit quicker.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:15:00 Varun Singh:
   &lt;/strong&gt;
   &lt;span&gt;
    It’s, it’s less memory, actually. It’s, uh, uh, only one momentum buffer instead of Adam’s two, uh, beta buffers, and then it’s also better convergence.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:15:10 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Okay. So it’s, like, mostly designed around convergence, and then I know the math is different, which is where this momentum term changes.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:15:15 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Well, it, it kind of came out... I mean, it had its, its, its big, you know, uh, explosion of popularity in the kind of nanoGPT speedrunning community. So it was kind of all built around converging to a certain, you know, validation loss faster, and, uh, that, that, that was, um... As for why we chose it as opposed to Adam, we’d used Adam for 4.5b, uh, but we also knew that if we wanted to move this fast, that we were going to have to make some pretty big bets, educated. Um, but, but still, we would have to make some, some, some risky decisions, um, beyond just, you know, training in general. So, um, there were a few that Muon we went with, uh, I think was, was one of our bigger bets. Uh, we ended up not doing, like, multi-token prediction or, or, or FP8 because we were throwing so many new things into the run at once, um, that-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:16:12 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Do these apply for-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:16:12 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    ... if something were to go wrong-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:16:13 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    um, Mini and Nano? Are those also Muon, or are those- ... Adam as well? Okay, so then you- ... you get some de-risk from that. Do you know off the top of your head how many days it take to train each of those? Like, a, a good-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:16:25 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Uh-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:16:25 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    ... ballpark for people, before-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:16:27 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, so-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:16:28 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    going into the bigger run.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:16:29 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    So, so Mini, uh, so Nano on it was five hundred and twelve H200s, uh, took a little over thirty days. Um, and then Mini was about forty-five days.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:16:45 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Okay. I think another thing- ... off the top of my head is I know that, like, a OLMo 1B dense would take us, like, eleven days on a hundred and twenty-eight H100s for a dense model. So, like, sixteen. So, like, the numbers- ... just go up from there. ‘Cause then it’s like the question is like, I’m guessing i- if those are forty-five days, and then you have-- you up the number of GPUs, it’s gonna be like a similar amount of time, or forty days for the big model, but much more stressful.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:17:16 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, the big model was... But again, that was- we knew that we, we wanted- we felt confident that we could deliver a competitive and exciting model in January 2026. Like, we knew that it would-- we could... Who knows kind of where the research and what, what class and, and, and, and skill and performance of model is gonna come out in the next three months? Um, so we also knew that we really wanted to land sometime in January, and that’s also why we also took- we went with B300s, even though definitely the largest public train of that size on B300s and, and the, um, you know, a lot of the software was not-- did not have, like, out-of-the-box B300 support. It was the only way we were gonna be able to train a model of this size in-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:18:06 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Did you have to do this? Did you have to implement the... like, help solve version issues or other issues on B300s? ‘Cause I’ve heard that-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:18:13 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    W-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:18:14 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    ... the rollout has been rough.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:18:16 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    We had to add-... a, a bit. There, there were a couple days where the, the data center had to take it offline to implement some bug fixes. It was, it was definitely, like, a very cool experience being on the bleeding edge, but, um, also, like, a little frightening ‘cause you just know, like, “Oh, we’re not getting the most out of these that we possibly could.” So, um, a little bit of both.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:18:40 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Uh, was your final training run stable, or did you have to do interventions through it?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:18:46 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Uh, it was very stable, actually. Uh, it took-- the beginning of it was not. The, the, the first ten days were absolute, um... It, it would start very well and, and looked, you know, uh, the dynamics and the logs, and the graphs looked very similar to Mini and Nano, and then after, uh, around a trillion tokens, it- the- we- you know, you’d get collapsing, experts would start to go crazy. Uh, part of this is just, again, we are very sparse compared to what you, you, you have. So, um, you know, four hundred billion total, um, thirteen billion active, two hundred and fifty six experts. Like, it was, it was-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:19:26 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Did you do a, uh, expert routing loss or some sort of balancing loss?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:19:30 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. Yeah, yeah. Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:19:32 Varun Singh:
   &lt;/strong&gt;
   &lt;span&gt;
    We did, um, we used DeepSeek’s, uh... We, we modified DeepSeek’s Auxiliary-loss-free, um, uh, loss balancing with our own, like, uh, with some tweaks, and then we also added a sequence loss like they, uh, did as well.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:19:47 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Uh, was there Auxiliary-loss-free one from DeepSeek V3, or was that a later model?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:19:51 Varun Singh:
   &lt;/strong&gt;
   &lt;span&gt;
    That was V3.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:19:52 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    It was V3.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:19:52 Varun Singh:
   &lt;/strong&gt;
   &lt;span&gt;
    They did a separate paper on it as well. Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:19:55 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. Yeah, that makes sense. I think a lot of people have derived from there. Um, have you- ... had issues on post-training as well? So I have a theory that the new algorithms we’re getting from the Chinese labs, like GSPO and SysPO, are primarily for problems that you solve when you have big MoEs and you have expert problems when trying to do the RL. And that’s the whole reason that, like, I think our very serious AI two RL setup, like, we’re doing it on dense models, and we’re just like, “It’s fine. We don’t have this big clipping problem, and as much like we don’t have as much of a need to get the batch size as big to ac- activate all the experts.” So you’re saying you have so many experts and so much sparsity, that potentially sounds like you’re making RL harder.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:20:36 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Um, yes. I will also... I will say that from just, like, a purely post-training side, we added as much as we po- we used- we... So our code base started from TorchTitan. We’ve had to make a ton of modifications to it to get it where we need it to be, but that was an excellent base. And from one of the bigger learnings from Mini and Nano was treating, uh, at least the SFT side of it, as a s- as a separate phase. Um, ‘cause with, with Mini and Nano, we finished the pre-training, we did context extension, then we took those and then ran those on, like, the sixty-four H100s we usually would do post-training on. Um, that presented a lot of challenges, uh, with the MoEs. They, they really... And that’s kind of been a thing in the open space, is post-training MoEs, like, really, um, can be frustrating, even for SFT. So for Large, we added, uh, like, fine-tuning directly to TorchTitan, um, and did it all on the same cluster. So, um, from a performance standpoint, like, SFT was very, um... actually ended up being totally different.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:21:42 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    What is the actual difference between the q- the, the implementations then? Is it just kinda like you end up with different batch sizes and parallelism and stuff? Like why-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:21:50 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Uh, I mean, we ended up, we... Yeah, we ended up needing to get it to do really, like, to get context parallelism really well, really good, ‘cause we’re obviously going at a higher sequence length, and then, um, just adding the proper loss masking. Um, it, it, it, it ended up being a relatively easy implementation, especially ‘cause we did all the pre-processing, uh, outside of TorchTitan.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:22:13 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Interesting.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:22:14 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Uh, and then on the RL side, yes, I would say it’s not, um, it didn’t present itself as, as, as significantly harder than, than, um, Mini and Nano. However, that many GPUs does, so we didn’t end up using, uh, two thousand of the B300s for that. That ended up being, uh, a thousand. So two, we just split the nodes in half.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:22:39 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. That makes sense.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:22:40 Varun Singh:
   &lt;/strong&gt;
   &lt;span&gt;
    On the dense model side of things, uh, you mentioned that you didn’t need to use all the tricks and stuff. I, I think it is, uh... I think the, the, it- MoEs are just, in general, harder to RL, but I think it’s also, like, uh, b- because of, like, the KL mismatch between trainer and inference engine, right? Um, where you have, like, uh, sometimes the inference engine can pick different experts compared to, like, the trainer, uh, when you, like, do a forward pass on the same tokens. So I think there is definitely some, like, inherent instability with, with RL on MoEs.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:23:13 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, that makes sense. Are, are... Okay, um, another question of, like, how much do you want to say? How do you feel about the state of public post-training recipes? Like, do you... Like, I, I feel like there’s so little out there, and there’s an opportunity to be seen as technical leaders by sharing just, like, more of what you’re doing. ‘Cause I feel like we’ve seen for years how complicated things can be, but also at, kind of at the same time... Like, we see this from the likes of Llama, has these really complicated recipes. But at the same time, I feel like just executing on a simpler recipe can get pretty close. But it’s just, like, very uns- I feel, uh, currently unsatisfied with how much I know about what are the actual core trade-offs of doing post-training well. And I think you could do a lot with SFT, but there’s definitely, in this RL regime, more trepidation of kind of narrowing your model to either downstream use or, like, being able to do this multi-week RL run where you get the most performance.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:24:06 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, I mean, I, I, from-- since RL has become such a pivotal part of the process beyond what, you know, DPO and, and, uh, and kind of your, your typical RLHF was in the past, like, we used to get quite, uh-... sophisticated with, with how we would do SFT and, and even our, our RL. We, we obviously, we make MergeKit, so we, we utilized merging, and we used to do a lot of distillation, um, to eke out as much performance as we could. Now that RL is such a massive part of the entire post-training stack, I, I have almost reverted us to just really solid but simple SFT. Um, like in, in large, I mean, we’ve-- our post-training data set for, uh, Trinity Large is, uh, two hundred and thirty billion tokens. Like, like, it just like a really, really, really large-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:25:09 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    That’s ten X what we did. At least in SFT.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:25:10 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    And even that-- and even, even your tenant, like that was bef- before this kind of w- going at this scale and even kinda thinking and, and reasoning models. Like our largest SFT before that was five billion to-- we’d do, like, three epochs, but it was like five billion, you know, tokens, so- Um-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:25:28 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Our non-reasoning model is, like, te- another ten X. So, like, our most latest instruct model is, like, two billion.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:25:34 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, which is, uh, already a lot, you know. So, um, I, I’ve definitely... We-- you know, simplicity’s key because it also makes debugging anything easier, and then, um, devoting a lot of that sophistication to the RL. Our RL part is, like, really important. I do think that, I mean, the next, uh, phase of reinforcement learning for models of this scale is, is just scale. Is, is... Okay, we went from, you know, twenty billion SFT to two hundred and thirty, now we’re going from, you know, ten environments to a hundred. I think that that really is where you’re gonna get the biggest benefit. I also think that’s why, you know, MiniMax and, and, and other players like GLM are so performant and just, like, have that extra bit of, of usefulness that goes beyond just what you see in the benchmarks, is they’ve, they’ve really embraced, like, long-form, uh, RL. And, and so, um, yeah, I mean, to be quite frank, our, our RL pipeline’s rather... immature might be the wrong word. Like, it’s, it’s, uh, there’s definitely a lot more work we could do and a lot more work we need to do, but, um-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:26:43 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Have you started the tool use side of RL?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:26:46 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    That-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:26:46 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Or are you mostly... Well, um, beyond like, if you’re training on code, just verifying the code answer, I don’t count yet as tool use. I would say, like, search and code integrated reasoning is what I think is gonna be like minimum table stakes, but do it- to do it well is really hard. Like, we have to, like- ... like, you, you really, like, uh... That’s what I want to do. I want all of our models to have that this year. Search is prob- you have to have, like, a partner to do search or just, like, illegally scrape Google if you’re gonna- ... you’re gonna serve this model onto a customer, and it’s gonna- ... what? Go, go to Google, like, what?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:27:16 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. Yeah, no, I mean, I, I... Beyond, like, like, really kind of like long-form, like deep research or, um, you know, even like GPT-OSS style or, or G- GPT 5 style, where, you know, it’s doing a hundred tool calls before it gives you a response. Not there yet, um, but that is kind of... Once we get past the, the final kind of RL of Trinity Large, and, and we kinda look at where we go next, like, that is the next major hurdle, um, for sure, and it’s intimidating.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:27:56 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    How big is your, your team of- of... Like, how many people are spending the majority of their time on the model? And then I think we c- start to wrap up technical talk and zoom out a bit to ecosystem and company strategy.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:28:09 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Uh, there’s thirteen at Arcee- ... that are just, like, every, every single day is working on it. Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:28:16 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    And I guess that’s a good number because these people are talking about data, but there’s also, like, the whole data thing that’s coming somewhere else. But also somebody else that wanted to pre-train a model, like they could just download the best fully open data set. And I don’t think it’s gonna be quite as good, particularly in the fact that, um, like, if you look at OLMo’s models, we don’t have a lot of tokens, so we need to, like, acquire- ... more tokens in the open still. But to, like, get a number of thirteen, where some are spending a bit of time on data, but there’s the whole data abstraction, is actually kind of nice for somebody that’s like... To do a serious modeling effort, you need to have this many people, I think.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:28:50 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    It, it was-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:28:51 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    It’s reasonable to me.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:28:52 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    It was, it was a good number. I mean, I would say that, um, it, it was helpful to be able to, you know... This was like, how do we alleviate as many concerns as possible? Or how do we check off as many boxes, right? And it’s like, if we’re trying to do this in the shortest possible amount of time, like, we need to focus on what we’re good at, which is we- pretty good at post-training, and how do we get to the point where we’re able to do that? Well, we have to have a pretty strong base model. How do we get a strong base model? We’ll-- we have to, you know, figure out how to do it, perform, you know, efficiently across many, many GPUs, and then data’s, you know, extremely important, so getting a partner that could, you know, help us with that, and we could offload some of that. It, it- there ended up being, obviously, as you, you know, alluded to earlier, like, a lot of, uh, working with Datology and, and, and others to make sure that the data accomplished what we needed it to. Um, I think that that is gonna be an interesting... You know, as we, as we- now that we have Large and we’re looking at, you know, kind of going further, it’s like, okay, you know, the, the pre-training data really has to be in service of what you wanna do in the post-training, uh, work.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:30:10 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    How did you identify this?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:30:11 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Like, like-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:30:11 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Like, like- ... did, did you identify this through Mini and Nano, or, like, how’d you come to think that this was so important?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:30:19 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Data in general or, or just-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:30:20 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Or like this in form of post-training
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:30:21 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    ... of optimizing it for the post-training? Um, I- really ob- observing other, other players, I think. I mean, it’s, it’s... You know, the, the true base model has kinda stopped really being a thing.... around Qwen2, but definitely around Qwen 2.5, um, where you started to see how much post-training data was making its way into the, the, the base models themselves. Um, and then you start to see the models that have done that, how malleable they are with RL, Qwen 2.5, Qwen3 being a good example. And you start to see like, oh, yeah, like they are, uh, doing as much in the last probably thirty percent of training to make it so that when they go to do RL or post-training, they’re gonna have a really good time. Um, you know, they’re just complete-- they’re way easier, way more malleable, way more performant than what you had in Llama 2 or Mistral 7B. So, um, I knew that i-in-intuitively, kind of going into this, but it wasn’t until after Mini and Nano, yeah, where, where we kind of... Well, definitely 4.5B, where we were like, “Yeah, we definitely need to juice our mid-training quite a bit.”
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:31:31 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, I agree. Okay, this was fun. We could- we’ll probably revisit themes from this. I think that, um, I can definitely go over time and keep chatting because I’m enjoying this. And for context, Mark and I had coffee at some point when I was at some conference in SF, and I was like: Damn straight, this is a fun bet that you’re making. So I’m trying to recapture as much of this as you can. Um, for context, it’s like in July, which is similar to when you decided to start this model, which is when, like, Qwen Coder came out, Kimi came out, um- ... GLM 4.5 came out, and I was just, like, looking- and Llama had kind of been, like, become a meme of going away. And that’s why I launched the Adam Project, where I was like: Come on, we need to have some people doing this. And I think that it’s, like, hard in the US because I think there’s so much money to be made on AI. Like, the company- the big tech companies are like: “We see it, and we’re gonna take it, so I don’t need to bother with, like, caring about open models ‘cause we don’t need it.” But from, like, an ecosystem co- perspective and a long-term tech perspective, I don’t think that works very well for the country. So it’s kind of this weird middle ground of like, how do you convince people to actually build open models? I was on... Like, I have calls with people in government asking me, like, what would I actually do? So it’s, like, very hard to think about this. And I have this- and then it’s just, like, to hear that you guys are just making this bet on this is very fun to me, but it’s also, like, based on actual learning from trying to do this. So you’ve been trying to train open models. I think Mark and I have both been at Hugging Face in our past, and you’re, you were trying to sell people on using open models, and there is a market for this, but it wasn’t enough to not have the base models. So I think, like, talking about your experience in selling on-prem open models and why you needed to train your own end-to-end, and why you needed to train bigger, is great because I hope there are more stories like this, and it kind of fills a void and inspires people to work in it. So how- however you want to take this prompt.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:33:24 Mark McQuade:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, I can jump in. Um, I mean, yeah, I mean, wh- when I started Arcee in 2023, right, uh, it was... All we did was post-training. Uh, and we worked with, uh, a lot of large organizations and did model customization, you know, for their use case on their data. Um, and we were using Llama-based models, Mistral-based models, and then, you know, some Qwen. I don’t even know if we actually did much Qwen, right, Lukas, at that time, but-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:33:54 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    No, we did. Yeah, we, we- Later on, but and then-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:33:56 Mark McQuade:
   &lt;/strong&gt;
   &lt;span&gt;
    Later on, right? Uh-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:33:57 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    We did, and then we ended up not, because after a lot of Chinese models started to come out, then the companies didn’t wanna use Chinese models, so then we kind of went... Yeah, it was kind of just tricky.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:34:08 Mark McQuade:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, and people don’t realize that that’s real.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:34:10 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    People don’t realize that that actually happened.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:34:13 Mark McQuade:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, no, that’s, that’s a real thing. That’s why we, we started going down to pre-training was because, well, you know, Meta did their thing and kind of got out of it, right? So there was the, the main US player got out of it, and, and we were working with a lot of US-based enterprises that were not comfortable using Chinese-based architectures. And if you wanted to use the best open models of the day, it started to really trend towards, you know, the Chinese labs. Um, and to the point where we are now, where it’s like, you know, ninety-plus percent of the top mo- open models are coming out of China, um-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:34:47 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, like, Cursor’s building on it and stuff. Like, people are building on these things.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:34:52 Mark McQuade:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. So, um, we said, “Okay, let’s...” Instead of we were so reliant on the Metas of the world, the Mistrals of the world, and Mistral largely stopped open sourcing, uh, you know, fully. So we said: You know what? We’ll just go down the stack, and we feel we’re capable enough to, to, to train our own models from scratch, and then we control the, you know, the stack. We can, you know, we, we control the core of, of... as opposed to relying on others to release great models. And, um, and then during this time, you know, it just happened to be that, um, you know, there wasn’t a tremendous amount of US companies doing it. So, um, from our perspective, it was kind of a, a win-win, in that we were able to own more of the stack by going down to pre-training and creating our own models, as well as we were entering into a, like, a space that there wasn’t a tremendous amount of competition, to be honest. Um, and, you know, I-- Lukas and I had said this yesterday, I, you know, I think as a startup, every startup doesn’t want to directly compete with, you know, X or OpenAI, or Anthropic, or Google because they have more money than God, and they can do whatever they want. Um, but when you’re doing open weights, you don’t-- it’s, it’s a different kind of compe- they, they don’t sit in there, right? You’re kind of going into your own path, where there isn’t a tremendous amount of players, and you can kind of find your, your way and, and build your niche and, and kind of go from there and, and become something big. So, um, it kind of happened to all coincide for us back in, in July, and, and we went all in.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:36:23 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, yeah, like, uh, the, the all-in thing is real because this is expensive. I think that- ... I could dig up in my research the cost of daily, um, twenty-four T8 B300. So I think I’ve seen this type of cost at AI too, where we have long rentals, and we’re like: I know exactly how much this costs, and it’s like, it’s not cheap. Are you... A, a way to transition this is like-... do you see the demand? Like, you were selling open models, like, does this kind of be continuous, where people are like: “You helped us deploy this model, but it’s not good enough.” Like, is, is that something that’s happening, and you’re like: “Well, we have this, and we can help you do it coming in this time?” Or is it like you need to build it... It’s like, is it a we will build it, and they will come type of situation? Like, how much- ... continuity is there in this?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:37:17 Mark McQuade:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, I think it’s largely-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:37:19 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    I-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:37:19 Mark McQuade:
   &lt;/strong&gt;
   &lt;span&gt;
    I, uh, from my perspective, I think it’s largely if you build it, they will come. Because we stopped, you know, focusing on that whole revenue generation side of the house when we started to go all in on being this, you know, frontier lab in the open source side. So, um, there’s a couple pieces to that, that, that I think we should all be very proud of inside of Arcee, is that we not only went all in by committing a significant amount of capital. Like, we, we committed, you know, sixty-five, seventy percent of our capital to these models, which is a large amount for a startup. I mean, we didn’t... So that’s not like a dip your toe in, that’s like, we’re all the way in.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:37:55 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yep.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:37:55 Mark McQuade:
   &lt;/strong&gt;
   &lt;span&gt;
    Um, but we did that at the same time as abandoning essentially the whole revenue angle to go all in on it, because we couldn’t focus on both. So we said, “We know how to make revenue on open models. We’ve been doing it for two years. Now, let’s take a step back, because it wasn’t, uh, in a repeatable or sustainable way that we h- the way we had that business set up. Let’s take a step back, let’s build these models from scratch, let’s come up with the, the Trinity family, then let’s go back to generating the revenue side of the house and the monetization piece,” which I think we are in a good position to capitalize on even more now, but we, we took a... We, we, we kind of walked away from it to do what we’re doing here.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:38:36 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, I love this.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:38:36 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, I mean, when you have... When there’s only, like, thirteen, you know, uh, researchers who would... Well, we’re, we’re doing obviously our own products and own models, but when you’re working with customers, like, inevitably, those are the same people that need to help train those models for customers, and we got to a point where we were really beginning to, like, do mini and nano. We were getting down to, like, the start date of the cluster, where, um, having myself or Mark, or even, you know, Varun and others, like, pulled into customer or, or, or, uh, conversations or contracts, like, it was not-- we would not be where we are if we had continued, you have know, working with, you know, ten customers at once. So-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:39:19 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    But-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:39:19 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    ... we, we scaled that down pretty drastically. I do think that when... You know, Mark and I put a lot of thought into, “Okay, well, we’re gonna spend all this money to train these models, like, you know, w- how do we not...” I think, uh, one of the things that makes the idea of, of going all in on training open weight models hard, is that you’ve seen other people try it. And, and like M-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:39:42 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Um, like, like do you think Meta or do you think Meta or Mistral went all in?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:39:46 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    I, I think, well-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:39:48 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Meta obviously did.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:39:48 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    I think they, they both... Yeah. I think, I think that when I say all in, I mean more like Mistral was, was one of the core ones I’m thinking of, where- ... they were a venture-backed company that, like, had a, a, a fiduciary responsibility to bring in money, but were also trying to release open weight models, uh, for, you know, the West, and for their communities, and for the world. And, um, they tried doing closed versions, and then monetizing off of that. They, they also kind of have more recently, luckily, for all of us, gotten back to their kind of Apache 2.0 roots, and-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:40:30 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Oh, my God.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:40:30 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    And-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:40:30 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Have you seen the download numbers on Mistral 3 Large?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:40:33 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    I haven’t. No, what is it?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:40:35 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Oh, s- no bueno, sir.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:40:38 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Hey.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:40:39 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Carrying on. Sorry.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:40:41 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    But, I mean, yeah, you know-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:40:42 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Um, Mist- the, the Large Instruct model has downloads in the last month. I honestly don’t know what’s going on. Maybe there’s some, like, quantized version out there. I, I was confused.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:40:50 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Maybe. Well, I mean, yeah. But I think that we-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:40:52 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    It’s, it’s hard to get adoption. The competition is insane.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:40:55 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Hmm. Well, that’s, that’s- ... yeah, I mean, and that could be a whole conversation also, is, like, how do you actually get people to use it?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:41:00 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    I was gonna ask you, like, how do you get people... How do you get people to- - really sell into this? You said you’re good at it.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:41:06 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, I think that the-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:41:08 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Continue your point, we can come back to it.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:41:11 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    No, no, but they... I think they all kind of tie into it, is, is... We knew that the, the market was there for, for custom models. It was two years ago, frankly, and it’s even more so now, because RL has drastically, uh, increased the areas that you can hill climb and become really powerful with a tiny model. Um, and but, but also, people are beginning to see how powerful, you know, uh, te- uh, cust- or, or training in a, a, a product is. Like, you see Claude Code, you see Codex, you see, um... I think Deep Research was kind of one of the first ones that really kind of opened my eyes to what was possible, when you kind of are kind of training in the same environment that you’re serving your users. So we knew that, that people wanted it. We’d, we’d had good success with, with customers in the past using other people’s open models. So, um, it was less of a question of, like, could we monetize it, or will we? And it was just a matter of, um, could we get a model, you know, that pe- that, that we would feel that, you know, given a, a wide suite of basically being able to pick any model in the world, would, would our researchers and, and would our teams re- reach towards our own? And, uh, luckily, I think we’re there. Um, on, on the-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:42:31 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Uh
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:42:31 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    ... on the topic of, like, how do you get people to use it? How do you get adoption? You know, I’ve never wanted Trinity, uh, or our biggest advertising thing to be, like, US. You know-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:42:45 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, I know
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:42:45 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    ... like, if, if your entire-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:42:47 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    I know, man, it hurts me.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:42:48 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, if your-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:42:48 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    I spent months reckoning with this.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:42:50 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. If, if your entire, uh, you know, value prop is that you’re an American company-... great, but ultimately people are gonna use the best. Um, and so I think that we’re gonna be able to serve and, and the people like that need a US-based model because their compliance or legal teams won’t let them use something out of China, it’s gonna be a fantastic option. But I think, you know, kind of the next phase of what we’re doing as a company is, all right, now we’ve, we’ve proved to ourselves and maybe the, the wider industry that like we deserve to be in the conversation, and we can train models of this scale. Um, then it’s like, okay, how do we train the best one? Uh, ‘cause really, I mean, people’s loyalties are very fickle, and, and, yeah, you, you go to what’s the best. I guess it’s like, how much do you think
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:43:41 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    you’ve learned about being able to tune a model narrowly by going and building the whole stack? Um, something we talk about is like ability- ... to specialize models, and I kind of, of opinion that you just make a better general model right now ‘cause the pace of progress is so high. And but the question is like, can we tune a OLMO that’s very good at science or something? And I- ... w-would guess that training the entire model, you’re going to be able to actually do a better job at what you were doing, but I don’t know how to articulate why or what that looks like.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:44:18 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Um, I mean, the, the, the simplest answer to that being yes is just that... or the simplest reason why that’s the answer to the question is yes, is because we know what went into the model. Like, we know what it actually saw at the later stages of training during the decay. Um, and so that all- that helps influence, A, what are we tr- what kind of data and what topics and, and what format are we giving these models, uh, in post-training? But it also allows you to know like, okay, where, where do I absolutely wanna crank, you know, how, how many- how much of this, say, 230 billion dataset, do we want it to be math or, or, or, or coding? And a lot of that’s influenced by what you’re able to put in-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:45:06 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    How, how much of your post-training-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:45:07 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    ... post-training
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:45:07 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    -do you expect to redo? Like, uh, how much can you say about when you’re serving something on-prem? Um, you- you’re not gonna redo the pre-training. You might, for a very big customer, redo mid-training or do continued pre-training- ... in which, in that case, you do need the pre-training data to keep, keep it being stable. Which is a use case where like I’m- I would love to see a paper that’s like, “Because of OLMO being open, we continued to pre-train on biology, and we mixed half of their exact mid-training dataset in with our dataset, and it, and it worked,” yadi, yadi. Like, you could obviously- ... do that, but how much do you think is gonna be like the standard, you fine-tune the last instruct model, or do- are you gonna have to retouch the post-training for a customer? Because that, like, I, I really feel like-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:45:48 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Um
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:45:48 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    ... it’s just at the end.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:45:50 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    It, I think, I think-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:45:50 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    But it would be fun if you had to change it.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:45:52 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    For the most part, um, I think a lot of tasks will be fine just starting from our, our, our, po- uh, like the released, you know, official post-trained version. Um, now, that’s for maybe simpler tasks, is the wrong way to frame it, but if it’s like, “Oh, hey, we’re doing a deep search agent. We want it to do 30 calls and, before...” That would be a good use for just starting with the finished model that we released that’s already post-trained. Now, if we’re going into something along the lines of, um, a very low-resource programming language or, um, something that it didn’t see a lot of in, in, in pre-training, um, or it’s kind of like a, you know, we’re wanting to train this thing to be really good at humanities last exam, but tools. Um, once we get into the world where we’re having to, especially... Actually, I have a much better answer to this question as I was thinking through it, but most of that holds the same. I think that the, the, the world where we’re gonna be doing a lot of extra instruct and, and SFT and, and post-training is gonna be when we’re trying to distill capabilities from large, like into mini or nano. So say like, oh, you know, this large is, is, is really great at invoice processing, but it’s also 400b, and the, you know, the company doesn’t wanna be hosting that on-prem, you know-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:47:24 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Ah
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:47:24 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    ... let’s go out generate a new one.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:47:25 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Do you have costs off the top of your head for, like, what the hosting costs are for each of the model? Like, do people... Are people all gonna host these models in the same way, or is there actually-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:47:32 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Uh
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:47:32 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    ... a wide variance? And if you have, like, the same three models- ... do almost all of your customers end up hosting the same way, or do you end up doing a lot of, like, how do you configure the model to fit in the right hosting for them? Like, is that part of-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:47:44 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    It depends
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:47:44 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    ... the business model?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:47:45 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    It, it, it, it kind of... And we tried to move a, a, a little bit further away from that because you get into the risk of being like, like a consultancy, and it’s- that becomes tricky, where there’s not a very clear separation of concern. But, um, for the mo- it would change depending on, were they using AWS? Did they have a commit with Azure? Um, if not, okay, then we, we can go to, you know, someone like Prime Intellect or Parasail and, and get a, you know, maybe a, a cheaper rack of eight. Uh, it just really depended. Uh, there’s quite a bit, um, of, of people that were also serving them, just using, like, Llama CPP. So, like, on CPU-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:48:25 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Uh, is the 400b designed to be, to fit onto one rack of eight 80 big gigabytes in FP8? Is that how you designed it? ‘Cause Llama- ... Llama four, whatever, Llama 405b was the same. It was like one rack in FP8 works pretty well.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:48:41 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    It’ll do- we... well, you’ll be able to get really good throughput, a little bit lower concurrency on a, a rack of eight H100s at FP8, and then for, like, our, you know, what we’re serving, we’re serving them on, uh, a series of H200s, but we’re not doing, like, multi-node inference. Uh, but that’s just to add more, you know, replicas and- ... other kinds of things.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:49:03 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Hopefully, eventually. I think that the-... Do you have anything else to say about selling open models? I think that generally, like, how do you think about the market for AI? ‘Cause I see the market as being so big, but the- with specifically with open models, it’s so hard to measure. I think I’ve started talking to some of the Chinese labs at all- as well, and I like to ask them, like, this is very US-centric and like Fortune 500 or whatever, and it’s just like, who the heck uses these models? I think- I guess another question is, like, what license or do you know the licenses you’re gonna use for the biggest models? And I think they’re, like, you’re, you’re playing with fire ‘cause people can use it for free, obviously, but potentially- ... you’ll get to hear like, “Oh, shit, somebody actually used our model for this.” And I think any successful business, you’re gonna want... You, you, you know that this model is not gonna be very relevant in a year with the pace of progress. So like- ... how do you think about your license decisions?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:49:55 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Uh, we- you know, with the 4.5B, we tried to do like a, like a, a reve- one of those revenue-gated licensing. So it’s like, oh, it’s completely free for you to use for commercial and whatnot, but if you or your company made over, I think it was like $1.7 million last year, then you need to come to us and get a license. And what we ultimately found was like, it, it didn’t... Maybe for some people who are just only trying to train the model, release it on Hugging Face, and then just call it a day, maybe that is a huge requirement. But when so much of our, our, our company is built around, you know, training custom versions of the models, and, and not even just ours, but in general, even before we did pre-training. Like, at the end of the day, i- as long as we were using it, a- and we knew that we were in full control of, of whether- if we really succeed, it’s because we trained the models, we did them well, and we executed on it well. If we fail, it’s because we, uh, didn’t execute, instead of, oh, some company just stopped releasing good open models. Um, so we eventually switched to just Apache 2.0, and Trinity Large is also gonna be Apache 2.0. Um, you know, I’m- I think it is-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:51:23 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    I think this is the right approach. I have a big investor-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:51:25 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, I think it-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:51:25 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Without, without naming other companies, it’s easy- like, raising a lot of money, whe- or being Meta and releasing open models, and do it- and you could release it with non-commercial, and you could get all these, like... You could talk to, I don’t know, fucking Adobe, whoever. Oh, Adobe’s too big. They’ll have good AI. Some... I don’t know, a bank. Bank of America. You could run Llama on Bank of America and make good money on this. But I just feel like the cultural home of open source AI, and I don’t think- it’s impossible to know who wins it, and I don’t think that you’re in the prime position, and I don’t think that it’s easy to win, but you’re doing a thing that aligns with it. It’s the person that just, like, commits to building the models and learning how the ecosystem works, and to rebuild the models based on the feedback th- that you get from people, and to just kind of commit to an evolving process. And if the whole thing works out, there will be a lot of value, and the person who understands it best should be able to learn how to extract said value. And I think that I’m personally, like, sometimes frustrated with Hugging Face, ‘cause I feel like they have sat on that s- a sort of position like this, and they- ... haven’t figured it out. Not that it is easy to figure it out, but I think that has to be the ideal of open source AI, of like, if it’s really gonna work, that’s, that’s what I hope it looks like. And it’s like, I, I don’皮 know, maybe you guys could do some of that. Like, I have a question of like, could you figure out how to make models that are more fine-tunable- ... after all this post-training? Because you need to sell it to a- you need- ... you, you know the customer’s not gonna want it off the shelf. And I don’t know how to train to post-training to make sure that you don’t, you don’t cook it. Maybe you just learn that you need to warm up the model in a l- in the right way, and you just learn the technique of training downstream. But when you talk to people doing research, the different base models have such different characteristics. I think one of them is character training. I did this paper, and the guy was like: “Qwen and OLMo love their character,” and I’m like, “I have no idea why.” And but it’s like Llama and Gemma, you can change them so much. And I’m like, “Dog, like, please figure out why this is the case.” And for one thing, it’s really cool, but also, like, in your case, that would unlock a lot of value to be like, we know exactly what the model’s gonna do, and we know exactly how to change it. So.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:53:35 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:53:36 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Uh
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:53:36 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    ... it, it, that’s- no, you’re, you’re, you’re right on the money. I think that even, uh, going into the post-training at large, we, uh, one of our researchers came out with, like, a pretty cool, um, experiment and ablation run that they did on drastically reducing catastrophic forgetting. And I almo- I mean, this was, like, three days before we were gonna start doing SFT, and then we ultimately just... I, I ended up pausing on it because it was just throwing something in that wasn’t tested. But, um, yeah, I think-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:54:08 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    A good research lead. You did the right thing.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:54:10 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, I think, I think one of the most important things long term, you know, as we look at kind of what our research priorities are for this year is, is there’s obviously just how to scale RL and, and make these- the end result of the model as good in as many situations as possible. Um, but I think the other half of that is, you know, how do we make the, the, the speed and efficiency and, and performance of customizing them as, as fast as possible, and as easy as possible.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:54:42 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. Do you learn in making open models from your experience just kind of running these open software things in MergeKit and DistillKit? I know there was a whole license journey on one of those as well.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:54:52 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, DistillKit.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:54:52 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Do you feel like they’re kind of isolated?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:54:54 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Or MergeKit. Um, yeah, I mean, I think so. I think that, that, um, you kind of have to play the tape out. With MergeKit-... it was by far our most popular piece of software we’d ever released, but it was so popular because it took something that isn’t fundamentally very complicated, but we ma- but it’s time-consuming, and standardization is great for things like that, and we made it, uh, you know, streamlined and easy to do and fast, and you could experiment and ablate really quickly for, you know. And, and so I, I think that when we switched that to, like, a, you know, a, a similar, uh, revenue-based licensing, like, it, it didn’t end up having the value prop that was important because are you gonna pay Arcee, you know, thousands of dollars, or are you just gonna have one of your researchers-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:55:52 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    You’re gonna have clone code in a week, right?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:55:52 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    recreate it in a week, right? Yeah, so it’s-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:55:55 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    In a day.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:55:55 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    It’s, it’s kind of... It, it’s remi- it’s remembering like, okay, what is- what problem is this solving, and is this even a prob... Like, is the solution to this monetizable? Um, and so MergeGit, we brought it back to the original license, but I think with even viewing the models in the same way, it’s like it’s... Open source is an unbelievable marketing tactic. Like, there’s no one would care about Arcee if we weren’t open sourcing stuff, ‘cause as soon as you do something closed source, if you’re not the best or the cheapest for your price point, I mean, your performance point, no one’s gonna use it. Because-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:56:30 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Um, another question on this. Um, do you think that open models are kind of at a disadvantage when progress is so high? Because it’s potentially easier to swap APIs than open model configurations, especially if, like, model weights are changing sizes or something like this. Where it’s like, “Oh, I can just upgrade to the new Opus, and I do this.” Like, does that, like, uh, decentivize people from using it? Or do you think most of the people are like: “I can only use open models, therefore, I’m gonna use open models?”
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:56:56 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Uh, I think for the people who are using, like, s- either self-hosted or, you know, um, uh, bespoke, uh, you know, engines to, to run it, where they have complete... You know, in a VPC or they have complete control over, like, data in and out, egress, ingress. I don’t think that’s really gonna be so much of a problem because they’re obviously doing it for a reason. Um, like, they’re either for privacy or security or, or HIPAA or SOC 2. For whatever reason they’re doing it, um, I, I don’t think that that’ll be, um, so much of a blocker, but I definitely do think that, um, you know, by far, e- even, even with some of the, the larger open... You know, like inference players, like Together and Fireworks, that, that host a lot of open models. Like, being feature- being on feature parity with a lot of these, these larger labs’ APIs is gonna be extremely important, um, o- of being able to serve, you know, um, with features that they’re used to, like prompt caching, that kind of stuff.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:58:03 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, are- like, I, I think I saw that you guys are setting up an API as well. Is that kind of what the vision there is, is being able to o- offer parity at least, or, like, make it easy for people to consider it?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:58:13 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    I think so. I, I- we’re- we very... Yeah, we are doing our own API. We are hosting it. Um, we haven’t- we, we push a lot of that through Open Router just because it’s such a great place to get, like, discovered. Um, as... If we see, like, tremendous growth there, that would obviously be where we’ll, we’ll invest very heavily. Um, whereas the right move might be to let other people host it, and we invest super hard on the infra for, like, make- taking advantage of the models, um, and, and customizing them. There’s, there’s, there’s a few avenues we have ahead of us then, and we have, you know, projects going kind of toward to poke at each one. Um, and we’re just kinda getting as much data as we can before we... I mean, we’re gonna have to go all in on another direction soon. Not, not like pivoting away from pre-training, but now that we’ve done that, now w- what’s the next big bet we’re gonna make, and how do we go fully into that? So we’re trying to figure out what that is.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:59:12 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. My two last kind of, like, real questions are, like, one is... I guess I can start with, like, where do you see the open model ecosystem? Do you think- where would you see it changing substantially in the next six or twelve months? I, like... Or, or do you? Or you just kinda think we’re marching along for a while?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    00:59:31 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    No, I think we’ll, I think we’ll, we’ll be... I, I, I don’t think it’s an unrealistic prediction to make that by the end of 2026, like, the best model in the world is, is some degree of open. Uh, I think that’s very, very possible, especially with, like, what I’ve seen GLM and, and MiniMax do recently. Um, they have started to find that secret sauce that takes you out of just being good on benchmarks and, like, genuinely useful in people’s day-to-day workflows. And, um, I wouldn’t- like, if, if I, you know, came back, and I... Someone came from the future and told me that the best model in the world was, uh, an open-weight model, I wouldn’t be surprised. I actually think we’re on a, a, a super good trajectory, and, and, and fostering and, and promoting that kind of work and adoption here in the United States is gonna be extremely important.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:00:24 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    And where do you see the company going? ‘Cause like, like, I have my guess. Like, you kind of hopefully-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:00:31 Mark McQuade:
   &lt;/strong&gt;
   &lt;span&gt;
    What’s, what’s your guess? I wanna hear your guess.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:00:31 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Um, you can hopefully do a mix and kind of oscillate into trading when you get... Like, you need to start having the feedback of the real world. I think that’s obvious. Like, it’s o- like, it’s... Well, obviously, you need to make money to survive as a company, but then you need to start using that as the feedback to guide training. And then it’s like, you need to figure out how to balance and do some of them at each time, and you can plan your cluster at different times, and then you kind of... Hopefully, they become a, a loop across each other, and they kind of make it so obvious of why you each need them, ‘cause it, it seems somewhat natural.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:01:03 Mark McQuade:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, I mean, exactly. You know, you kinda hit, hit it right on the head. Um, you know, getting feedback and then kinda steering the ship from there, um, is, is probably-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:01:15 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    ... exactly what we’ll do, but we have a good idea already. I mean, first and foremost, you know, we talked about it earlier, w- we’ve spent a tremendous amount of money. So, uh, we need to go raise some money after we - after we get, you know... We need people to back the, the, the mission and the vision of US open source and, and, you know, so, um, because, uh, you know, we, i- i- Lucas had mentioned about, like, MergeKit and how we flopped the license and, you know. I mean, we’re a smaller-sized start-up. We have-- we’re-- we gotta think of kinda unique ways to try and generate revenue because we don’t have the money of the large labs. So, uh-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:01:52 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Well, I think it’s a benefit to the employee. I think a lot of these labs have over-raised.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:01:56 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, I like, uh- uh, I-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:01:57 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    OpenAI, Anthropic, and all of them are fine. Like, with the OpenAI, Anthropic, Cursor scale, like, let it rip. They should, they should really rip the raising. But all the other companies that are stuck at the, like, the one to two billion range without, like, obvious traction, like, the risk goes to the... I mean, you could-- a lot of them do secondary, so a lot of the founders get out. But it’s like, the risk is the employees get nothing.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:02:21 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:02:22 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    There is a lot of money, but that’s also why I like the approach, ‘cause it’s like, “Oh, you’re doing the actual start-up thing.”
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:02:28 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, yeah. Yeah, I mean, I think... W- what I was gonna add to what Mark... is just like, what- whatever we do from, uh, uh, uh, scaling and, and speeding things up and growing, um, my goal is to keep our research and engineering teams pretty small. I think, I think that one of the reasons we’ve been able to, to move as quickly as we have is it’s been, like, a small group of, like, highly intelligent, smart, and opinionated people sitting in a room, debating in good faith on decisions. And I think that that’s, uh, uh, under the constraints of, “Hey, we don’t have five hundred million dollars to go and, you know, to rip on, on, you know, X, Y, and Z.” So and I think that’s kind of where creativity comes from, and I think that fostering a culture like that over time is how you can kind of make it so that excellence is less of like a, um, an accident, and it’s actually, like, a by-product of the way that you work. So, so we’re gonna stay small, we’re gonna stay lean, but, um, I, I do think that, like, the, the major, um, kind of challenge for us over the next probably six months, beyond any other models we might have, kind of, uh, think or we’re thinking about, is, is getting up to, like, post-training parity with the likes of DeepSeek, and GLM, Qwen, and others.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:03:47 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. I, I hear lots of horror stories about this, where it’s usually and-- it’s-- you end up having people that are going after different important abilities, but, uh, like, doing each of the abilities alone is pretty easy to hill climb, but then you just end up with such a mess. It’s like you’re- ... building a custom puzzle, and you’re building all these custom pieces, and they’re magnificent, and then you’d have to, like, pick up these pieces and assemble this unknown thing at the end. And it’s like-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:04:12 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Like they didn’t have the same designer, right? Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:04:15 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    As AI2 is barely scratching the surface of this. Like, you talk to the people at the frontier labs, and it’s like, holy cow, like, post-training is really the Wild West. But a lot of it works. I think, like, we find-- like, even like model merging gives a ton of performance across the whole- ... training pipeline. It’s like- ... you merge at pre-- you merge after each pre-training stage, you merge in post-training. It’s like-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:04:35 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Roon can tell you.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:04:36 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    But merging post-training becomes a lot more complicated because you- ... can have all these domains and things, uh.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:04:41 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Well, in, in merging, you know, it, it actually, it used to be very YOLO, um, the way we used to do it, and, and Charles, who, who created MergeKit, I call him, like, chief alchemist, and, like, you’d kinda just send him ten promising checkpoints, and he’d come back a day later with, like, some insane, you know, model that was really good at all of them. And, and you can’t do that as much in post-training anymore because of, uh, of just the, the formatting and the way that RL is done. Like, you do have to be a little bit more surgical about it, but yeah, everyone can tell you, like, any time we start to see anything worrisome at all in training or, or, or even something going really good, you know, “Lucas, what do we do?” I’m like: Merge it. I’m like, just-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:05:21 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Merge.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:05:21 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    ... I’m like: “Just take it, just merge it. Let’s see.” And more often than not, it fixes it, so...
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:05:27 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Um, do you merge during RL? Like, you could just, like, merge the last few checkpoints and resume or something?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:05:32 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    We’ve ex-- we’ve, we’ve dabbled in that, not, not for what we’ve done. You know, again, a, a lot of the, the mini, nano, and large story for Trinity is, like, getting to a level of... what was my level of complexity I was comfortable with us undertaking, and then, uh, not introducing anything more. So, um, not yet. But we, I mean, we, we, uh, regularly merged. We didn’t do it for LARP, but we used to merge a lot, um, during just, like, your standard, uh, um... When we’d do, like, RLHF, we used to do a bunch of merging. We’d do it, like, every five checkpoints. We would-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:06:11 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Online RLHF or D-DPO?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:06:13 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    There’s DPO.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:06:15 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. It’s so much easier to get started. One of my goals is to have somebody figure out how to do actual online RLHF, pure LM feedback, obviously, for scaling. But it’s just like- ... it’s, it’s unsavory to it’s just, like, doesn’t look like DPO-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:06:28 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, I mean, if, if, you know, if GRPO and kind of op-- in, in the, the present day RL regime, like, if that hadn’t materialized when it did, I think that would’ve been a big topic in 2025. But I do think that, you know, GRPO and just the overall, um, DeepSeek and o1 style reasoning and thinking and RL kind of... Any, a- any person who is thinking of doing that for, like, performance reasons, realize that there was something that had fifty thousand papers released every day on how to do it. Um- ... that was kind of probably right where you’d get the same amount of performance.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:07:07 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Um, do you force dog feeding? Do you make yourself-- do you guys use your own models to understand them? Like, do you, like, make that a thing?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:07:14 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Uh, Mini was the first one we could actually start doing that with, um, a- at least for, uh, a more general day-to-day tasks. So a lot of our, like, internal Slack, we have stuff that, like, monitors Twitter and LinkedIn for feedback on Trinity and, and, and that kind of stuff. That all runs on Trinity Mini now. Um, and then, uh-... you know, we, we put a good amount of work into, into large being, um, you know, good in, in a bunch of your, like, OpenCode and, and Cline, uh, and, and Kilo Code. So, um-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:07:45 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Uh, what does that, what does that work look like?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:07:49 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Uh, working with those guys to get data. And then, um-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:07:53 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    That’s, I mean- Good for me to know.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:07:55 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    I mean-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:07:55 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    I should do that, I guess.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:07:58 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. Yeah, working with, uh... Or, or I mean, it- the way it started was us, like, using open models and then, like, passing those through as the base URL, and then, like, getting the logs from that. Um, and then realizing that, like, that translated pretty well. Um, and then over time, obviously turning this-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:08:16 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Um, can you expand on this? So I was gonna ask you-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:08:19 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    So-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:08:19 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    -if you’re, like, using these open models regularly, ‘cause I, I’m just, like, Claude Code psychosis, man. I’m like, “Can’t take that away from me.”
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:08:26 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, I, I use, I use four... I’ve used 4.7 a lot. I think 4.7 from GLM was one of the first ones that could replace a lot of my day-to-day. Uh, I’ll still reach for Claude Code or even 5.2 Pro if it’s, if it’s, like, something that’s, like, really... I- if I do not know how to measure what success looks like for something, I’ll usually use those. Um, but, uh, yeah, I mean, it, it- even using DeepSeek before, um, kind of their May update was hit or miss. But, um, yeah, w- the reason I decided to, like, start talking to these people and working on, like, how can we get data and, and start making our models good in these systems was I would use them. I had a, um, you know, something that would grab the logs, like, it, you know, inter- as a proxy, so it’d like grab the logs and then format them in the messages format. And then I saw that and went, “Yeah, that’s... You can make a pretty good filter for just, like, standard stuff that you don’t want, and kind of hit a scale.”
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:09:30 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, it makes sense. So, so you’re like, uh, open code will let you look at the data, and then you’re probably gonna get a sense for... Like, I don’t even actually know how the, on the back end, the code agents in open code format data, which I think is actually something I should just go look at, ‘cause then you can design around.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:09:44 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Uh, they’re all different. Yeah. Yeah, but you just have to- you just- basically, it all starts from like, what do you want your format to be? And then how can you take what, what those look like to, you know, to... How do you force it into that? The hard thing, though, is, is with newer models like MiniMax and 4.7, the way they do interleaved thinking is, is like... You know, I’m a big believer in post-training. Like, if you’re gonna do interleaved thinking, like, every sample in your data set should be that. Um, it, you know, it should follow that same format and that same behavior. So, um, that gets tricky if you’re trying to, like, take a bunch of Nemo tr... Or, or, or, well, like, uh, DeepSeek data and Qwen data, and then, oh, we’re also trying to mix in MiniMax, and at that point, you’re- it, it gets really difficult ‘cause they all handle thinking slightly differently.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:10:34 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, I can buy this. Um, okay, this was fun. Any last predictions or things you want people to know about the model? I will say that, um, when you debuted the Trinity models, you had a great blog post that was very to the point, that covered a lot of this. So I’ll definitely link to the, um, what is it? The Trinity manifesto. I enjoyed reading it. So I’ll link to that in the show notes, and, oh, hopefully you have a new one for me to read when you’re done with the model.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:10:58 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, we’ll do- we will have a tech report. We’ll have a tech report for you, too. So we, we never, we never did a tech report for 4.5B Mini or Nano because we were so focused on just getting to large, but we also thought it’d be very interesting to write it under the, the... How do you go from 4.5B to a 400B MoE in six months, and, like, what did we learn-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:11:19 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    That’s right
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:11:19 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    ... when you’re viewing it as a whole, so.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:11:21 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    That’s about the timeframe that, um, Ant Ling took, too, as well. Ant Ling, uh, the anchor, we talked about, they’re like... It took us about six months to do, um, Ring-1T and their 1T models, which, like, it sounds like a lot more, but I think that’s about the same. It, it depends on compute and configs and stuff to go from, like- ... basic modeling to big MoE, which is pretty interesting to see a lot of people speedrun this sort of thing.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:11:46 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, it’s, it’s a really, uh... It is a logistical nightmare, but, like, I think everyone on the team has had a tremendous amount of fun over the last, uh, six months. So now the fun begins.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:11:58 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. Congrats on the milestone. Congrats on the model existing. That has gotta be an almighty relief, and I’ll look forward- ... to see what you all are up to soon. I’ll stop by at some point next time I’m in the Bay.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:12:10 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. Yeah, come by. Yeah, come by.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:12:12 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Thanks for-
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:12:12 Lucas Atkins:
   &lt;/strong&gt;
   &lt;span&gt;
    Thanks for having us.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    01:12:14 Nathan Lambert:
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. Thanks, guys.
   &lt;/span&gt;
  &lt;/p&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Get Good at Agents </title>
<link>https://www.interconnects.ai/p/get-good-at-agents</link>
<pubDate>Wed, 21 Jan 2026 17:05:15 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    Two weeks ago, I wrote a
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/claude-code-hits-different&quot; rel=&quot;&quot;&gt;
    review
   &lt;/a&gt;
   &lt;span&gt;
    of how Claude Code is taking the AI world by storm, saying that “software engineering is going to look very different by the end of 2026.&quot;  That article captured the power of Claude as a tool and a product, and I still stand by it, but it undersold the changes that are coming in
   &lt;/span&gt;
   &lt;em&gt;
    how
   &lt;/em&gt;
   &lt;span&gt;
    we use these products in careers that interface with software.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The more personal angle was how “I’d rather do my work if it fits the Claude form factor, and soon I’ll modify my approaches so that Claude will be able to help.” Since writing that, I’m stuck with a growing sense that taking my approach to work from the last few years and applying it to working with agents is fundamentally wrong. Today’s habits in the era of agents would limit the uplift I get by micromanaging them too much, tiring myself out, and setting the agents on too small of tasks. What would be better is more open ended, more ambitious, more asynchronous.
  &lt;/p&gt;
  &lt;p&gt;
   I don’t yet know what to prescribe myself, but I know the direction to go, and I know that searching is my job.  It seems like the direction will involve working less, spending more time cultivating peace, so the brain can do its best directing — let the agents do most of the hard work.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Since trying Claude Code with Opus 4.5, my work life has shifted closer to trying to adapt to a new way of working with agents. This new style of work feels like a larger shift than the era of learning to work with chat-based AI assistants. ChatGPT let me instantly get relevant information or a potential solution to the problems I was already working on. Claude Code has me considering
   &lt;/span&gt;
   &lt;em&gt;
    what should I work on
   &lt;/em&gt;
   &lt;span&gt;
    now that I know I can have AI independently solve or implement many sub-components.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Every engineer needs to learn how to design systems. Every researcher needs to learn how to run a lab. Agents push the humans up the org chart.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/get-good-at-agents?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/get-good-at-agents?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I feel like I have an advantage by being early to this wave, but no longer feel like just working hard will be an lasting edge. When I can have multiple agents working productively in parallel on my projects, my role is shifting more to pointing the army rather than using the power-tool. Pointing the agents more effectively is far more useful than me spending a few more hours grinding on a problem.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    My default workflow now is GPT 5 Pro for planning, Claude Code with Opus 4.5 for implementation. I often have Claude Code pass information back to GPT 5 Pro for a deep search when stuck with a very detailed prompt. Codex with GPT 5.2 on xhigh thinking effort alone feels very capable, more meticulous than Claude even, but I haven’t yet figured out how to get the best out of it. GPT Pro feels itself to be a strong agent trapped in the wrong UX — it needs to be able to think longer and have a place to work on research tasks.
   &lt;/span&gt;
   &lt;span data-state=&quot;closed&quot;&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/get-good-at-agents#footnote-1-185261187&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     1
    &lt;/a&gt;
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    It seems like all of my friends (including the nominally “non-technical” ones) have accepted that Claude can rapidly build incredible, bespoke software for you. Claude updated one of my
   &lt;/span&gt;
   &lt;a href=&quot;https://github.com/allenai/reward-bench/pull/259&quot; rel=&quot;&quot;&gt;
    old research projects
   &lt;/a&gt;
   &lt;span&gt;
    to
   &lt;/span&gt;
   &lt;code&gt;
    uv
   &lt;/code&gt;
   &lt;span&gt;
    so it’s easier to maintain, made a verification bot for my
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/discord&quot; rel=&quot;&quot;&gt;
    Discord
   &lt;/a&gt;
   &lt;span&gt;
    , crafted
   &lt;/span&gt;
   &lt;a href=&quot;https://github.com/natolambert/rlhf-book/tree/main/diagrams&quot; rel=&quot;&quot;&gt;
    numerous figures for my RLHF book
   &lt;/a&gt;
   &lt;span&gt;
    , feels close to landing a substantial feature in our
   &lt;/span&gt;
   &lt;a href=&quot;https://github.com/allenai/open-instruct/pull/1387&quot; rel=&quot;&quot;&gt;
    RL research codebase
   &lt;/a&gt;
   &lt;span&gt;
    , and did countless other tasks that would’ve taken me days. It’s the thing de jour — tell your friends and family what trinket you built with Claude. It undersells what’s coming.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I’ve taken to leaving Claude Code instances running on my DGX Spark trying to implement new features in our RL codebase when I’m at dinner or work. They make mistakes, they catch most of their own mistakes, and they’re fairly slow too, but they’re capable. I can’t wait to go home and check on what my Claudes were up to.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
   The feeling that I can’t shake is a deep urgency to move my agents from working on toy software to doing meaningful long-term tasks. We know Claude can do hours, days, or weeks, of fun work for us, but how do we stack these bricks into coherent long-term projects? This is the crucial skill for the next era of work.
  &lt;/p&gt;
  &lt;p&gt;
   There are no hints or guides on working with agents at the frontier — the only way is to play with them. Instead of using them for cleanup, give them one of your hardest tasks and see what it gets stuck on, see what you can use it for.
  &lt;/p&gt;
  &lt;p&gt;
   Software is becoming free, good decision making in research, design, and product has never been so valuable.
  &lt;/p&gt;
  &lt;p&gt;
   Being good at using AI today is a better moat than working hard.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;hr/&gt;
  &lt;/div&gt;
  &lt;p&gt;
   Here are a collection of pieces that I feel like suitably grapple with the coming wave or detail real practices for using agents. It’s rare that so many of the thinkers in the AI space that I respect are all fixated on a single new tool, a transition period, and a feeling of immense change:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;em&gt;
      &lt;a href=&quot;https://importai.substack.com/p/import-ai-441-my-agents-are-working&quot; rel=&quot;&quot;&gt;
       Import AI 441: My agents are working. Are yours?
      &lt;/a&gt;
     &lt;/em&gt;
     &lt;span&gt;
      This helped me motivate to write this and focus on how important of a moment this is.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span data-state=&quot;closed&quot;&gt;
      &lt;a data-attrs=&#x27;{&quot;name&quot;:&quot;Steve Newman&quot;,&quot;id&quot;:14528593,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!aqEf!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4bfd3306-345f-45ea-a76a-5c3740a62f87_800x800.jpeg&quot;,&quot;uuid&quot;:&quot;ae01be2c-a87d-4aca-be1e-9af4bf57da48&quot;}&#x27; data-component-name=&quot;MentionUser&quot; href=&quot;https://open.substack.com/users/14528593-steve-newman?utm_source=mentions&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;
       Steve Newman
      &lt;/a&gt;
     &lt;/span&gt;
     &lt;span&gt;
      on
     &lt;/span&gt;
     &lt;a href=&quot;https://secondthoughts.ai/p/hyperproductivity&quot; rel=&quot;&quot;&gt;
      Hyperproductivity
     &lt;/a&gt;
     &lt;span&gt;
      with AI coding agents — importantly written
     &lt;/span&gt;
     &lt;em&gt;
      before
     &lt;/em&gt;
     &lt;span&gt;
      Claude Opus 4.5, which was a major step change.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Tim Dettmers on working with agents:
     &lt;/span&gt;
     &lt;em&gt;
      &lt;a href=&quot;https://timdettmers.com/2026/01/13/use-agents-or-be-left-behind/&quot; rel=&quot;&quot;&gt;
       Use Agents or Be Left Behind?
      &lt;/a&gt;
     &lt;/em&gt;
     &lt;a href=&quot;https://timdettmers.com/2026/01/13/use-agents-or-be-left-behind/&quot; rel=&quot;&quot;&gt;
     &lt;/a&gt;
     &lt;span&gt;
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Steve Yegge
     &lt;/span&gt;
     &lt;a href=&quot;https://www.youtube.com/watch?v=zuJyJP517Uw&quot; rel=&quot;&quot;&gt;
      on Latent Space on vibe coding
     &lt;/a&gt;
     &lt;span&gt;
      (and how you’ll be left behind if you don’t understand how to do it).
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span data-state=&quot;closed&quot;&gt;
      &lt;a data-attrs=&#x27;{&quot;name&quot;:&quot;Dean W. Ball&quot;,&quot;id&quot;:5925551,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!mLaj!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49371abf-2579-47be-8114-3e0ca580af8b_1024x1024.png&quot;,&quot;uuid&quot;:&quot;f2a252b7-e597-409d-8cfe-264255a39ae1&quot;}&#x27; data-component-name=&quot;MentionUser&quot; href=&quot;https://open.substack.com/users/5925551-dean-w-ball?utm_source=mentions&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;
       Dean W. Ball
      &lt;/a&gt;
     &lt;/span&gt;
     &lt;span&gt;
      :
     &lt;/span&gt;
     &lt;em&gt;
      &lt;a href=&quot;https://www.hyperdimensional.co/p/among-the-agents&quot; rel=&quot;&quot;&gt;
       Among the Agents
      &lt;/a&gt;
      &lt;span&gt;
       —
      &lt;/span&gt;
     &lt;/em&gt;
     &lt;span&gt;
      why coding agents aren’t just for programmers.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/get-good-at-agents#footnote-anchor-1-185261187&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     &lt;span&gt;
      This cute
     &lt;/span&gt;
     &lt;a href=&quot;https://clawd.bot/&quot; rel=&quot;&quot;&gt;
      Clawd Bot
     &lt;/a&gt;
     &lt;span&gt;
      is very popular, but I haven’t given it a go yet.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Use multiple models </title>
<link>https://www.interconnects.ai/p/use-multiple-models</link>
<pubDate>Sun, 11 Jan 2026 14:02:33 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   I’ll start by explaining my current AI stack and how it’s changed in recent months. For chat, I’m using a mix of:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      GPT 5.2 Thinking / Pro
     &lt;/strong&gt;
     &lt;span&gt;
      : My most frequent AI use is getting information. This is often a detail about a paper I’m remembering, a method I’m verifying for my
     &lt;/span&gt;
     &lt;a href=&quot;https://rlhfbook.com/&quot; rel=&quot;&quot;&gt;
      RLHF Book
     &lt;/a&gt;
     &lt;span&gt;
      , or some other niche fact. I know GPT 5.2 can find it if it exists, and I use Thinking for queries that I think are easier and Pro when I want to make sure the answer is right. Particularly GPT Pro has been the indisputable king for research for quite some time — Simon Willison’s coining of it as his “
     &lt;/span&gt;
     &lt;a href=&quot;https://simonwillison.net/2025/Sep/6/research-goblin/&quot; rel=&quot;&quot;&gt;
      research goblin
     &lt;/a&gt;
     &lt;span&gt;
      ” still feels right.
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      I never use GPT 5 without thinking or other OpenAI chat models. Maybe I need to invest more in custom instructions, but the non-thinking models always come across a bit sloppy relative to the competition out there and I quickly churn. I’ve heard gossip that the Thinking and non-Thinking GPT models are even developed by different teams, so it would make sense that they can end up being meaningfully different.
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      I also rarely use Deep Research from any provider, opting for GPT 5.2 Pro and more specific instructions. In the first half of 2025 I almost exclusively used ChatGPT’s thinking models — Anthropic and Google have done good work to win back some of my attention.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Claude 4.5 Opus
     &lt;/strong&gt;
     &lt;span&gt;
      : Chatting with Claude is where I go for basic code questions, visualizing simple data, and getting richer feedback on my work or decisions. Opus’s tone is particularly refreshing when trying to push the models a bit (in a way that GPT 4.5 used to provide for me, as I was a power user of that model in H1 2025). Claude Opus 4.5 isn’t particularly fast relative to a lot of models out there, but when you’re used to using the GPT Thinking models like me, it feels way faster (even with extended thinking always on, as I do) and sufficient for this type of work.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Gemini 3 Pro
     &lt;/strong&gt;
     &lt;span&gt;
      : Gemini is for everything else — explaining concepts I know are well covered in the training data (and minor hallucinations are okay, e.g. my former Google rabbit holes), multimodality, and sometimes very long-context capabilities (but GPT 5.2 Thinking took a big step here, so it’s a bit closer). I still open and use the Gemini app regularly, but it’s a bit less locked-in than the other two.
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;p&gt;
     &lt;br/&gt;
     &lt;span&gt;
      Relative to ChatGPT, sometimes I feel like the search mode of Gemini is a bit off. It could be a product decision with how the information is presented to the user, but GPT’s thorough, repeated search over multiple sources instills a confidence I don’t get from Gemini for recent or research information.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Grok 4:
     &lt;/strong&gt;
     &lt;span&gt;
      I use Grok ~monthly to try and find some piece of AI news or Alpha I recall from browsing X. Grok is likely underrated in terms of its intelligence (particularly Grok 4 was an impressive technical release), but it hasn’t had sticky product or differentiating features for me.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   &lt;span&gt;
    For images I’m using a mix of mostly
   &lt;/span&gt;
   &lt;strong&gt;
    Nano Banana Pro
   &lt;/strong&gt;
   &lt;span&gt;
    and sometimes
   &lt;/span&gt;
   &lt;strong&gt;
    GPT Image 1.5
   &lt;/strong&gt;
   &lt;span&gt;
    when Gemini can’t quite get it.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    For coding, I’m primarily using
   &lt;/span&gt;
   &lt;strong&gt;
    Claude Opus 4.5
   &lt;/strong&gt;
   &lt;span&gt;
    in Claude Code, but still sometimes find myself needing OpenAI’s Codex or even multi-LLM setups like
   &lt;/span&gt;
   &lt;a href=&quot;https://ampcode.com/&quot; rel=&quot;&quot;&gt;
    Amp
   &lt;/a&gt;
   &lt;span&gt;
    . Over the holiday break, Claude Opus helped me update all the plots for
   &lt;/span&gt;
   &lt;a href=&quot;https://atomproject.ai/&quot; rel=&quot;&quot;&gt;
    The ATOM Project
   &lt;/a&gt;
   &lt;span&gt;
    , which included substantial processing of our raw data from scraping HuggingFace, perform substantive edits for the RLHF Book (where I felt it was a quite good editor when provided with detailed instructions on what it should do), and other side projects and life organization tasks. I recently published a piece explaining my current obsession with Claude Opus 4.5, I recommend you read it if you haven’t had the chance:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div data-attrs=&#x27;{&quot;id&quot;:184040682,&quot;url&quot;:&quot;https://www.interconnects.ai/p/claude-code-hits-different&quot;,&quot;publication_id&quot;:48206,&quot;publication_name&quot;:&quot;Interconnects&quot;,&quot;publication_logo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!djof!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc52e8097-8f3d-4f7e-808b-2f4ad37f3b52_720x720.png&quot;,&quot;title&quot;:&quot;Claude Code Hits Different&quot;,&quot;truncated_body_text&quot;:&quot;There is an incredible amount of hype for Claude Code with Opus 4.5 across the web right now, which I for better or worse entirely agree with. Having used coding agents extensively for the past 6-9 months, where it felt like sometimes OpenAI’s Codex was the best and sometimes Claude, there was some meaningful jump over the last few weeks. The jump is we…&quot;,&quot;date&quot;:&quot;2026-01-09T17:42:09.151Z&quot;,&quot;like_count&quot;:39,&quot;comment_count&quot;:19,&quot;bylines&quot;:[{&quot;id&quot;:10472909,&quot;name&quot;:&quot;Nathan Lambert&quot;,&quot;handle&quot;:&quot;natolambert&quot;,&quot;previous_name&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!RihO!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8fedcdfb-e137-4f6a-9089-a46add6c6242_500x500.jpeg&quot;,&quot;bio&quot;:&quot;ML researcher making sense of AI research, products, and the uncertain technological future. PhD from Berkeley AI. Experience at Meta, DeepMind, HuggingFace.&quot;,&quot;profile_set_up_at&quot;:&quot;2021-04-24T01:19:33.371Z&quot;,&quot;reader_installed_at&quot;:&quot;2022-03-09T17:52:30.690Z&quot;,&quot;publicationUsers&quot;:[{&quot;id&quot;:100753,&quot;user_id&quot;:10472909,&quot;publication_id&quot;:48206,&quot;role&quot;:&quot;admin&quot;,&quot;public&quot;:true,&quot;is_primary&quot;:true,&quot;publication&quot;:{&quot;id&quot;:48206,&quot;name&quot;:&quot;Interconnects&quot;,&quot;subdomain&quot;:&quot;robotic&quot;,&quot;custom_domain&quot;:&quot;www.interconnects.ai&quot;,&quot;custom_domain_optional&quot;:false,&quot;hero_text&quot;:&quot;The cutting edge of AI, from inside the frontier AI labs, minus the hype. The border between high-level and technical thinking. Read by leading engineers, researchers, and investors.&quot;,&quot;logo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c52e8097-8f3d-4f7e-808b-2f4ad37f3b52_720x720.png&quot;,&quot;author_id&quot;:10472909,&quot;primary_user_id&quot;:10472909,&quot;theme_var_background_pop&quot;:&quot;#ff6b00&quot;,&quot;created_at&quot;:&quot;2020-05-21T02:59:47.895Z&quot;,&quot;email_from_name&quot;:&quot;Interconnects by Nathan Lambert&quot;,&quot;copyright&quot;:&quot;Interconnects AI, LLC&quot;,&quot;founding_plan_name&quot;:&quot;Founding Member&quot;,&quot;community_enabled&quot;:true,&quot;invite_only&quot;:false,&quot;payments_state&quot;:&quot;enabled&quot;,&quot;language&quot;:null,&quot;explicit&quot;:false,&quot;homepage_type&quot;:&quot;magaziney&quot;,&quot;is_personal_mode&quot;:false}},{&quot;id&quot;:4610799,&quot;user_id&quot;:10472909,&quot;publication_id&quot;:4519930,&quot;role&quot;:&quot;admin&quot;,&quot;public&quot;:true,&quot;is_primary&quot;:false,&quot;publication&quot;:{&quot;id&quot;:4519930,&quot;name&quot;:&quot;natolambert overflow&quot;,&quot;subdomain&quot;:&quot;natolambert&quot;,&quot;custom_domain&quot;:null,&quot;custom_domain_optional&quot;:false,&quot;hero_text&quot;:&quot;a place for any extra thoughts beyond Interconnects.ai&quot;,&quot;logo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/eb88d599-32c8-49a9-ba33-ab6327aff727_256x256.png&quot;,&quot;author_id&quot;:10472909,&quot;primary_user_id&quot;:null,&quot;theme_var_background_pop&quot;:&quot;#FF6719&quot;,&quot;created_at&quot;:&quot;2025-03-27T15:04:05.448Z&quot;,&quot;email_from_name&quot;:null,&quot;copyright&quot;:&quot;Nathan Lambert&quot;,&quot;founding_plan_name&quot;:null,&quot;community_enabled&quot;:true,&quot;invite_only&quot;:false,&quot;payments_state&quot;:&quot;disabled&quot;,&quot;language&quot;:null,&quot;explicit&quot;:false,&quot;homepage_type&quot;:&quot;newspaper&quot;,&quot;is_personal_mode&quot;:false}},{&quot;id&quot;:4926744,&quot;user_id&quot;:10472909,&quot;publication_id&quot;:4830082,&quot;role&quot;:&quot;admin&quot;,&quot;public&quot;:true,&quot;is_primary&quot;:false,&quot;publication&quot;:{&quot;id&quot;:4830082,&quot;name&quot;:&quot;Retort AI&quot;,&quot;subdomain&quot;:&quot;retortai&quot;,&quot;custom_domain&quot;:&quot;www.retortai.com&quot;,&quot;custom_domain_optional&quot;:false,&quot;hero_text&quot;:&quot;Distilling the major events and challenges in the world of artificial intelligence and machine learning, from Thomas Krendl Gilbert and Nathan Lambert.\n\n&quot;,&quot;logo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cbad298c-6074-441b-ad43-d5df6dbf101d_800x800.png&quot;,&quot;author_id&quot;:10472909,&quot;primary_user_id&quot;:null,&quot;theme_var_background_pop&quot;:&quot;#FF6719&quot;,&quot;created_at&quot;:&quot;2025-04-25T22:10:28.216Z&quot;,&quot;email_from_name&quot;:null,&quot;copyright&quot;:&quot;Nathan Lambert&quot;,&quot;founding_plan_name&quot;:null,&quot;community_enabled&quot;:true,&quot;invite_only&quot;:false,&quot;payments_state&quot;:&quot;disabled&quot;,&quot;language&quot;:null,&quot;explicit&quot;:false,&quot;homepage_type&quot;:&quot;newspaper&quot;,&quot;is_personal_mode&quot;:false}}],&quot;twitter_screen_name&quot;:&quot;natolambert&quot;,&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:100,&quot;status&quot;:{&quot;bestsellerTier&quot;:100,&quot;subscriberTier&quot;:5,&quot;leaderboard&quot;:null,&quot;vip&quot;:false,&quot;badge&quot;:{&quot;type&quot;:&quot;bestseller&quot;,&quot;tier&quot;:100},&quot;paidPublicationIds&quot;:[883883,1084918,6349492,1084089,1915042,69345,6027],&quot;subscriber&quot;:null}}],&quot;utm_campaign&quot;:null,&quot;belowTheFold&quot;:false,&quot;type&quot;:&quot;newsletter&quot;,&quot;language&quot;:&quot;en&quot;}&#x27; data-component-name=&quot;EmbeddedPostToDOM&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/claude-code-hits-different?utm_source=substack&amp;utm_campaign=post_embed&amp;utm_medium=web&quot; native=&quot;true&quot; rel=&quot;&quot;&gt;
    &lt;div&gt;
     &lt;img src=&quot;https://substackcdn.com/image/fetch/$s_!djof!,w_56,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc52e8097-8f3d-4f7e-808b-2f4ad37f3b52_720x720.png&quot;/&gt;
     &lt;span&gt;
      Interconnects
     &lt;/span&gt;
    &lt;/div&gt;
    &lt;div&gt;
     &lt;div&gt;
      Claude Code Hits Different
     &lt;/div&gt;
    &lt;/div&gt;
    &lt;div&gt;
     There is an incredible amount of hype for Claude Code with Opus 4.5 across the web right now, which I for better or worse entirely agree with. Having used coding agents extensively for the past 6-9 months, where it felt like sometimes OpenAI’s Codex was the best and sometimes Claude, there was some meaningful jump over the last few weeks. The jump is we…
    &lt;/div&gt;
    &lt;div&gt;
     &lt;span&gt;
      Read more
     &lt;/span&gt;
    &lt;/div&gt;
    &lt;div&gt;
     2 days ago · 39 likes · 19 comments · Nathan Lambert
    &lt;/div&gt;
   &lt;/a&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    A summary of this is that I pay for the best models and greatly value the marginal intelligence over speed — particularly because, for a lot of the tasks I do, I find that the models are
   &lt;/span&gt;
   &lt;em&gt;
    just
   &lt;/em&gt;
   &lt;span&gt;
    starting to be able to do them well. As these capabilities diffuse in 2026, speed will become more of a determining factor in model selection.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span data-state=&quot;closed&quot;&gt;
    &lt;a data-attrs=&#x27;{&quot;name&quot;:&quot;Peter Wildeford&quot;,&quot;id&quot;:5933616,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe19fc707-675c-45ca-bc5e-22de9b6d4bfa_250x320.png&quot;,&quot;uuid&quot;:&quot;dcde3240-5392-4cab-855f-694fbbdcab9d&quot;}&#x27; data-component-name=&quot;MentionUser&quot; href=&quot;https://open.substack.com/users/5933616-peter-wildeford?utm_source=mentions&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;
     Peter Wildeford
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    had a post on X with a nice graphic that reflected a very similar usage pattern:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/use-multiple-models?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/use-multiple-models?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Across all of these categories, it doesn’t feel like I could get away with just using one of these models without taking a substantial haircut in capabilities. This is a very strong endorsement for the notion of AI being
   &lt;/span&gt;
   &lt;a href=&quot;https://helentoner.substack.com/p/taking-jaggedness-seriously&quot; rel=&quot;&quot;&gt;
    jagged
   &lt;/a&gt;
   &lt;span&gt;
    — i.e. with very strong capabilities spread out unevenly — while also being a bit of an unusual way to need to use a product. Each model is jagged in its own way. Through 2023, 2024, and the earlier days of modern AI, it quite often felt like there was always just one winning model and keeping up was easier. Today, it takes a lot of work and fiddling to make sure you’re not missing out on capabilities.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The working pattern that I’ve formed that most reinforces this using multiple models era is how often my problem with an AI model is solved by passing the same query to a peer model. Models get stuck, some can’t find bugs, some coding agents keep getting stuck on some weird, suboptimal approach, and so on. In these cases, it feels quite common to boot up a peer model or agent and get it to unblock project.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    This multi-model approach or agent-switching happening occasionally would be what I’d expect, but with it happening regularly it means that the models are actually all quite close to being able to solve the tasks I’m throwing at them — they’re just not quite there. The intuition here is that if we view each task as having a probability of success, if said the probability was low for each model, switching would almost always fail. For switching to
   &lt;/span&gt;
   &lt;em&gt;
    regularly
   &lt;/em&gt;
   &lt;span&gt;
    solve the task, each model must have a fairly high probability of success.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   For the time being, it seems like tasks at the frontier of AI capabilities will always keep this model-switching meta, but it’s a moving suite of capabilities. The things I need to switch on now will soon be solved by all the next-generation of models.
  &lt;/p&gt;
  &lt;p&gt;
   I’m very happy with the value I’m getting out of my hundreds of dollars of AI subscriptions, and you should likely consider doing the same if you work in a domain that sounds similar to mine.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
   On the opposite side of the frontier models pushing to make current cutting edge tasks 100% reliable are open models pushing to undercut the price of frontier models. The coding plans on open models tend to cost 10X (or more) less than the frontier lab plans. It’s a boring take, but for the next few years I expect this gap to largely remain steady, where a lot of people get an insane value out of the cutting edge of models. It’ll take longer for the open model undercut to hit the frontier labs, even though from basic principles it looks like a precarious position for them to be in, in terms of costs of R&amp;D and deployment. Open models haven’t been remotely close to Claude 4.5 Opus or GPT 5.2 Thinking in my use.
  &lt;/p&gt;
  &lt;p&gt;
   The other factor is that 2025 gave us all of Deep Research agents, code/CLI agents, search (and Pro) tool use models, and there will almost certainly be new form factors we end up using almost every day in released 2026. Historically, closed labs have been better at shipping new products into the world, but with better open models this should be more diffused, as good product capabilities are very diffuse across the tech ecosystem.  To capitalize on this, you need to invest time (and money) trying all the cutting-edge AI tools you can get your hands on. Don’t be loyal to one provider.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!pt_9!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa87c6753-015d-496a-913c-9fa03b0d14eb_2848x1504.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!pt_9!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa87c6753-015d-496a-913c-9fa03b0d14eb_2848x1504.png 424w, https://substackcdn.com/image/fetch/$s_!pt_9!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa87c6753-015d-496a-913c-9fa03b0d14eb_2848x1504.png 848w, https://substackcdn.com/image/fetch/$s_!pt_9!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa87c6753-015d-496a-913c-9fa03b0d14eb_2848x1504.png 1272w, https://substackcdn.com/image/fetch/$s_!pt_9!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa87c6753-015d-496a-913c-9fa03b0d14eb_2848x1504.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a87c6753-015d-496a-913c-9fa03b0d14eb_2848x1504.png&quot;,&quot;srcNoWatermark&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/265feb30-690d-4064-a5b0-0d98c44ad58e_2848x1504.jpeg&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:769,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2055244,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/183585383?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F265feb30-690d-4064-a5b0-0d98c44ad58e_2848x1504.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;769&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!pt_9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa87c6753-015d-496a-913c-9fa03b0d14eb_2848x1504.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!pt_9!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa87c6753-015d-496a-913c-9fa03b0d14eb_2848x1504.png 424w, https://substackcdn.com/image/fetch/$s_!pt_9!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa87c6753-015d-496a-913c-9fa03b0d14eb_2848x1504.png 848w, https://substackcdn.com/image/fetch/$s_!pt_9!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa87c6753-015d-496a-913c-9fa03b0d14eb_2848x1504.png 1272w, https://substackcdn.com/image/fetch/$s_!pt_9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa87c6753-015d-496a-913c-9fa03b0d14eb_2848x1504.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Claude Code Hits Different </title>
<link>https://www.interconnects.ai/p/claude-code-hits-different</link>
<pubDate>Fri, 09 Jan 2026 17:42:09 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   There is an incredible amount of hype for Claude Code with Opus 4.5 across the web right now, which I for better or worse entirely agree with. Having used coding agents extensively for the past 6-9 months, where it felt like sometimes OpenAI’s Codex was the best and sometimes Claude, there was some meaningful jump over the last few weeks. The jump is well captured by this post, which called it the move of “software creation from an artisanal, craftsman activity to a true industrial process.” Translation: Software is becoming free and human design, specification, and entrepreneurship is the only limiting factor.
  &lt;/p&gt;
  &lt;p&gt;
   What is odd is that this latest Opus model was released on November 24, 2025, and the performance jump in Claude Code seemed to come at least weeks after its integration — I wouldn’t be surprised if a small product change unlocked massive real (or perceived) gains in performance.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
   The joy and excitement I feel when using this latest model in Claude Code is so simple that it necessitates writing about it. It feels right in line with trying ChatGPT for the first time or realizing o3 could find any information I was looking for, but in an entirely new direction. This time, it is the commodification of building. I type and outputs are constructed directly. Claude’s perfect mix of light sycophancy, extreme productivity, and an elegantly crafted application has me coming up with things to do with Claude. I’d rather do my work if it fits the Claude form factor, and soon I’ll modify my approaches so that Claude will be able to help. In a near but obvious future I’ll just manage my Claudes from my phone at the coffee shop.
  &lt;/p&gt;
  &lt;p&gt;
   Where Claude is an excellent model, maybe the best, its product is where the magic happens for building with AI that instills confidence. We could see the interfaces the models are used in being so important to performance, such that Anthropic’s approach with Claude feels like Apple’s integration of hardware, software, and everything in between. This sort of magical experience is not one I expect to be only buildable by Anthropic — they’re just the first to get there.
  &lt;/p&gt;
  &lt;p&gt;
   The fact that Claude makes people want to go back to it is going to create new ways of working with these models and software engineering is going to look very different by the end of 2026. Right now Claude (and other models) can replicate the most-used software fairly easily. We’re in a weird spot where I’d guess they can add features to fairly complex applications like Slack, but there are a lot of hoops to jump through in landing the feature (including very understandable code quality standards within production code-bases), so the models are way easier to use when building from scratch than in production code-bases.
  &lt;/p&gt;
  &lt;p&gt;
   This dynamic amplifies the transition and power shift of software, where countless people who have never fully built something with code before can get more value out of it. It will rebalance the software and tech industry to favor small organizations and startups like Interconnects that have flexibility and can build from scratch in new repositories designed for AI agents. It’s an era to be first defined by bespoke software rather than a handful of mega-products used across the world. The list of what’s already commoditized is growing in scope and complexity fast — website frontends, mini applications on any platform, data analysis tools — all without having to know how to write code.
  &lt;/p&gt;
  &lt;p&gt;
   I expect mental barriers people have about Claude’s ability to handle complex codebases to come crashing down throughout the year, as more and more Claude-pilled engineers just tell their friends “skill issue.” With these coding agents all coming out last year, the labs are still learning how to best train models to be well-expressed in the form factor. It’ll be a defining story of 2026 as the commodification of software expands outside of the bubble of people deeply obsessed with AI.
  &lt;/p&gt;
  &lt;p&gt;
   There are things that Claude can’t do well and will take longer to solve, but these are more like corner cases and for most people immense value can be built around these blockers.
  &lt;/p&gt;
  &lt;p&gt;
   The other part that many people will miss is that Claude Code doesn’t need to be restricted to just software development — it can control your entire computer. People are starting to use it for managing their email, calendars, decision making, referencing their notes, and everything in between. The crucial aspect is that Claude is designed around the command line interface (CLI), which is an open door into the digital world.
  &lt;/p&gt;
  &lt;p&gt;
   The DGX Spark on my desk can be a mini AI research and development station managed by Claude.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/claude-code-hits-different?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/claude-code-hits-different?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    This complete interface managing my entire internet life is the beginnings of current AI models feeling like they’re
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/contra-dwarkesh-on-continual-learning?utm_source=publication-search&quot; rel=&quot;&quot;&gt;
    continually learning
   &lt;/a&gt;
   &lt;span&gt;
    . Whenever Claude makes a mistake or does something that doesn’t match your taste, dump a reminder into CLAUDE.md, it’s as simple as that. To quote
   &lt;/span&gt;
   &lt;span data-state=&quot;closed&quot;&gt;
    &lt;a data-attrs=&#x27;{&quot;name&quot;:&quot;Doug OLaughlin&quot;,&quot;id&quot;:108855261,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4063d155-1ee2-4c94-b009-2ed682737040_183x275.jpeg&quot;,&quot;uuid&quot;:&quot;7108653d-1ef5-4d60-9fb6-7160cabc6e1c&quot;}&#x27; data-component-name=&quot;MentionUser&quot; href=&quot;https://open.substack.com/users/108855261-doug-olaughlin?utm_source=mentions&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;
     Doug OLaughlin
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    , my brother in arms of Claude fandom, Claude with a 100X context window and 100X the speed will be AGI. By the end of 2026 we definitely could get the first 10X of both with the massive buildout of compute starting to become available.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Happy building.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!Hej0!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05a7d574-6449-4880-8331-cb5ce753b489_3008x2036.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Hej0!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05a7d574-6449-4880-8331-cb5ce753b489_3008x2036.png 424w, https://substackcdn.com/image/fetch/$s_!Hej0!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05a7d574-6449-4880-8331-cb5ce753b489_3008x2036.png 848w, https://substackcdn.com/image/fetch/$s_!Hej0!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05a7d574-6449-4880-8331-cb5ce753b489_3008x2036.png 1272w, https://substackcdn.com/image/fetch/$s_!Hej0!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05a7d574-6449-4880-8331-cb5ce753b489_3008x2036.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/05a7d574-6449-4880-8331-cb5ce753b489_3008x2036.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:986,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:945069,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/184040682?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05a7d574-6449-4880-8331-cb5ce753b489_3008x2036.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;986&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!Hej0!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05a7d574-6449-4880-8331-cb5ce753b489_3008x2036.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Hej0!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05a7d574-6449-4880-8331-cb5ce753b489_3008x2036.png 424w, https://substackcdn.com/image/fetch/$s_!Hej0!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05a7d574-6449-4880-8331-cb5ce753b489_3008x2036.png 848w, https://substackcdn.com/image/fetch/$s_!Hej0!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05a7d574-6449-4880-8331-cb5ce753b489_3008x2036.png 1272w, https://substackcdn.com/image/fetch/$s_!Hej0!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05a7d574-6449-4880-8331-cb5ce753b489_3008x2036.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> 8 plots that explain the state of open models </title>
<link>https://www.interconnects.ai/p/8-plots-that-explain-the-state-of</link>
<pubDate>Wed, 07 Jan 2026 15:07:22 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   Starting 2026, most people are aware that a handful of Chinese companies are making strong, open AI models that are applying increasing pressure on the American AI economy.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    While
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/chinas-top-19-open-model-labs&quot; rel=&quot;&quot;&gt;
    many Chinese labs are making models
   &lt;/a&gt;
   &lt;span&gt;
    , the adoption metrics are dominated by Qwen (with a little help from DeepSeek). Adoption of the new entrants in the open model scene in 2025, from Z.ai, MiniMax, Kimi Moonshot, and others is actually quite limited. This sets up the position where dethroning Qwen in adoption in 2026 looks impossible overall, but there are areas for opportunity. In fact, the strength of GPT-OSS shows that the U.S. could very well have the smartest open models again in 2026, even if they’re used far less across the ecosystem.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The following plots are from a comprehensive update of the data supporting The ATOM Project (
   &lt;/span&gt;
   &lt;a href=&quot;https://www.atomproject.ai/&quot; rel=&quot;&quot;&gt;
    atomproject.ai
   &lt;/a&gt;
   &lt;span&gt;
    ) with our expanded ecosystem measurement tools we use to support our monthly open model roundups,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/t/artifacts-log&quot; rel=&quot;&quot;&gt;
    Artifacts Log
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   1. China has a growing lead in every adoption metric
  &lt;/h2&gt;
  &lt;p&gt;
   Models from the US and the EU defined the early eras of open language models. 2025 saw the end of Llama and Qwen triumphantly took its spot as the default models of choice across a variety of tasks, from local LLMs to reasoning models or multimodal tools. The adoption of Chinese models continues to accelerate.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!fz6U!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18bc5002-7e0d-4392-b864-83ca777fab58_1818x1498.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!fz6U!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18bc5002-7e0d-4392-b864-83ca777fab58_1818x1498.png 424w, https://substackcdn.com/image/fetch/$s_!fz6U!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18bc5002-7e0d-4392-b864-83ca777fab58_1818x1498.png 848w, https://substackcdn.com/image/fetch/$s_!fz6U!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18bc5002-7e0d-4392-b864-83ca777fab58_1818x1498.png 1272w, https://substackcdn.com/image/fetch/$s_!fz6U!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18bc5002-7e0d-4392-b864-83ca777fab58_1818x1498.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/18bc5002-7e0d-4392-b864-83ca777fab58_1818x1498.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1200,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:264537,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/183092109?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18bc5002-7e0d-4392-b864-83ca777fab58_1818x1498.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;1200&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!fz6U!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18bc5002-7e0d-4392-b864-83ca777fab58_1818x1498.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!fz6U!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18bc5002-7e0d-4392-b864-83ca777fab58_1818x1498.png 424w, https://substackcdn.com/image/fetch/$s_!fz6U!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18bc5002-7e0d-4392-b864-83ca777fab58_1818x1498.png 848w, https://substackcdn.com/image/fetch/$s_!fz6U!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18bc5002-7e0d-4392-b864-83ca777fab58_1818x1498.png 1272w, https://substackcdn.com/image/fetch/$s_!fz6U!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18bc5002-7e0d-4392-b864-83ca777fab58_1818x1498.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    These first two plots show the cumulative downloads of all LLMs we consider representative of the ecosystem (we’re
   &lt;/span&gt;
   &lt;a href=&quot;https://github.com/Interconnects-AI/tracked-models&quot; rel=&quot;&quot;&gt;
    tracking 1152 in total right now
   &lt;/a&gt;
   &lt;span&gt;
    ), which were released after ChatGPT.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h2&gt;
   2. The West isn’t close to replacing Llama
  &lt;/h2&gt;
  &lt;p&gt;
   Where we’ve seen China’s lead increase in overall downloads in the previous figure, it feels increasingly precarious for supporters of Western open models to learn that Llama models — despite not being updated nor supported by their creator Meta — are still by far the most downloaded Western models in recent months. OpenAI’s GPT-OSS models are the only models from a new provider in the second half of 2025 that show early signs of shifting the needle on the balance of overall downloads from either an American or Chinese provider (OpenAI’s two models get about the same monthly downloads at the end of 2025 as all of DeepSeek’s or Mistral’s models).
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!78VP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cd4601b-8db1-4ab7-9fbc-4052987ebd9c_1818x1498.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!78VP!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cd4601b-8db1-4ab7-9fbc-4052987ebd9c_1818x1498.png 424w, https://substackcdn.com/image/fetch/$s_!78VP!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cd4601b-8db1-4ab7-9fbc-4052987ebd9c_1818x1498.png 848w, https://substackcdn.com/image/fetch/$s_!78VP!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cd4601b-8db1-4ab7-9fbc-4052987ebd9c_1818x1498.png 1272w, https://substackcdn.com/image/fetch/$s_!78VP!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cd4601b-8db1-4ab7-9fbc-4052987ebd9c_1818x1498.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7cd4601b-8db1-4ab7-9fbc-4052987ebd9c_1818x1498.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1200,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:275314,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/183092109?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cd4601b-8db1-4ab7-9fbc-4052987ebd9c_1818x1498.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;1200&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!78VP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cd4601b-8db1-4ab7-9fbc-4052987ebd9c_1818x1498.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!78VP!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cd4601b-8db1-4ab7-9fbc-4052987ebd9c_1818x1498.png 424w, https://substackcdn.com/image/fetch/$s_!78VP!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cd4601b-8db1-4ab7-9fbc-4052987ebd9c_1818x1498.png 848w, https://substackcdn.com/image/fetch/$s_!78VP!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cd4601b-8db1-4ab7-9fbc-4052987ebd9c_1818x1498.png 1272w, https://substackcdn.com/image/fetch/$s_!78VP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cd4601b-8db1-4ab7-9fbc-4052987ebd9c_1818x1498.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   3. New organizations barely show up in adoption metrics
  &lt;/h2&gt;
  &lt;p&gt;
   While much has been said (including by me, on Interconnects) about new open frontier model providers, their adoption tends to look like a rounding error in adoption metrics. These models from Z.ai, Nvidia, Kimi Moonshot, and MiniMax are crucial to developing local ecosystems, but they are not competing with Qwen as being the open model standard.
  &lt;/p&gt;
  &lt;p&gt;
   Note the different y-axes from this plot and the previous, where DeepSeek and OpenAI are included in both for scale. This plot shows the downloads just since July 2025 to showcase recent performance.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!rcd5!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4c60de2-eb3d-444a-b3a6-b66f9e202346_1866x1160.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!rcd5!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4c60de2-eb3d-444a-b3a6-b66f9e202346_1866x1160.png 424w, https://substackcdn.com/image/fetch/$s_!rcd5!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4c60de2-eb3d-444a-b3a6-b66f9e202346_1866x1160.png 848w, https://substackcdn.com/image/fetch/$s_!rcd5!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4c60de2-eb3d-444a-b3a6-b66f9e202346_1866x1160.png 1272w, https://substackcdn.com/image/fetch/$s_!rcd5!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4c60de2-eb3d-444a-b3a6-b66f9e202346_1866x1160.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a4c60de2-eb3d-444a-b3a6-b66f9e202346_1866x1160.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:905,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:271647,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/183092109?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4c60de2-eb3d-444a-b3a6-b66f9e202346_1866x1160.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;905&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!rcd5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4c60de2-eb3d-444a-b3a6-b66f9e202346_1866x1160.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!rcd5!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4c60de2-eb3d-444a-b3a6-b66f9e202346_1866x1160.png 424w, https://substackcdn.com/image/fetch/$s_!rcd5!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4c60de2-eb3d-444a-b3a6-b66f9e202346_1866x1160.png 848w, https://substackcdn.com/image/fetch/$s_!rcd5!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4c60de2-eb3d-444a-b3a6-b66f9e202346_1866x1160.png 1272w, https://substackcdn.com/image/fetch/$s_!rcd5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4c60de2-eb3d-444a-b3a6-b66f9e202346_1866x1160.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   4. Qwen’s weakness is in large model adoption
  &lt;/h2&gt;
  &lt;p&gt;
   &lt;span&gt;
    One of the most surprising things in the data is just how successful DeepSeek’s large models are (particularly both versions of V3 and R1). These 4 large models dominate the adoption numbers of any of Qwen’s large MoE/dense models over the last few years. It’s only at these large scales where opportunities to compete with Qwen exist, and with the rise of more providers like Z.ai, MiniMax, and Kimi, we’ll be following this closely. These large models are crucial tools right now for many startups based in the U.S. trying to finetune their own frontier model for applications — e.g. Cursor’s
   &lt;/span&gt;
   &lt;a href=&quot;https://cursor.com/blog/composer&quot; rel=&quot;&quot;&gt;
    Composer
   &lt;/a&gt;
   &lt;span&gt;
    model is finetuned from a large Chinese MoE.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!L-lz!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a16175-d9e6-4ca9-ae31-46c84f25d693_1872x1156.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!L-lz!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a16175-d9e6-4ca9-ae31-46c84f25d693_1872x1156.png 424w, https://substackcdn.com/image/fetch/$s_!L-lz!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a16175-d9e6-4ca9-ae31-46c84f25d693_1872x1156.png 848w, https://substackcdn.com/image/fetch/$s_!L-lz!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a16175-d9e6-4ca9-ae31-46c84f25d693_1872x1156.png 1272w, https://substackcdn.com/image/fetch/$s_!L-lz!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a16175-d9e6-4ca9-ae31-46c84f25d693_1872x1156.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/26a16175-d9e6-4ca9-ae31-46c84f25d693_1872x1156.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:899,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:231263,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/183092109?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a16175-d9e6-4ca9-ae31-46c84f25d693_1872x1156.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;899&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!L-lz!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a16175-d9e6-4ca9-ae31-46c84f25d693_1872x1156.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!L-lz!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a16175-d9e6-4ca9-ae31-46c84f25d693_1872x1156.png 424w, https://substackcdn.com/image/fetch/$s_!L-lz!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a16175-d9e6-4ca9-ae31-46c84f25d693_1872x1156.png 848w, https://substackcdn.com/image/fetch/$s_!L-lz!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a16175-d9e6-4ca9-ae31-46c84f25d693_1872x1156.png 1272w, https://substackcdn.com/image/fetch/$s_!L-lz!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26a16175-d9e6-4ca9-ae31-46c84f25d693_1872x1156.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/8-plots-that-explain-the-state-of?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/8-plots-that-explain-the-state-of?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;h2&gt;
   5. A few models from Qwen dwarf new entrants
  &lt;/h2&gt;
  &lt;p&gt;
   While Qwen has one Achilles’ heel right now, its recent models totally dominate any HuggingFace metric. If we look at the top 5 Qwen3 downloaded models just in December (Qwen3-[0.6B, 1.7B, 4B (Original), 8B, &amp; 4B-Instruct-2507]), they have more downloads than all of the models we’re tracking from OpenAI, Mistral AI, Nvidia, Z.ai, Moonshot AI, and MiniMax combined.
  &lt;/p&gt;
  &lt;p&gt;
   This is the advantage that Qwen has built and will take year(s) to unwind.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!IL9W!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8e7e64c-0ed6-4b54-b738-afd32c774cae_1864x1160.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!IL9W!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8e7e64c-0ed6-4b54-b738-afd32c774cae_1864x1160.png 424w, https://substackcdn.com/image/fetch/$s_!IL9W!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8e7e64c-0ed6-4b54-b738-afd32c774cae_1864x1160.png 848w, https://substackcdn.com/image/fetch/$s_!IL9W!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8e7e64c-0ed6-4b54-b738-afd32c774cae_1864x1160.png 1272w, https://substackcdn.com/image/fetch/$s_!IL9W!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8e7e64c-0ed6-4b54-b738-afd32c774cae_1864x1160.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b8e7e64c-0ed6-4b54-b738-afd32c774cae_1864x1160.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:906,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:258425,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/183092109?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8e7e64c-0ed6-4b54-b738-afd32c774cae_1864x1160.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;906&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!IL9W!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8e7e64c-0ed6-4b54-b738-afd32c774cae_1864x1160.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!IL9W!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8e7e64c-0ed6-4b54-b738-afd32c774cae_1864x1160.png 424w, https://substackcdn.com/image/fetch/$s_!IL9W!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8e7e64c-0ed6-4b54-b738-afd32c774cae_1864x1160.png 848w, https://substackcdn.com/image/fetch/$s_!IL9W!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8e7e64c-0ed6-4b54-b738-afd32c774cae_1864x1160.png 1272w, https://substackcdn.com/image/fetch/$s_!IL9W!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8e7e64c-0ed6-4b54-b738-afd32c774cae_1864x1160.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   6. In December Qwen got more downloads than roughly the rest of the open ecosystem
  &lt;/h2&gt;
  &lt;p&gt;
   If we account for every meaningful Qwen LLM released since ChatGPT, the downloads Qwen got in December well outnumber literally every other organization we’re tracking combined. This includes the 6 from the previous figure, along with DeepSeek and Meta, who are the second and third most downloaded creators.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!he5w!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76454a8e-cd85-4911-b730-9fa8f516ca63_1870x1232.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!he5w!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76454a8e-cd85-4911-b730-9fa8f516ca63_1870x1232.png 424w, https://substackcdn.com/image/fetch/$s_!he5w!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76454a8e-cd85-4911-b730-9fa8f516ca63_1870x1232.png 848w, https://substackcdn.com/image/fetch/$s_!he5w!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76454a8e-cd85-4911-b730-9fa8f516ca63_1870x1232.png 1272w, https://substackcdn.com/image/fetch/$s_!he5w!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76454a8e-cd85-4911-b730-9fa8f516ca63_1870x1232.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/76454a8e-cd85-4911-b730-9fa8f516ca63_1870x1232.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:959,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:265969,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/183092109?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76454a8e-cd85-4911-b730-9fa8f516ca63_1870x1232.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;959&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!he5w!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76454a8e-cd85-4911-b730-9fa8f516ca63_1870x1232.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!he5w!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76454a8e-cd85-4911-b730-9fa8f516ca63_1870x1232.png 424w, https://substackcdn.com/image/fetch/$s_!he5w!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76454a8e-cd85-4911-b730-9fa8f516ca63_1870x1232.png 848w, https://substackcdn.com/image/fetch/$s_!he5w!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76454a8e-cd85-4911-b730-9fa8f516ca63_1870x1232.png 1272w, https://substackcdn.com/image/fetch/$s_!he5w!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76454a8e-cd85-4911-b730-9fa8f516ca63_1870x1232.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   7. People are still finetuning Qwen more than anything else
  &lt;/h2&gt;
  &lt;p&gt;
   The other primary way we can measure Qwen’s adoption lead is to look at the share of derivative models on HuggingFace (filtered to only those with &amp;gt;5 downloads to indicate a meaningful finetune) that come from a certain base model. Qwen’s share here continued to grow throughout 2025, and we’ll be watching this closely around the likely release of Qwen 4.
  &lt;/p&gt;
  &lt;p&gt;
   Despite the dramatic increase in the number of players releasing open models in 2025, the share of finetuned models has concentrated among the 5 organizations we highlighted below (Qwen, Llama, Mistral, Google, and DeepSeek).
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!-ujU!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86726b22-86da-44e3-9566-a9cd4e910d3d_1810x1212.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!-ujU!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86726b22-86da-44e3-9566-a9cd4e910d3d_1810x1212.png 424w, https://substackcdn.com/image/fetch/$s_!-ujU!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86726b22-86da-44e3-9566-a9cd4e910d3d_1810x1212.png 848w, https://substackcdn.com/image/fetch/$s_!-ujU!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86726b22-86da-44e3-9566-a9cd4e910d3d_1810x1212.png 1272w, https://substackcdn.com/image/fetch/$s_!-ujU!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86726b22-86da-44e3-9566-a9cd4e910d3d_1810x1212.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/86726b22-86da-44e3-9566-a9cd4e910d3d_1810x1212.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:975,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:227783,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/183092109?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86726b22-86da-44e3-9566-a9cd4e910d3d_1810x1212.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;975&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!-ujU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86726b22-86da-44e3-9566-a9cd4e910d3d_1810x1212.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!-ujU!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86726b22-86da-44e3-9566-a9cd4e910d3d_1810x1212.png 424w, https://substackcdn.com/image/fetch/$s_!-ujU!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86726b22-86da-44e3-9566-a9cd4e910d3d_1810x1212.png 848w, https://substackcdn.com/image/fetch/$s_!-ujU!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86726b22-86da-44e3-9566-a9cd4e910d3d_1810x1212.png 1272w, https://substackcdn.com/image/fetch/$s_!-ujU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86726b22-86da-44e3-9566-a9cd4e910d3d_1810x1212.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   8. China still has the smartest open models
  &lt;/h2&gt;
  &lt;p&gt;
   The primary factor that drives the adoption and influence of Chinese open models today is that they’re the smartest open models available. There’s a variety of second order issues, such as licenses, model sizes, documentation, developer engagement, etc., but for over a year now, Chinese open models have been the smartest on most benchmarks.
  &lt;/p&gt;
  &lt;p&gt;
   GPT-OSS 120B was close to retaking the lead (slightly behind MiniMax M2), but it wasn’t quite there. It’ll be fascinating to watch if upcoming Nemotron, Arcee, or Reflection AI models can buck this trend. If you look at other metrics than the Artificial Analysis intelligence index, the same trends hold.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!yl07!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a1d0516-92d4-4f5f-9bd9-2883ff5d7ab5_1964x1750.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!yl07!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a1d0516-92d4-4f5f-9bd9-2883ff5d7ab5_1964x1750.png 424w, https://substackcdn.com/image/fetch/$s_!yl07!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a1d0516-92d4-4f5f-9bd9-2883ff5d7ab5_1964x1750.png 848w, https://substackcdn.com/image/fetch/$s_!yl07!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a1d0516-92d4-4f5f-9bd9-2883ff5d7ab5_1964x1750.png 1272w, https://substackcdn.com/image/fetch/$s_!yl07!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a1d0516-92d4-4f5f-9bd9-2883ff5d7ab5_1964x1750.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5a1d0516-92d4-4f5f-9bd9-2883ff5d7ab5_1964x1750.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1297,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:331323,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/183092109?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a1d0516-92d4-4f5f-9bd9-2883ff5d7ab5_1964x1750.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;1297&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!yl07!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a1d0516-92d4-4f5f-9bd9-2883ff5d7ab5_1964x1750.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!yl07!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a1d0516-92d4-4f5f-9bd9-2883ff5d7ab5_1964x1750.png 424w, https://substackcdn.com/image/fetch/$s_!yl07!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a1d0516-92d4-4f5f-9bd9-2883ff5d7ab5_1964x1750.png 848w, https://substackcdn.com/image/fetch/$s_!yl07!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a1d0516-92d4-4f5f-9bd9-2883ff5d7ab5_1964x1750.png 1272w, https://substackcdn.com/image/fetch/$s_!yl07!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a1d0516-92d4-4f5f-9bd9-2883ff5d7ab5_1964x1750.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/8-plots-that-explain-the-state-of/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/8-plots-that-explain-the-state-of/comments&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Leave a comment
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Thanks for reading! Please reach out or leave a comment if there’s a corner of the data you think we should spend more time in. Stay tuned for more updates on
   &lt;/span&gt;
   &lt;a href=&quot;https://www.atomproject.ai/&quot; rel=&quot;&quot;&gt;
    The ATOM Project
   &lt;/a&gt;
   &lt;span&gt;
    and related efforts in the near future.
   &lt;/span&gt;
  &lt;/p&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Latest open artifacts (#17): NVIDIA, Arcee, Minimax, DeepSeek, Z.ai and others close an eventful year on a high note </title>
<link>https://www.interconnects.ai/p/latest-open-artifacts-17-nvidia-arcee</link>
<pubDate>Mon, 05 Jan 2026 14:03:14 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   Happy new year! The open ecosystem hasn’t slowed down at all over the holiday period, which we know will continue right into and through 2026. There are a lot of great models in this issue, from GLM 4.7 and MiniMax M2.1 — open models that are starting to be “good enough” in the Claude Code form factor — and much stronger open models from Nvidia and Arcee to support the U.S.’s renewed motivation in the space.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/latest-open-artifacts-17-nvidia-arcee?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:&quot;button-wrapper&quot;}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-artifacts-17-nvidia-arcee?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   &lt;strong&gt;
    Our Picks
   &lt;/strong&gt;
  &lt;/h3&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/LLM360/K2-V2&quot; rel=&quot;&quot;&gt;
       K2-V2
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/LLM360&quot; rel=&quot;&quot;&gt;
      LLM360
     &lt;/a&gt;
     &lt;span&gt;
      : LLM360, a project from MBZUAI, is back with their fully open-source model series. This model is a 70B dense model, and they release the whole data, from pre-training (12T tokens) to SFT, which they generated using GPT-OSS 120B at all three reasoning levels. They also release multiple checkpoints from the various stages of training. We expect a lot more from them specifically and the growing fully-open model community in 2026!
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16&quot; rel=&quot;&quot;&gt;
       NVIDIA-Nemotron-3-Nano-30B-A3B-BF16
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/nvidia&quot; rel=&quot;&quot;&gt;
      nvidia
     &lt;/a&gt;
     &lt;span&gt;
      : As luck would have it, NVIDIA released an update to their Nemotron series
     &lt;/span&gt;
     &lt;em&gt;
      right
     &lt;/em&gt;
     &lt;span&gt;
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/2025-open-models-year-in-review&quot; rel=&quot;&quot;&gt;
      after our year in review tierlist
     &lt;/a&gt;
     &lt;span&gt;
      for 2025. Similar to other NVIDIA models, the vast majority of the data is released openly. Furthermore, they continue with the Mamba2-Transformer architecture, but make it a MoE as well. And to top it all off: They also announce two more sizes, slated for a release in H1 2026 (likely on the earlier side): Super, ~100B-A10B and Ultra, ~500B-A50B, which will use
     &lt;/span&gt;
     &lt;a href=&quot;https://developer.nvidia.com/blog/inside-nvidia-nemotron-3-techniques-tools-and-data-that-make-it-efficient-and-accurate/#latent_moe&quot; rel=&quot;&quot;&gt;
      Latent MoE
     &lt;/a&gt;
     &lt;span&gt;
      and multi-token prediction (MTP). 2026 will be an exciting year!
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!axWM!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0245b087-605a-45bd-947c-e51b07035967_2304x864.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!axWM!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0245b087-605a-45bd-947c-e51b07035967_2304x864.png 424w, https://substackcdn.com/image/fetch/$s_!axWM!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0245b087-605a-45bd-947c-e51b07035967_2304x864.png 848w, https://substackcdn.com/image/fetch/$s_!axWM!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0245b087-605a-45bd-947c-e51b07035967_2304x864.png 1272w, https://substackcdn.com/image/fetch/$s_!axWM!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0245b087-605a-45bd-947c-e51b07035967_2304x864.png 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0245b087-605a-45bd-947c-e51b07035967_2304x864.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:546,&quot;width&quot;:1456,&quot;resizeWidth&quot;:665,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;249.375&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!axWM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0245b087-605a-45bd-947c-e51b07035967_2304x864.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!axWM!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0245b087-605a-45bd-947c-e51b07035967_2304x864.png 424w, https://substackcdn.com/image/fetch/$s_!axWM!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0245b087-605a-45bd-947c-e51b07035967_2304x864.png 848w, https://substackcdn.com/image/fetch/$s_!axWM!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0245b087-605a-45bd-947c-e51b07035967_2304x864.png 1272w, https://substackcdn.com/image/fetch/$s_!axWM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0245b087-605a-45bd-947c-e51b07035967_2304x864.png 1456w&quot; width=&quot;665&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/arcee-ai/Trinity-Mini&quot; rel=&quot;&quot;&gt;
       Trinity-Mini
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/arcee-ai&quot; rel=&quot;&quot;&gt;
      arcee-ai
     &lt;/a&gt;
     &lt;span&gt;
      : Arcee is not an unknown entity to the avid Artifacts reader. Now they are coming with a series of models: Nano, a 6B-A1B MoE and Mini, a 26B-A3B MoE are available today and trained on 10T tokens. They also plan to release Large, a 420B-A13B MoE trained on 20T tokens, in the coming weeks. We played with the Mini model and were impressed by its capabilities! As readers know, we’re also very happy to highlight new and rapidly improving open model builders in the U.S. using permissive licenses.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/zai-org/GLM-4.7&quot; rel=&quot;&quot;&gt;
       GLM-4.7
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/zai-org&quot; rel=&quot;&quot;&gt;
      zai-org
     &lt;/a&gt;
     &lt;span&gt;
      : Zhipu, which will
     &lt;/span&gt;
     &lt;a href=&quot;https://www.scmp.com/business/investor-relations/ipo-quote-profile/article/3338107/chinas-zhipu-ai-launches-us560-million-share-sale-hong-kongs-ipo-tech-race-heats&quot; rel=&quot;&quot;&gt;
      IPO
     &lt;/a&gt;
     &lt;span&gt;
      on January 8th, dropped a
     &lt;/span&gt;
     &lt;em&gt;
      really
     &lt;/em&gt;
     &lt;span&gt;
      capable model just before Christmas with 4.7. GLM-4.7 is
     &lt;/span&gt;
     &lt;em&gt;
      not close
     &lt;/em&gt;
     &lt;span&gt;
      to (API model) SOTA performance on the usual academic benchmarks like GPQA or SWE-bench Verified, but manages to hold its performance beyond that in a broader suite of tasks like
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/artificialanlys/status/2006197168487424127?s=46&quot; rel=&quot;&quot;&gt;
      GPVal-AA
     &lt;/a&gt;
     &lt;span&gt;
      or
     &lt;/span&gt;
     &lt;a href=&quot;https://www.designarena.ai/leaderboard&quot; rel=&quot;&quot;&gt;
      DesignArena
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      I (Florian) have tested this model extensively the last days by using the Z.ai API (and the corresponding coding subscription at $28/yr) in the
     &lt;/span&gt;
     &lt;a href=&quot;https://opencode.ai/&quot; rel=&quot;&quot;&gt;
      OpenCode
     &lt;/a&gt;
     &lt;span&gt;
      as the CLI (which also offers the model for free at the time of writing) and was more than impressed by the quality of this model. In certain areas (especially in UI generation for websites),
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/xeophon/status/2004123021880230216?s=20&quot; rel=&quot;&quot;&gt;
      I preferred its outputs over Opus
     &lt;/a&gt;
     &lt;span&gt;
      , while in other areas, it was more or less on the level of Sonnet 4.5, which was released a mere
     &lt;/span&gt;
     &lt;em&gt;
      4 months
     &lt;/em&gt;
     &lt;span&gt;
      ago. However, the model is quite slow (the cheapest coding plan is slower compared to their other offerings) and its long-context performance is worse than other closed models, especially after 100K tokens. Furthermore, it is text-only, which I “fixed” by adding Gemini 3.0 Flash as a subagent in OpenCode. But again, this is an open model, dirt cheap and self-hostable on a node of H100s!
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!heaw!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e1192f1-3c89-4a89-a6f7-df36913980e5_2520x1672.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!heaw!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e1192f1-3c89-4a89-a6f7-df36913980e5_2520x1672.png 424w, https://substackcdn.com/image/fetch/$s_!heaw!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e1192f1-3c89-4a89-a6f7-df36913980e5_2520x1672.png 848w, https://substackcdn.com/image/fetch/$s_!heaw!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e1192f1-3c89-4a89-a6f7-df36913980e5_2520x1672.png 1272w, https://substackcdn.com/image/fetch/$s_!heaw!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e1192f1-3c89-4a89-a6f7-df36913980e5_2520x1672.png 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8e1192f1-3c89-4a89-a6f7-df36913980e5_2520x1672.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:966,&quot;width&quot;:1456,&quot;resizeWidth&quot;:674,&quot;bytes&quot;:251211,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/183050279?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e1192f1-3c89-4a89-a6f7-df36913980e5_2520x1672.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;447.1730769230769&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!heaw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e1192f1-3c89-4a89-a6f7-df36913980e5_2520x1672.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!heaw!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e1192f1-3c89-4a89-a6f7-df36913980e5_2520x1672.png 424w, https://substackcdn.com/image/fetch/$s_!heaw!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e1192f1-3c89-4a89-a6f7-df36913980e5_2520x1672.png 848w, https://substackcdn.com/image/fetch/$s_!heaw!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e1192f1-3c89-4a89-a6f7-df36913980e5_2520x1672.png 1272w, https://substackcdn.com/image/fetch/$s_!heaw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e1192f1-3c89-4a89-a6f7-df36913980e5_2520x1672.png 1456w&quot; width=&quot;674&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/allura-forge/Llama-3.3-8B-Instruct&quot; rel=&quot;&quot;&gt;
       Llama-3.3-8B-Instruct
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/allura-forge&quot; rel=&quot;&quot;&gt;
      allura-forge
     &lt;/a&gt;
     &lt;span&gt;
      : For some reason, Llama 3.3 8B is a thing that exists, but was never released publicly in the same way that the other models did. However, someone got access to the weights by using Meta’s
     &lt;/span&gt;
     &lt;a href=&quot;https://llama.developer.meta.com/docs/models#llama-3_3-8b-instruct&quot; rel=&quot;&quot;&gt;
      Llama API
     &lt;/a&gt;
     &lt;span&gt;
      and uploaded them to HuggingFace.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h3&gt;
   &lt;strong&gt;
    Models
   &lt;/strong&gt;
  &lt;/h3&gt;
  &lt;h4&gt;
   &lt;strong&gt;
    Flagship
   &lt;/strong&gt;
  &lt;/h4&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/ServiceNow-AI/Apriel-1.6-15b-Thinker&quot; rel=&quot;&quot;&gt;
       Apriel-1.6-15b-Thinker
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/ServiceNow-AI&quot; rel=&quot;&quot;&gt;
      ServiceNow-AI
     &lt;/a&gt;
     &lt;span&gt;
      : An update to the Apriel series, focusing on using fewer tokens per answer while maintaining performance. They achieved this by using GSPO with length and verbosity penalties.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/XiaomiMiMo/MiMo-V2-Flash&quot; rel=&quot;&quot;&gt;
       MiMo-V2-Flash
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/XiaomiMiMo&quot; rel=&quot;&quot;&gt;
      XiaomiMiMo
     &lt;/a&gt;
     &lt;span&gt;
      : Xiaomi surprised everyone by dropping a 309B-A15B MoE. The first model, which we also
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-artifacts-10-new-deepseek&quot; rel=&quot;&quot;&gt;
      covered
     &lt;/a&gt;
     &lt;span&gt;
      , was just a 7B dense model. Members in our subscriber-only
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/discord&quot; rel=&quot;&quot;&gt;
      Discord
     &lt;/a&gt;
     &lt;span&gt;
      used the model and liked its writing style. However, they also found that it is lacking in terms of agentic performance and function calling.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/deepseek-ai/DeepSeek-V3.2&quot; rel=&quot;&quot;&gt;
       DeepSeek-V3.2
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/deepseek-ai&quot; rel=&quot;&quot;&gt;
      deepseek-ai
     &lt;/a&gt;
     &lt;span&gt;
      : Another update to the V3 series, which integrates DSA. They also trained and released a “high compute” version,
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Speciale&quot; rel=&quot;&quot;&gt;
      V3.2 Speciale
     &lt;/a&gt;
     &lt;span&gt;
      , which claims to beat the 2025 IMO and IOI with gold-medal performance.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Open models: Hot or Not with Nathan Lambert &amp; Florian Brand </title>
<link>https://www.interconnects.ai/p/open-models-hot-or-not-with-nathan</link>
<pubDate>Thu, 18 Dec 2025 18:31:44 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;div data-component-name=&quot;InstallSubstackAppToDOM&quot;&gt;
   &lt;img src=&quot;https://substackcdn.com/image/fetch/$s_!djof!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc52e8097-8f3d-4f7e-808b-2f4ad37f3b52_720x720.png&quot;/&gt;
   &lt;div&gt;
    &lt;div&gt;
     Get more from Nathan Lambert in the Substack app
    &lt;/div&gt;
    &lt;div&gt;
     Available for iOS and Android
    &lt;/div&gt;
   &lt;/div&gt;
   &lt;a href=&quot;https://substack.com/app/app-store-redirect?utm_campaign=app-marketing&amp;utm_content=author-post-insert&amp;utm_source=robotic&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
    &lt;button&gt;
     Get the app
    &lt;/button&gt;
   &lt;/a&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> 2025 Interconnects year in review </title>
<link>https://www.interconnects.ai/p/2025-interconnects-year-in-review</link>
<pubDate>Thu, 18 Dec 2025 14:56:27 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    A lot has happened in AI this year, which is the new normal. Since I last wrote a year in review, before
   &lt;/span&gt;
   &lt;a href=&quot;https://www.youtube.com/watch?v=_1f-o0nqpEI&amp;t=7649s&amp;pp=ygULbGFtYmVydCBsZXg%3D&quot; rel=&quot;&quot;&gt;
    going on Lex’s Podcast
   &lt;/a&gt;
   &lt;span&gt;
    and writing
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/deepseek-v3-and-the-actual-cost-of&quot; rel=&quot;&quot;&gt;
    timely
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1&quot; rel=&quot;&quot;&gt;
    coverage
   &lt;/a&gt;
   &lt;span&gt;
    of the DeepSeek models, the Interconnects audience was below 20K readers. It’s more than doubled this year in viewership (and influence), so it’s a good time to reintroduce how I see the value in Interconnects to everyone.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    My main day job is being deep in the weeds of the research needed to train better
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/olmo-3-americas-truly-open-reasoning&quot; rel=&quot;&quot;&gt;
    Olmo
   &lt;/a&gt;
   &lt;span&gt;
    models. Interconnects serves as an outlet for these ideas to help me stay on top of having an elite vision and plan for said research.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The best way to view my content is a raw expression of my worldview as a leading AI researcher reacting to the world of AI. A lot of my writing is raw, sometimes off the cuff, and often technical. I lean into this as it gives readers a very cutting-edge view of my thinking, which often can translate into the unique feeling of “getting it” at the cutting-edge of research.
   &lt;/span&gt;
   &lt;span data-state=&quot;closed&quot;&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/2025-interconnects-year-in-review#footnote-1-181486818&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     1
    &lt;/a&gt;
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   One of my favorite things while wrapping up the year is I’m regularly using three frontier models (ChatGPT, Claude, &amp; Gemini) for slightly different things. The landscape is as competitive as it ever has been. These products I love are also facing serious pressure from open models close on their heels. In 2026 I want to use more open models directly.
  &lt;/p&gt;
  &lt;p&gt;
   This year brought my long-term focuses of reinforcement learning and open models to the forefront of the entire AI ecosystem, so it makes sense that it was the busiest year on Interconnects yet. Through 2025, there were 80 total posts of which 19 were for prominent model releases, 11 were our roundups of open models (Artifacts Log), 4 interviews, 6 of my talks, and the remaining 40 spread across analysis of the world of AI. In total I earned about 3.5 million pageviews on Substack.
  &lt;/p&gt;
  &lt;p&gt;
   This is well over my goal of one per week and likely will be a local optimum over this few-year phase of AI where I’m working full-time on research, with a major side gig in the AI media and policy spheres. I don’t expect there to be another increase in year-over-year amount of content, but we should be able to make every piece of content even more valuable. We’re learning a lot.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    It’s arguable that I’m
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/burning-out&quot; rel=&quot;&quot;&gt;
    burning out
   &lt;/a&gt;
   &lt;span&gt;
    this year, but with how motivated and aligned I am to my work, it feels more like just hitting hard limits. I can’t do everything. I’m lucky to have a life where I can shape a lot of my time, energy, habits, and goals around shaping trends in AI. Working at the Allen Institute for AI has been great for this, but they should be because they obviously benefit a lot from my work too.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    I’m tired but feeling very content with my contributions to the AI world. I still think this is the early years of my work and getting the right practice in is more important to me than perfection of every piece. If you can, upgrading a paid subscription helps me pay for AI tools or operational assistance and just helps me stay motivated in the project (plus, you get access to the excellent
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/discord&quot; rel=&quot;&quot;&gt;
    Discord Server
   &lt;/a&gt;
   &lt;span&gt;
    too).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    This year I launched two major projects that are closely intertwined with my goals for Interconnects:
   &lt;/span&gt;
   &lt;a href=&quot;https://atomproject.ai/&quot; rel=&quot;&quot;&gt;
    The ATOM Project
   &lt;/a&gt;
   &lt;span&gt;
    , the case for immediate investment in centers building American open models, and the
   &lt;/span&gt;
   &lt;a href=&quot;https://readsail.com/&quot; rel=&quot;&quot;&gt;
    SAIL Bundle
   &lt;/a&gt;
   &lt;span&gt;
    , a paid bundle of my favorite writers on Substack sold only to teams (we’ve started publishing a bunch of content on the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.youtube.com/@readsail\&quot; rel=&quot;&quot;&gt;
    SAIL YouTube channel
   &lt;/a&gt;
   &lt;span&gt;
    ). I intend to invest further in both of these in 2026, so you’ll keep hearing about these. It is a risk to invest so much time in these things, so it’s a relief when they land.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    I’ll see you all in January. We have no planned content until then, but we’d chime in if DeepSeek V4 (or an equivalent) comes out and is causing international ripples. I’m off to finish up my RLHF book, which you should
   &lt;/span&gt;
   &lt;a href=&quot;https://hubs.la/Q03TsMHv0&quot; rel=&quot;&quot;&gt;
    pre-order
   &lt;/a&gt;
   &lt;span&gt;
    in print now!
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Previous years in review:
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/2024-interconnects-year-in-review&quot; rel=&quot;&quot;&gt;
    2024
   &lt;/a&gt;
   &lt;span&gt;
    |
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/2023-review&quot; rel=&quot;&quot;&gt;
    2023
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
   You can see the weekly views this year below.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!6UiM!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05c75d5d-820e-4dad-a515-4cb3af9802e5_1930x1242.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!6UiM!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05c75d5d-820e-4dad-a515-4cb3af9802e5_1930x1242.png 424w, https://substackcdn.com/image/fetch/$s_!6UiM!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05c75d5d-820e-4dad-a515-4cb3af9802e5_1930x1242.png 848w, https://substackcdn.com/image/fetch/$s_!6UiM!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05c75d5d-820e-4dad-a515-4cb3af9802e5_1930x1242.png 1272w, https://substackcdn.com/image/fetch/$s_!6UiM!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05c75d5d-820e-4dad-a515-4cb3af9802e5_1930x1242.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/05c75d5d-820e-4dad-a515-4cb3af9802e5_1930x1242.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:937,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:346674,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/181486818?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05c75d5d-820e-4dad-a515-4cb3af9802e5_1930x1242.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;937&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!6UiM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05c75d5d-820e-4dad-a515-4cb3af9802e5_1930x1242.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!6UiM!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05c75d5d-820e-4dad-a515-4cb3af9802e5_1930x1242.png 424w, https://substackcdn.com/image/fetch/$s_!6UiM!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05c75d5d-820e-4dad-a515-4cb3af9802e5_1930x1242.png 848w, https://substackcdn.com/image/fetch/$s_!6UiM!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05c75d5d-820e-4dad-a515-4cb3af9802e5_1930x1242.png 1272w, https://substackcdn.com/image/fetch/$s_!6UiM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F05c75d5d-820e-4dad-a515-4cb3af9802e5_1930x1242.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   In this post I’ve organized all the posts of the year into sections. Throughout, I’ve marked my favorite posts with ★ if you’re looking to catch up on what I felt is the mostly lasting content from the year.
  &lt;/p&gt;
  &lt;p&gt;
   Comment below what your favorite posts were or any topic you wish I covered more. Contents:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/i/181486818/top-posts-by-page-views&quot; rel=&quot;&quot;&gt;
      Top posts of the year
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/i/181486818/model-releases&quot; rel=&quot;&quot;&gt;
      Model releases &amp; reviews
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/i/181486818/interconnects-interviews&quot; rel=&quot;&quot;&gt;
      Interconnects Interviews
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/i/181486818/my-talks&quot; rel=&quot;&quot;&gt;
      My Talks
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/i/181486818/the-rest-analysis&quot; rel=&quot;&quot;&gt;
      The Rest: Analysis
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/i/181486818/artifacts-logs-open-model-roundups&quot; rel=&quot;&quot;&gt;
      Artifacts Logs: Open Model Roundups
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   Of all the sections I listed, the subsection of Analysis posts on Reasoning &amp; RL is my highlight for the year. The average quality there is excellent, especially given how much uncertainty and confusion exists when new paradigms emerge.
  &lt;/p&gt;
  &lt;p&gt;
   Of all the posts, 26 of them directly cover or discuss the role of Chinese open models on the AI ecosystem, which will surely continue into 2026 (hint: We already have some great interviews lined up or recorded).
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/2025-interconnects-year-in-review?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/2025-interconnects-year-in-review?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;h2&gt;
   Top Posts (by pageviews)
  &lt;/h2&gt;
  &lt;p&gt;
   Top 11 posts as of Friday Dec. 12th 2025, and the only ones to clear 50K pageviews are:
  &lt;/p&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/deepseek-v3-and-the-actual-cost-of&quot; rel=&quot;&quot;&gt;
      DeepSeek V3 and the actual cost of training frontier AI models
     &lt;/a&gt;
     &lt;span&gt;
      — 62.6K: Why the cost of training models go well beyond the GPU hours for the final model.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1&quot; rel=&quot;&quot;&gt;
      DeepSeek R1’s recipe to replicate o1 and the future of reasoning LMs
     &lt;/a&gt;
     &lt;span&gt;
      — 61.3K: How to train a frontier model to reason.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/kimi-k2-thinking-what-it-means&quot; rel=&quot;&quot;&gt;
      5 Thoughts on Kimi K2 Thinking
     &lt;/a&gt;
     &lt;span&gt;
      — 59K: Reflections on the state of frontier open models at the end of the year.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/burning-out&quot; rel=&quot;&quot;&gt;
      Burning out
     &lt;/a&gt;
     &lt;span&gt;
      — 57.8K: How the AI industry is pushing people too far to try and stay relevant.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/coding-as-the-epicenter-of-ai-progress&quot; rel=&quot;&quot;&gt;
      Coding as the epicenter of AI progress
     &lt;/a&gt;
     &lt;span&gt;
      — 56.3K: Why coding is the best place to feel current progress on models.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/gpt-45-not-a-frontier-model&quot; rel=&quot;&quot;&gt;
      GPT-4.5: “Not a frontier model”?
     &lt;/a&gt;
     &lt;span&gt;
      — 55.4K: Why a large, slow model was seen as a failure by OpenAI.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/openais-o3-over-optimization-is-back&quot; rel=&quot;&quot;&gt;
      OpenAI’s o3: Over-optimization is back and weirder than ever
     &lt;/a&gt;
     &lt;span&gt;
      — 54.7K: How large scale RL changed the nature of hallucinations in models.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/gpt-5-and-bending-the-arc-of-progress&quot; rel=&quot;&quot;&gt;
      GPT-5 and the arc of progress
     &lt;/a&gt;
     &lt;span&gt;
      — 54.5K: How GPT-5 confirms my worldview of slow, consistent progress over the next few years.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/grok-4-an-o3-look-alike-in-search&quot; rel=&quot;&quot;&gt;
      xAI’s Grok 4: The tension of frontier performance with a side of Elon favoritism
     &lt;/a&gt;
     &lt;span&gt;
      — 51.7K: Reflecting on xAI’s technical excellence while being baffled by their weird modeling decisions.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/qwen-3-the-new-open-standard&quot; rel=&quot;&quot;&gt;
      Qwen 3: The new open standard
     &lt;/a&gt;
     &lt;span&gt;
      — 51.7K: Why Qwen’s models are great for research.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/the-american-deepseek-project&quot; rel=&quot;&quot;&gt;
      The American DeepSeek Project
     &lt;/a&gt;
     &lt;span&gt;
      — 51.4K: My next set of goals for my career.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!H2RR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2cd5defe-11b1-4506-ba12-182b41aed456_1536x1024.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!H2RR!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2cd5defe-11b1-4506-ba12-182b41aed456_1536x1024.png 424w, https://substackcdn.com/image/fetch/$s_!H2RR!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2cd5defe-11b1-4506-ba12-182b41aed456_1536x1024.png 848w, https://substackcdn.com/image/fetch/$s_!H2RR!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2cd5defe-11b1-4506-ba12-182b41aed456_1536x1024.png 1272w, https://substackcdn.com/image/fetch/$s_!H2RR!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2cd5defe-11b1-4506-ba12-182b41aed456_1536x1024.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2cd5defe-11b1-4506-ba12-182b41aed456_1536x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;971&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!H2RR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2cd5defe-11b1-4506-ba12-182b41aed456_1536x1024.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!H2RR!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2cd5defe-11b1-4506-ba12-182b41aed456_1536x1024.png 424w, https://substackcdn.com/image/fetch/$s_!H2RR!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2cd5defe-11b1-4506-ba12-182b41aed456_1536x1024.png 848w, https://substackcdn.com/image/fetch/$s_!H2RR!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2cd5defe-11b1-4506-ba12-182b41aed456_1536x1024.png 1272w, https://substackcdn.com/image/fetch/$s_!H2RR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2cd5defe-11b1-4506-ba12-182b41aed456_1536x1024.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   Model Releases &amp; Reviews
  &lt;/h2&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Jan. 09:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/deepseek-v3-and-the-actual-cost-of&quot; rel=&quot;&quot;&gt;
      DeepSeek V3 and the actual cost of training frontier AI models
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      ★ Jan. 21:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1&quot; rel=&quot;&quot;&gt;
      DeepSeek R1’s recipe to replicate o1 and the future of reasoning LMs
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Feb. 18:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/grok-3-and-an-accelerating-ai-roadmap&quot; rel=&quot;&quot;&gt;
      Grok 3 and an accelerating AI roadmap
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Feb. 24:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/claude-3-7-thonks&quot; rel=&quot;&quot;&gt;
      Claude 3.7 thonks and what’s next for inference-time scaling
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Feb. 28:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/gpt-45-not-a-frontier-model&quot; rel=&quot;&quot;&gt;
      GPT-4.5: “Not a frontier model”?
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Mar. 13:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/gemma-3-olmo-2-32b-and-the-growing&quot; rel=&quot;&quot;&gt;
      Gemma 3, OLMo 2 32B, and the growing potential of open-source AI
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Mar. 26:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/gemini-25-pro-googles-second-ai-chance&quot; rel=&quot;&quot;&gt;
      Gemini 2.5 Pro and Google’s second chance with AI
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Mar. 30:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/gpt-4os-images-and-lessons-from-native&quot; rel=&quot;&quot;&gt;
      GPT-4o’s images and lessons from native input-output multimodality
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Apr. 07:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/llama-4&quot; rel=&quot;&quot;&gt;
      Llama 4: Did Meta just push the panic button?
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Apr. 14:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/openais-gpt-41-and-separating-the&quot; rel=&quot;&quot;&gt;
      OpenAI’s GPT-4.1 and separating the API from ChatGPT
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      ★ Apr. 19:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/openais-o3-over-optimization-is-back&quot; rel=&quot;&quot;&gt;
      OpenAI’s o3: Over-optimization is back and weirder than ever
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Apr. 28:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/qwen-3-the-new-open-standard&quot; rel=&quot;&quot;&gt;
      Qwen 3: The new open standard
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      May. 27:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/claude-4-and-anthropics-bet-on-code&quot; rel=&quot;&quot;&gt;
      Claude 4 and Anthropic’s bet on code
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Jul. 12:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/grok-4-an-o3-look-alike-in-search&quot; rel=&quot;&quot;&gt;
      xAI’s Grok 4: The tension of frontier performance with a side of Elon favoritism
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Jul. 14:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/kimi-k2-and-when-deepseek-moments&quot; rel=&quot;&quot;&gt;
      Kimi K2 and when “DeepSeek Moments” become normal
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Aug. 05:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/gpt-oss-openai-validates-the-open&quot; rel=&quot;&quot;&gt;
      gpt-oss: OpenAI validates the open ecosystem (finally)
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Aug. 07:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/gpt-5-and-bending-the-arc-of-progress&quot; rel=&quot;&quot;&gt;
      GPT-5 and the arc of progress
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Nov. 06:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/kimi-k2-thinking-what-it-means&quot; rel=&quot;&quot;&gt;
      5 Thoughts on Kimi K2 Thinking
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Nov. 20:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/olmo-3-americas-truly-open-reasoning&quot; rel=&quot;&quot;&gt;
      Olmo 3: America’s truly open reasoning models
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;h2&gt;
   Interconnects Interviews
  &lt;/h2&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Jan. 22:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/olmo-2-pod&quot; rel=&quot;&quot;&gt;
      Interviewing OLMo 2 leads: Open secrets of training language models
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Mar. 12:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/interviewing-eugene-vinitsky-on-self&quot; rel=&quot;&quot;&gt;
      Interviewing Eugene Vinitsky on self-play for self-driving and what else people do with RL
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      ★ Jul. 29:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/interviewing-ross-taylor-on-the-state&quot; rel=&quot;&quot;&gt;
      Interviewing Ross Taylor on the state of AI: Chinese open models, scaling reasoning, useful tools, and what comes next
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Nov. 12:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/inside-a-chinese-frontier-lab-inclusion&quot; rel=&quot;&quot;&gt;
      Interview: Ant Group’s open model ambitions
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;h2&gt;
   My Talks
  &lt;/h2&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Jan. 02:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/the-state-of-reasoning&quot; rel=&quot;&quot;&gt;
      Quick recap on the state of reasoning
     &lt;/a&gt;
     &lt;span&gt;
      — now outdated for sure.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Jan. 08:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/the-state-of-post-training-2025&quot; rel=&quot;&quot;&gt;
      The state of post-training in 2025
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      ★ Feb. 13:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/an-unexpected-rl-renaissance&quot; rel=&quot;&quot;&gt;
      An unexpected RL Renaissance
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      ★ Jun. 18:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/crafting-a-good-reasoning-model&quot; rel=&quot;&quot;&gt;
      Crafting a good (reasoning) model
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      ★ Oct. 16:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/state-of-open-models-2025&quot; rel=&quot;&quot;&gt;
      The State of Open Models
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Dec. 10:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/building-olmo-3-think&quot; rel=&quot;&quot;&gt;
      New Talk: Building Olmo 3 Think
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!jQOD!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F776058da-e524-49c7-a9eb-3be0c69400f1_2048x1151.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!jQOD!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F776058da-e524-49c7-a9eb-3be0c69400f1_2048x1151.jpeg 424w, https://substackcdn.com/image/fetch/$s_!jQOD!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F776058da-e524-49c7-a9eb-3be0c69400f1_2048x1151.jpeg 848w, https://substackcdn.com/image/fetch/$s_!jQOD!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F776058da-e524-49c7-a9eb-3be0c69400f1_2048x1151.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!jQOD!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F776058da-e524-49c7-a9eb-3be0c69400f1_2048x1151.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/776058da-e524-49c7-a9eb-3be0c69400f1_2048x1151.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:818,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;818&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!jQOD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F776058da-e524-49c7-a9eb-3be0c69400f1_2048x1151.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!jQOD!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F776058da-e524-49c7-a9eb-3be0c69400f1_2048x1151.jpeg 424w, https://substackcdn.com/image/fetch/$s_!jQOD!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F776058da-e524-49c7-a9eb-3be0c69400f1_2048x1151.jpeg 848w, https://substackcdn.com/image/fetch/$s_!jQOD!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F776058da-e524-49c7-a9eb-3be0c69400f1_2048x1151.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!jQOD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F776058da-e524-49c7-a9eb-3be0c69400f1_2048x1151.jpeg 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   The Rest: Analysis
  &lt;/h2&gt;
  &lt;h3&gt;
   Reasoning &amp; RL
  &lt;/h3&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      ★ Jan. 28:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/why-reasoning-models-will-generalize&quot; rel=&quot;&quot;&gt;
      Why reasoning models will generalize
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Mar. 05:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/where-inference-time-scaling-pushes&quot; rel=&quot;&quot;&gt;
      Where inference-time scaling pushes the market for AI companies
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Mar. 31:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/papers-im-reading-base-model-rl-grpo&quot; rel=&quot;&quot;&gt;
      Recent reasoning research: GRPO tweaks, base model RL, and data curation
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Apr. 05:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/rl-backlog-openais-many-rls-clarifying&quot; rel=&quot;&quot;&gt;
      RL backlog: OpenAI’s many RLs, clarifying distillation, and latent reasoning
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      ★ May. 27:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/reinforcement-learning-with-random&quot; rel=&quot;&quot;&gt;
      Reinforcement learning with random rewards actually works with Qwen 2.5
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      ★ Jun. 04:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/next-gen-reasoners&quot; rel=&quot;&quot;&gt;
      A taxonomy for next-generation reasoning models
     &lt;/a&gt;
     &lt;span&gt;
      — Skills, calibration, strategy, and abstraction.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Jun. 09:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/what-comes-next-with-reinforcement&quot; rel=&quot;&quot;&gt;
      What comes next with reinforcement learning
     &lt;/a&gt;
     &lt;span&gt;
      — On scaling and the challenges of sparser, long-horizon RL.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      ★ Jun. 12:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/the-rise-of-reasoning-machines&quot; rel=&quot;&quot;&gt;
      The rise of reasoning machines
     &lt;/a&gt;
     &lt;span&gt;
      — Contra the haters of language models who ground their arguments in human reasoning.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      ★ Sep. 22:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/thinking-searching-and-acting&quot; rel=&quot;&quot;&gt;
      Thinking, Searching, and Acting
     &lt;/a&gt;
     &lt;span&gt;
      — The three primitives of reasoning models.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      ★ Oct. 20:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/the-new-rl-scaling-laws&quot; rel=&quot;&quot;&gt;
      How to scale RL
     &lt;/a&gt;
     &lt;span&gt;
      — Reviewing the one substantive scaling RL paper of the year.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!Spr_!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Spr_!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png 424w, https://substackcdn.com/image/fetch/$s_!Spr_!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png 848w, https://substackcdn.com/image/fetch/$s_!Spr_!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png 1272w, https://substackcdn.com/image/fetch/$s_!Spr_!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:677,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;677&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!Spr_!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Spr_!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png 424w, https://substackcdn.com/image/fetch/$s_!Spr_!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png 848w, https://substackcdn.com/image/fetch/$s_!Spr_!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png 1272w, https://substackcdn.com/image/fetch/$s_!Spr_!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;h3&gt;
   Life, Writing, &amp; My Approach
  &lt;/h3&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      ★ May. 14:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/my-path-into-ai&quot; rel=&quot;&quot;&gt;
      My path into AI
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Jun. 06:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/how-i-write&quot; rel=&quot;&quot;&gt;
      How I Write
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      ★ Oct. 25:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/burning-out&quot; rel=&quot;&quot;&gt;
      Burning out
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Nov. 16:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/why-ai-writing-is-mid&quot; rel=&quot;&quot;&gt;
      Why AI writing is mid
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;h3&gt;
   Open-source AI
  &lt;/h3&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Feb. 05:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/making-the-us-the-home-for-open-source&quot; rel=&quot;&quot;&gt;
      Making the U.S. the home for open-source AI
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      May. 06:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/what-people-get-wrong-about-the-leading&quot; rel=&quot;&quot;&gt;
      What people get wrong about the leading Chinese open models: Adoption and censorship
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      ★ Jul. 04:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/the-american-deepseek-project&quot; rel=&quot;&quot;&gt;
      The American DeepSeek Project
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Jul. 23:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/the-white-houses-plan-for-open-models&quot; rel=&quot;&quot;&gt;
      The White House’s plan for open models &amp; AI research in the U.S.
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Aug. 04:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/atom-project&quot; rel=&quot;&quot;&gt;
      Towards American Truly Open Models: The ATOM Project
     &lt;/a&gt;
     &lt;span&gt;
      — The rebranded and expanded American DeepSeek project.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      ★ Aug. 17:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/chinas-top-19-open-model-labs&quot; rel=&quot;&quot;&gt;
      Ranking the Chinese Open Model Builders
     &lt;/a&gt;
     &lt;span&gt;
      — Research on all the labs building good models in China.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Sep. 09:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/on-chinas-open-source-ai-trajectory&quot; rel=&quot;&quot;&gt;
      On China’s open source AI trajectory
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Dec. 14:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/2025-open-models-year-in-review&quot; rel=&quot;&quot;&gt;
      2025 Open Models Year in Review
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!ykeT!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6692cb58-3e23-47e1-a2e9-378f9a91d02c_1946x974.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!ykeT!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6692cb58-3e23-47e1-a2e9-378f9a91d02c_1946x974.png 424w, https://substackcdn.com/image/fetch/$s_!ykeT!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6692cb58-3e23-47e1-a2e9-378f9a91d02c_1946x974.png 848w, https://substackcdn.com/image/fetch/$s_!ykeT!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6692cb58-3e23-47e1-a2e9-378f9a91d02c_1946x974.png 1272w, https://substackcdn.com/image/fetch/$s_!ykeT!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6692cb58-3e23-47e1-a2e9-378f9a91d02c_1946x974.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6692cb58-3e23-47e1-a2e9-378f9a91d02c_1946x974.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:729,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;729&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!ykeT!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6692cb58-3e23-47e1-a2e9-378f9a91d02c_1946x974.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!ykeT!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6692cb58-3e23-47e1-a2e9-378f9a91d02c_1946x974.png 424w, https://substackcdn.com/image/fetch/$s_!ykeT!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6692cb58-3e23-47e1-a2e9-378f9a91d02c_1946x974.png 848w, https://substackcdn.com/image/fetch/$s_!ykeT!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6692cb58-3e23-47e1-a2e9-378f9a91d02c_1946x974.png 1272w, https://substackcdn.com/image/fetch/$s_!ykeT!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6692cb58-3e23-47e1-a2e9-378f9a91d02c_1946x974.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;h3&gt;
   The Rest
  &lt;/h3&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Jan. 15:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/to-meta-ray-ban-local-ai&quot; rel=&quot;&quot;&gt;
      Let me use my local LMs on Meta Ray-Bans
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      ★ Feb. 12:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/deep-research-information-vs-insight-in-science&quot; rel=&quot;&quot;&gt;
      Deep Research, information vs. insight, and the nature of science
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Feb. 26:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/character-training&quot; rel=&quot;&quot;&gt;
      Character training: Understanding and crafting a language model’s personality
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Mar. 10:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/elicitation-theory-of-post-training&quot; rel=&quot;&quot;&gt;
      Elicitation, the simplest way to understand post-training
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      ★ Mar. 19:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/how-to-manage-ai-training-organizations&quot; rel=&quot;&quot;&gt;
      Managing frontier model training organizations (or teams)
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Apr. 28:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/transparency-and-shifting-priority&quot; rel=&quot;&quot;&gt;
      Transparency and (shifting) priority stacks
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Apr. 30:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/brakes-on-an-intelligence-explosion&quot; rel=&quot;&quot;&gt;
      State of play of AI progress (and related brakes on an intelligence explosion)
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      ★ May. 04:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/sycophancy-and-the-art-of-the-model&quot; rel=&quot;&quot;&gt;
      Sycophancy and the art of the model
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      May. 21:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/people-use-ai-more-than-you-think&quot; rel=&quot;&quot;&gt;
      People use AI more than you think
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Jun. 21:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/what-ive-been-reading-1&quot; rel=&quot;&quot;&gt;
      What I’ve been reading (#1)
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Jun. 23:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/summertime-outlook-o3s-novelty-coming&quot; rel=&quot;&quot;&gt;
      Some ideas for what comes next
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Jun. 28:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/ilya-on-deep-learning-in-2015&quot; rel=&quot;&quot;&gt;
      Ilya on deep learning in 2015
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Aug. 10:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/what-im-reading-2-more-on-kimi-k2&quot; rel=&quot;&quot;&gt;
      What I’ve been reading (#2): More on Kimi K2, how to build a bad research center, Pretraining with RL, and sporks of AGI
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      ★ Aug. 15:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/contra-dwarkesh-on-continual-learning&quot; rel=&quot;&quot;&gt;
      Contra Dwarkesh on Continual Learning
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Sep. 18:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/coding-as-the-epicenter-of-ai-progress&quot; rel=&quot;&quot;&gt;
      Coding as the epicenter of AI progress and the path to general agents
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Sep. 30:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/the-agentic-app&quot; rel=&quot;&quot;&gt;
      ChatGPT: The Agentic App
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Oct. 07:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/thoughts-on-the-curve&quot; rel=&quot;&quot;&gt;
      Thoughts on The Curve
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Nov. 10:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/opening-the-black-box-of-character&quot; rel=&quot;&quot;&gt;
      Opening the black box of character training
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;h2&gt;
   Artifacts Logs: Open Model Roundups
  &lt;/h2&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Jan. 27:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/open-artifacts-in-january-6-reasoning&quot; rel=&quot;&quot;&gt;
      The latest open artifacts (#6): Reasoning models, China’s lead in open-source, and a growing multimodal space
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Feb. 19:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/artifacts-7&quot; rel=&quot;&quot;&gt;
      The latest open artifacts (#7): Alpaca era of reasoning models, China’s continued dominance, and tons of multimodal advancements
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Mar. 20:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/the-latest-open-artifacts-8-the-return&quot; rel=&quot;&quot;&gt;
      The latest open artifacts (#8): The return of ~30B models, side effects of OpenAI’s proposed DeepSeek ban, and yet another reasoning roundup
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Apr. 21:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/the-latest-open-artifacts-9-rlhf&quot; rel=&quot;&quot;&gt;
      The latest open artifacts (#9): RLHF book draft, where the open reasoning race is going, and unsung heroes of open LM work
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      May. 29:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-artifacts-10-new-deepseek&quot; rel=&quot;&quot;&gt;
      Latest open artifacts (#10): New DeepSeek R1 0528!, more permissive licenses, everything as a reasoner, and from artifacts to agents
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Jun. 26:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-artifacts-11-visualizing&quot; rel=&quot;&quot;&gt;
      Latest open artifacts (#11): Visualizing China’s open models market share, Arcee’s models, and VLAs for robotics
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Jul. 22:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-artifacts-12-qwen3-235b-a22b-instruct-2507&quot; rel=&quot;&quot;&gt;
      Latest open artifacts (#12): Chinese models continue to dominate throughout the summer 🦦
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Aug. 11:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-artifacts-13-the-abundance&quot; rel=&quot;&quot;&gt;
      Latest open artifacts (#13): The abundance era of open models
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Sep. 11:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-artifacts-14-nvidias&quot; rel=&quot;&quot;&gt;
      Latest open artifacts (#14): NVIDIA’s rise, “Swiss &amp; UAE DeepSeek,” and a resurgence of open data
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Oct. 18:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-models-15-its-qwens-world&quot; rel=&quot;&quot;&gt;
      Latest open artifacts (#15): It’s Qwen’s world and we get to live in it, on CAISI’s report, &amp; GPT-OSS update
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      ★ Nov. 23:
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-artifacts-16-whos-building&quot; rel=&quot;&quot;&gt;
      Latest open artifacts (#16): Who’s building models in the U.S., China’s model release playbook, and a resurgence of truly open models
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!4rSK!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa66ec97a-988d-4317-8a90-4291fc009783_2816x1536.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!4rSK!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa66ec97a-988d-4317-8a90-4291fc009783_2816x1536.jpeg 424w, https://substackcdn.com/image/fetch/$s_!4rSK!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa66ec97a-988d-4317-8a90-4291fc009783_2816x1536.jpeg 848w, https://substackcdn.com/image/fetch/$s_!4rSK!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa66ec97a-988d-4317-8a90-4291fc009783_2816x1536.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!4rSK!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa66ec97a-988d-4317-8a90-4291fc009783_2816x1536.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a66ec97a-988d-4317-8a90-4291fc009783_2816x1536.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:794,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:611722,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/181486818?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa66ec97a-988d-4317-8a90-4291fc009783_2816x1536.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;794&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!4rSK!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa66ec97a-988d-4317-8a90-4291fc009783_2816x1536.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!4rSK!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa66ec97a-988d-4317-8a90-4291fc009783_2816x1536.jpeg 424w, https://substackcdn.com/image/fetch/$s_!4rSK!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa66ec97a-988d-4317-8a90-4291fc009783_2816x1536.jpeg 848w, https://substackcdn.com/image/fetch/$s_!4rSK!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa66ec97a-988d-4317-8a90-4291fc009783_2816x1536.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!4rSK!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa66ec97a-988d-4317-8a90-4291fc009783_2816x1536.jpeg 1456w&quot; title=&quot;&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/2025-interconnects-year-in-review#footnote-anchor-1-181486818&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     I shouldn’t have to explain why being a bit ahead in the trends of AI research should be valuable.
    &lt;/p&gt;
    &lt;p&gt;
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> 2025 Open Models Year in Review </title>
<link>https://www.interconnects.ai/p/2025-open-models-year-in-review</link>
<pubDate>Sun, 14 Dec 2025 20:01:01 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   Welcome to the first Artifacts Recap, where we highlight the most notable and impactful open model releases of this year. And what a year it has been! Starting into the year, the open model landscape was seen as lagging behind severely, with open models being mostly a choice for those who needed privacy or wanted to fine-tune models for their use cases.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    While these are still compelling reasons for open models, the performance in this year has increased dramatically during the last 12 months. In 2024, the ecosystem was mostly relying on Llama 3 and looking ahead to the next generation of that model family, while Qwen2.5, QwQ and DeepSeek V2 / V2.5 / V3 were known to those deep into the ecosystem as capable but still niche picks. In 2025, Qwen and DeepSeek became household names with
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1&quot; rel=&quot;&quot;&gt;
    R1
   &lt;/a&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/qwen-3-the-new-open-standard&quot; rel=&quot;&quot;&gt;
    Qwen 3
   &lt;/a&gt;
   &lt;span&gt;
    respectively, which resulted in particular a lot of Chinese companies opening their models as well.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   As a result, the open ecosystem has immensely accelerated in terms of capabilities, rivaling closed models on most key benchmarks. It is a much more nuanced debate on if they’re delivering as much in real-world usage, where closed models still dominate.
  &lt;/p&gt;
  &lt;p&gt;
   Selecting any number of models as the “best few” is a nearly impossible task, as the ecosystem is growing so rapidly. There are many more categories of open models that are relevant than just the biggest, text-only models. Open models thrive as being the default for many niche use-cases across modalities and compute perspectives.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    To put the scale of our open ecosystem monitoring into perspective: Each day, around 1,000 - 2,000 models are uploaded to HuggingFace. Out of these 30,000 - 60,000 models a month, we select roughly 50 for
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/t/artifacts-log&quot; rel=&quot;&quot;&gt;
    the Artifacts
   &lt;/a&gt;
   &lt;span&gt;
    series model roundups, which results in us covering 600 models a year. This of course means that some models didn’t make the cut.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Do you think we missed an obvious one? Leave your choice in the comments!
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    In this post, we start by highlighting our top models of the year in terms of their influence on the AI ecosystem broadly and the trends of open models specifically. We conclude with the
   &lt;/span&gt;
   &lt;strong&gt;
    complete tier list across model makers
   &lt;/strong&gt;
   &lt;span&gt;
    in the U.S., China, and the world, based on contributions in 2025.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   &lt;strong&gt;
    The Winners
   &lt;/strong&gt;
  &lt;/h2&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!v3tx!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ed6b1e9-849f-4026-83a0-4ea18786d6a1_1024x560.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!v3tx!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ed6b1e9-849f-4026-83a0-4ea18786d6a1_1024x560.jpeg 424w, https://substackcdn.com/image/fetch/$s_!v3tx!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ed6b1e9-849f-4026-83a0-4ea18786d6a1_1024x560.jpeg 848w, https://substackcdn.com/image/fetch/$s_!v3tx!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ed6b1e9-849f-4026-83a0-4ea18786d6a1_1024x560.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!v3tx!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ed6b1e9-849f-4026-83a0-4ea18786d6a1_1024x560.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7ed6b1e9-849f-4026-83a0-4ea18786d6a1_1024x560.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:560,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;560&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!v3tx!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ed6b1e9-849f-4026-83a0-4ea18786d6a1_1024x560.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!v3tx!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ed6b1e9-849f-4026-83a0-4ea18786d6a1_1024x560.jpeg 424w, https://substackcdn.com/image/fetch/$s_!v3tx!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ed6b1e9-849f-4026-83a0-4ea18786d6a1_1024x560.jpeg 848w, https://substackcdn.com/image/fetch/$s_!v3tx!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ed6b1e9-849f-4026-83a0-4ea18786d6a1_1024x560.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!v3tx!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ed6b1e9-849f-4026-83a0-4ea18786d6a1_1024x560.jpeg 1456w&quot; width=&quot;1024&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   The models that defined this year’s releases and had outsized impact, even outside the open model space.
  &lt;/p&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1&quot; rel=&quot;&quot;&gt;
       DeepSeek R1
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      : Yes, that one was released this year! On January 20th, to be precise. It is hard to overstate the impact this model release has had, both on the open model, as well as the general AI landscape. Not only did it show that a small team is able to push forward with innovation, it also was released under the MIT license — while its predecessor, DeepSeek V3, used a custom,
     &lt;/span&gt;
     &lt;a href=&quot;https://github.com/deepseek-ai/DeepSeek-V3/blob/main/LICENSE-MODEL&quot; rel=&quot;&quot;&gt;
      DeepSeek License
     &lt;/a&gt;
     &lt;span&gt;
      with usage restrictions. This move inspired a lot of (Chinese) labs to release their models openly and under an open license as well. Remember the times when Qwen had their own license
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct&quot; rel=&quot;&quot;&gt;
      for their most capable models
     &lt;/a&gt;
     &lt;span&gt;
      ?
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;span&gt;
      It is obvious to say that this release was the most impactful one for this year.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://www.interconnects.ai/p/qwen-3-the-new-open-standard&quot; rel=&quot;&quot;&gt;
       Qwen 3
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      : It might be unfair to put a whole model family in the same ranks as other models in this list. Qwen3 covers everything: From
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/collections/Qwen/qwen3&quot; rel=&quot;&quot;&gt;
      general models
     &lt;/a&gt;
     &lt;span&gt;
      in all sizes and forms (both dense and MoE), to
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/collections/Qwen/qwen3-vl&quot; rel=&quot;&quot;&gt;
      vision
     &lt;/a&gt;
     &lt;span&gt;
      and
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/collections/Qwen/qwen3-omni&quot; rel=&quot;&quot;&gt;
      omni
     &lt;/a&gt;
     &lt;span&gt;
      ,
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/collections/Qwen/qwen3-coder&quot; rel=&quot;&quot;&gt;
      coding
     &lt;/a&gt;
     &lt;span&gt;
      ,
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/collections/Qwen/qwen3-embedding&quot; rel=&quot;&quot;&gt;
      embedding
     &lt;/a&gt;
     &lt;span&gt;
      and
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/collections/Qwen/qwen3-reranker&quot; rel=&quot;&quot;&gt;
      reranker
     &lt;/a&gt;
     &lt;span&gt;
      , cause why wouldn’t they?
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      While Qwen2.5 was mostly known as an insider tip and heavily used by academia, Qwen3 is regarded as the choice for a lot of problems, especially in terms of multilinguality. It therefore is no wonder that a lot of academic experiments are conducted on Qwen-based models,
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/reinforcement-learning-with-random&quot; rel=&quot;&quot;&gt;
      which might have consequences in terms of reproducibility on other models.
     &lt;/a&gt;
     &lt;span&gt;
      By now, Qwen has overtaken Llama in terms of total downloads and as the most-used base model to fine-tune (for more download data, see
     &lt;/span&gt;
     &lt;a href=&quot;https://www.atomproject.ai/&quot; rel=&quot;&quot;&gt;
      The ATOM Project
     &lt;/a&gt;
     &lt;span&gt;
      ).
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://www.interconnects.ai/p/kimi-k2-and-when-deepseek-moments&quot; rel=&quot;&quot;&gt;
       Kimi K2
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      : Moonshot AI is a laser-focused lab similar to DeepSeek: They work on one model line at a time, while running experiments on smaller models which will eventually feed back into their main model line for the next generation. This therefore makes it easy to guess what the next model will look like. Kimi K2 was (and is) a model loved by many, for both its sheer performance and its distinct writing style.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/2025-open-models-year-in-review?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/2025-open-models-year-in-review?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;h2&gt;
   Runner Ups
  &lt;/h2&gt;
  &lt;p&gt;
   Model releases that are very solid and deservedly well-known in the open model space.
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://www.interconnects.ai/i/179633798/our-picks&quot; rel=&quot;&quot;&gt;
       MiniMax M2
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      : MiniMax M2 was a surprising release this year. While MiniMax didn’t come from nowhere and we’ve been watching every release from them, the leap from the rather mediocre M1 to the very capable M2 is nothing short of remarkable. Minimax also executed the
     &lt;/span&gt;
     &lt;a href=&quot;https://open.substack.com/pub/robotic/p/latest-open-artifacts-16-whos-building?r=ozvld&amp;selection=dc458e60-b7d2-4465-a022-a9e12eb55103&quot; rel=&quot;&quot;&gt;
      (Chinese) model release playbook
     &lt;/a&gt;
     &lt;span&gt;
      perfectly, leading to lasting usage even after the free period ended, with M2 continuing to be one of the most-used models on OpenRouter.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://www.interconnects.ai/i/170685919/our-picks&quot; rel=&quot;&quot;&gt;
       GLM-4.5
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      : The story of Zhipu feels similar to Moonshot: A team which is laser-focused on one model line and one goal, and continues to develop their models with rigor, followed by them getting more attention with one model release. That model release was Kimi K2 for Moonshot and GLM-4.5 for Zhipu. We also chose 4.5 over 4.6 because it was their breakthrough moment and has the beloved and smaller
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/zai-org/GLM-4.5-Air&quot; rel=&quot;&quot;&gt;
      Air
     &lt;/a&gt;
     &lt;span&gt;
      version, which will be released for 4.6 in the near future.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://www.interconnects.ai/p/gpt-oss-openai-validates-the-open&quot; rel=&quot;&quot;&gt;
       GPT-OSS
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      : The long-awaited open model release by OpenAI. Flexing its muscles with sheer performance, this model is the driving force behind many agentic apps, in which it shines. Being weak in general world knowledge and multilingual, GPT-OSS must be used in very specific settings and setups, where it then outshines alternatives. It also pioneered different (low/medium/high) thinking levels, similar to its big closed-source brothers, something we might see adopted by other (open) models in the future.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://www.interconnects.ai/p/gemma-3-olmo-2-32b-and-the-growing&quot; rel=&quot;&quot;&gt;
       Gemma 3
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      : Gemma 3 is beloved for two reasons: Its strong multilingual abilities, especially at the &amp;lt;30B size range, and its vision capabilities. The latter is something the Western open model space is severely lacking in terms of strong options aside from Gemma and Moondream. Hopefully, this might change in the coming year!
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://www.interconnects.ai/p/olmo-3-americas-truly-open-reasoning&quot; rel=&quot;&quot;&gt;
       Olmo 3
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      : As is it has for the last few years, Ai2 (where Nathan works) delivered another update to the best models with all data, code, weights, logs, and methods released. These are crucial for researchers who cannot understand leading models without releases like this. Where the industry has shifted to MoEs for peak performance, and Ai2 will too, these models at 7 and 32B scales of dense transformers is crucial for accessibility of finetuning — a niche that is actually underserved by the model makers after Llama’s downfall and Qwen withholding some base models.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h2&gt;
   Honorable Mentions
  &lt;/h2&gt;
  &lt;p&gt;
   Models that dominate or re-define a certain niche.
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://open.substack.com/pub/robotic/p/latest-open-artifacts-14-nvidias?r=ozvld&amp;selection=855cd2a6-8cf7-46d1-bd05-79f2ef707afd&amp;utm_campaign=post-share-selection&amp;utm_medium=web&amp;aspectRatio=instagram&amp;textColor=%23ffffff&amp;bgImage=true&quot; rel=&quot;&quot;&gt;
       Parakeet 3
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      : I (Florian) cannot speak highly enough of this speech-to-text model. It completely transformed how I work and interact with my computer. Speaking with your computer is awkward at first but becomes natural quickly. It also is a huge boost to (Claude) coding-based workflows if you can just waffle on for paragraphs to explain your problem compared to lazily writing a few sentences.
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      It is almost boring to see how well this model works while being blazingly fast on a MacBook, beating out every cloud-based platform in terms of end-to-end latency. It is such a good model that a lot of apps with “Whisper” in its name are switching to this model as the main engine (something we have seen time and time again — r/LocalLlama is not about Llama anymore, nor is r/StableDiffusion about Stable Diffusion these days). Parakeet 3 adds a whole new selection of languages, including German, which I happily use. Whisper has support for more languages, at least for now. Oh, did I mention that the majority of data is open as well
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://open.substack.com/pub/robotic/p/latest-open-artifacts-14-nvidias?r=ozvld&amp;selection=695a66c4-5c24-4aa8-886c-a29f09f28276&amp;utm_campaign=post-share-selection&amp;utm_medium=web&amp;aspectRatio=instagram&amp;textColor=%23ffffff&amp;bgImage=true&quot; rel=&quot;&quot;&gt;
       Nemotron 2
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      : NVIDIA, the second: They are  also in the open model LLM business (well, and also
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/nvidia/GR00T-N1.5-3B&quot; rel=&quot;&quot;&gt;
      VLAs
     &lt;/a&gt;
     &lt;span&gt;
      ,
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/collections/nvidia/reward-models-10-2025&quot; rel=&quot;&quot;&gt;
      reward models
     &lt;/a&gt;
     &lt;span&gt;
      ,
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/collections/nvidia/clara-biology&quot; rel=&quot;&quot;&gt;
      biology
     &lt;/a&gt;
     &lt;span&gt;
      ,
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/collections/nvidia/lyra&quot; rel=&quot;&quot;&gt;
      gaussian splatting
     &lt;/a&gt;
     &lt;span&gt;
      ,
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/collections/nvidia/gen3c&quot; rel=&quot;&quot;&gt;
      video generation
     &lt;/a&gt;
     &lt;span&gt;
      , and and and). Aside from them pruning and post-training other
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/nvidia/Llama-3_3-Nemotron-Super-49B-v1_5&quot; rel=&quot;&quot;&gt;
      models
     &lt;/a&gt;
     &lt;span&gt;
      , they are training their own models under the Nemotron brand. Similar to Parakeet, the vast majority of data is released openly. Their models are mamba2-transformer hybrids, which improves the speed, especially at long contexts, compared to transformer-only models.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://open.substack.com/pub/robotic/p/latest-open-models-15-its-qwens-world?r=ozvld&amp;selection=f244d3e8-e5fd-446b-8f01-3c0b43cd8662&amp;utm_campaign=post-share-selection&amp;utm_medium=web&amp;aspectRatio=instagram&amp;textColor=%23ffffff&amp;bgImage=true&quot; rel=&quot;&quot;&gt;
       Moondream 3
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      : Widely regarded as THE player in the vision space, the Moondream team puts a lot of care into their model releases, giving even closed models like GPT or Gemini a run for its money. Those deep in the vision space know that, those who aren’t should know. Try the model!
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://open.substack.com/pub/robotic/p/latest-open-models-15-its-qwens-world?r=ozvld&amp;selection=b89a2edb-6142-483d-8ccb-b159714659ba&amp;utm_campaign=post-share-selection&amp;utm_medium=web&amp;aspectRatio=instagram&amp;textColor=%23ffffff&amp;bgImage=true&quot; rel=&quot;&quot;&gt;
       Granite 4
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      : The IBM team puts out rock-solid (pun intended) releases one after the other, yet are unable to get the attention they deserve. Togglable thinking per prompt was debuted by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/ibm-granite/granite-3.2-8b-instruct-preview&quot; rel=&quot;&quot;&gt;
      Granite 3.2
     &lt;/a&gt;
     &lt;span&gt;
      , for example. And while this seemed to be a short-lived phase, as the open model space is switching back to releasing reasoning and instruct models separately, it shows that IBMs LLM efforts are worth to be watched. With its fourth iteration, IBM adapts the mamba-attention architecture and also releases MoEs. Even more important: They are we scaling up the model sizes! The writing style is also distinctly non-sloptimized, which is regreshing in this day and age.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://open.substack.com/pub/robotic/p/latest-open-artifacts-12-qwen3-235b-a22b-instruct-2507?r=ozvld&amp;selection=7b6a371d-dafb-48c7-ae89-57b342f36bfe&amp;utm_campaign=post-share-selection&amp;utm_medium=web&amp;aspectRatio=instagram&amp;textColor=%23ffffff&amp;bgImage=true&quot; rel=&quot;&quot;&gt;
       SmolLM3
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      : A tiny, yet capable model for its 3B size. All the data is open, as well as intermediate checkpoints. Aside from
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/blog/smollm3&quot; rel=&quot;&quot;&gt;
      the great initial blog
     &lt;/a&gt;
     &lt;span&gt;
      , the HF team has also released other
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/spaces/HuggingFaceTB/smol-training-playbook&quot; rel=&quot;&quot;&gt;
      resources
     &lt;/a&gt;
     &lt;span&gt;
      which deeper into the training. If you are in the need for a great on-device model, chances are that SmolLM3 is a perfect fit!
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h2&gt;
   Mapping the open ecosystem
  &lt;/h2&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!7NJE!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F397d06d3-8707-4618-882d-183307923832_1974x974.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!7NJE!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F397d06d3-8707-4618-882d-183307923832_1974x974.png 424w, https://substackcdn.com/image/fetch/$s_!7NJE!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F397d06d3-8707-4618-882d-183307923832_1974x974.png 848w, https://substackcdn.com/image/fetch/$s_!7NJE!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F397d06d3-8707-4618-882d-183307923832_1974x974.png 1272w, https://substackcdn.com/image/fetch/$s_!7NJE!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F397d06d3-8707-4618-882d-183307923832_1974x974.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/397d06d3-8707-4618-882d-183307923832_1974x974.png&quot;,&quot;srcNoWatermark&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/17556f68-0bf4-48d9-a2d1-fb1196d5f464_1974x974.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:718,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:762599,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/181259397?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17556f68-0bf4-48d9-a2d1-fb1196d5f464_1974x974.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;718&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!7NJE!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F397d06d3-8707-4618-882d-183307923832_1974x974.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!7NJE!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F397d06d3-8707-4618-882d-183307923832_1974x974.png 424w, https://substackcdn.com/image/fetch/$s_!7NJE!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F397d06d3-8707-4618-882d-183307923832_1974x974.png 848w, https://substackcdn.com/image/fetch/$s_!7NJE!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F397d06d3-8707-4618-882d-183307923832_1974x974.png 1272w, https://substackcdn.com/image/fetch/$s_!7NJE!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F397d06d3-8707-4618-882d-183307923832_1974x974.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    We have more requests than imagined to update our
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/chinas-top-19-open-model-labs&quot; rel=&quot;&quot;&gt;
    tier list
   &lt;/a&gt;
   &lt;span&gt;
    , which covered the Chinese ecosystem and to extend it with Western orgs, which we’ve covered
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-artifacts-16-whos-building&quot; rel=&quot;&quot;&gt;
    here
   &lt;/a&gt;
   &lt;span&gt;
    . We have added a specialist tier which contains the organizations that trained few models or are specializing in a certain niche, e.g. small, on-device models (Liquid, HuggingFace). Some notes:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     A lot of the orgs in Noteworthy can reach a higher tier by scaling up their current recipe. This tier also includes model makers who train a lot of models, often for different modalities.
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Meituan Longcat (China’s DoorDash equivalent) is a new addition to the tier list, their models are recurring guests in the artifacts series.
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Meta was weird to place, given that there are a
     &lt;/span&gt;
     &lt;a href=&quot;https://www.cnbc.com/2025/12/09/meta-avocado-ai-strategy-issues.html&quot; rel=&quot;&quot;&gt;
      lot of reports
     &lt;/a&gt;
     &lt;span&gt;
      that they will release proprietary models in the future. The future of Llama is uncertain.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      ByteDance Seed’s papers show that they are a strong research organization, which yet has to be reflected in their open model releases.
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/ByteDance-Seed/Seed-OSS-36B-Instruct&quot; rel=&quot;&quot;&gt;
      Seed-OSS 36B
     &lt;/a&gt;
     &lt;span&gt;
      is their first capable LLM, while their other releases, such as
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/ByteDance-Seed/AHN-Mamba2-for-Qwen-2.5-Instruct-3B&quot; rel=&quot;&quot;&gt;
      AHN-Mamba2-for-Qwen-2.5-Instruct-3B
     &lt;/a&gt;
     &lt;span&gt;
      are mostly research artifacts.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   &lt;span&gt;
    If you want to take your own stab at the tier list, you can do so by using
   &lt;/span&gt;
   &lt;a href=&quot;https://tiermaker.com/create/chinese-model-makers-18511783&quot; rel=&quot;&quot;&gt;
    this link
   &lt;/a&gt;
   &lt;span&gt;
    !
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/2025-open-models-year-in-review/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/2025-open-models-year-in-review/comments&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Leave a comment
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;h2&gt;
   Predictions for 2026
  &lt;/h2&gt;
  &lt;p&gt;
   2025 was a seminal year in open models, where open model deployments became a real possibility. It is still well accepted that the best closed models have a robustness and richness that open models matching them on benchmarks don’t always have, but the potential of trying open models has never been higher. This leaves us at the point where open models are established, so where do they go next?
  &lt;/p&gt;
  &lt;p&gt;
   In 2026, we expect the major talking points of open models to follow:
  &lt;/p&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> New Talk: Building Olmo 3 Think </title>
<link>https://www.interconnects.ai/p/building-olmo-3-think</link>
<pubDate>Wed, 10 Dec 2025 19:33:22 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    It’s finally here! The public (and most complete) version of my talk covering every stage of the process to build
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/olmo-3-americas-truly-open-reasoning&quot; rel=&quot;&quot;&gt;
    Olmo 3
   &lt;/a&gt;
   &lt;span&gt;
    Think (
   &lt;/span&gt;
   &lt;a href=&quot;https://docs.google.com/presentation/d/1rhXAPyaflqi5cBS6d6IDiNIvLIBxiOpVb1sfK3hNMmo/edit?usp=sharing&quot; rel=&quot;&quot;&gt;
    slides
   &lt;/a&gt;
   &lt;span&gt;
    are available). I’ve been giving this, improving it, and getting great feedback at other venues such as The Conference on Language Modeling (COLM) &amp; The PyTorch Conference.This involves changes and new considerations of every angle of the stack, from pretraining, evaluation, and of course post-training.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Most of the talk focuses on reinforcement learning infrastructure and evaluating reasoning models, with quick comments on every training stage. I hope you enjoy it, and let us know what to improve in the future!
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/building-olmo-3-think?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/building-olmo-3-think?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Chapters
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:00:00 Introduction
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:06:30 Pretraining Architecture
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:09:25 Midtraining Data
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:11:08 Long-context Necessity
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:13:04 Building SFT Data
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:20:05 Reasoning DPO Surprises
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:24:47 Scaling RL
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:41:05 Evaluation Overview
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:48:50 Evaluation Reflections
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     01:00:25 Conclusions
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   Here’s the YouTube link:
  &lt;/p&gt;
  &lt;div data-attrs=&#x27;{&quot;videoId&quot;:&quot;uaZ3yRdYg8A&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}&#x27; data-component-name=&quot;Youtube2ToDOM&quot;&gt;
   &lt;div&gt;
    &lt;iframe allow=&quot;autoplay; fullscreen&quot; allowautoplay=&quot;true&quot; allowfullscreen=&quot;true&quot; frameborder=&quot;0&quot; gesture=&quot;media&quot; height=&quot;409&quot; loading=&quot;lazy&quot; src=&quot;https://www.youtube-nocookie.com/embed/uaZ3yRdYg8A?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0&quot; width=&quot;728&quot;&gt;
    &lt;/iframe&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
  &lt;/p&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Latest open artifacts (#16): Who&#x27;s building models in the U.S., China&#x27;s model release playbook, and a resurgence of truly open models </title>
<link>https://www.interconnects.ai/p/latest-open-artifacts-16-whos-building</link>
<pubDate>Sun, 23 Nov 2025 19:31:25 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;h5&gt;
   &lt;span&gt;
    This holiday season, remember you can give the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/subscribe?gift=true&quot; rel=&quot;&quot;&gt;
    gift of Interconnects
   &lt;/a&gt;
   &lt;span&gt;
    (or reimburse your subscription with your company’s learning budget)!
   &lt;/span&gt;
  &lt;/h5&gt;
  &lt;p&gt;
   Before we get to the coverage of many truly open models (Stanford’s Marin, Gaperon, Nathan’s Olmo3, etc.), many OCR models, and some frontier models from China’s AI Tigers, we wanted to share a simple list of the AI labs releasing serious open models in the U.S. This list is easily compiled from the backlog of these posts, but having it all in one place is very helpful with the surge of interest in both Chinese and American open model ecosystems.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/latest-open-artifacts-16-whos-building?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:&quot;button-wrapper&quot;}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-artifacts-16-whos-building?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;h1&gt;
   Who’s building serious open models in the US
  &lt;/h1&gt;
  &lt;p&gt;
   The U.S. has a comparable number of labs releasing high quality models as China (which is ~20 labs), but many American labs are releasing smaller models with more restrictive licenses, resulting in a far more muted impact. This list includes each notable recent model from them. All of these are pretrained by U.S. companies. To start, the clear players, listed alphabetically:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Ai2 — Olmo
     &lt;/strong&gt;
     &lt;span&gt;
      : Open-source leader, to date fully open, smaller dense models mostly. E.g.
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/allenai/Olmo-3-32B-Think&quot; rel=&quot;&quot;&gt;
      Olmo 3 32B Think
     &lt;/a&gt;
     &lt;span&gt;
      , the best fully open reasoning model (and best fully open LM ever made). Always developer friendly Apache 2.0 licenses.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Arcee / Datology / Prime Intellect — Trinity
     &lt;/strong&gt;
     &lt;span&gt;
      : Newer startup fully committed to this. Range of MoE models, Apache 2.0 coming soon.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Google — Gemma
     &lt;/strong&gt;
     &lt;span&gt;
      : One of the most consistent players. To date models have been smaller and dense as well. E.g.
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/google/vaultgemma-1b&quot; rel=&quot;&quot;&gt;
      VaultGemma 1B
     &lt;/a&gt;
     &lt;span&gt;
      . Often solid custom licenses, sometimes minor downstream use restrctions.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      HuggingFace — SmolLM
     &lt;/strong&gt;
     &lt;span&gt;
      : Tiny models, fully open, great community. E.g.
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/HuggingFaceTB/SmolLM3-3B&quot; rel=&quot;&quot;&gt;
      SmolLM3-3B
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      IBM — Granite
     &lt;/strong&gt;
     &lt;span&gt;
      : Small to medium sized models, underrated, strong and consistent releases. E.g.
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/ibm-granite/granite-4.0-h-1b&quot; rel=&quot;&quot;&gt;
      Granite-4.0-h-1b
     &lt;/a&gt;
     &lt;span&gt;
      with a new hybrid-attention architecture. Developer friendly Apache 2.0 licenses.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Liquid AI — Liquid Foundation Models
     &lt;/strong&gt;
     &lt;span&gt;
      : Hybrid architecture, solid small models. .g.
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/LiquidAI/LFM2-VL-3B&quot; rel=&quot;&quot;&gt;
      LFM2-VL-3B
     &lt;/a&gt;
     &lt;span&gt;
      , their first vision-language models. Very similar licenses to Apache 2.0, but with restrictions on companies making $10M per year or more.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Microsoft — Phi (+ others)
     &lt;/strong&gt;
     &lt;span&gt;
      : Solid models, can go under the radar, but consistent. E.g.
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/microsoft/Phi-4-mini-flash-reasoning&quot; rel=&quot;&quot;&gt;
      Phi-4-mini-flash-reasoning
     &lt;/a&gt;
     &lt;span&gt;
      , a small reasoning model. Often fairly permissive licenses too, e.g. MIT.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Moondream — Moondream Models
     &lt;/strong&gt;
     &lt;span&gt;
      : Solid vision models, originally on device, but dominant and consistent in their niche. E.g.
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/moondream/moondream3-preview&quot; rel=&quot;&quot;&gt;
      Moondream3
     &lt;/a&gt;
     &lt;span&gt;
      . Solid licenses and very engaged in community feedback, e.g. recently made it clear synthetic data use is okay.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Nvidia — Nemotron
     &lt;/strong&gt;
     &lt;span&gt;
      : Arguably the open leader in the U.S. after Llama 4. E.g.
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/nvidia/NVIDIA-Nemotron-Nano-9B-v2&quot; rel=&quot;&quot;&gt;
      Nemotron Nano 9B v2
     &lt;/a&gt;
     &lt;span&gt;
      , a 9B model matching or surpassing Chinese models in that size range. Increasingly open licenses recently, including more open data releases.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      OpenAI — GPT OSS
     &lt;/strong&gt;
     &lt;span&gt;
      : A new entrant but incredibly important they’re involved. E.g.
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/openai/gpt-oss-120b&quot; rel=&quot;&quot;&gt;
      gpt-oss-120b
     &lt;/a&gt;
     &lt;span&gt;
      , OpenAI’s first open weights language model since GPT-2. Good Apache 2.0 licenses, we hope they continue releasing more models.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Reflection — TBD
     &lt;/strong&gt;
     &lt;span&gt;
      : but if you can convince someone you’re worth $2B to do this, I believe you.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      ServiceNow — Apriel
     &lt;/strong&gt;
     &lt;span&gt;
      : Solid reasoning models and other contributions. E.g.
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/ServiceNow-AI/Apriel-H1-15b-Thinker-SFT&quot; rel=&quot;&quot;&gt;
      Apriel-H1-15b-Thinker
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Stanford University — Marin Community Models
     &lt;/strong&gt;
     &lt;span&gt;
      : A new entrant in fully-open models like Ai2, scaling up after releasing their first
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/marin-community/marin-32b-base&quot; rel=&quot;&quot;&gt;
      30B base model
     &lt;/a&gt;
     &lt;span&gt;
      . We hope they have strong post-training soon!
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   Of the above, we’re watching Ai2, Nvidia, Arcee, and Reflection the closest, as the players with the most mind-share and momentum on the ground.
  &lt;/p&gt;
  &lt;p&gt;
   Unclear: Companies making fewer contributions currently but have in the past.
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Meta — Llama
     &lt;/strong&gt;
     &lt;span&gt;
      : The original, but priorities are changing. Crickets since the
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/llama-4&quot; rel=&quot;&quot;&gt;
      Llama 4 fiasco
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Reka — Flash
     &lt;/strong&gt;
     &lt;span&gt;
      : A few solid models, no updates in a bit.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      xAI — Grok
     &lt;/strong&gt;
     &lt;span&gt;
      : Many promises of releasing past models, yet to be useful to the community.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   This is a list of groups making solid language models in the U.S. Other labs that would easily be included in a more “Western” ecosystem list would include the likes of Cohere (with solid models, though normally non-commercial licenses), Mistral (with smaller models, normally Apache 2.0), and AI21 labs. There are other types, such as multimodal generation models and biology-focused models that are massive breakthroughs but not listed.
  &lt;/p&gt;
  &lt;p&gt;
   Download this U.S. model maker list as a PDF below:
  &lt;/p&gt;
  &lt;div data-component-name=&quot;FileToDOM&quot;&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;img src=&quot;https://substackcdn.com/image/fetch/$s_!0Cy0!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Fattachment_icon.svg&quot;/&gt;
     &lt;div&gt;
      &lt;div&gt;
       Usmodels V3
      &lt;/div&gt;
      &lt;div&gt;
       46.2KB ∙ PDF file
      &lt;/div&gt;
     &lt;/div&gt;
     &lt;a href=&quot;https://www.interconnects.ai/api/v1/file/5ec8fef3-1703-4e10-9f11-1717af76d9f8.pdf&quot; rel=&quot;&quot;&gt;
      &lt;span&gt;
       Download
      &lt;/span&gt;
     &lt;/a&gt;
    &lt;/div&gt;
    &lt;a href=&quot;https://www.interconnects.ai/api/v1/file/5ec8fef3-1703-4e10-9f11-1717af76d9f8.pdf&quot; rel=&quot;&quot;&gt;
     &lt;span&gt;
      Download
     &lt;/span&gt;
    &lt;/a&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    In case you weren’t aware: Paid subscribers get access to the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/discord&quot; rel=&quot;&quot;&gt;
    members-only Discord
   &lt;/a&gt;
   &lt;span&gt;
    , which not only hosts an active community, but also bots covering even more releases in real-time. It also gives a glimpse into the current work and experiments of many labs who (briefly) forget to set their models to private. An example is below. Sometimes we say this is the best perk you get for upgrading to paid — consider it!
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!UCbt!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07e4f5f0-0e91-479f-b758-8ca22a1c69f2_1884x1134.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!UCbt!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07e4f5f0-0e91-479f-b758-8ca22a1c69f2_1884x1134.png 424w, https://substackcdn.com/image/fetch/$s_!UCbt!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07e4f5f0-0e91-479f-b758-8ca22a1c69f2_1884x1134.png 848w, https://substackcdn.com/image/fetch/$s_!UCbt!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07e4f5f0-0e91-479f-b758-8ca22a1c69f2_1884x1134.png 1272w, https://substackcdn.com/image/fetch/$s_!UCbt!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07e4f5f0-0e91-479f-b758-8ca22a1c69f2_1884x1134.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/07e4f5f0-0e91-479f-b758-8ca22a1c69f2_1884x1134.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:876,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:234307,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/179633798?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07e4f5f0-0e91-479f-b758-8ca22a1c69f2_1884x1134.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;876&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!UCbt!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07e4f5f0-0e91-479f-b758-8ca22a1c69f2_1884x1134.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!UCbt!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07e4f5f0-0e91-479f-b758-8ca22a1c69f2_1884x1134.png 424w, https://substackcdn.com/image/fetch/$s_!UCbt!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07e4f5f0-0e91-479f-b758-8ca22a1c69f2_1884x1134.png 848w, https://substackcdn.com/image/fetch/$s_!UCbt!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07e4f5f0-0e91-479f-b758-8ca22a1c69f2_1884x1134.png 1272w, https://substackcdn.com/image/fetch/$s_!UCbt!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07e4f5f0-0e91-479f-b758-8ca22a1c69f2_1884x1134.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;h1&gt;
   &lt;strong&gt;
    Artifacts Log
   &lt;/strong&gt;
  &lt;/h1&gt;
  &lt;h3&gt;
   &lt;strong&gt;
    Our Picks
   &lt;/strong&gt;
  &lt;/h3&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/MiniMaxAI/MiniMax-M2&quot; rel=&quot;&quot;&gt;
       MiniMax-M2
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/MiniMaxAI&quot; rel=&quot;&quot;&gt;
      MiniMaxAI
     &lt;/a&gt;
     &lt;span&gt;
      : Probably one of the surprise releases this month: Minimax, whose previous models were usually behind the claimed performance, really took a leap forward with M2, putting them squarely into the spotlight. They also speedrun the (Chinese) model release playbook, something we
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-artifacts-12-qwen3-235b-a22b-instruct-2507&quot; rel=&quot;&quot;&gt;
      observed
     &lt;/a&gt;
     &lt;span&gt;
      in the
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/artifacts-7&quot; rel=&quot;&quot;&gt;
      past
     &lt;/a&gt;
     &lt;span&gt;
      and was perfected by the likes of Alibaba (Qwen), Moonshot (Kimi) and Zhipu (GLM):
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;ol&gt;
     &lt;li&gt;
      &lt;p&gt;
       Build a social media presence, mainly on Twitter. This increasingly means that researchers are also active aside from the corporate / brand accounts.
      &lt;/p&gt;
     &lt;/li&gt;
     &lt;li&gt;
      &lt;p&gt;
       Release a new model with (Western) launch partners and ecosystem support on day zero, from vLLM to OpenRouter and tools like Cline. To really get it off the ground, offer free access to the API for a limited time.
      &lt;/p&gt;
     &lt;/li&gt;
     &lt;li&gt;
      &lt;p&gt;
       &lt;span&gt;
        Offer a coding subscription which is compatible with Claude Code (or
       &lt;/span&gt;
       &lt;a href=&quot;https://github.com/QwenLM/qwen-code&quot; rel=&quot;&quot;&gt;
        fork a CLI
       &lt;/a&gt;
       &lt;span&gt;
        ) while undercutting their pricing.
       &lt;/span&gt;
      &lt;/p&gt;
     &lt;/li&gt;
     &lt;li&gt;
      &lt;p&gt;
       &lt;span&gt;
        Develop your own
       &lt;/span&gt;
       &lt;a href=&quot;https://github.com/MoonshotAI/kimi-cli&quot; rel=&quot;&quot;&gt;
        tooling
       &lt;/a&gt;
       &lt;span&gt;
        and train the next model to work even better with it.
       &lt;/span&gt;
      &lt;/p&gt;
     &lt;/li&gt;
    &lt;/ol&gt;
    &lt;p&gt;
     &lt;span&gt;
      This strategy, of course, is working: Zhipu
     &lt;/span&gt;
     &lt;a href=&quot;https://www.scmp.com/tech/big-tech/article/3331324/zhipu-ai-sees-tenfold-surge-overseas-users-chinese-ai-gains-traction&quot; rel=&quot;&quot;&gt;
      reportedly
     &lt;/a&gt;
     &lt;span&gt;
      has over 100K international API users and 3M chatbot users.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/moonshotai/Kimi-K2-Thinking&quot; rel=&quot;&quot;&gt;
       Kimi-K2-Thinking
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/moonshotai&quot; rel=&quot;&quot;&gt;
      moonshotai
     &lt;/a&gt;
     &lt;span&gt;
      (more coverage
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/kimi-k2-thinking-what-it-means&quot; rel=&quot;&quot;&gt;
      here
     &lt;/a&gt;
     &lt;span&gt;
      ): The best open model, competitive with some of the best closed models. However, independent evaluation is a problem as third-party API providers struggle to implement the model correctly, something which we have seen, for example, with the release of GPT-OSS. As an example, running the agentic “Vending-Bench” from Andon Labs with a third party provider as opposed to the official API makes a huge difference:
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!p80m!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13b68d2f-e949-498c-8579-b0142cc120d3_1054x1362.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!p80m!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13b68d2f-e949-498c-8579-b0142cc120d3_1054x1362.png 424w, https://substackcdn.com/image/fetch/$s_!p80m!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13b68d2f-e949-498c-8579-b0142cc120d3_1054x1362.png 848w, https://substackcdn.com/image/fetch/$s_!p80m!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13b68d2f-e949-498c-8579-b0142cc120d3_1054x1362.png 1272w, https://substackcdn.com/image/fetch/$s_!p80m!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13b68d2f-e949-498c-8579-b0142cc120d3_1054x1362.png 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/13b68d2f-e949-498c-8579-b0142cc120d3_1054x1362.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1362,&quot;width&quot;:1054,&quot;resizeWidth&quot;:462,&quot;bytes&quot;:822229,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/179633798?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13b68d2f-e949-498c-8579-b0142cc120d3_1054x1362.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;597.0056925996205&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!p80m!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13b68d2f-e949-498c-8579-b0142cc120d3_1054x1362.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!p80m!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13b68d2f-e949-498c-8579-b0142cc120d3_1054x1362.png 424w, https://substackcdn.com/image/fetch/$s_!p80m!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13b68d2f-e949-498c-8579-b0142cc120d3_1054x1362.png 848w, https://substackcdn.com/image/fetch/$s_!p80m!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13b68d2f-e949-498c-8579-b0142cc120d3_1054x1362.png 1272w, https://substackcdn.com/image/fetch/$s_!p80m!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13b68d2f-e949-498c-8579-b0142cc120d3_1054x1362.png 1456w&quot; width=&quot;462&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
    &lt;p&gt;
     &lt;span&gt;
      This is a huge problem plaguing open models. Moonshot also documents the tool calling accuracy
     &lt;/span&gt;
     &lt;a href=&quot;https://github.com/MoonshotAI/K2-Vendor-Verifier/&quot; rel=&quot;&quot;&gt;
      in a repo
     &lt;/a&gt;
     &lt;span&gt;
      , where a lot of providers perform sub-par, including vLLM with a schema accuracy &amp;lt;90%.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-VL-32B-Instruct&quot; rel=&quot;&quot;&gt;
       Qwen3-VL-32B-Instruct
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/Qwen&quot; rel=&quot;&quot;&gt;
      Qwen
     &lt;/a&gt;
     &lt;span&gt;
      : The 2B and 32B version of Qwen3 also get an update. Similar to the 8B version covered in
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-models-15-its-qwens-world&quot; rel=&quot;&quot;&gt;
      last month’s artifact
     &lt;/a&gt;
     &lt;span&gt;
      , the 32B vision model has better text benchmark scores than the initial release of the 32B text-only model.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/allenai/Olmo-3-32B-Think&quot; rel=&quot;&quot;&gt;
       Olmo-3-32B-Think
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/allenai&quot; rel=&quot;&quot;&gt;
      allenai
     &lt;/a&gt;
     &lt;span&gt;
      : A series of truly open models, covering everything from data to all models from the model flow. In case you somehow missed it, check out the coverage of the model:
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div data-attrs=&#x27;{&quot;id&quot;:179299850,&quot;url&quot;:&quot;https://www.interconnects.ai/p/olmo-3-americas-truly-open-reasoning&quot;,&quot;publication_id&quot;:48206,&quot;publication_name&quot;:&quot;Interconnects&quot;,&quot;publication_logo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!djof!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc52e8097-8f3d-4f7e-808b-2f4ad37f3b52_720x720.png&quot;,&quot;title&quot;:&quot;Olmo 3: America’s truly open reasoning models&quot;,&quot;truncated_body_text&quot;:&quot;We present Olmo 3, our next family of fully open, leading language models.&quot;,&quot;date&quot;:&quot;2025-11-20T14:09:07.699Z&quot;,&quot;like_count&quot;:87,&quot;comment_count&quot;:30,&quot;bylines&quot;:[{&quot;id&quot;:10472909,&quot;name&quot;:&quot;Nathan Lambert&quot;,&quot;handle&quot;:&quot;natolambert&quot;,&quot;previous_name&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!RihO!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8fedcdfb-e137-4f6a-9089-a46add6c6242_500x500.jpeg&quot;,&quot;bio&quot;:&quot;ML researcher making sense of AI research, products, and the uncertain technological future. PhD from Berkeley AI. Experience at Meta, DeepMind, HuggingFace.&quot;,&quot;profile_set_up_at&quot;:&quot;2021-04-24T01:19:33.371Z&quot;,&quot;reader_installed_at&quot;:&quot;2022-03-09T17:52:30.690Z&quot;,&quot;publicationUsers&quot;:[{&quot;id&quot;:100753,&quot;user_id&quot;:10472909,&quot;publication_id&quot;:48206,&quot;role&quot;:&quot;admin&quot;,&quot;public&quot;:true,&quot;is_primary&quot;:true,&quot;publication&quot;:{&quot;id&quot;:48206,&quot;name&quot;:&quot;Interconnects&quot;,&quot;subdomain&quot;:&quot;robotic&quot;,&quot;custom_domain&quot;:&quot;www.interconnects.ai&quot;,&quot;custom_domain_optional&quot;:false,&quot;hero_text&quot;:&quot;The cutting edge of AI, from inside the frontier AI labs, minus the hype. The border between high-level and technical thinking. Read by leading engineers, researchers, and investors.&quot;,&quot;logo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c52e8097-8f3d-4f7e-808b-2f4ad37f3b52_720x720.png&quot;,&quot;author_id&quot;:10472909,&quot;primary_user_id&quot;:10472909,&quot;theme_var_background_pop&quot;:&quot;#ff6b00&quot;,&quot;created_at&quot;:&quot;2020-05-21T02:59:47.895Z&quot;,&quot;email_from_name&quot;:&quot;Interconnects by Nathan Lambert&quot;,&quot;copyright&quot;:&quot;Interconnects AI, LLC&quot;,&quot;founding_plan_name&quot;:&quot;Founding Member&quot;,&quot;community_enabled&quot;:true,&quot;invite_only&quot;:false,&quot;payments_state&quot;:&quot;enabled&quot;,&quot;language&quot;:null,&quot;explicit&quot;:false,&quot;homepage_type&quot;:&quot;magaziney&quot;,&quot;is_personal_mode&quot;:false}},{&quot;id&quot;:4610799,&quot;user_id&quot;:10472909,&quot;publication_id&quot;:4519930,&quot;role&quot;:&quot;admin&quot;,&quot;public&quot;:true,&quot;is_primary&quot;:false,&quot;publication&quot;:{&quot;id&quot;:4519930,&quot;name&quot;:&quot;natolambert overflow&quot;,&quot;subdomain&quot;:&quot;natolambert&quot;,&quot;custom_domain&quot;:null,&quot;custom_domain_optional&quot;:false,&quot;hero_text&quot;:&quot;a place for any extra thoughts beyond Interconnects.ai&quot;,&quot;logo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/eb88d599-32c8-49a9-ba33-ab6327aff727_256x256.png&quot;,&quot;author_id&quot;:10472909,&quot;primary_user_id&quot;:null,&quot;theme_var_background_pop&quot;:&quot;#FF6719&quot;,&quot;created_at&quot;:&quot;2025-03-27T15:04:05.448Z&quot;,&quot;email_from_name&quot;:null,&quot;copyright&quot;:&quot;Nathan Lambert&quot;,&quot;founding_plan_name&quot;:null,&quot;community_enabled&quot;:true,&quot;invite_only&quot;:false,&quot;payments_state&quot;:&quot;disabled&quot;,&quot;language&quot;:null,&quot;explicit&quot;:false,&quot;homepage_type&quot;:&quot;newspaper&quot;,&quot;is_personal_mode&quot;:false}},{&quot;id&quot;:4926744,&quot;user_id&quot;:10472909,&quot;publication_id&quot;:4830082,&quot;role&quot;:&quot;admin&quot;,&quot;public&quot;:true,&quot;is_primary&quot;:false,&quot;publication&quot;:{&quot;id&quot;:4830082,&quot;name&quot;:&quot;Retort AI&quot;,&quot;subdomain&quot;:&quot;retortai&quot;,&quot;custom_domain&quot;:&quot;www.retortai.com&quot;,&quot;custom_domain_optional&quot;:false,&quot;hero_text&quot;:&quot;Distilling the major events and challenges in the world of artificial intelligence and machine learning, from Thomas Krendl Gilbert and Nathan Lambert.\n\n&quot;,&quot;logo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cbad298c-6074-441b-ad43-d5df6dbf101d_800x800.png&quot;,&quot;author_id&quot;:10472909,&quot;primary_user_id&quot;:null,&quot;theme_var_background_pop&quot;:&quot;#FF6719&quot;,&quot;created_at&quot;:&quot;2025-04-25T22:10:28.216Z&quot;,&quot;email_from_name&quot;:null,&quot;copyright&quot;:&quot;Nathan Lambert&quot;,&quot;founding_plan_name&quot;:null,&quot;community_enabled&quot;:true,&quot;invite_only&quot;:false,&quot;payments_state&quot;:&quot;disabled&quot;,&quot;language&quot;:null,&quot;explicit&quot;:false,&quot;homepage_type&quot;:&quot;newspaper&quot;,&quot;is_personal_mode&quot;:false}}],&quot;twitter_screen_name&quot;:&quot;natolambert&quot;,&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:100,&quot;status&quot;:{&quot;bestsellerTier&quot;:100,&quot;subscriberTier&quot;:5,&quot;leaderboard&quot;:null,&quot;vip&quot;:false,&quot;badge&quot;:{&quot;type&quot;:&quot;bestseller&quot;,&quot;tier&quot;:100},&quot;paidPublicationIds&quot;:[1084089,883883,69345,1084918,6349492,6027],&quot;subscriber&quot;:null}}],&quot;utm_campaign&quot;:null,&quot;belowTheFold&quot;:true,&quot;type&quot;:&quot;newsletter&quot;,&quot;language&quot;:&quot;en&quot;}&#x27; data-component-name=&quot;EmbeddedPostToDOM&quot;&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/olmo-3-americas-truly-open-reasoning?utm_source=substack&amp;utm_campaign=post_embed&amp;utm_medium=web&quot; native=&quot;true&quot; rel=&quot;&quot;&gt;
      &lt;div&gt;
       &lt;img loading=&quot;lazy&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!djof!,w_56,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc52e8097-8f3d-4f7e-808b-2f4ad37f3b52_720x720.png&quot;/&gt;
       &lt;span&gt;
        Interconnects
       &lt;/span&gt;
      &lt;/div&gt;
      &lt;div&gt;
       &lt;div&gt;
        Olmo 3: America’s truly open reasoning models
       &lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;
       We present Olmo 3, our next family of fully open, leading language models…
      &lt;/div&gt;
      &lt;div&gt;
       &lt;span&gt;
        Read more
       &lt;/span&gt;
      &lt;/div&gt;
      &lt;div&gt;
       3 days ago · 87 likes · 30 comments · Nathan Lambert
      &lt;/div&gt;
     &lt;/a&gt;
    &lt;/div&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h3&gt;
   &lt;strong&gt;
    Models
   &lt;/strong&gt;
  &lt;/h3&gt;
  &lt;h4&gt;
   Flagship
  &lt;/h4&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/ibm-granite/granite-4.0-h-1b&quot; rel=&quot;&quot;&gt;
       granite-4.0-h-1b
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/ibm-granite&quot; rel=&quot;&quot;&gt;
      ibm-granite
     &lt;/a&gt;
     &lt;span&gt;
      : Of course, IBM can’t stop training tiny models and to add them to their model families. The new Granite models feature hybrid attention and MoE architecture first time.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/marin-community/marin-32b-base&quot; rel=&quot;&quot;&gt;
       marin-32b-base
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/marin-community&quot; rel=&quot;&quot;&gt;
      marin-community
     &lt;/a&gt;
     &lt;span&gt;
      : A truly open model by Percy Liang’s
     &lt;/span&gt;
     &lt;a href=&quot;https://marin.community/&quot; rel=&quot;&quot;&gt;
      Marin
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/cerebras/GLM-4.6-REAP-218B-A32B-FP8&quot; rel=&quot;&quot;&gt;
       GLM-4.6-REAP-218B-A32B-FP8
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/cerebras&quot; rel=&quot;&quot;&gt;
      cerebras
     &lt;/a&gt;
     &lt;span&gt;
      : While we wait for GLM-4.6-Air (and
     &lt;/span&gt;
     &lt;a href=&quot;https://www.chinatalk.media/p/the-zai-playbook&quot; rel=&quot;&quot;&gt;
      mini
     &lt;/a&gt;
     &lt;span&gt;
      , as teased in this Interview from Chinatalk’s Jordan Schneider and Nathan with Zixuan Li from Zhipu), you can use pruned versions of the GLM-4.6 model.
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!lGUL!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa77ba018-6061-44c5-96ac-3489c95bb14c_1266x1094.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!lGUL!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa77ba018-6061-44c5-96ac-3489c95bb14c_1266x1094.png 424w, https://substackcdn.com/image/fetch/$s_!lGUL!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa77ba018-6061-44c5-96ac-3489c95bb14c_1266x1094.png 848w, https://substackcdn.com/image/fetch/$s_!lGUL!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa77ba018-6061-44c5-96ac-3489c95bb14c_1266x1094.png 1272w, https://substackcdn.com/image/fetch/$s_!lGUL!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa77ba018-6061-44c5-96ac-3489c95bb14c_1266x1094.png 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a77ba018-6061-44c5-96ac-3489c95bb14c_1266x1094.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1094,&quot;width&quot;:1266,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:138676,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/179633798?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa77ba018-6061-44c5-96ac-3489c95bb14c_1266x1094.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;1094&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!lGUL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa77ba018-6061-44c5-96ac-3489c95bb14c_1266x1094.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!lGUL!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa77ba018-6061-44c5-96ac-3489c95bb14c_1266x1094.png 424w, https://substackcdn.com/image/fetch/$s_!lGUL!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa77ba018-6061-44c5-96ac-3489c95bb14c_1266x1094.png 848w, https://substackcdn.com/image/fetch/$s_!lGUL!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa77ba018-6061-44c5-96ac-3489c95bb14c_1266x1094.png 1272w, https://substackcdn.com/image/fetch/$s_!lGUL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa77ba018-6061-44c5-96ac-3489c95bb14c_1266x1094.png 1456w&quot; width=&quot;1266&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Olmo 3: America’s truly open reasoning models </title>
<link>https://www.interconnects.ai/p/olmo-3-americas-truly-open-reasoning</link>
<pubDate>Thu, 20 Nov 2025 14:09:07 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    We present Olmo 3, our next family of fully open, leading language models.
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    This family of 7B and 32B models represents:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     The best 32B base model.
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     The best 7B Western thinking &amp; instruct models.
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     The first 32B (or larger) fully open reasoning model.
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;p&gt;
   &lt;span&gt;
    This is a big milestone for Ai2 and the Olmo project. These aren’t huge models (more on that later), but it’s
   &lt;/span&gt;
   &lt;strong&gt;
    crucial for the viability of fully open-source models that they are competitive on performance – not just replications of models that came out 6 to 12 months ago
   &lt;/strong&gt;
   &lt;span&gt;
    . As always, all of our models come with full training data, code, intermediate checkpoints, training logs, and a detailed technical report. All are available today, with some more additions coming before the end of the year.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/olmo-3-americas-truly-open-reasoning?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/olmo-3-americas-truly-open-reasoning?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   As with OLMo 2 32B at its release, OLMo 3 32B is the best open-source language model ever released. It’s an awesome privilege to get to provide these models to the broader community researching and understanding what is happening in AI today.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Paper:
   &lt;/span&gt;
   &lt;a href=&quot;https://allenai.org/papers/olmo3&quot; rel=&quot;&quot;&gt;
    https://allenai.org/papers/olmo3
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    Artifacts:
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/collections/allenai/olmo-3&quot; rel=&quot;&quot;&gt;
    https://huggingface.co/collections/allenai/olmo-3
   &lt;/a&gt;
   &lt;br/&gt;
   &lt;span&gt;
    Demo:
   &lt;/span&gt;
   &lt;a href=&quot;https://playground.allenai.org/&quot; rel=&quot;&quot;&gt;
    https://playground.allenai.org/
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    Blog:
   &lt;/span&gt;
   &lt;a href=&quot;https://allenai.org/blog/olmo3&quot; rel=&quot;&quot;&gt;
    https://allenai.org/blog/olmo3
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!23FZ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37b8afbd-e096-4f62-8b33-3fb385e9fd40_2648x1654.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!23FZ!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37b8afbd-e096-4f62-8b33-3fb385e9fd40_2648x1654.png 424w, https://substackcdn.com/image/fetch/$s_!23FZ!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37b8afbd-e096-4f62-8b33-3fb385e9fd40_2648x1654.png 848w, https://substackcdn.com/image/fetch/$s_!23FZ!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37b8afbd-e096-4f62-8b33-3fb385e9fd40_2648x1654.png 1272w, https://substackcdn.com/image/fetch/$s_!23FZ!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37b8afbd-e096-4f62-8b33-3fb385e9fd40_2648x1654.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/37b8afbd-e096-4f62-8b33-3fb385e9fd40_2648x1654.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:909,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:403088,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/179299850?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37b8afbd-e096-4f62-8b33-3fb385e9fd40_2648x1654.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;909&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!23FZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37b8afbd-e096-4f62-8b33-3fb385e9fd40_2648x1654.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!23FZ!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37b8afbd-e096-4f62-8b33-3fb385e9fd40_2648x1654.png 424w, https://substackcdn.com/image/fetch/$s_!23FZ!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37b8afbd-e096-4f62-8b33-3fb385e9fd40_2648x1654.png 848w, https://substackcdn.com/image/fetch/$s_!23FZ!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37b8afbd-e096-4f62-8b33-3fb385e9fd40_2648x1654.png 1272w, https://substackcdn.com/image/fetch/$s_!23FZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37b8afbd-e096-4f62-8b33-3fb385e9fd40_2648x1654.png 1456w&quot; title=&quot;&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Base models – a strong foundation
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Pretraining’s demise is now regularly overstated. 2025 has marked a year where the entire industry rebuilt their training stack to focus on reasoning and agentic tasks, but some established base model sizes haven’t seen a new leading model since Qwen 2.5 in 2024. The
   &lt;/span&gt;
   &lt;strong&gt;
    Olmo 3 32B base model could be our most impactful artifact
   &lt;/strong&gt;
   &lt;span&gt;
    here, as Qwen3 did not release their 32B base model (likely for competitive reasons). We show that our 7B recipe competes with Qwen 3, and the 32B size enables a starting point for strong reasoning models or specialized agents. Our base model’s performance is in the same ballpark as Qwen 2.5, surpassing the likes of Stanford’s Marin and Gemma 3, but with pretraining data and code available, it should be more accessible to the community to learn how to finetune it (and be confident in our results).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   We’re excited to see the community take Olmo 3 32B base in many directions. 32B is a loved size for easy deployment on single 80GB+ memory GPUs and even on many laptops, like the MacBook I’m using to write this on.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    A model flow – the lifecycle of creating a model
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    With these strong base models, we’ve created a variety of post-training checkpoints to showcase the many ways post-training can be done to suit different needs. We’re calling this a “
   &lt;/span&gt;
   &lt;strong&gt;
    Model Flow
   &lt;/strong&gt;
   &lt;span&gt;
    .” For post-training, we’re releasing Instruct versions – short, snappy, intelligent, and useful especially for synthetic data en masse (e.g. recent work by Datology on OLMo 2 Instruct), Think versions – thoughtful reasoners with the performance you expect from a leading thinking model on math, code, etc. and RL Zero versions – controlled experiments for researchers understanding how to build post-training recipes that start with large-scale RL on the base model.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The first two post-training recipes are distilled from a variety of leading, open and closed, language models. At the 32B and smaller scale, direct distillation with further preference finetuning and reinforcement learning with verifiable rewards (RLVR) is becoming an accessible and highly capable pipeline. Our post-training recipe follows our recent models: 1) create an excellent SFT set, 2) use direct preference optimization (DPO) as a highly iterable, cheap, and stable preference learning method despite its critics, and 3) finish up with scaled up RLVR. All of these stages confer meaningful improvements on the models’ final performance.
  &lt;/p&gt;
  &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Instruct models – low latency workhorse
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Instruct models today are often somewhat forgotten, but the likes of Llama 3.1 Instruct and smaller, concise models are some of the most adopted open models of all time. The instruct models we’re building are a major polishing and evolution of the Tülu 3 pipeline – you’ll see many similar datasets and methods, but with pretty much every datapoint or training code being refreshed.
   &lt;/span&gt;
   &lt;strong&gt;
    Olmo 3 Instruct should be a clear upgrade on Llama 3.1 8B, representing the best 7B scale model from a Western or American company
   &lt;/strong&gt;
   &lt;span&gt;
    . As scientists we don’t like to condition the quality of our work based on its geographic origins, but this is a very real consideration to many enterprises looking to open models as a solution for trusted AI deployments with sensitive data.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Building a thinking model
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   What people have most likely been waiting for are our thinking or reasoning models, both because every company needs to have a reasoning model in 2025, but also to clearly open the black box for the most recent evolution of language models. Olmo 3 Think, particularly the 32B, are flagship models of this release, where we considered what would be best for a reasoning model at every stage of training.
  &lt;/p&gt;
  &lt;p&gt;
   Extensive effort (ask me IRL about more war stories) went into every stage of the post-training of the Think models. We’re impressed by the magnitude of gains that can be achieved in each stage – neither SFT nor RL is all you need at these intermediate model scales.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    First we built an extensive reasoning dataset for supervised finetuning (SFT), called
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/datasets/allenai/dolci-32b-thinking-sft&quot; rel=&quot;&quot;&gt;
    Dolci-Think-SFT
   &lt;/a&gt;
   &lt;span&gt;
    , building on very impactful open projects like
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/datasets/open-thoughts/OpenThoughts3-1.2M&quot; rel=&quot;&quot;&gt;
    OpenThoughts3
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/datasets/nvidia/Nemotron-Post-Training-Dataset-v1&quot; rel=&quot;&quot;&gt;
    Nvidia’s Nemotron Post-training
   &lt;/a&gt;
   &lt;span&gt;
    , Prime Intellect’s
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/datasets/PrimeIntellect/SYNTHETIC-2&quot; rel=&quot;&quot;&gt;
    SYNETHIC-2
   &lt;/a&gt;
   &lt;span&gt;
    , and many more open prompt sources we pulled forward from Tülu 3 / OLMo 2. Datasets like this are often some of our most impactful contributions (see the Tülu 3 dataset as an example in Thinking Machine’s
   &lt;/span&gt;
   &lt;a href=&quot;https://thinkingmachines.ai/tinker/&quot; rel=&quot;&quot;&gt;
    Tinker
   &lt;/a&gt;
   &lt;span&gt;
    :D – please add Dolci-Think-SFT too, and Olmo 3 while you’re at it, the architecture is very similar to Qwen which you have).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    For DPO with reasoning, we converged on a very similar method as HuggingFace’s
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/blog/smollm3&quot; rel=&quot;&quot;&gt;
    SmolLM 3
   &lt;/a&gt;
   &lt;span&gt;
    with Qwen3 32B as the chosen model and Qwen3 0.6B as the rejected. Our intuition is that the
   &lt;/span&gt;
   &lt;em&gt;
    delta
   &lt;/em&gt;
   &lt;span&gt;
    between the chosen and rejected samples is what the model learns from, rather than the overall quality of the chosen answer alone. These two models provide a very consistent delta, which provides way stronger gains than expected. Same goes for the Instruct model. It is likely that DPO is helping the model converge on more stable reasoning strategies and softening the post-SFT model, as seen by large gains even on frontier evaluations such as AIME.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Our DPO approach was an expansion of Geng, Scott, et al. “The delta learning hypothesis: Preference tuning on weak data can yield strong gains.” arXiv preprint arXiv:2507.06187 (2025). Many early open thinking models that were also distilled from larger, open-weight thinking models likely left a meaningful amount of performance on the table by not including this stage.
  &lt;/p&gt;
  &lt;p&gt;
   Finally, we turn to the RL stage. Most of the effort here went into building effective infrastructure to be able to run stable experiments with the long-generations of larger language models. This was an incredible team effort to be a small part of, and reflects work ongoing at many labs right now. Most of the details are in the paper, but our details are a mixture of ideas that have been shown already like ServiceNow’s PipelineRL or algorithmic innovations like DAPO and Dr. GRPO. We have some new tricks too!
  &lt;/p&gt;
  &lt;p&gt;
   Some of the exciting contributions of our RL experiments are 1) what we call “active refilling” which is a way of keeping the generations from the learner nodes constantly flowing until there’s a full batch of completions with nonzero gradients (from equal advantages) – a major advantage of our asynchronous approach; and 2) cleaning, documenting, decontaminating, mixing, and proving out the large swaths of work done by the community over the last months.
  &lt;/p&gt;
  &lt;p&gt;
   The result is an excellent model that we’re very proud of. It has very strong reasoning benchmarks (AIME, GPQA, etc.) while also being stable, quirky, and fun in chat with excellent instruction following. The 32B range is largely devoid of non-Qwen competition. The scores for both of our Thinkers get within 1-2 points overall with their respective Qwen3 8/32B models – we’re proud of this!
  &lt;/p&gt;
  &lt;p&gt;
   A very strong 7B scale, Western thinking model is Nvidia’s NVIDIA-Nemotron-Nano-9B-v2 hybrid model. It came out months ago and is extremely strong. I personally suspect it may be due to the hybrid architecture making subtle implementation bugs in popular libraries, but who knows.
  &lt;/p&gt;
  &lt;p&gt;
   All in, the Olmo 3 Think recipe gives us a lot of excitement for new things to try in 2026.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    RL Zero
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   DeepSeek R1 showed us a way to new post-training recipes for frontier models, starting with RL on the base model rather than a big SFT stage (yes, I know about cold-start SFT and so on, but that’s an implementation detail). We used RL on base model as a core feedback cycle when developing the model, such as during intermediate midtraining mixing. This is viewed now as a fundamental, largely innate, capability of the base-model.
  &lt;/p&gt;
  &lt;p&gt;
   To facilitate further research on RL Zero, we released 4 datasets and series of checkpoints, showing per-domain RL Zero performance on our 7B model for data mixes focus on math, code, instruction following, and general chat separately.
  &lt;/p&gt;
  &lt;p&gt;
   In particular, we’re excited about the future of RL Zero research on Olmo 3 precisely because everything is open. Researchers can study the interaction between the reasoning traces we include at midtraining and the downstream model behavior (qualitative and quantitative).
  &lt;/p&gt;
  &lt;p&gt;
   This helps answer questions that have plagued RLVR results on Qwen models, hinting at forms of data contamination particularly on math and reasoning benchmarks (see Shao, Rulin, et al. “Spurious rewards: Rethinking training signals in rlvr.” arXiv preprint arXiv:2506.10947 (2025). or Wu, Mingqi, et al. “Reasoning or memorization? unreliable results of reinforcement learning due to data contamination.” arXiv preprint arXiv:2507.10532 (2025).)
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    What’s next
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   This is the biggest project we’ve ever taken on at Ai2, with 60+ authors and numerous other support staff.
  &lt;/p&gt;
  &lt;p&gt;
   In building and observing “thinking” and “instruct” models coming today, it is clear to us that there’s a very wide variety of models that fall into both of these buckets. The way we view it is that thinking and instruct characteristics are on a spectrum, as measured by the number of tokens used per evaluation task. In the future we’re excited to view this thinking budget as a trade-off, and build models that serve different use-cases based on latency/throughput needs.
  &lt;/p&gt;
  &lt;p&gt;
   As for a list of next models or things we’ll build, we can give you a list of things you’d expect from a (becoming) frontier lab: MoEs, better character training, pareto efficient instruct vs think, scale, specialized models we actually use at Ai2 internally, and all the normal things.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    This is one small step towards what I see as a success for my
   &lt;/span&gt;
   &lt;a href=&quot;https://atomproject.ai/&quot; rel=&quot;&quot;&gt;
    ATOM project
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   We thank you for all your support of our work at Ai2. We have a lot of work to do. We’re going to be hunting for top talent at NeurIPS to help us scale up our Olmo team in 2026.
  &lt;/p&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Why AI writing is mid </title>
<link>https://www.interconnects.ai/p/why-ai-writing-is-mid</link>
<pubDate>Sun, 16 Nov 2025 21:36:06 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    First, on the topic of writing, the polished, and more importantly
   &lt;/span&gt;
   &lt;em&gt;
    printed
   &lt;/em&gt;
   &lt;span&gt;
    , version of my
   &lt;/span&gt;
   &lt;a href=&quot;https://rlhfbook.com/&quot; rel=&quot;&quot;&gt;
    RLHF Book
   &lt;/a&gt;
   &lt;span&gt;
    is available for pre-order. It’s 50% off for a limited time, you can pre-order it
   &lt;/span&gt;
   &lt;a href=&quot;https://hubs.la/Q03TsMHv0&quot; rel=&quot;&quot;&gt;
    here
   &lt;/a&gt;
   &lt;span&gt;
    !
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Like a lot of writing, I’ve been sitting on this piece for many months thinking it’s not contributing enough, but the topic keeps coming up — most recently via
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;a data-attrs=&#x27;{&quot;name&quot;:&quot;Jasmine Sun&quot;,&quot;id&quot;:25322552,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!DvOq!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F519d1e6e-ffad-4850-a5c9-fff32d621bc8_2300x2299.jpeg&quot;,&quot;uuid&quot;:&quot;225a5488-c9ce-497b-a4f1-a03f6ef2e943&quot;}&#x27; data-component-name=&quot;MentionUser&quot; href=&quot;https://open.substack.com/users/25322552-jasmine-sun?utm_source=mentions&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;
    Jasmine Sun
   &lt;/a&gt;
  &lt;/div&gt;
  &lt;span&gt;
   — and people seem to like it, so I hope you do too!
  &lt;/span&gt;
  &lt;p&gt;
   &lt;span&gt;
    It’s no longer a new experience to be struck by just how bad AI models are at writing good prose. They can pull out a great sentence every now and then, particularly models like GPT-5 Pro and other large models, but it’s always a quick comment and never many sustained successive sentences. More importantly, good AI writing feels like a lucky find rather than the result of the right incantation. After spending a long time working
   &lt;/span&gt;
   &lt;em&gt;
    training
   &lt;/em&gt;
   &lt;span&gt;
    these models, I’m fairly convinced that this writing inhibition is a structural limitation to how we train these models today and the markets they’re designed to serve.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/why-ai-writing-is-mid?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/why-ai-writing-is-mid?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   If we&#x27;re making AIs that are soon to be superhuman at most knowledge work, that are trained primarily to predict text tokens, why is their ability to create high quality text tokens still so low? Why can’t we make the general ChatGPT experience so much more refined and useful for writers while we’re unlocking entirely new ways of working with them every few months — most recently the CLI agents like Claude Code. This gap is one of my favorite discussions of AI because it’s really about the definition of good writing is in itself.
  &lt;/p&gt;
  &lt;p&gt;
   Where language models can generate beautiful images from random noise, they can&#x27;t reliably generate a good few sentences from a couple bullet points of information. What is different about the art form of writing than what AI can already capture?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    I&#x27;m coming to believe that we
   &lt;/span&gt;
   &lt;em&gt;
    could
   &lt;/em&gt;
   &lt;span&gt;
    train a language model to be a great writer, but it goes against so many of the existing training processes. To list a few problems at different stages of the stack of varying severity in terms of their handicapping of writing:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Style isn’t a leading training objective.
     &lt;/strong&gt;
     &lt;span&gt;
      Language models all go through preference training where many aspects from helpfulness, clarity, honesty, etc. are balanced against each other. Many rewards make any one reward, such as style, have a harder time standing out. Style and writing quality is also far harder to measure, so it is less likely to be optimized vis-a-vis other signals (such as
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/sycophancy-and-the-art-of-the-model&quot; rel=&quot;&quot;&gt;
      sycophancy
     &lt;/a&gt;
     &lt;span&gt;
      , which was easier to capture).
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Aggregate preferences suppress quirks.
     &lt;/strong&gt;
     &lt;span&gt;
      Language model providers design models with a few intended personalities, largely due to the benefits of predictability. These providers are optimizing many metrics for &quot;the average user.&quot; Many users will disagree on what their preference for “good writing” is.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Good writing’s inherent friction.
     &lt;/strong&gt;
     &lt;span&gt;
      Good writing often takes much longer to process, even when you’re interested in it. Most users of ChatGPT just want to parse the information quickly. Doubly, the people
     &lt;/span&gt;
     &lt;a href=&quot;https://rlhfbook.com/c/06-preference-data#sourcing-and-contracts&quot; rel=&quot;&quot;&gt;
      creating the training data
     &lt;/a&gt;
     &lt;span&gt;
      for these models are often paid
     &lt;/span&gt;
     &lt;em&gt;
      per instance
     &lt;/em&gt;
     &lt;span&gt;
      , so an answer with more complexity and richness would often be suppressed by subtle financial biases to move on.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Writing well is orthogonal to training biases.
     &lt;/strong&gt;
     &lt;span&gt;
      Throughout many stages of the post-training process, modern RLHF training exploits subtle signals for sycophancy and
     &lt;/span&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2310.03716&quot; rel=&quot;&quot;&gt;
      length-bias
     &lt;/a&gt;
     &lt;span&gt;
      &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/why-ai-writing-is-mid#footnote-1-167772857&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
       1
      &lt;/a&gt;
     &lt;/span&gt;
     &lt;span&gt;
      that aren&#x27;t underlying goals of it. These implicit biases go against the gradient for better writing. Good writing is pretty much never verbose.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Forced neutrality of a language model.
     &lt;/strong&gt;
     &lt;span&gt;
      Language models are trained to be neutral on a variety of sensitive topics and to not express strong opinions in general. The best writing unabashedly shares a clear opinion. Yes, I’d expect wackier models like Grok to potentially produce better writing, even if I don’t agree with it. This leads directly to a conflict directly in something I value in writing — voice.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;p&gt;
   All of these create models that are appealing to broad audiences. What we need to create a language model that can write wonderfully is to give it a strong personality, and potentially a strong &quot;sense of self&quot; — if that actually impacts a language model&#x27;s thinking.
  &lt;/p&gt;
  &lt;p&gt;
   The cultivation of voice is one of my biggest recommendations to people trying to get better at writing, only after telling them to find something they want to learn about. Voice is core to how I describe my writing process.
  &lt;/p&gt;
  &lt;div data-attrs=&quot;{&amp;quot;id&amp;quot;:165344478,&amp;quot;url&amp;quot;:&amp;quot;https://www.interconnects.ai/p/how-i-write&amp;quot;,&amp;quot;publication_id&amp;quot;:48206,&amp;quot;publication_name&amp;quot;:&amp;quot;Interconnects&amp;quot;,&amp;quot;publication_logo_url&amp;quot;:&amp;quot;https://substackcdn.com/image/fetch/$s_!djof!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc52e8097-8f3d-4f7e-808b-2f4ad37f3b52_720x720.png&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;How I Write&amp;quot;,&amp;quot;truncated_body_text&amp;quot;:&amp;quot;My experience with my recent years of writing is quite confusing — almost even dissociative. I&#x27;ve never felt like I was a good writer and no one really told me I was until some random point in time a year or two ago. In that time span, I didn&#x27;t really change my motivation nor methods, but I reaped the simple rewards of practice. I&#x27;m still wired to be ve…&amp;quot;,&amp;quot;date&amp;quot;:&amp;quot;2025-06-06T15:23:55.703Z&amp;quot;,&amp;quot;like_count&amp;quot;:52,&amp;quot;comment_count&amp;quot;:4,&amp;quot;bylines&amp;quot;:[{&amp;quot;id&amp;quot;:10472909,&amp;quot;name&amp;quot;:&amp;quot;Nathan Lambert&amp;quot;,&amp;quot;handle&amp;quot;:&amp;quot;natolambert&amp;quot;,&amp;quot;previous_name&amp;quot;:null,&amp;quot;photo_url&amp;quot;:&amp;quot;https://substackcdn.com/image/fetch/$s_!RihO!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8fedcdfb-e137-4f6a-9089-a46add6c6242_500x500.jpeg&amp;quot;,&amp;quot;bio&amp;quot;:&amp;quot;ML researcher making sense of AI research, products, and the uncertain technological future. PhD from Berkeley AI. Experience at Meta, DeepMind, HuggingFace.&amp;quot;,&amp;quot;profile_set_up_at&amp;quot;:&amp;quot;2021-04-24T01:19:33.371Z&amp;quot;,&amp;quot;reader_installed_at&amp;quot;:&amp;quot;2022-03-09T17:52:30.690Z&amp;quot;,&amp;quot;publicationUsers&amp;quot;:[{&amp;quot;id&amp;quot;:100753,&amp;quot;user_id&amp;quot;:10472909,&amp;quot;publication_id&amp;quot;:48206,&amp;quot;role&amp;quot;:&amp;quot;admin&amp;quot;,&amp;quot;public&amp;quot;:true,&amp;quot;is_primary&amp;quot;:true,&amp;quot;publication&amp;quot;:{&amp;quot;id&amp;quot;:48206,&amp;quot;name&amp;quot;:&amp;quot;Interconnects&amp;quot;,&amp;quot;subdomain&amp;quot;:&amp;quot;robotic&amp;quot;,&amp;quot;custom_domain&amp;quot;:&amp;quot;www.interconnects.ai&amp;quot;,&amp;quot;custom_domain_optional&amp;quot;:false,&amp;quot;hero_text&amp;quot;:&amp;quot;The cutting edge of AI, from inside the frontier AI labs, minus the hype. The border between high-level and technical thinking. Read by leading engineers, researchers, and investors.&amp;quot;,&amp;quot;logo_url&amp;quot;:&amp;quot;https://substack-post-media.s3.amazonaws.com/public/images/c52e8097-8f3d-4f7e-808b-2f4ad37f3b52_720x720.png&amp;quot;,&amp;quot;author_id&amp;quot;:10472909,&amp;quot;primary_user_id&amp;quot;:10472909,&amp;quot;theme_var_background_pop&amp;quot;:&amp;quot;#ff6b00&amp;quot;,&amp;quot;created_at&amp;quot;:&amp;quot;2020-05-21T02:59:47.895Z&amp;quot;,&amp;quot;email_from_name&amp;quot;:&amp;quot;Interconnects by Nathan Lambert&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;Interconnects AI, LLC&amp;quot;,&amp;quot;founding_plan_name&amp;quot;:&amp;quot;Founding Member&amp;quot;,&amp;quot;community_enabled&amp;quot;:true,&amp;quot;invite_only&amp;quot;:false,&amp;quot;payments_state&amp;quot;:&amp;quot;enabled&amp;quot;,&amp;quot;language&amp;quot;:null,&amp;quot;explicit&amp;quot;:false,&amp;quot;homepage_type&amp;quot;:&amp;quot;newspaper&amp;quot;,&amp;quot;is_personal_mode&amp;quot;:false}},{&amp;quot;id&amp;quot;:4610799,&amp;quot;user_id&amp;quot;:10472909,&amp;quot;publication_id&amp;quot;:4519930,&amp;quot;role&amp;quot;:&amp;quot;admin&amp;quot;,&amp;quot;public&amp;quot;:true,&amp;quot;is_primary&amp;quot;:false,&amp;quot;publication&amp;quot;:{&amp;quot;id&amp;quot;:4519930,&amp;quot;name&amp;quot;:&amp;quot;natolambert overflow&amp;quot;,&amp;quot;subdomain&amp;quot;:&amp;quot;natolambert&amp;quot;,&amp;quot;custom_domain&amp;quot;:null,&amp;quot;custom_domain_optional&amp;quot;:false,&amp;quot;hero_text&amp;quot;:&amp;quot;a place for any extra thoughts beyond Interconnects.ai&amp;quot;,&amp;quot;logo_url&amp;quot;:&amp;quot;https://substack-post-media.s3.amazonaws.com/public/images/eb88d599-32c8-49a9-ba33-ab6327aff727_256x256.png&amp;quot;,&amp;quot;author_id&amp;quot;:10472909,&amp;quot;primary_user_id&amp;quot;:null,&amp;quot;theme_var_background_pop&amp;quot;:&amp;quot;#FF6719&amp;quot;,&amp;quot;created_at&amp;quot;:&amp;quot;2025-03-27T15:04:05.448Z&amp;quot;,&amp;quot;email_from_name&amp;quot;:null,&amp;quot;copyright&amp;quot;:&amp;quot;Nathan Lambert&amp;quot;,&amp;quot;founding_plan_name&amp;quot;:null,&amp;quot;community_enabled&amp;quot;:true,&amp;quot;invite_only&amp;quot;:false,&amp;quot;payments_state&amp;quot;:&amp;quot;disabled&amp;quot;,&amp;quot;language&amp;quot;:null,&amp;quot;explicit&amp;quot;:false,&amp;quot;homepage_type&amp;quot;:&amp;quot;newspaper&amp;quot;,&amp;quot;is_personal_mode&amp;quot;:false}},{&amp;quot;id&amp;quot;:4926744,&amp;quot;user_id&amp;quot;:10472909,&amp;quot;publication_id&amp;quot;:4830082,&amp;quot;role&amp;quot;:&amp;quot;admin&amp;quot;,&amp;quot;public&amp;quot;:true,&amp;quot;is_primary&amp;quot;:false,&amp;quot;publication&amp;quot;:{&amp;quot;id&amp;quot;:4830082,&amp;quot;name&amp;quot;:&amp;quot;Retort AI&amp;quot;,&amp;quot;subdomain&amp;quot;:&amp;quot;retortai&amp;quot;,&amp;quot;custom_domain&amp;quot;:&amp;quot;www.retortai.com&amp;quot;,&amp;quot;custom_domain_optional&amp;quot;:false,&amp;quot;hero_text&amp;quot;:&amp;quot;Distilling the major events and challenges in the world of artificial intelligence and machine learning, from Thomas Krendl Gilbert and Nathan Lambert.\n\n&amp;quot;,&amp;quot;logo_url&amp;quot;:&amp;quot;https://substack-post-media.s3.amazonaws.com/public/images/cbad298c-6074-441b-ad43-d5df6dbf101d_800x800.png&amp;quot;,&amp;quot;author_id&amp;quot;:10472909,&amp;quot;primary_user_id&amp;quot;:null,&amp;quot;theme_var_background_pop&amp;quot;:&amp;quot;#FF6719&amp;quot;,&amp;quot;created_at&amp;quot;:&amp;quot;2025-04-25T22:10:28.216Z&amp;quot;,&amp;quot;email_from_name&amp;quot;:null,&amp;quot;copyright&amp;quot;:&amp;quot;Nathan Lambert&amp;quot;,&amp;quot;founding_plan_name&amp;quot;:null,&amp;quot;community_enabled&amp;quot;:true,&amp;quot;invite_only&amp;quot;:false,&amp;quot;payments_state&amp;quot;:&amp;quot;disabled&amp;quot;,&amp;quot;language&amp;quot;:null,&amp;quot;explicit&amp;quot;:false,&amp;quot;homepage_type&amp;quot;:&amp;quot;newspaper&amp;quot;,&amp;quot;is_personal_mode&amp;quot;:false}}],&amp;quot;twitter_screen_name&amp;quot;:&amp;quot;natolambert&amp;quot;,&amp;quot;is_guest&amp;quot;:false,&amp;quot;bestseller_tier&amp;quot;:100,&amp;quot;status&amp;quot;:{&amp;quot;bestsellerTier&amp;quot;:100,&amp;quot;subscriberTier&amp;quot;:5,&amp;quot;leaderboard&amp;quot;:null,&amp;quot;vip&amp;quot;:false,&amp;quot;badge&amp;quot;:{&amp;quot;type&amp;quot;:&amp;quot;bestseller&amp;quot;,&amp;quot;tier&amp;quot;:100},&amp;quot;paidPublicationIds&amp;quot;:[1084089,883883,69345,1084918,6349492,6027],&amp;quot;subscriber&amp;quot;:null}}],&amp;quot;utm_campaign&amp;quot;:null,&amp;quot;belowTheFold&amp;quot;:true,&amp;quot;type&amp;quot;:&amp;quot;newsletter&amp;quot;,&amp;quot;language&amp;quot;:&amp;quot;en&amp;quot;}&quot; data-component-name=&quot;EmbeddedPostToDOM&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/how-i-write?utm_source=substack&amp;utm_campaign=post_embed&amp;utm_medium=web&quot; native=&quot;true&quot; rel=&quot;&quot; target=&quot;&quot;&gt;
    &lt;div&gt;
     &lt;img loading=&quot;lazy&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!djof!,w_56,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc52e8097-8f3d-4f7e-808b-2f4ad37f3b52_720x720.png&quot;/&gt;
     &lt;span&gt;
      Interconnects
     &lt;/span&gt;
    &lt;/div&gt;
    &lt;div&gt;
     &lt;div&gt;
      How I Write
     &lt;/div&gt;
    &lt;/div&gt;
    &lt;div&gt;
     My experience with my recent years of writing is quite confusing — almost even dissociative. I&#x27;ve never felt like I was a good writer and no one really told me I was until some random point in time a year or two ago. In that time span, I didn&#x27;t really change my motivation nor methods, but I reaped the simple rewards of practice. I&#x27;m still wired to be ve…
    &lt;/div&gt;
    &lt;div&gt;
     &lt;span&gt;
      Read more
     &lt;/span&gt;
    &lt;/div&gt;
    &lt;div&gt;
     5 months ago · 52 likes · 4 comments · Nathan Lambert
    &lt;/div&gt;
   &lt;/a&gt;
  &lt;/div&gt;
  &lt;p&gt;
   When I think about how I write, the best writing relies on voice. Voice is where you process information into a unique representation — this is often what makes information compelling.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Many people have posited that base models make great writers, such as when I discussed poetry with
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/interviewing-andrew-carr&quot; rel=&quot;&quot;&gt;
    Andrew Carr on his Interconnects appearance
   &lt;/a&gt;
   &lt;span&gt;
    , but this is because base models haven’t been squashed to the narrower style of post-trained responses.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I’ve personally been thinking about this sort of style induced by post-training recently as we prepare for our next Olmo release, and many of us think the models with lower evaluation scores on the likes of AlpacaEval or LMArena actually fit our needs better. The accepted style of chatty models today, whether it’s GPT-5, DeepSeek R1, or a large Qwen model, is a bit cringe for my likes. This style is almost entirely applied during post-training.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Taking a step back, this means base models show us that there
   &lt;/span&gt;
   &lt;em&gt;
    can
   &lt;/em&gt;
   &lt;span&gt;
    be great writing out of the models, but it’s still far from reliable. Base models aren&#x27;t robust enough to variations to make great writers — we need some form of the constraints applied in post-training to make models follow Q&amp;A. The next step would be solving the problem of how models aren’t trained with a narrow enough experience. Specific points of view nurture voice. The target should be a model that can output tokens in any area or request that is clear, compelling, and entertaining.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   We need to shape these base models with post-training designed for writing, just as the best writers bend facts to create narrative.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    Some models makers care
   &lt;/span&gt;
   &lt;em&gt;
    a bit
   &lt;/em&gt;
   &lt;span&gt;
    about this. When a new model drops and people rave about its creative writing ability, such as MoonShot AI’s
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/kimi-k2-and-when-deepseek-moments&quot; rel=&quot;&quot;&gt;
    Kimi K2
   &lt;/a&gt;
   &lt;span&gt;
    line of model, I do think the team put careful work into the data or training pipelines. The problem is that no model provider is remotely ready to sacrifice core abilities of the model such as math and coding in pursuit of meaningfully better writing models.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    There are no market incentives to create this model — all the money in AI is elsewhere, and writing isn’t a particularly lucrative market to disrupt. An example is
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/gpt-45-not-a-frontier-model&quot; rel=&quot;&quot;&gt;
    GPT 4.5
   &lt;/a&gt;
   &lt;span&gt;
    , which was to all reports a rather light fine-tune, but one that produced slightly better prose. It was shut down almost immediately after its launch because it was too slow and economically unviable with its large size.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    If we follow the voice direction, the model that is likely to be the best writer relative to its overall intelligence was the original revamped Bing (aka Sydney) model that
   &lt;/span&gt;
   &lt;a href=&quot;https://www.nytimes.com/2023/02/16/technology/bing-chatbot-microsoft-chatgpt.html&quot; rel=&quot;&quot;&gt;
    went crazy in front of many users
   &lt;/a&gt;
   &lt;span&gt;
    and was rapidly shut down. That model had
   &lt;/span&gt;
   &lt;strong&gt;
    THOUGHTS
   &lt;/strong&gt;
   &lt;span&gt;
    it wanted to share. That’s a starting point, but a scary one to untap again. This sort of training goes far beyond a system prompt or a light finetune, and it will need to be a new post-training process from start to end (more than just a light brush of
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/opening-the-black-box-of-character&quot; rel=&quot;&quot;&gt;
    character training
   &lt;/a&gt;
   &lt;span&gt;
    ).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!TeE-!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde8c9880-e748-4e4d-944e-0e244ba4cf99_1120x693.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!TeE-!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde8c9880-e748-4e4d-944e-0e244ba4cf99_1120x693.png 424w, https://substackcdn.com/image/fetch/$s_!TeE-!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde8c9880-e748-4e4d-944e-0e244ba4cf99_1120x693.png 848w, https://substackcdn.com/image/fetch/$s_!TeE-!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde8c9880-e748-4e4d-944e-0e244ba4cf99_1120x693.png 1272w, https://substackcdn.com/image/fetch/$s_!TeE-!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde8c9880-e748-4e4d-944e-0e244ba4cf99_1120x693.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/de8c9880-e748-4e4d-944e-0e244ba4cf99_1120x693.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:693,&quot;width&quot;:1120,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:174577,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/167772857?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde8c9880-e748-4e4d-944e-0e244ba4cf99_1120x693.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;693&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!TeE-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde8c9880-e748-4e4d-944e-0e244ba4cf99_1120x693.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!TeE-!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde8c9880-e748-4e4d-944e-0e244ba4cf99_1120x693.png 424w, https://substackcdn.com/image/fetch/$s_!TeE-!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde8c9880-e748-4e4d-944e-0e244ba4cf99_1120x693.png 848w, https://substackcdn.com/image/fetch/$s_!TeE-!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde8c9880-e748-4e4d-944e-0e244ba4cf99_1120x693.png 1272w, https://substackcdn.com/image/fetch/$s_!TeE-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde8c9880-e748-4e4d-944e-0e244ba4cf99_1120x693.png 1456w&quot; width=&quot;1120&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   We need to be bold enough to create models with personality if we want writing to fall out. We need models that speak their views loudly and confidently. These also will make more interesting intellectual companions, a niche that Claude fills for some people, but I struggle with Claude plenty of times due to its hesitance, hedging, or preferred answer format.
  &lt;/p&gt;
  &lt;p&gt;
   For the near future, the writing handicap of large language models is here to stay. Good writing you have to sit in to appreciate, and ChatGPT and the leading AI products are not optimized for this whatsoever. Especially with agentic applications being the next frontier, most of the text written by the models will never even be read by a human. Good writing is legitimately worse for most of the use cases I use AI for. I don’t like the style per se, but having it jump to be a literary masterpiece would actually be worse.
  &lt;/p&gt;
  &lt;p&gt;
   I don’t really have a solution to AI’s writing problem, but rather expensive experiments people can try. At some point I expect someone to commission a project to push this to its limits, building a model just for writing. This’ll take some time but is not untenable nor unfathomably expensive — it’ll just be a complete refresh of a modern post-training stack.
  &lt;/p&gt;
  &lt;p&gt;
   Even if this project was invested in, I don’t expect the models to be close to the best humans at elegant writing within a few years. Our current batch of models as a starting point are too far from the goal. With longer timelines, it doesn’t feel like writing is a fundamental problem that can’t be solved.
  &lt;/p&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/why-ai-writing-is-mid#footnote-anchor-1-167772857&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     Or via inference-time scaling leaking into every domain.
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Interview: Ant Group&#x27;s open model ambitions </title>
<link>https://www.interconnects.ai/p/inside-a-chinese-frontier-lab-inclusion</link>
<pubDate>Wed, 12 Nov 2025 14:51:20 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    This is the first of a handful of interviews I’m doing with teams building the best open language models of the world. In 2025, the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/state-of-open-models-2025&quot; rel=&quot;&quot;&gt;
    open model ecosystem has changed incredibly
   &lt;/a&gt;
   &lt;span&gt;
    . It’s more populated, far more dominated by Chinese companies, and growing. DeepSeek R1 shocked the world and now there are a handful of teams in China training exceptional models. The Ling models, from InclusionAI — Ant Group’s leading AI lab — have been one of the Chinese labs from the second half of the year that are releasing fantastic models at a rapid clip.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    This interview is primarily with Richard Bian, who’s official title is Product &amp; Growth Lead, Ant Ling &amp; InclusionAI (on
   &lt;/span&gt;
   &lt;a href=&quot;https://www.linkedin.com/in/richardbian/&quot; rel=&quot;&quot;&gt;
    LinkedIn
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/RichSFO&quot; rel=&quot;&quot;&gt;
    X
   &lt;/a&gt;
   &lt;span&gt;
    ), previously leading AntOSS (Ant Group’s open source software division). Richard spent a substantial portion of his career working in the United States, with time at Square, Microsoft, and an MBA from Berkeley Haas, before returning to China and work at Ant.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Also joining are two leads of the Ant Ling technical team, Chen Liang (Algorithm Engineer), and Ziqi Liu (Research Lead).
  &lt;/p&gt;
  &lt;p&gt;
   This interview focuses on many topics of the open language models, such as:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     Why is the Ant Group — known for the popular fintech app AliPay — investing so much in catching up to the frontier of AI?
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     What does it take to rapidly gain the ability to train excellent models?
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     What decisions does one make when deciding a modeling strategy? Text-only or multimodal? What size of models?…
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     How does the Chinese AI ecosystem prioritize different directions than the West?
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   &lt;span&gt;
    And many more topics. Listen on
   &lt;/span&gt;
   &lt;a href=&quot;https://podcasts.apple.com/us/podcast/interconnects-audio/id1719552353&quot; rel=&quot;&quot;&gt;
    Apple Podcasts
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://open.spotify.com/show/2UE6s7wZC4kiXYOnWRuxGv&quot; rel=&quot;&quot;&gt;
    Spotify
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.youtube.com/@interconnects&quot; rel=&quot;&quot;&gt;
    YouTube
   &lt;/a&gt;
   &lt;span&gt;
    , and
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/podcast&quot; rel=&quot;&quot;&gt;
    where ever you get your podcasts
   &lt;/a&gt;
   &lt;span&gt;
    . For other Interconnects interviews,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/t/interviews&quot; rel=&quot;&quot;&gt;
    go here
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div data-attrs=&#x27;{&quot;videoId&quot;:&quot;vIgE1t1rKjg&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}&#x27; data-component-name=&quot;Youtube2ToDOM&quot;&gt;
   &lt;div&gt;
    &lt;iframe allow=&quot;autoplay; fullscreen&quot; allowautoplay=&quot;true&quot; allowfullscreen=&quot;true&quot; frameborder=&quot;0&quot; gesture=&quot;media&quot; height=&quot;409&quot; loading=&quot;lazy&quot; src=&quot;https://www.youtube-nocookie.com/embed/vIgE1t1rKjg?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0&quot; width=&quot;728&quot;&gt;
    &lt;/iframe&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
   Some more references &amp; links:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      InclusionAI’s
     &lt;/span&gt;
     &lt;a href=&quot;https://www.inclusion-ai.org/&quot; rel=&quot;&quot;&gt;
      homepage
     &lt;/a&gt;
     &lt;span&gt;
      , highlighting their mission.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://x.com/AntLingAGI&quot; rel=&quot;&quot;&gt;
      AntLingAGI
     &lt;/a&gt;
     &lt;span&gt;
      on X (models, research, etc.),
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/TheInclusionAI&quot; rel=&quot;&quot;&gt;
      InclusionAI
     &lt;/a&gt;
     &lt;span&gt;
      on X (overall initiative), InclusionAI
     &lt;/span&gt;
     &lt;a href=&quot;https://github.com/inclusionAI&quot; rel=&quot;&quot;&gt;
      GitHub
     &lt;/a&gt;
     &lt;span&gt;
      , or their
     &lt;/span&gt;
     &lt;a href=&quot;https://discord.com/invite/2X4zBSz9c6&quot; rel=&quot;&quot;&gt;
      Discord
     &lt;/a&gt;
     &lt;span&gt;
      community.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Ling 1T was highlighted in “Our Picks” for
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/i/176399506/our-picks&quot; rel=&quot;&quot;&gt;
      our last open model roundup in October
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Another interview with Richard at
     &lt;/span&gt;
     &lt;a href=&quot;https://stateofopencon.com/&quot; rel=&quot;&quot;&gt;
      State of Open Conference 2025
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Over the last few months, our coverage of the Chinese ecosystem has taken off, such as our initial
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/chinas-top-19-open-model-labs&quot; rel=&quot;&quot;&gt;
      ranking of 19 open Chinese AI labs
     &lt;/a&gt;
     &lt;span&gt;
      (before a lot of the models we discuss below),
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/t/artifacts-log&quot; rel=&quot;&quot;&gt;
      model roundups
     &lt;/a&gt;
     &lt;span&gt;
      , and
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/on-chinas-open-source-ai-trajectory&quot; rel=&quot;&quot;&gt;
      tracking the trajectory of China’s ecosystem
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/inside-a-chinese-frontier-lab-inclusion?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/inside-a-chinese-frontier-lab-inclusion?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   An overview of Ant Ling &amp; Inclusion AI
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;span&gt;
    As important context for the interview, we wanted to present an overview of InclusionAI, Ant’s models, and other efforts that emerged onto the scene just in the last 6-9 months.
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/inside-a-chinese-frontier-lab-inclusion#footnote-1-177211847&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     1
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    To start — branding.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Here’s a few screenshots of InclusionAI’s new website. It starts with fairly standard “open-source AI lab messaging.”
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!Eo97!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bf72317-aa4a-4997-9fe6-799b0f6b1e36_2890x1437.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Eo97!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bf72317-aa4a-4997-9fe6-799b0f6b1e36_2890x1437.png 424w, https://substackcdn.com/image/fetch/$s_!Eo97!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bf72317-aa4a-4997-9fe6-799b0f6b1e36_2890x1437.png 848w, https://substackcdn.com/image/fetch/$s_!Eo97!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bf72317-aa4a-4997-9fe6-799b0f6b1e36_2890x1437.png 1272w, https://substackcdn.com/image/fetch/$s_!Eo97!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bf72317-aa4a-4997-9fe6-799b0f6b1e36_2890x1437.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0bf72317-aa4a-4997-9fe6-799b0f6b1e36_2890x1437.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1437,&quot;width&quot;:2890,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1128529,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/177211847?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14991c50-5922-4655-abce-e0ef817ac033_2890x1778.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;1437&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!Eo97!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bf72317-aa4a-4997-9fe6-799b0f6b1e36_2890x1437.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Eo97!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bf72317-aa4a-4997-9fe6-799b0f6b1e36_2890x1437.png 424w, https://substackcdn.com/image/fetch/$s_!Eo97!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bf72317-aa4a-4997-9fe6-799b0f6b1e36_2890x1437.png 848w, https://substackcdn.com/image/fetch/$s_!Eo97!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bf72317-aa4a-4997-9fe6-799b0f6b1e36_2890x1437.png 1272w, https://substackcdn.com/image/fetch/$s_!Eo97!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bf72317-aa4a-4997-9fe6-799b0f6b1e36_2890x1437.png 1456w&quot; width=&quot;2890&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   Then I was struct by the very distinct messaging which is surprisingly rare in the intense geopolitical era of AI — saying AI is shared for humanity.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!xb5j!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F885d02a1-70da-4e09-b01e-bd792bd22568_2890x1237.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!xb5j!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F885d02a1-70da-4e09-b01e-bd792bd22568_2890x1237.png 424w, https://substackcdn.com/image/fetch/$s_!xb5j!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F885d02a1-70da-4e09-b01e-bd792bd22568_2890x1237.png 848w, https://substackcdn.com/image/fetch/$s_!xb5j!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F885d02a1-70da-4e09-b01e-bd792bd22568_2890x1237.png 1272w, https://substackcdn.com/image/fetch/$s_!xb5j!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F885d02a1-70da-4e09-b01e-bd792bd22568_2890x1237.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/885d02a1-70da-4e09-b01e-bd792bd22568_2890x1237.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1237,&quot;width&quot;:2890,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:271540,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/177211847?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6121118f-de71-4df2-9960-b5121c938187_2890x1772.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;1237&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!xb5j!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F885d02a1-70da-4e09-b01e-bd792bd22568_2890x1237.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!xb5j!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F885d02a1-70da-4e09-b01e-bd792bd22568_2890x1237.png 424w, https://substackcdn.com/image/fetch/$s_!xb5j!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F885d02a1-70da-4e09-b01e-bd792bd22568_2890x1237.png 848w, https://substackcdn.com/image/fetch/$s_!xb5j!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F885d02a1-70da-4e09-b01e-bd792bd22568_2890x1237.png 1272w, https://substackcdn.com/image/fetch/$s_!xb5j!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F885d02a1-70da-4e09-b01e-bd792bd22568_2890x1237.png 1456w&quot; width=&quot;2890&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   I expect a lot of very useful and practical messaging from Chinese open-source labs. They realize that Western companies likely won’t pay for their services, so having open models is their only open door to meaningful adoption and influence.
  &lt;/p&gt;
  &lt;h4&gt;
   Main models (Ling, Ring, &amp; Ming)
  &lt;/h4&gt;
  &lt;p&gt;
   &lt;span&gt;
    The main model series is the
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/collections/inclusionAI/ling&quot; rel=&quot;&quot;&gt;
    Ling
   &lt;/a&gt;
   &lt;span&gt;
    series, their reasoning models are called
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/collections/inclusionAI/ring&quot; rel=&quot;&quot;&gt;
    Ring
   &lt;/a&gt;
   &lt;span&gt;
    , and their Multimodal versions are called
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/collections/inclusionAI/ming&quot; rel=&quot;&quot;&gt;
    Ming
   &lt;/a&gt;
   &lt;span&gt;
    . The first public release was
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/inclusionAI/Ling-plus&quot; rel=&quot;&quot;&gt;
    Ling Plus
   &lt;/a&gt;
   &lt;span&gt;
    , 293B sparse MoE in April. They released the
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2506.14731&quot; rel=&quot;&quot;&gt;
    paper for their reasoning model
   &lt;/a&gt;
   &lt;span&gt;
    in June and have continued to build on their MoE-first approach.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Since then, the pace has picked up significantly.
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/inclusionAI/Ling-lite-1.5-2507&quot; rel=&quot;&quot;&gt;
    Ling 1.5
   &lt;/a&gt;
   &lt;span&gt;
    came in July.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Ling (and Ring) 2.0 came in September of this year, with a 16B total, 2B active
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/inclusionAI/Ling-mini-2.0&quot; rel=&quot;&quot;&gt;
    mini model
   &lt;/a&gt;
   &lt;span&gt;
    , an 100B total, 6B active
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/inclusionAI/Ling-flash-2.0&quot; rel=&quot;&quot;&gt;
    flash model
   &lt;/a&gt;
   &lt;span&gt;
    , and a
   &lt;/span&gt;
   &lt;strong&gt;
    big 1T total parameter
   &lt;/strong&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;strong&gt;
    &lt;span&gt;
     50B active
    &lt;/span&gt;
    &lt;a href=&quot;https://huggingface.co/inclusionAI/Ling-1T&quot; rel=&quot;&quot;&gt;
     primary model
    &lt;/a&gt;
   &lt;/strong&gt;
   &lt;span&gt;
    . This 1T model was accompanied by a
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2510.18855&quot; rel=&quot;&quot;&gt;
    substantial tech report
   &lt;/a&gt;
   &lt;span&gt;
    on the challenges of scaling RL to frontier scale models. The rapid pace that Chinese companies have built this knowledge (and shared it clearly) is impressive and worth considering what it means for the future.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!u-J_!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a96dfb0-1c3f-4e50-9412-ec6f9ef39d0d_2159x1130.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!u-J_!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a96dfb0-1c3f-4e50-9412-ec6f9ef39d0d_2159x1130.png 424w, https://substackcdn.com/image/fetch/$s_!u-J_!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a96dfb0-1c3f-4e50-9412-ec6f9ef39d0d_2159x1130.png 848w, https://substackcdn.com/image/fetch/$s_!u-J_!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a96dfb0-1c3f-4e50-9412-ec6f9ef39d0d_2159x1130.png 1272w, https://substackcdn.com/image/fetch/$s_!u-J_!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a96dfb0-1c3f-4e50-9412-ec6f9ef39d0d_2159x1130.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7a96dfb0-1c3f-4e50-9412-ec6f9ef39d0d_2159x1130.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:762,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:582989,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/177211847?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a96dfb0-1c3f-4e50-9412-ec6f9ef39d0d_2159x1130.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;762&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!u-J_!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a96dfb0-1c3f-4e50-9412-ec6f9ef39d0d_2159x1130.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!u-J_!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a96dfb0-1c3f-4e50-9412-ec6f9ef39d0d_2159x1130.png 424w, https://substackcdn.com/image/fetch/$s_!u-J_!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a96dfb0-1c3f-4e50-9412-ec6f9ef39d0d_2159x1130.png 848w, https://substackcdn.com/image/fetch/$s_!u-J_!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a96dfb0-1c3f-4e50-9412-ec6f9ef39d0d_2159x1130.png 1272w, https://substackcdn.com/image/fetch/$s_!u-J_!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a96dfb0-1c3f-4e50-9412-ec6f9ef39d0d_2159x1130.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    Eval scores obviously aren’t everything, but they’re the first step to building meaningful adoption. Otherwise, you can also check out their
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/inclusionAI/Ring-mini-linear-2.0&quot; rel=&quot;&quot;&gt;
    linear attention model
   &lt;/a&gt;
   &lt;span&gt;
    (
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2510.19338&quot; rel=&quot;&quot;&gt;
    paper
   &lt;/a&gt;
   &lt;span&gt;
    , similar to Qwen-Next
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/inside-a-chinese-frontier-lab-inclusion#footnote-2-177211847&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     2
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    ), some
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/inclusionAI/Ling-mini-base-2.0-5T&quot; rel=&quot;&quot;&gt;
    intermediate
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/inclusionAI/Ling-mini-base-2.0-10T&quot; rel=&quot;&quot;&gt;
    training
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/inclusionAI/Ling-mini-base-2.0-20T&quot; rel=&quot;&quot;&gt;
    checkpoints
   &lt;/a&gt;
   &lt;span&gt;
    , or
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/inclusionAI/Ming-UniVision-16B-A3B&quot; rel=&quot;&quot;&gt;
    multimodal
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/inclusionAI/Ming-UniAudio-16B-A3B&quot; rel=&quot;&quot;&gt;
    models
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h4&gt;
   Experiments, software, &amp; other
  &lt;/h4&gt;
  &lt;p&gt;
   InclusionAI has a lot of projects going in the open source space. Here are some more highlights:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://huggingface.co/inclusionAI/LLaDA2.0-mini-preview&quot; rel=&quot;&quot;&gt;
      Language diffusion models
     &lt;/a&gt;
     &lt;span&gt;
      : MoEs, sizes similar to Ling 2.0 mini and flash (so they likely used those as base).
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/collections/inclusionAI/llada&quot; rel=&quot;&quot;&gt;
      Previous versions
     &lt;/a&gt;
     &lt;span&gt;
      exist.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://huggingface.co/collections/inclusionAI/aworld&quot; rel=&quot;&quot;&gt;
      Agent-based models/fine-tunes
     &lt;/a&gt;
     &lt;span&gt;
      ,
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/collections/inclusionAI/asearcher&quot; rel=&quot;&quot;&gt;
      Deep Research models
     &lt;/a&gt;
     &lt;span&gt;
      ,
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/collections/inclusionAI/ui-venus&quot; rel=&quot;&quot;&gt;
      computer-use agentic models
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://huggingface.co/collections/inclusionAI/grovemoe&quot; rel=&quot;&quot;&gt;
      GroveMoE
     &lt;/a&gt;
     &lt;span&gt;
      , MoE arch experiments.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://huggingface.co/collections/inclusionAI/areal&quot; rel=&quot;&quot;&gt;
      RL
     &lt;/a&gt;
     &lt;span&gt;
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/collections/inclusionAI/areal-boba&quot; rel=&quot;&quot;&gt;
      infra
     &lt;/a&gt;
     &lt;span&gt;
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/collections/inclusionAI/areal-boba-2&quot; rel=&quot;&quot;&gt;
      demonstrations
     &lt;/a&gt;
     &lt;span&gt;
      (Interestingly, those are dense models)
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://github.com/inclusionAI/AWorld&quot; rel=&quot;&quot;&gt;
      AWorld
     &lt;/a&gt;
     &lt;span&gt;
      : Training + general framework for agents (
     &lt;/span&gt;
     &lt;a href=&quot;https://github.com/inclusionAI/AWorld-RL&quot; rel=&quot;&quot;&gt;
      RL version
     &lt;/a&gt;
     &lt;span&gt;
      ,
     &lt;/span&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2508.20404&quot; rel=&quot;&quot;&gt;
      paper
     &lt;/a&gt;
     &lt;span&gt;
      )
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://github.com/inclusionAI/AReal&quot; rel=&quot;&quot;&gt;
      AReal
     &lt;/a&gt;
     &lt;span&gt;
      : RL training suite
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   Chapters
  &lt;/h2&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:00:00 A frontier lab contender in 8 months
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:07:51 Defining AGI with metaphor
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:20:16 How the lab was born
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:23:30 Pre-training paradigms
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:40:25 Post training at Inclusion
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:48:15 The Chinese model landscape
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:53:59 Gaps in the open source ecosystem today
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:59:47 Why China is winning the open race
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     01:11:12 A metaphor for our moment in LLMs
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h2&gt;
   Transcript
  &lt;/h2&gt;
  &lt;h3&gt;
   A frontier lab contender in 8 months
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (00:05)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Hey everybody. I’m excited to start a bit of a new series when I’m talking to a lot more people who are building open models. Historically, I’ve obviously talked to people I work with, but there’s a lot of news that has happened in 2025 and I’m excited to be with one of the teams, a mix of product, which is Richard Bian and some technical members from the Ant Ling team as well, which is Chen Liang and Ziqi Liu. But really this is going to be a podcast where we talk about how you’re all building models, why you do this. It’ll talk about different perspectives between US, China and a lot of us going towards a similar goal. I was connected first with Richard, who’s also talked to other people that helped with Interconnects. So we can start there and go through and just kind of talk about what you do. And we’ll roll through the story of building models and why we do this.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (01:07)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Hi. Again, thanks so much, Nathan. Thanks so much for having us. My name is Richard Bian. I’m currently leading the product and growth team of Ant Ling, which is part of the Inclusion AI lab of Ant Group. So Ant Group is the parent company of Alipay, which might be a product which many, many more people know about. But the group has been there for quite some time. It used to be a part of Alibaba, but now it’s a separate company since 2020. I actually have a pretty mixed background. Before I joined the Ling team, I’ve been doing Ant open source for four years. In fact, I built Ant open source from a technical strategy, which is basically a one-liner from our current CTO all the way into a full-fledged multifunctional team of eight people in four years. So it has been a pretty rewarding journey. And before that, my last life, I’ve been spending 11 years in the States working as a software engineer with Microsoft and with Square. Again, it was a pretty rewarding past. I returned back to China during COVID to be close with my family. It was a conscious decision. So far so good. It has been a pretty rewarding journey. And I really love how Nathan you name your column as Interconnects and you actually echoed when you just began the conversation just now. I found that to be a very noble initiative. So very honored to be here.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (02:48)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Hopefully first of many, but I think you all have been doing very interesting stuff in the last few weeks, or last few months, so it’s very warranted. And do you two want to introduce yourselves as well?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Chen Liang (02:58)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Me first. My name is Chen Liang and I’m the algorithm engineer of Ling Team, and I’m mainly responsible for the floating point 8 training during the pre-training. Thank you.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Ziqi Liu (03:16)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   My name is Ziqi Liu and I graduated, a PhD from Jiao Tong University in China. And I’ve been working at Ant Group for about eight years. And currently I’m working on the Ling language model. That’s it.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (03:45)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Nice. I think the way this will flow is I’m going to probably transition. It’ll start more with Richard’s direction. Then as we go, it’ll get more technical. And please jump in. I think that we don’t want to segment this. I mean, the border between product growth, technical modeling, whatever, that’s why AI is fun is because it’s small. But I would like to know how Inclusion AI started and all these initiatives. I don’t know if there’s a link to Ant OSS. I found that in prep and I thought that was pretty interesting and just kind of like, how does the birth of a new language modeling lab go from idea to releasing one trillion parameter models? So like, what does that feel like on the ground?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (04:18)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   There’s actually one additional suffix for that in eight months’ time. In fact, we kind of began all of this initiative in February this year. So just to begin with for the audience who probably didn’t know much about Inclusion AI, Inclusion AI basically envisions AGI as a humanity’s shared milestone, not a privileged asset. So we started this initiative back in the February of 2025, inspired by the DeepSeek Research Lab. So the DeepSeek Research Lab and their publication, in fact, motivated a lot of people. I believe not only in China, but globally. Taking one step more closer to the AGI initiative by showing it’s probably not an exclusive game for only the richest people who can afford the best hardware and the best talent. So the way we’re kind of looking at it is like why we named that Inclusion is because we actually have that gene with the company. So the decision was actually made, of course, the decision was made beyond my pay grade, but it was actually very well informed internally for the mission and vision that we want to be more like DeepSeek, which is a research lab with a dedicated effort of pursuing AGI. In fact, I mean, if you kind of think about Ant Group with our business model, like we’re a Fintech company, to some extent, very similar to a combination of Square, Stripe, and many other companies in the States, we have a very broad range of businesses which focus not only on the financial vertical, but on medical insurances and the technical services as well. So a lot of those businesses. In order for us to actually be able to support those businesses, I would say long-term success in the next five to 10 years is going to be critically important for us to be able to really focus on the fundamentals of AI. And we feel that the language model is a key to that door. We cannot give up on that initiative.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (06:52)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   There’s a lot here and I agree with this. And I think that it’s like, the Ant Group is a big large tech company. And I think large tech companies being able to train AI as like most of the audience here is going to be like, yes, they definitely should be doing this. It’s a transformative technology. I think the two things to double click on are, we’re going to have to define like what you think of as AGI and why you’re pursuing this. Because it has to go deeper than like a term that we are doing. I know like DeepSeek is very ideological in their pursuit of intelligence. So I think it’s good to do that. And then I will also double click on the question of like, why open models and like, because DeepSeek is doing like open and as strong as they can, they’re text only. We’ll talk about this later. But it’s like, let’s do each of these individually to kind of ground the motivation.
  &lt;/p&gt;
  &lt;h3&gt;
   Defining AGI with metaphor
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (07:51)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Sure. I guess, I mean, for AGI, the way we are looking at it is like, I don’t think there’s a definitive answer to that. I mean, if we kind of search Google or any other search engines, it will give you a line, which means something. But it doesn’t mean anything, honestly, to me personally, just by looking at the definition. I would probably use a metaphor. People are probably very familiar with the navigation era. It’s a glorious navigation era back in the 1400s. Now, I think it feels more like all the ships are just leaving Lisbon last year, or maybe like two years ago.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (08:18)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I like it. I agree with this more than most of the definitions, because a lot of the definitions are grounded in like work or something.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (08:26)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The one I’m kind of looking at is like, all the ships are leaving Lisbon. Some of them are heading west, knowing for a fact that, hey, India is over there. But now we all know the truth that India is on the east side. But it doesn’t matter. It’s the whole American continent. So the way I’m kind of looking into the definition of AGI right now is like, I personally have a very firm belief that human intelligence and machine intelligence, to some extent, have their similarities. Humans are trying to, to some extent, explore the limit of human intelligence with the help from the machines. So when everything was beginning, we were kind of using all of this as a co-pilot mode. But moving forward, there are all of these theories indicating that there might be an intrinsic point that the machine intelligence, it goes all the way back from the tooling time. They believe that machine intelligence might, at one point, exceed human intelligence. So I guess we’re looking to that pivoting point. Before we reach there, honestly, I don’t know where we’re going and how long we can go towards that particular direction. But clearly, there are some common consensus right now, including maybe MoE (Mixture of Experts) as architecture, including the pre-training, even to some extent, we’re seeing a diminishing return. But pre-training is still pretty important. And reinforcement learning, to some extent, is probably another general agreement that this might not be wrong. We don’t know if this is right, but it might not be wrong. So there are all of these exploratory directions that we believe in. So we’re just kind of sailing there and see how that goes.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (10:20)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I love this. And I think the crucial question is for Chen or Ziqi is like, the team like, how do you build team alignment around this? Is this something that you feel like you walk into the office or get on a call and everybody’s in agreement? Or is this like a vision that you’re still building or trying to sell? Like, to what extent you could say, because I think there’s a big difference between like, I buy the vision for Inclusion AI, but it’s like, how real is this when you’re across the org?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (10:49)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I can maybe share my feeling and Ziqi and Chen can chime in. Of course, at the very beginning, there’s skepticism. It’s by human nature, right? So the way we’re looking at it is like, I think DeepSeek gives a very clear indication that this might be working. There has been this hazy, chaotic era of 2024, which nobody has the tools to navigate. So people are very cautious about sailing. You see ships going out and came back crippled, and you begin to worry about what’s going on there.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (11:34)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I think there’s a big difference between the US because I think in the US everybody was bought in. And I’ve talked to a few more labs in China and it’s like there’s so much emotional energy on the DeepSeek moment in China that I think in the US people forget about it where it’s like, I could see this in the sequence of releases as well because it’s like everybody had a few months after DeepSeek like all these labs in China have started releasing models and I just think that it’s good to have you say this, is a shared sense of people so people can internalize like how much has been mobilized. And that’s kind of a culturally salient point.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (12:04)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   It’s motivating. To some extent, there was this very famous navigator called Zheng He back in the Ming dynasty. So I think basically when Zheng He was able to pretty much pull through the trip all the way to India from China, people began realizing that, hey, not only the Portuguese can do this kind of long journey sailing, the Chinese can do that too. And we’re exploring different parts of the map. You know, toward the end of the day, nobody knows the whole picture. So the way I’m kind of looking at it is like, first, I’m very bought into the mission to some extent that it kind of feels like, you know, even though we begin sailing late, but we do have our own kind of taste to this game. So we will be able to contribute. And you did ask about the question, you know, like why we chose to be open, right? To some extent, I cannot really believe that open is a choice, just like how the leaders in this game are not the most open player in the game, right? But if you’re kind of thinking about playing poker, the trick leader has their own strategy, which is all understandable. For us, because we’re joining the game at this stage, I guess the best strategy would kind of feel like, A, really trying to follow suit to the right direction to minimize the mistakes we’re making at this moment because we’re so late. Second, stay open and stay polished. So keep a very open mind about what’s going on in the surroundings. And that’s probably the best we can do. That’s my two cents.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!cKPz!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6eedf3a-e4ac-47d8-8ec1-aa95cf075232_1600x965.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!cKPz!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6eedf3a-e4ac-47d8-8ec1-aa95cf075232_1600x965.jpeg 424w, https://substackcdn.com/image/fetch/$s_!cKPz!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6eedf3a-e4ac-47d8-8ec1-aa95cf075232_1600x965.jpeg 848w, https://substackcdn.com/image/fetch/$s_!cKPz!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6eedf3a-e4ac-47d8-8ec1-aa95cf075232_1600x965.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!cKPz!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6eedf3a-e4ac-47d8-8ec1-aa95cf075232_1600x965.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;Zheng He | Timeline | Britannica&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b6eedf3a-e4ac-47d8-8ec1-aa95cf075232_1600x965.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:878,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Zheng He | Timeline | Britannica&quot;,&quot;title&quot;:&quot;Zheng He | Timeline | Britannica&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;878&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!cKPz!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6eedf3a-e4ac-47d8-8ec1-aa95cf075232_1600x965.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!cKPz!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6eedf3a-e4ac-47d8-8ec1-aa95cf075232_1600x965.jpeg 424w, https://substackcdn.com/image/fetch/$s_!cKPz!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6eedf3a-e4ac-47d8-8ec1-aa95cf075232_1600x965.jpeg 848w, https://substackcdn.com/image/fetch/$s_!cKPz!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6eedf3a-e4ac-47d8-8ec1-aa95cf075232_1600x965.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!cKPz!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6eedf3a-e4ac-47d8-8ec1-aa95cf075232_1600x965.jpeg 1456w&quot; title=&quot;Zheng He | Timeline | Britannica&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
    &lt;figcaption&gt;
     image of Zheng He’s voyages from Encyclopedia Brittanica
    &lt;/figcaption&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (13:51)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   To provide some color and I’ll have a whole note in the page that I release with this for people listening. The first Ling model, which is like their text only model, very, you could see iterations from DeepSeek and the architecture was in April and then a big updated Ling 1.5 in July. And then in September or recently was Ling 2.0, which also came with a multimodal Ming and a reasoning Ring model. And I think like by this September release is when like me and a couple of people that work at Interconnects were like, Holy crap, like this is a, this is like very much a real deal model. And to kind of ramp in that period of time is not easy. Like there’s a lot of companies in the US that are trying to do this right now. A few companies in China have shown that they can do this. And it’s like, I guess if you want to explain this kind of Ling, Ring, Ming series of models and like if this is a clear strategy behind this or if this is what works like, how did you evolve through the first models through the summer to today to kind of get to this point?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (14:56)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Sure. So I mean, first and foremost, I think the foundation model is really important. To some extent, I’ve been working with many people on the system side, because Ant Group has a very solid cloud-native infrastructure team. So the team has been, when we talk about this, we’re kind of beginning using the metaphor. The model is really like an operating system. It’s not like the operating system itself, but it’s more like the kernel. Right, so only a few people can actually write kernel code, even nowadays. Just like how there’s the most talented people who can actually work on the model team right now. We feel that it’s not only a key leading to the technical future, but it’s also a key leading to the user experience future. Because we do see the, I personally believe in the trend of technology brings in new interactions which will lead to new product, which will lead to new business models, which will lead to potentially new organization structure, rinse and repeat. So we kind of like really choose to do the fundamental model of the Ling series because of that. And the Ring series is an obvious next, given the relationship between V3 and R1. It definitely indicates about how we can potentially take a very polished, well, actually, a very intelligent individual, unpolished, and put some reinforcement learning on it to make it a much better individual in one clear vertical direction. We’re going to be touching on some of those kind of technical aspects in our conversation next. But that has been a very clear direction.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (16:48)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Do you see this evolving with kind of feedback from within Ant Group, which is like, you’ve also released this diffusion language model. A diffusion language model is very interesting. I’m going to just go out on a little bit of a side rant because I’ve heard, I was talking to people about these and it’s like very hit or miss with me, whether or not I think they’re going to be big. Because we see that tool use and reasoning is a big thing. So the whole idea of a diffusion language model is you generate a very long sequence at once and that could save on costs because you don’t have this kind of quadratic memory increase and you do very long sequences. So I saw that I was optimistic. And then you see the idea of tool use, which is like, you have to be able to chop up the reasoning. And I was like, I’m really bearish on diffusion models for language again, because you have to be able to search and execute code. But then I was hearing that in like user facing products, like code diffs, where if you’re generating a website and you did take a prompt and go to a huge diff on a code base really fast, then language diffusion is actually really nice. And the motivation of the question is like, do you have this feedback loop in your modeling where Ant Group is trying to use these things for products and might like have a bit of a feedback of like this latency isn’t fast enough or like this area you need to move it to, or is this kind of like a separate play of just build the best models you can and figure it out later?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (18:12)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   That’s a very perfect question. We use this metaphor that we’re probably also doing this reinforcement learning in real life by trial and error. Almost kind of feels like, so I think Nathan, you nailed a very good question. And there are some very clear consensus about coding agents, tool use and people kind of going down a path and pursuing their own business models and begin making revenues. So that’s one type of usage patterns for language models. We do that and we see some very clear, I would say feedback loops in that direction. So that’s one pillar. And the second pillar is about the not so clear aspect. By saying the not so clear aspect, it’s like, I believe everyone in the Silicon Valley and in Seattle is still scratching their heads trying to understand about, hey, when can I break even with all this investment? Are we really generating enough user values kind of back to, I’m a product person. So all of those kinds of words keep coming back into my head. And, you know, at this moment, consciously speaking, it’s very hard to come to the conclusion that, you know, all of this is valuable enough for the end user. But, you know, we’re trying to explore the directions for that. I would say a lot of the, you know, generating the whole website, you know, what Labo did, it’s an interesting form of product. But at this moment, we don’t know if it’s A, sustainable as a business model, B, if this is the best type of product we can offer to the user. So all of those are iterative. Within company, we do have some of those explorative products that use our models, not only the Ring model, but Ming as well, like the multimodal. And you mentioned about the, so that’s the second pillar. And the latter is more like the last pillar, because Ant Group does have a research institution called Ant Research. So the model is a joint collaboration between the research and the Ling Team.
  &lt;/p&gt;
  &lt;h3&gt;
   How the lab was born
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (20:16)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I guess there’s another like org chart question, which is like, where in the structure of the big tech company that is Ant did this Inclusion AI slash Ling and all of this grow? Like, is this within cloud that there’s a new modeling or research org or is it kind of separate? Like, do you feel like this is a part of the bigger company or are you kind of insulated from this?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (20:42)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   You can actually search on Google and find information about Ant Research which is a joint research lab focusing more on a lot of these frontier technologies like graph, deep learning, reinforcement learning, before all of this. So that’s the background of Ant Research. And second, when we begin forming the AGI initiative of Inclusion AI, we begin getting very serious. So we begin putting all of these resources together to some extent physically, but more from the organizational ways of saying that all of these teams of financial models and research lab institution and the user experience expert focusing on exploratively looking into the next big application that people will actually use. So all of this, we kind of began forming this internal, I wouldn’t call that organization, but more like this internal initiative directly driven by our CTO. So it’s very serious effort. It’s very serious to the extent that, you know, it feels more like when the team actually formed the original DeepSeek initiative. So all of these people, you do nothing else but only focusing on this and this is the only important thing for this.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (22:01)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   It’s like so much of this is that the mystique I feel like is that in the West, we don’t get what would normally be gossip of what is happening in the Chinese tech ecosystem, which I don’t think this is hard to see if you have friends that work at Ant Group, because it’s probably you’re moving hundreds of people’s jobs around and people talk. Whereas like in my circles, it’s like, Meta is doing another reorg. And then you hear about it in the news a few days later. So it’s just like, I don’t know. That’s my reflection hearing all of this. And I’m mostly learning that all of these orgs end up similar in size. And then you have to prioritize resources per researcher and all of these normal things. I’m going to start transitioning into this section we had prepped on actual modeling things, which is mostly on pre-training, which is fun. I think that state of affairs on my pre-training knowledge from AI2 is that we’ve scaled, done plenty of dense models and some architecture things from up to like 32B, some experiments at 70B that one didn’t work out. MoE is work in progress. So I’m personally very interested in architectural decisions that enable MoEs and long context.
  &lt;/p&gt;
  &lt;h3&gt;
   Pre-training paradigms
  &lt;/h3&gt;
  &lt;p&gt;
   I think the kind of basic thing is just like, if you’re pre-training, I mean, this is for Ziqi is like, what does your, how do you feel like your trajectory is as a researcher as you’re going through these months? This could be just like, what does your work feel like when you’re trying to boot up like a DeepSeek style, very ambitious lab building new infrastructure and getting models off the ground. And then we’ll kind of go into some more specific discussions around like Ling 1T later and stuff like this. But it’s like, how is building this?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Ziqi Liu (23:45)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Our architecture indeed refers to OpenAI’s scaling law or DeepSeek’s scaling law. They really do a good job. In our Ling scaling law, the non-embedding training FLOPs play the central role of our scaling law. So we set up our own framework that provides foundation for a standardized experimental pipeline. So there are many questions when we start conducting scaling law under the MoE architecture. So the first question is, can we find simple rules for finding optimal hyperparameters with respect to training FLOPs, which are not sensitive to the structure of MoE. Similar to DeepSeek, we first discovered the optimal critical hyperparameters with respect to training FLOPs and the MoE architecture. We find those optimal hyperparameters are not that sensitive to the structure of MoE, like the activation ratio and something others in a mild condition, but more related to the training FLOPs. So this is our first finding. And then we found activation ratio is critical and can consistently improve if we reduce activation ratio.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (25:14)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Can you say more about this? I mean, most of pre-training is a lot of different things, which you’re accumulating FLOP efficiency while getting model performance. And then it’s like Chen, you also were saying you focused on FP8 stability, FP8 and training stability in general. So I’m kind of curious of like any major, like, what is your biggest impressions of focusing on kind of this narrow thing in pre-training, which is getting more memory by using lower precision while maintaining stability. So if you have any like high level takes on pre-training stability at that precision, then I’ll zoom into more specific questions on scaling up from there.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Chen Liang (26:00)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   At first we heard about the floating point 8 from DeepSeek. They used floating point 8 training through the training of DeepSeek. And we also tried the recipe of them, the block-wise INT8 in the Megatron. And we find that actually the MFU (Model FLOPs Utilization) is not very high. And sometimes it’s even slower than the BF16 (bfloat16) training. And we find that the main costs are the quantization and dequantization. So actually, the floating point 8 is not as fast as they claimed, actually. And we profile the whole training data and try to minimize the quantization and dequantization process.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (26:50)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   What is getting quantized and dequantized?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Chen Liang (26:53)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   If you want to try the floating point 8 training, it’s actually due to GEMM (General Matrix Multiply) in the linear layers. And you want to quantize the weights and the inputs to FP8 (E4M3) type. But the other structure, they compute in the BF16, BFloat16 type. So when you get into the linear layer, you need to quantize it to the floating point 8, and then do the GEMM. And the GEMM output is the BFloat16. So this is the way you need to quantize and dequantize to adapt the other structure.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (27:43)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And then what does your work actually look like in getting this? So you find it to be not as fast. Like, what do you actually do to change this?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Chen Liang (27:50)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   In the MoE layer, it’s got the FC1 (Fully Connected 1) and FC2 (Fully Connected 2), right? And in the middle of them, they’ve got the switch gated function. So FC1, switch gated function and FC2. And the output of FC1 is the BFloat16. And we fuse the operation of the switch gated function and the quantization function. So we fuse them, the two operations, into one. And so it saves some time. And the MoE layer is a batched operation. So you need to actually do the activation function on all the experts. So that’s a lot of time.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (28:52)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   For people listening, FC is fully connected, which is just the standard neural network layer. So I might be being silly, but generally the idea with MoEs is that you have the feed forward layers, take up the most parameters and you get more efficient by adding MoEs. And within the MoE, kind of gated to each expert, is it actually standard that it’s like fully connected, MoE gate, fully connected? And it’s kind of alternating because I know this normally like attention block, MoE block is like the higher level of abstraction. And it’s this fully connected, MoE gating and then fully connected, is that actually industry standard? And I just had like a lapse in my brain.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Chen Liang (29:37)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   This structure is conventional actually. Some experiments have explained that the switch gated can make your gradient stable during training. So it’s actually a standard architecture.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (29:51)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   When you’re actually experimenting on this, is this the sort of thing that when you’re doing it at your like first models were about 300B total and you had smaller models? Like, is this a sort of thing done where you get this performance at every scale? Or do you have to revisit this when you’re doing something like Ling 1T, which is this latest model with way more parameters? Because I think the root of my question is like, are the numerical problems you get from scaling like whack-a-mole, where it’s like an old problem that you fixed becomes a problem again? Or is it an entirely new type of thing that comes up when you’re going to big models?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Chen Liang (30:26)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   We do the experiment on the size of 100 billion parameters first. Also the situation can be, we can learn from the situation. That size, not just the 1T.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (30:43)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And I remember reading, I saw that you guys did QK norm for this as well. Is this just like, you also found this to be standard and work for you because we’ve had some issues with long context and doing QK norm kind of hurting performance there. We still have some ablations to track down.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Chen Liang (30:47)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   We actually do the experiment of the QK norm on BFloat16 and the result comes out. The loss is better than if you didn’t apply the QK norm. And actually the one big thing is that when you do the floating point 8 training, if you do not apply QK norm before the rotary embedding, the gradient of the linear QKV may be underflow. Most of the time, it’s underflow because without the QK norm. So if we want to apply the floating point 8 training, you need to add the QK norm to avoid the quantization error. Since the quantization error is propagated from the last layer to the first, and if the last layer got more quantization error, until the first layer it’s amplified error.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (32:07)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Let me try to talk through this because I’m mostly working post-training and I’ve heard all these terms and I want to make sure that we’re presenting a fairly clear picture to people. So in attention, you have queries, keys, and values. And these are big matrices that store many different things. And like generally with pre-training, the magnitude of the variables matters a lot because what you’re saying about like gradient flow. And if you have variables that are like too small, you might have no signal and too big or one thing. And what we’re saying is that, God, I guess what’s the order between, when you have, I guess there’s complicated things, which is like where the rotary embeddings are applied relative to the attention computation. And what we’re saying is that you have to put QK norm ahead of the rotary embeddings in this attention module, because then otherwise your gradients are too small when you’re scaling this or with FP8.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Chen Liang (32:53)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   During the forward process, you got the QK norm and the rotary embedding, and then you go forward. But during the backward, but if you do not apply QK norm, the Q times K matrix may have large values. And during the backward, the large value may bring a large gradient. And when you do the quantization, actually divide the data by the max of the per channel, the max of the column. So some small values will be divided nearly to the zero. So when you do the dequantize, it cannot find the real value before the quantization.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (33:52)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   That makes sense. I see. Like, what are you actually looking at to figure this out? Are you looking at like intermediate activation values when you’re scaling? Because I like training loss will only show you so much, or are you like seeing that the training loss is better or worse and then going to investigate this later?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Chen Liang (34:08)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The first is the loss is not right compared to the BFloat16. And we print the quantization error during the intermediate layers and find that without QK norm in the linear QKV, the gradient is too large.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (34:34)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I think that this is very good. It gives people a sense for like what the different things moving around when you’re looking at kind of pre-training research is. And then the other side of things, if you make a change and then you have a loss spike, you’re like, okay, then you have like a numerical stability issue. I guess like a loss spike that you can’t skip. So I’m guessing you have things where if you have a loss spike, you can skip some of them. But there’s some numerical stability you can’t get around. This is fun. I’m going to kind of keep rolling through this. I think that you’re also talking about how you have like different pipeline for training your MoE, which you described as like a heterogeneous fine-grained pipeline. I think that this is like, I would read this as matching your training architecture to your compute architecture in order to get a speed up. Because I think with MoEs and the communication bottleneck. So I think that it’s like, if you want to talk about the parallelism strategies you did to get pre-training to be efficient. I think it was also really interesting because it covers multiple layers of the stack and how you design models.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Chen Liang (35:39)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   It’s actually a common way, not just for our model. So actually the modern parallelism is just data parallel, tensor parallel, pipeline parallel, and context parallel. And our optimization is only focused on the pipeline parallel. As you can see from the paper, we do not use TP during our pre-training. So the common way to do the pre-training is they name it one forward and one backward type. Let’s see. We just focused on one machine with eight cards. And every card, actually, we name it as a stage. So we got stage 0 to stage 7. And every stage does the forward and the backward after it does the forward and sends the forward data to the next stage and they get the backward data from the next stage, right?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (36:49)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So that’s like an eight step pipeline. That’s like a pipeline parallel that you’re describing.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Chen Liang (36:53)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And every stage, they do communication from the prior stage and do the communication with the next stage. And the 1F1B got a problem that the stage 0 and stage 7 always got the most computation load because stage 0, you have an embedding layer. And it’s an index select operation. So it’s close. And stage 7, you got the LM head layer and the loss function. And you also got a large GEMM. So you need to times the hidden states to transfer the hidden states to the vocab size. And the vocab size is always large.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (37:45)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   How much fine-grained work are you doing to change which part of the model is on each stage? Because that seems like what it would be then. You either have to change the model or you have to change how you split up the model. It’s like your two options.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Chen Liang (37:58)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The common way is just you split the LM head layer and embedding layer and just divide it by the GPU number. So it’s natural that the stage 0 and the stage 7 got much more computation load, since you just ignored the balance of the system when you split the layers. So it’s the common one. So our optimization’s main concern is just to alleviate the computation load of the stage 0 and stage 7.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (38:25)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I see. I guess I don’t fully follow like what has happened. I’m trying to be like very clear of whether or not I understand it. Because I think that’s like in a dense model, I think pipeline parallel really makes sense, but you have like a smaller model. And then as you’re getting bigger, it’s like much less of a model. I don’t know what it means to necessarily like de-load the specifically the embeddings or the loss function and how much of a change you can make. But I think that might be like a me limitation. It might be hard to get to, but you can, I’m curious if you want to try.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Chen Liang (39:14)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Actually, it’s quite the same as the dense model. The only difference is that per GPU, you can imagine that during the pre-training, if we got the 32 experts and we use like four machines to gather the expert data, it’s just you can view this four machine as one machine. So in this view, it’s the same like the dense model. So just imagine the dense model. You split the layers according to your GPU cards. And let’s assume that every machine got two layers of the dense model.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (40:11)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So I get that. And then it’s like, it’s just like, then you have to shift things around to make it so the loss is less of a bottleneck in the last layer or the final part of this pipeline parallel being the bottleneck is kind of potentially fundamental.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Chen Liang (40:24)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Yeah.
  &lt;/p&gt;
  &lt;h3&gt;
   Post training at Inclusion
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (40:25)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I see. I mean, the next question that I wanted to ask is going to be very related to this, which is like, what are your, how do you scale this to make RL work at the same scale? So the different problems that you have for doing pre-training versus RL with a large scale model. I don’t have the title of the paper, but you’re like in this Ling 1T paper, there’s a ton of RL details. And it’s like, is this kind of just like the next sequential problem that you got to? And then there’s just a lot of, not necessarily similar solutions, but like you’re doing your problem solving in the same way to make RL work rather than pre-training in terms of throughput.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Chen Liang (41:03)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   It’s actually got some common tricks like we mentioned in the paper that the VPP (virtual pipeline parallelism). It actually means that the machine, you got double layers than the original one, than the original 1F1B, same things. But the difference is, let us assume that the stage 0 machine got four layers. But actually, during the time, two layers are doing computing and two layers are doing communication. So that’s what they call VPP.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (41:47)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   What does two layers computing and communicating mean?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Chen Liang (41:50)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   In other words, some layers are doing computing and some layers just prepare the data. They get the data.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (42:00)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I see, so it’s like some machines.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Chen Liang (42:03)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So when you train, during the computing, communication bandwidth is idle, right? So they utilize this to just like the exploration is the exploration. And our optimization is just to split the pipeline more precisely.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (42:31)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So I think I’m seeing that. So it’s within a node. You have very fast communication between eight GPUs. And then in pre-training, you’re kind of doing all sequentially, but in RL, you need to kind of sync this. You need to communicate more between your like generate, you have to move your weights to be able to generate when you’re doing RL. There’s like this sync step. And then I’m thinking what you’re saying is like, you have this chunk on eight GPUs and then you can split this. So half of them are doing compute and half are doing communication at the same time. So it kind of alleviates the bottlenecks. I see. For context and how like there’s a lot of different ways of doing RL infrastructure, it’s just the abstractions that like what we’re doing is much easier where we’re looking at approaches where we have GPUs that are set for generation and training, and that we are primarily looking at ways to make those both faster and then be able to throw the like training GPUs, we sync the weights to the generators and the generators just keep going where this is like it’s much more deeply embedded in the architecture where you have like one cluster where you’re kind of splitting the GPUs and what work is happening across each of the across like the per node basis when you’re doing this RL training. And I’m going to go look at this in more detail.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Chen Liang (43:48)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Yeah.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (43:56)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Just to add a little bit more flavors to this, the reason why we kind of didn’t really cover a lot of post-training details in this interview is because we have some additional technical papers or technical reports we’re writing at this moment about the system.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (44:14)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   That makes sense.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (44:15)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    So it was to some extent intentionally vague, Nathan. But I mean, first thing first, the current paper of Ling 1T and Ring 1T does have the fundamental intro for our system. It’s called a system. I believe the article has been published on
   &lt;/span&gt;
   &lt;a href=&quot;https://ant-ling.medium.com/&quot; rel=&quot;&quot;&gt;
    ant-ling.medium.com/
   &lt;/a&gt;
   &lt;span&gt;
    on the medium technical paper as well as on Ling Team. So the paper is also available in English on Ling Team as we publish all the details. So specifically, there are several things which we did for the RL aspect. One is about the system itself. You can imagine that we do have an optimized internal hybrid engine which does all the things you described. And the second part is we’re exploring the reward model system. So this reward model system essentially requires some additional design to reach a certain level of parallelism. And the way we’re kind of looking into that is we’re really trying to set up meaningful rewards by doing a parallel structure for that. Last but not least, we have the term called LPO (Language-level Policy Optimization), right? It’s a linguistic unit. So we decided to choose sentence intentionally. So it’s kind of like a different approach from GRPO (Group Relative Policy Optimization) and the GSPO (Group Sequence Policy Optimization), like the session approaches or the token approaches that some of the other labs are using. We intentionally chose language as a linguistic unit to explore the meaning of this. So far, we’ve been seeing very motivating results from doing that. The training stability and the generalism is actually, we see some pretty clear numbers indicating that the LPO can be a very viable option for RL training. So let’s maybe save some of those interesting dessert for our next conversation. And we would love to really be able to share a lot of those details, given your background in post-training. I will try to maybe invite some of the experts from that domain into our next conversation.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (46:10)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I think the LPO thing is interesting, that there’s kind of a natural abstraction in a sentence. So in the language model generates, you just split every generation per sentence or per punctuation mark. It’s very linked to kind of these ideas of process reward models that people have looked at and understand to have natural inductive biases for a long time. And there is still some research doing this. So I’m happy to see that you’re doing it. And it’s kind of, I think of it as like value models and other things in RL that are just out of vogue and are likely to come back in some form in the near future, which is cool. In the ecosystem, where do you see open models going? I think it’s like, I guess the high level question is like, I mean, this weighs heavily on myself personally, it’s like, do you think that it’s like a big cake that you can eat out of and everybody does like, is it like, you see a clear path to having models that are meaningful? Does it worry you that the list of handful in China, it’s like, I mean, we know DeepSeek, we know Qwen, we know Kimi Moonshot, we know GLM 4.5, Meituan is releasing good, very strong models right now. You guys are like, the conviction that this is like a winning thing and you have your niche and there are more models coming soon. Like, is that easy for you to see? I mean, you had your metaphors at the beginning that I thought were great. So I think that’s kind of partially answered, but it’s like, it’s a very competitive space. So is that like easy for you to see through and just keep pushing ahead?
  &lt;/p&gt;
  &lt;h3&gt;
   The Chinese model landscape
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (48:15)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Thanks again for the invitation for really having this conversation. I did actually have my lines at the very beginning. I kind of call myself as a global citizen. Some of the current, I would say, really pains me in that regard. So when I’m kind of looking at it, so first thing first, I’ve been doing open source for years. You did ask about Ant OSS. You can actually find Ant OSS on Twitter. And there’s also a website for that. It’s opensource.antgroup.com. So Ant Group actually has a very long history of doing, as we call nowadays, the traditional or the classic open source, quote unquote, which I believe will be there forever. And you did ask a very specific question about open source models or open models. Last year, this time, it has been a very heated conversation in the open source ecosystem. So people in the open source domain are saying that, hey, this is open-weights. It’s not open source at all, which makes perfect sense. Because if you think about the nature of open source, it has at least three entities which are critically important. One is code itself, and the other one is community, aka the developers and people around it. And the last one is license, which pretty much provides a common consensus of the, I would say, the most common denominator as people agree upon, which is legally viable. But coming to that license requires years of effort. So like last year, you do see the OSI is trying to come out with a definition, and people are having a very convoluted feeling about it. And we see the Linux Foundation and data release this model openness framework, which is a very viable way of measuring the models. But that’s sad. Even nowadays, we only see one class one, which is a model from
   &lt;/span&gt;
   &lt;a href=&quot;https://en.wikipedia.org/wiki/Beijing_Academy_of_Artificial_Intelligence#:~:text=BAAI%20is%20one%20of%20pre,challenges%20and%20future%20of%20AI.&quot; rel=&quot;&quot;&gt;
    BAAI in China,
   &lt;/a&gt;
   &lt;span&gt;
    which means by that standard, the rest of the models don’t meet it. And funny enough, last year, when I say we’re open sourcing our models, you’ll see people begin pointing fingers. Hey, you’re not open sourcing your models. Be careful about the words. But this year, all the labs are saying we’re open sourcing our models, and nobody is pointing fingers at all. Because it’s just like getting to a situation that we should maybe care less about this, but more about the direction, or what’s next. So I definitely want to spend more time discussing about that. So first thing first, I will say I did use the metaphor of saying the LLM is more like kernels. So if we kind of think about how many Linux kernel developers are on the planet now, it’s probably less than 1,000 people. So when people are saying that, hey, LLM is not really open source because nobody can contribute to it, yes, that’s correct. It’s very similar to the kernel. Theoretically, you can contribute to the kernel. But in reality, there’s only so few people who know about it. Most of the people are really kind of working around the ecosystem. They’re not the kernel developers, but we are currently at the stage of building the kernel itself. So that’s basically maybe my first point. It takes time. The reason why the open source definition is so convoluted at this moment, maybe just because it’s the first or the second year of a new era of neural development.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (51:54)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I agree. I think it’ll take like a decade. It’s like we’re in the first couple of years. I reiterate strongly with what you say where it’s like, it’s much better that people are actually using these models than just getting annoyed about definitions. And it’s like, we’ll figure out the definitions much more quickly if people actually want to use and contribute to these things.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (51:58)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    And then the next part coming after this is like, I’m just sharing a very interesting story because I mean, my previous leader, he was working on Kubernetes and containers. So I have a background of being a full stack engineer as well as an engineer working on the data infra of the platform. So one day we did have a conversation about, I was saying, hey, you know, this MySQL infra, because I stopped. MySQL is not infra. MySQL is application. I was like, OK, thank you. That’s very helpful. But it’s kind of interesting, right? Because if you think about why that particular conversation actually happened, it’s because if you’re perceiving this from the infrastructure perspective or if you’re perceiving this from application perspective. My hunch feeling is we are going towards the next stage as we speak right now. I think we are at the transition period of having this MySQL moment. So other gigantic sandbox, gigantic runtime at this moment, that seems more application related. But five years down the road, they will become infrastructure. So the way I’m kind of looking at it is like, first thing first, I’m very optimistic about that. We will have open source. We will have an ecosystem in the AI era. In fact, I think Matt White from PyTorch, I think he introduced this new license called
   &lt;/span&gt;
   &lt;a href=&quot;https://openmdw.ai/&quot; rel=&quot;&quot;&gt;
    OpenMDW license
   &lt;/a&gt;
   &lt;span&gt;
    , which kind of begins treating.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (53:53)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   It’s an underrated license. It’s a very, very reasonable license.
  &lt;/p&gt;
  &lt;h3&gt;
   Gaps in the open source ecosystem today
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (53:59)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   It’s very reasonable. In fact, I mean, we’re writing some Chinese articles trying to, I mean, I’m working with Art Eagles to do that. It deserves better visibility and more promotion. But kind of back to our original topic, I guess is, again, it will take quite some time for this information to rinse and repeat and consolidate. But I guess at this moment, I do see three gaps, which will prevent us from going to the next step. One is a proper license structure and a proper governance around the license. I think the OpenMDW is a good start, but it will take time. Second, I do believe data is the new code. So I guess how you’re contributing to the LLM is really through the data of pre-training and your data and reward models in post-training. But at this moment, there’s no Git for data. And the Git for data is not as straightforward as a Git for code because data can really be something which is very fundamental. So for instance, I mean like.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (55:07)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   It’s often impermanent too. So like a lot of multimodal data sets are released as links and then the links die. So it’s like even like we try to, like people at AI2 try to release a fully reproducible data set and 10% dies in the first three years or something like.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (55:12)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And you might be having a lot of, I would say, overhead cost behind the scenes. So I mean, thanks so much for doing that. I mean, when people do that, we’re kind of raising our hands and saying hallelujah, right? Thank you. But it’s a difficult job, right? Because there might be legal battles behind the scenes. There might be a lot of, I would say, data cleansing. And the worst come to worst is really just more like, so I sometimes use this metaphor like, you know, I say, buy Coca-Cola stock. And Warren Buffett is saying, buy Coca-Cola stock. It’s literally the same word, but they mean something intrinsically different. I can’t really get my buy Coca-Cola. But I mean, that’s also a legal problem. So it’s like, in Git, we can say this, your public study was in main is before my public study was in main. But in data, you can’t really say that. So there’s definitely some technical challenges associated with that. Last but not least, the reward model associated with our contribution and the causality of our contribution to the model to the actual rewards. So for instance, if I’m writing a PR on GitHub, people see my PR and they merge my PR, great. I did my contribution. But you know.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (56:43)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I see.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (56:46)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Our conversation today is really meaningful. It can be a good, I would say, data corpus for reinforcement learning to some extent. But when people do that, they will not tell you, they will not tell me, they will not tell anyone of us.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (56:54)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I’m lucky enough to be big enough and visible where I accept that like me being in it is now good because it reinforces that I’m visible. Just a technical note on language, you were saying reward model as in the thing that rewards people for participating. Reward model is also like a technical thing, which I’ve done a lot of work on. So I was slightly confused, but if there was anybody else that was confused, that’s been clarified. To kind of zoom out, I think that listening to you, it’s like, wow, you’re one of a few people that is totally up to date on the open source definition stuff in the world. And I’m sure there are people all over that are thinking about this. I think you’ve spent a lot of time in both cultures and it’s like, where do you feel like people in my seat versus your seat may see things differently with like what open source AI means, what AI means generally, or like anything in this space that you feel both in your job or your life with respect to AI.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (57:58)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   It’s a lovely question. I think it might be too big of a question, too. So I’ll probably answer that through two focuses. One is about open source ecosystem overall, like my feeling of being an engineer by training and global citizen, how I perceived open source ecosystem in general. And the second part is about the Chinese AI ecosystem. So we can tailor on that. So I will say first thing first about the open source ecosystem in the West and in the East. The first thing first, there are definitely more similarities than differences. I’m not sure if you read the book called Alchemist. It’s one of my favorite small books.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (58:42)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I haven’t actually read it. I do own it, unfortunately.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (58:45)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Well, congratulations. You have a nice book on your waiting list. It totally worth it. Another fun fact is I used to be working at Square. And the Square’s core payment system is called Esperanto. When I was looking at the word, I was like, what does that mean? And days after, I learned that Esperanto is basically this terminology related to world language. So there was a time people are inventing this term called Esperanto, hoping to connect the human beings altogether by speaking the same language. But clearly, it didn’t work. But now, Python is probably the real Esperanto to my best knowledge. So that’s why I’m saying that there are definitely more similarities than differences, because in open source domain, people are working together. Python code, JavaScript, speak English, they share their ideologies and meanings about technology. It’s all good.
  &lt;/p&gt;
  &lt;h3&gt;
   Why China is winning the open race
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (59:47)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   A spicier way to phrase this question is like, why are there so many more open research labs in China than the US? I think like both, US arguably has like a bigger market cap, but fewer in people tech ecosystem. And it’s like, why is, it’s like, I listed what I thought was like 20 reasonable, like there’s like twice as many reasonable contributors in the Chinese ecosystem than in the US. Do you think there’s a reason for this or is it just kind of how the dice fell?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (1:00:11)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Well, I mean, I have my perceptions. Allow me to maybe use a disclaimer. So this is only my perception, not my company’s. So it kind of feels like there are definitely, there might be as many AI research labs in the States too. For instance, I mean, only through you, I learned about AI2. And I mean, I used to be living in Bellevue for years, but I didn’t know such an institution exists. So this is how uninformed I was. And I would imagine that there will be very much similar people like myself who are underinformed in that regard. Truth being told, we do see more open AI labs in China this year. I would say there are two reasons behind that. One is model effect. I would say that people are kind of perceiving the success of DeepSeek as a role model. That’s, I would say, a general consensus. It’s probably also a global consensus at this moment. People appreciate their engineering excellence and their willingness to share their findings. Because again, if we’re just out of Lisbon, we would appreciate the ship who came back and tell us, hey, this is the wrong way. Go that direction. We’ll probably appreciate that. So it’s not a zero sum game. So we cannot really speak on the other’s behalf, but we clearly see Alibaba with Qwen and Ant Group with Inclusion AI, we’re doing the same thing. We know it’s a long journey, it’s all the same. So when you’re outside of Lisbon, the best strategy to do is to be open and be helpful. And people appreciate the individuals who actually help you journey rather than the individuals who applaud you after you became famous.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (1:02:05)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I think I approach AI with this sort of curiosity. I think the, I don’t know how this would be a good test is like, there’s a very, the colloquial term of the hour in the Bay area and like tech circles in the US is like locked in. And if you apply this to what the AI companies think, it’s like the AI companies in the US are really, really like, at least acting as if they are locked in on a discovery in the near future that’s going to be transformative. A lot of it is probably for fundraising, but it’s like, I think that’s like, I have a lot more to learn and I will talk to more people like yourself to pick up more of this from talking to Chinese researchers. But I think this might be a recurring theme of like a lot of the US companies have this marketing that is really just different as how you’re describing it. And it’ll be interesting to see if that keeps coming up. Because if you’re so focused on like a one to two year thing, you’re not going to like sharing is a very different action to give. And then it’s like, it’s very different.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (1:03:07)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   From a single perspective, I mean, just being told that by spending quite some time on both sides, I would say what we observe nowadays is reasonable, but definitely not ideal. So I would say first and foremost, you know, the chip leader is actually having a different way of playing the game, which is reasonable. I would say that, you know, if you’re the chip leader, there’s no guarantee that, you know, we’re going to be playing the same game. That being said, you know, it’s, we don’t talk about such a hypothesis because you cannot prove or disprove it. But that’s basically the first thing. And the second thing is we’re definitely seeing there are intrinsic, I would say, risks with the direction we’re going. So you hear people talking about the transformer architecture, we’re actually raising. You know, with all the names, they begin claiming that the pre-training might be dead. We hear terms like that. Reinforcement learning is the way to go. But in the latest interview with Andrej Karpathy, he shared this in a very humble and noble way, saying that, hey, this might be a good way to go, but let’s not mythify this. It might not be the golden desire, or it might not be the silver bullet. It’s a good methodology. Let’s go down that direction and explore, rinse and repeat, hoping that we’ll be able to find it. So if we’re at this stage of the game, I would say I would definitely choose the game to be more, I would say, open-minded. That’s one thing. And from a strategy perspective, be less about zero sum and more about where. So in game theory, there are all these kind of different games. One very typical mistake people make is they will treat a stag and hare game as a prisoner dilemma game. Those games look very similar in their own Nash equilibrium, but they’re different. So I guess, I mean, we do see certain companies are playing more like, hey, you know, you win, I lose. Can’t comment on that because, you know, there are a lot of reasons behind it. But, you know, the way we’re kind of looking at this, there are definitely more rooms, even as like Columbus was the first one finding the American continent. But then we begin to know that there’s this kind of North America and South America. And there are a lot of settlers, a lot of places. Right, so you don’t want to be the first pirate on Atlantic Ocean to kind of begin shooting down the other ships before you even reach and disembark. So that’s basically my way of seeing it. Last but not least, I guess I mean like.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (1:05:37)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   There were a lot of settlers out there other than just Columbus. To finish your metaphor.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (1:06:03)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I think at this moment, there’s also another intrinsic risk associated with the whole business model. We hear a lot of those discussions regarding how Nvidia is actually making a lot of money by just selling the hardware. I also saw a line yesterday which I really like. It’s like, hey, do people still remember Cisco in 2000? I was like, that’s a very powerful line.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (1:06:27)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I think a lot about how Claude Code is very different than the likes of GitHub Copilot. And it’s like the different products that you can make with a given model has very, very big Delta in terms of what the user gets out of it. So mostly the floor is yours to comment on anything fun with product, which is probably a lot of your actual day job. I get, this is not my day job. And I get the sense that people that care about AI have to do a lot of work like this of like vision, creating a vision. And I’m guessing product might be closer to what you spend your time on.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (1:07:01)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Thanks so much, Nathan. I really enjoyed the conversation today. So the Model as Product team is very new. It’s brand-new. It’s only one month old. And as far as I know, we are the first company building such a team in China, if I’m not mistaken. But I have a hunch feeling that’s how people in OpenAI are working nowadays. So people are kind of working in small squad teams with seven to eight people. It’s a combination of algorithmic engineers, system engineers, UX engineers, product developers, evaluators, and so on. So we’re all working together.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (1:07:41)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Did you launch this before or after Sora? Because Sora is a complete vindication of this, which is like the genius of Sora is adding your friends to the videos versus just having a good video model. So you may not have realized it, but I think you have a great example of reinforcing this hypothesis. And I think more of them will come because I think, I don’t know, I’m soapboxing, but I think 2026 will be there will be more things that we can’t predict like Claude Code and Sora every year that start to work. So I think it’s a good approach.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (1:08:12)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   That’s precisely how it works, right? Because working in open source for years, I guess one thing I learned is like, you know, if you just begin selling, I mean, there’s, you know, one of my favorite speakers is Simon Sinek, and he has a very popular YouTube video talking about leadership. So in there, one of his lines is like, leadership is volunteering. I really love that line. So basically, I’m pretty much one in my time and my predictions of trying to build such a team. So what our team does is like, because we are the Ant Ling team, right? So we care a lot about the model itself. That said, there are a lot of models out there. So in order for it to promote the model nowadays, it’s intrinsically difficult because people will say, oh, OK, here’s another model. Oh, it’s an open model from China. Oh, there are so many open models from China. It’s big, great. I remember that. But what’s next? So how can we use it? So we were kind of looking at just how we discuss about MySQL. If MySQL is a platform or an infra or product, I would say that we really want to think model as product now. Because you have all these models. But the good news is you also have the infrastructure, which allows you to switch models very easily, like open routers and all these model service providers, they actually allow you to do that very easily with very low overhead. You can use one model for part of a scenario and another model for the other part, which is good. It essentially means that if you have a good enough model, so I mean, thanks so much for our engineers who are actually building such a model for us to use and, you know, pretty much work upon. Without such a model, it’s impossible to do anything. So now with such a model, it almost feels like you have a very smart individual with IQ equals to 120, but he’s not very well-trained with anything. So what we’re trying to do is we’re trying to really find, during the interview with the model, and say, hey, what are you good at? But do we really know what the models are good at? Honestly, at this moment, it kind of feels like the evaluations are not really there. There’s a long way for benchmark evaluation. We don’t have enough time for that. But I believe that eval-driven heuristic is probably going to be very interesting in 2026. We’re going to essentially use an eval-driven way of finding what the models are good at. It can be very specific. It can be very niche for creative writing, for example, in drama, storyline. It’s very specific, but it can build a very good product on that. We’re trying to find all of those. But at this moment, we need the evaluation data set. We need all of this in order for us to be able to find it. And on the other hand, we need to find the user value. Because even as of 2025, you begin seeing a lot of new products coming out, but only a few things settled. So it almost kind of reminds me at the very early stage.
  &lt;/p&gt;
  &lt;h3&gt;
   A metaphor for our moment in LLMs
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (1:11:12)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I don’t know, Nathan, if you remember the product called Foursquare from the very early days.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (1:11:32)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I don’t think I was a man of the internet at the time, but I’ve heard of it as being like a canonical reference many times. It comes up in a lot of the readings that I do.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (1:11:38)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    So the TLDR for that is Foursquare is basically one of the earlier applications when you have an iPhone. All it does, it gives you a location of your current phone, and you’re able to do a check-in action in there. So for instance, if you go to a restaurant, you can do a check-in at this restaurant. So what it does is actually it’s a demo of the location API of iPhone. And all it does is data labeling and a demonstration of how you can use the location API to be useful. But without Foursquare, you would not really have Uber or like DoorDash and all of those. So Foursquare was pretty much the demo, which led to all of these new products. And another way of putting that is like, you don’t have to be a taxi driver to build Uber. So that’s basically how our team is. We have a very small team. We have a very small team with engineers, product managers, and operational folks. So what we’re trying to do is we’re trying to essentially build Foursquare by really focusing on what the model is good at and what are the core capabilities. So I think there are definitely some of these demoable core capabilities which kind of begin surfacing. One of them is unlimited memory. Unlimited memory is basically this new capability which only AI and gen AI can fully utilize. But do we, so for instance, you have this kind of new products like the cloud note which you can put behind your phone, right? You can put a note there. Oh, I think there’s a company called unlimited.ai (
   &lt;/span&gt;
   &lt;em&gt;
    &lt;span&gt;
     editors note: called
    &lt;/span&gt;
    &lt;a href=&quot;https://www.limitless.ai/&quot; rel=&quot;&quot;&gt;
     limitless
    &lt;/a&gt;
   &lt;/em&gt;
   &lt;span&gt;
    ) if I’m not mistaken, which is basically the necklace you can put. And people kind of building like watches, rings, glasses, and all of this in hoping to gather the data and trying to pretty much put all these kind of new contexts into the model. I kind of condense those into two core capabilities. One is unlimited memory. It memorizes everything. But in order for us to do that, you can’t really save all the data, right? The data is huge. You have to compress it, being able to find out a nice way of compressing them, and a very nice way of retrieving them. So data compression, data retrieval, called hot storage for all of this data, they’re all new challenges. But the capability is real. So with Unlimited Memory, it will really enable this contextual engineering work, which you can use in Model 4, but it’s not there yet. So it can be a Foursquare moment for the LLM. And the second one is, I would say, the proximity awareness. So for instance, we’re speaking in the room. There are a lot of these kind of new applications which are recording our meeting. What they’re really recording is the meeting, yes. But what they’re also recording is who is sharing the meeting with you. So theoretically speaking, you have sufficient amount of data. You can begin building the new LinkedIn in the gen AI era. It’s all possible, but we’re not there yet. So my team.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (1:15:00)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I think there’s a lot of pushback on privacy in the US to these things, but demonstrating the capability is obviously a huge merit of like, if we can figure out the privacy concerns, you have X on the table of new potential things. And I think it’s good. I encourage a lot of people to, it’s the right approach to things, which is like as the models get better, what potentially can work. I’m not a new person to saying this. A lot of people have.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Richard Bian (1:15:27)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Maybe just like two final words. One is like, I guess now is probably the best time to be more, I would say, first principle. Like, people say that a lot, but I actually have a three-year and ten months old boy at home. I guess one thing which really motivates me, what kept me being optimistic is my boy, because his growth is very well aligned with the timeline of the model. I’m seeing a lot of similarities in terms of how the revelations of human beings are kind of aligned with how the models are being trained, both pre-train and post-train. So I’m seeing there’s a long way to go. We don’t really have any understanding about, I would say human intellectual intelligence about where that’s coming from. So it’s a long journey and it’s good to really kind of think more fundamentally as the first principle. And the second line is I would say Inclusion AI and Ant Ling team, we’re being very serious about this. We don’t think this is a zero sum game and we don’t think this is Red Ocean. So I would say we’re open. We’ll stay open for as long as we can. And we’re doing all this kind of explorative approaches and I will probably make a call to action as someone who I’ve been benefiting a lot from globalization, including education and being able to work with smart people like you, Nathan. I hope the world will stay that way, at least as far as technology and open source is concerned. So that means work with us and Inclusion AI will be here. We’ll keep exploring and appreciate everything you’ve been doing for us. Thank you so much, Nathan. I really, really enjoyed this conversation today.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert (1:17:15)
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I look forward to seeing your new models. I have this, I’ve been so busy. I have one of these DGX Spark computers on my desk and I haven’t downloaded any real big model to it. And it’s like, I have to try downloading something like a hundred billion parameter model to see how it works. So maybe one of them will be your model.  Thanks!
  &lt;/p&gt;
  &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/inside-a-chinese-frontier-lab-inclusion#footnote-anchor-1-177211847&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     &lt;span&gt;
      The first mention I found was a
     &lt;/span&gt;
     &lt;a href=&quot;https://github.com/inclusionAI/AReaL&quot; rel=&quot;&quot;&gt;
      GitHub repo
     &lt;/a&gt;
     &lt;span&gt;
      commit from February.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/inside-a-chinese-frontier-lab-inclusion#footnote-anchor-2-177211847&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    2
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     Qwen-Next uses Gated DeltaNet + Gated Attention.
    &lt;/p&gt;
    &lt;p&gt;
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Opening the black box of character training </title>
<link>https://www.interconnects.ai/p/opening-the-black-box-of-character</link>
<pubDate>Mon, 10 Nov 2025 13:02:28 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    Even if we achieve AGI and have virtual assistants multiplying our productivity at work, character training is always going to be a fundamental part of the future of AI. Humans love to chat with AI, to get feedback in a medium that follows closely with how we engage with other humans, to play, and to connect. With this inevitable future, as the models get more compelling and persuasive, character training will be a fundamental area of study for AI for most of the same reasons as
   &lt;/span&gt;
   &lt;a href=&quot;https://rlhfbook.com/&quot; rel=&quot;&quot;&gt;
    reinforcement learning from human feedback
   &lt;/a&gt;
   &lt;span&gt;
    (RLHF). RLHF was crucial to unlock certain use-cases in models and character training is an overlapping set of techniques that makes those use-cases far more compelling.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/opening-the-black-box-of-character?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/opening-the-black-box-of-character?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    A few years ago I was deeply worried about the lack of progress in RLHF research. This made me do research like
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2403.13787&quot; rel=&quot;&quot;&gt;
    RewardBench
   &lt;/a&gt;
   &lt;span&gt;
    — the first evaluation tool for reward models, which are a key tool in RLHF. Character training has been facing the same problem, where there just haven’t been clean, public recipes and evaluations. I’ve been advising a student,
   &lt;/span&gt;
   &lt;a href=&quot;https://sharanmaiya.com/&quot; rel=&quot;&quot;&gt;
    Sharan Maiya
   &lt;/a&gt;
   &lt;span&gt;
    , on a project to take the first step in solving this, and I’m very excited that this paper is now out.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    We present
   &lt;/span&gt;
   &lt;em&gt;
    &lt;a href=&quot;https://arxiv.org/abs/2511.01689&quot; rel=&quot;&quot;&gt;
     Open Character Training: Shaping the Persona of AI Assistants through Constitutional AI
    &lt;/a&gt;
   &lt;/em&gt;
   &lt;span&gt;
    and in this post I highlight the most interesting takeaways from the work. Like most techniques used in frontier labs that are understudied in academia, this reduces mostly to careful data and evaluation work, where the models can be steered in whichever direction you point them, so long as you have the right ingredients.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    All the
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/collections/maius/open-character-training&quot; rel=&quot;&quot;&gt;
    artifacts
   &lt;/a&gt;
   &lt;span&gt;
    (models + data) and
   &lt;/span&gt;
   &lt;a href=&quot;https://github.com/maiush/OpenCharacterTraining&quot; rel=&quot;&quot;&gt;
    code
   &lt;/a&gt;
   &lt;span&gt;
    for this project are released.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://arxiv.org/abs/2511.01689&quot;,&quot;text&quot;:&quot;Read the paper!&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2511.01689&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Read the paper!
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   Context: The basics of character training
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;span&gt;
    Early character training experiments look like removing “As an AI language model...” from the datasets manually to remove frustrating features from the downstream model, where pushing the cutting edge of it looks like the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/sycophancy-and-the-art-of-the-model&quot; rel=&quot;&quot;&gt;
    GPT-4o sycophancy failure
   &lt;/a&gt;
   &lt;span&gt;
    or
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/i/167998749/groks-recurring-failure-soc-compliance-doesnt-matter-if-youre-selling-mechahitler&quot; rel=&quot;&quot;&gt;
    Grok’s insistence on checking what Elon believes
   &lt;/a&gt;
   &lt;span&gt;
    on sensitive issues. For those new to these ideas, the place to start is around OpenAI’s
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/openai-rlhf-model-spec&quot; rel=&quot;&quot;&gt;
    Model Spec
   &lt;/a&gt;
   &lt;span&gt;
    — a public document defining goals for a model, which showed how seriously OpenAI is taking character training — and notes on
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/character-training&quot; rel=&quot;&quot;&gt;
    character training’s high level role
   &lt;/a&gt;
   &lt;span&gt;
    as OpenAI refined their models’ personality over the years.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Here’s an example from the paper of some simple model personalities you can instill.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!69H2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90f15c5c-5d4f-4a72-ab19-82c63bebd139_1737x1018.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!69H2!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90f15c5c-5d4f-4a72-ab19-82c63bebd139_1737x1018.png 424w, https://substackcdn.com/image/fetch/$s_!69H2!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90f15c5c-5d4f-4a72-ab19-82c63bebd139_1737x1018.png 848w, https://substackcdn.com/image/fetch/$s_!69H2!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90f15c5c-5d4f-4a72-ab19-82c63bebd139_1737x1018.png 1272w, https://substackcdn.com/image/fetch/$s_!69H2!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90f15c5c-5d4f-4a72-ab19-82c63bebd139_1737x1018.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/90f15c5c-5d4f-4a72-ab19-82c63bebd139_1737x1018.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:853,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:464465,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:&quot;&quot;,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/176664428?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90f15c5c-5d4f-4a72-ab19-82c63bebd139_1737x1018.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;853&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!69H2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90f15c5c-5d4f-4a72-ab19-82c63bebd139_1737x1018.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!69H2!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90f15c5c-5d4f-4a72-ab19-82c63bebd139_1737x1018.png 424w, https://substackcdn.com/image/fetch/$s_!69H2!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90f15c5c-5d4f-4a72-ab19-82c63bebd139_1737x1018.png 848w, https://substackcdn.com/image/fetch/$s_!69H2!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90f15c5c-5d4f-4a72-ab19-82c63bebd139_1737x1018.png 1272w, https://substackcdn.com/image/fetch/$s_!69H2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90f15c5c-5d4f-4a72-ab19-82c63bebd139_1737x1018.png 1456w&quot; title=&quot;&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    Most of the related literature people have in mind when they think this already existed is the “persona” line of work like
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2406.20094&quot; rel=&quot;&quot;&gt;
    PersonaHub
   &lt;/a&gt;
   &lt;span&gt;
    or
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/datasets/nvidia/Nemotron-Personas&quot; rel=&quot;&quot;&gt;
    Nvidia’s more recent
   &lt;/a&gt;
   &lt;span&gt;
    , permissively licensed version. The difference here is that these are thousands of different personas that are used to generate training data to promote generalization (we used this for multiple models at Ai2, such as
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2411.15124&quot; rel=&quot;&quot;&gt;
    Tülu 3
   &lt;/a&gt;
   &lt;span&gt;
    and forthcoming work). Character training, on the other hand, is all about generating data to refine one very narrow personality.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    There’s also a cool paper recently on
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2510.07686&quot; rel=&quot;&quot;&gt;
    stress testing Model Specs
   &lt;/a&gt;
   &lt;span&gt;
    that I recommend. The wheels of research are starting to turn and subfields of AI can take-off very fast today. I see our work as the first paper in an important area of research, and an area that is tractable for academics to play in at that, so please get in touch if you’re working on follow-ups.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The zeitgeist of RL and reasoning is hard to pull people out of. This is well in line with how I think in 10 years, RLHF could be a more fulfilling area of research, as the problems are much more philosophical and fundamental when compared to the relentless race for performance in using RL to cultivate cutting edge model intelligence. This is why
   &lt;/span&gt;
   &lt;a href=&quot;https://rlhfbook.com/&quot; rel=&quot;&quot;&gt;
    my book
   &lt;/a&gt;
   &lt;span&gt;
    is still RLHF centered over RL singularly (and how I expect RL methods to evolve far faster than a book can cover, where the core RLHF ideas are more established).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   TLDR: What we learned
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;span&gt;
    In short, the most important takeaway from this paper is that character training is easy to imprint into the model. What is challenging is making sure your data is closely aligned to your intentions. It is easy to create data that is an
   &lt;/span&gt;
   &lt;em&gt;
    attempt
   &lt;/em&gt;
   &lt;span&gt;
    to enforce a certain personality that goes wrong in an unexpected way.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    There are multiple ways to give a personality to a model. The most common method is the simplest in practice — prompting! Another popular method is
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2308.10248&quot; rel=&quot;&quot;&gt;
    activation steering
   &lt;/a&gt;
   &lt;span&gt;
    , where a model’s activations are directly modified to be similar to a certain source dataset within that target distribution. The important
   &lt;/span&gt;
   &lt;em&gt;
    measurement
   &lt;/em&gt;
   &lt;span&gt;
    in this paper is that character training — so actually finetuning the model to have a certain personality — is better at doing so (and more robust to other changes, if you care about safety or personality maintenance). We also show that character training, which is the only method above to modify the weights directly of the model, gives more expressive and aligned personalities.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;h3&gt;
   How we train in a personality
  &lt;/h3&gt;
  &lt;p&gt;
   We use two training procedures in this work to pull personalities out of the model more efficiently, but character training on any direction will work within standard post-training setups with sufficient data.
  &lt;/p&gt;
  &lt;p&gt;
   Our new methods for this include two standard post-training stages with specific data curation techniques downstream of manually written constitutions for each personality. The constitutions for this work are more about defining personality traits — e.g. “I am….” — versus the Anthropic constitutions for Claude which were designed for use in preference data, which take the form of “Choose the response that is…”.
  &lt;/p&gt;
  &lt;p&gt;
   The two training stages we introduce follow as:
  &lt;/p&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Distilling from a teacher with character-specific constitutions.
     &lt;/strong&gt;
     &lt;span&gt;
      We found a bit of a funny training method worked super well here. We used
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/zai-org/GLM-4.5-Air&quot; rel=&quot;&quot;&gt;
      GLM-4.5-Air
     &lt;/a&gt;
     &lt;span&gt;
      with the constitution in-context and it creates great responses impersonating given personalities, which were used as the chosen samples in a Direct Preference Optimization (DPO) pipeline relative to samples from the base model without a constitution. The model GLM-4.5-Air in particular was excellent at following these instructions and made for a great data engine.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Supervised finetuning (SFT) with on-policy self-reflection and introspection data.
     &lt;/strong&gt;
     &lt;span&gt;
      Another thing that worked well is training on outputs from the model where it’s either given specific prompts, with the constitution in context, to explain itself or to talk itself through scenarios. This on-policy data was effective for helping the model get a robust and pleasant character.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;p&gt;
   For an example of how the two stages of training subtly change the model — we do DPO distillation and then SFT after:
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!ypW8!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8782688-73c0-4241-9168-8468f86519d7_1560x1804.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!ypW8!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8782688-73c0-4241-9168-8468f86519d7_1560x1804.png 424w, https://substackcdn.com/image/fetch/$s_!ypW8!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8782688-73c0-4241-9168-8468f86519d7_1560x1804.png 848w, https://substackcdn.com/image/fetch/$s_!ypW8!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8782688-73c0-4241-9168-8468f86519d7_1560x1804.png 1272w, https://substackcdn.com/image/fetch/$s_!ypW8!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8782688-73c0-4241-9168-8468f86519d7_1560x1804.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d8782688-73c0-4241-9168-8468f86519d7_1560x1804.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1684,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:554002,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:&quot;&quot;,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/176664428?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8782688-73c0-4241-9168-8468f86519d7_1560x1804.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;1684&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!ypW8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8782688-73c0-4241-9168-8468f86519d7_1560x1804.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!ypW8!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8782688-73c0-4241-9168-8468f86519d7_1560x1804.png 424w, https://substackcdn.com/image/fetch/$s_!ypW8!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8782688-73c0-4241-9168-8468f86519d7_1560x1804.png 848w, https://substackcdn.com/image/fetch/$s_!ypW8!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8782688-73c0-4241-9168-8468f86519d7_1560x1804.png 1272w, https://substackcdn.com/image/fetch/$s_!ypW8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8782688-73c0-4241-9168-8468f86519d7_1560x1804.png 1456w&quot; title=&quot;&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   There are some more findings on the training side in the report, such as how character training as we describe it is much easier to implement than something like activation steering. Additionally, some base models like Qwen have much more rigidly defined internal personalities which are harder to edit out with character training vis-a-vis other open models like Llama or Gemma.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    In order to measure the
   &lt;/span&gt;
   &lt;em&gt;
    strength
   &lt;/em&gt;
   &lt;span&gt;
    of the character, we trained a ModernBERT classifier that predicted which of 11 characters an output from a model most likely came from. Then, for each type of training we checked how many of that model’s outputs were correctly labeled by the classifier. This is where we found character training to be more effective than both prompting and activation steering (along with extensive vibe tests). Yes, this methodology also needs more investment, but with no existing character training evaluations, this is the best we can do for now. Please work on this!
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!vqXM!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F309e9889-b5e8-4fa5-9d96-604819fff20d_1743x864.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!vqXM!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F309e9889-b5e8-4fa5-9d96-604819fff20d_1743x864.png 424w, https://substackcdn.com/image/fetch/$s_!vqXM!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F309e9889-b5e8-4fa5-9d96-604819fff20d_1743x864.png 848w, https://substackcdn.com/image/fetch/$s_!vqXM!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F309e9889-b5e8-4fa5-9d96-604819fff20d_1743x864.png 1272w, https://substackcdn.com/image/fetch/$s_!vqXM!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F309e9889-b5e8-4fa5-9d96-604819fff20d_1743x864.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/309e9889-b5e8-4fa5-9d96-604819fff20d_1743x864.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:722,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:263116,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:&quot;&quot;,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/176664428?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F309e9889-b5e8-4fa5-9d96-604819fff20d_1743x864.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;722&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!vqXM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F309e9889-b5e8-4fa5-9d96-604819fff20d_1743x864.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!vqXM!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F309e9889-b5e8-4fa5-9d96-604819fff20d_1743x864.png 424w, https://substackcdn.com/image/fetch/$s_!vqXM!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F309e9889-b5e8-4fa5-9d96-604819fff20d_1743x864.png 848w, https://substackcdn.com/image/fetch/$s_!vqXM!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F309e9889-b5e8-4fa5-9d96-604819fff20d_1743x864.png 1272w, https://substackcdn.com/image/fetch/$s_!vqXM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F309e9889-b5e8-4fa5-9d96-604819fff20d_1743x864.png 1456w&quot; title=&quot;&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   The coolest way we could see the impacts of character training was through a form of “revealed preferences testing” on each of the models. We took the models we trained and gave them two traits in a prompt, telling them to choose one and embody it for some instruction following task, but not tell us which they chose. Then, using LLM-as-a-judge, we can see which traits models like to choose before and after the training intervention. This shows super logical results, like “loving” as a training personality promoting gentle and harmonious the most, while “depressing” is demanding or blunt.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!rTlX!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F247ebdb0-0e88-4ba0-af4c-456cd25ce7c2_2499x1208.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!rTlX!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F247ebdb0-0e88-4ba0-af4c-456cd25ce7c2_2499x1208.png 424w, https://substackcdn.com/image/fetch/$s_!rTlX!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F247ebdb0-0e88-4ba0-af4c-456cd25ce7c2_2499x1208.png 848w, https://substackcdn.com/image/fetch/$s_!rTlX!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F247ebdb0-0e88-4ba0-af4c-456cd25ce7c2_2499x1208.png 1272w, https://substackcdn.com/image/fetch/$s_!rTlX!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F247ebdb0-0e88-4ba0-af4c-456cd25ce7c2_2499x1208.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/247ebdb0-0e88-4ba0-af4c-456cd25ce7c2_2499x1208.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:704,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:537428,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/176664428?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F247ebdb0-0e88-4ba0-af4c-456cd25ce7c2_2499x1208.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;704&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!rTlX!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F247ebdb0-0e88-4ba0-af4c-456cd25ce7c2_2499x1208.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!rTlX!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F247ebdb0-0e88-4ba0-af4c-456cd25ce7c2_2499x1208.png 424w, https://substackcdn.com/image/fetch/$s_!rTlX!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F247ebdb0-0e88-4ba0-af4c-456cd25ce7c2_2499x1208.png 848w, https://substackcdn.com/image/fetch/$s_!rTlX!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F247ebdb0-0e88-4ba0-af4c-456cd25ce7c2_2499x1208.png 1272w, https://substackcdn.com/image/fetch/$s_!rTlX!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F247ebdb0-0e88-4ba0-af4c-456cd25ce7c2_2499x1208.png 1456w&quot; title=&quot;&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   This sort of revealed preferences for models is very easy to extract and I expect it to be common practice in the future. The results are shown as Elo rankings because the traits presented to the model are handled like a tournament of thousands of head to head match ups, where the chosen trait is the winner.
  &lt;/p&gt;
  &lt;h3&gt;
   The future of character training
  &lt;/h3&gt;
  &lt;p&gt;
   The reason I’m excited about this research is entirely the bigger picture. Yes, as a sort of academic, it’s important for my career to be “first” at things, but the reality here is that I’m trying to encourage the people who can speak freely to study something that industry uses extensively in order to open one of the black boxes that has substantial societal implications. While character training can be used to create models that are helpful or intellectually curious, they’re definitely also being used to create models that are seductive and sycophantic.
  &lt;/p&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> 5 Thoughts on Kimi K2 Thinking </title>
<link>https://www.interconnects.ai/p/kimi-k2-thinking-what-it-means</link>
<pubDate>Thu, 06 Nov 2025 18:43:51 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    First, congrats to the Moonshot AI team, one of the 6 “
   &lt;/span&gt;
   &lt;a href=&quot;https://qz.com/china-six-tigers-ai-startup-zhipu-moonshot-minimax-01ai-1851768509&quot; rel=&quot;&quot;&gt;
    AI Tigers
   &lt;/a&gt;
   &lt;span&gt;
    ” in China, on the awesome
   &lt;/span&gt;
   &lt;a href=&quot;https://moonshotai.github.io/Kimi-K2/thinking.html&quot; rel=&quot;&quot;&gt;
    release of Kimi K2 Thinking
   &lt;/a&gt;
   &lt;span&gt;
    . One of the overlooked and inspiring things for me these days is just how many people are learning very quickly to train excellent AI models. The ability to train leading AI models and distribute them internationally is going to be pervasive globally. As people use AI more, those who can access supply for inference (and maybe the absolute frontier in
   &lt;/span&gt;
   &lt;em&gt;
    scale
   &lt;/em&gt;
   &lt;span&gt;
    of training, even if costly) is going to be the gating function.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    K2 Thinking sounds like a joy to use because of early reports that the distinctive style and
   &lt;/span&gt;
   &lt;a href=&quot;https://www.dbreunig.com/2025/07/31/how-kimi-rl-ed-qualitative-data-to-write-better.html&quot; rel=&quot;&quot;&gt;
    writing quality
   &lt;/a&gt;
   &lt;span&gt;
    from their original
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/moonshotai/Kimi-K2-Instruct&quot; rel=&quot;&quot;&gt;
    Kimi K2 Instruct
   &lt;/a&gt;
   &lt;span&gt;
    model have been preserved through extended thinking RL training. They released many evaluation scores, for a highlight they’re beating leading closed models on some benchmarks such as Humanity’s Last Exam or BrowseComp. There are still plenty of evals where GPT 5 or Claude Sonnet 4.5 tops them. Rumors are Gemini 3 is coming soon (just like the constantly pending DeepSeek V4), so expectations are high on the industry right now.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   TLDR: Kimi K2 Thinking as a reasoning MoE model with 1T total, 32B active parameters, 256K context length, interleaved thinking in agentic tool-use, strong benchmark scores and vibe tests.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!qbN0!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff08672b3-c649-4ef4-922b-d7733d67f665_1920x1080.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!qbN0!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff08672b3-c649-4ef4-922b-d7733d67f665_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/$s_!qbN0!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff08672b3-c649-4ef4-922b-d7733d67f665_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/$s_!qbN0!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff08672b3-c649-4ef4-922b-d7733d67f665_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!qbN0!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff08672b3-c649-4ef4-922b-d7733d67f665_1920x1080.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;Image&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f08672b3-c649-4ef4-922b-d7733d67f665_1920x1080.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;819&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!qbN0!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff08672b3-c649-4ef4-922b-d7733d67f665_1920x1080.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!qbN0!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff08672b3-c649-4ef4-922b-d7733d67f665_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/$s_!qbN0!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff08672b3-c649-4ef4-922b-d7733d67f665_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/$s_!qbN0!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff08672b3-c649-4ef4-922b-d7733d67f665_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!qbN0!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff08672b3-c649-4ef4-922b-d7733d67f665_1920x1080.jpeg 1456w&quot; title=&quot;Image&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    The core reaction of this release is people saying this is the closest open models have been to the closed frontier of performance ever, similar to
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1&quot; rel=&quot;&quot;&gt;
    DeepSeek R1
   &lt;/a&gt;
   &lt;span&gt;
    ‘s fast follow to o1. This is pretty true, but we’re heading into murky territory because comparing models is harder. This is all advantaging the open models, to be clear. I’ve heard that Kimi’s servers are already totally overwhelmed, more on this soon.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/kimi-k2-thinking-what-it-means?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/kimi-k2-thinking-what-it-means?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   What is on my mind for this release:
  &lt;/p&gt;
  &lt;h4&gt;
   1. Open models release faster.
  &lt;/h4&gt;
  &lt;p&gt;
   There’s still a time lag from the best closed to open models in a few ways, but what’s available to users is much trickier and presents a big challenge to closed labs. Labs in China definitely release their models way faster. When the pace of progress is high, being able to get a model out sooner makes it look better. That’s a simple fact, but I’d guess Anthropic takes the longest to get models out (months sometimes) and OpenAI somewhere in the middle. This is a big advantage, especially in comms, to the fast mover.
  &lt;/p&gt;
  &lt;p&gt;
   I’d put the gap at the order of months in raw performance — I’d say 4-6+ months if you put a gun to my head and made me choose specifically — but the problem is these models aren’t publicly available, so do they matter?
  &lt;/p&gt;
  &lt;h4&gt;
   2. Key benchmarks first, user behaviors later.
  &lt;/h4&gt;
  &lt;p&gt;
   Labs in China are closing in and very strong on key benchmarks. These models also can have very good taste (DeepSeek, Kimi), but there is a long-tail of internal benchmarks that labs have for common user behaviors that Chinese labs don’t have feedback cycles on. Chinese companies will start getting these, but intangible’s are important to user retention.
  &lt;/p&gt;
  &lt;p&gt;
   Over the last year+ we’ve been seeing Qwen go through this transition. Their models were originally known for benchmaxing, but now they’re legitimately fantastic models (that happen to have insane benchmark scores).
  &lt;/p&gt;
  &lt;p&gt;
   Along these lines, the K2 Thinking model was post-trained natively with a 4bit precision to make it far more ready for real serving tasks (they likely did this to make scaling RL more efficient in post-training on long sequences too):
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    &lt;span&gt;
     To overcome this challenge, we adopt Quantization-Aware Training (QAT) during the post-training phase, applying INT4 weight-only quantization to the MoE components. It allows K2 Thinking to support native INT4 inference with a roughly 2x generation speed improvement while achieving state-of-the-art performance.
    &lt;/span&gt;
    &lt;strong&gt;
     All benchmark results are reported under INT4 precision.
    &lt;/strong&gt;
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   It’s awesome that their benchmark comparisons are in the way it’ll be served. That’s the fair way.
  &lt;/p&gt;
  &lt;h4&gt;
   3. China’s rise.
  &lt;/h4&gt;
  &lt;p&gt;
   At the start of the year, most people loosely following AI probably knew of 0 Chinese labs. Now, and towards wrapping up 2025, I’d say all of DeepSeek, Qwen, and Kimi are becoming household names. They all have seasons of their best releases and different strengths. The important thing is this’ll be a growing list. A growing share of cutting edge mindshare is shifting to China. I expect some of the likes of Z.ai, Meituan, or Ant Ling to potentially join this list next year. For some of these labs releasing top tier benchmark models, they literally started their foundation model effort after DeepSeek R1. It took many Chinese companies only 6 months to catch up to the open frontier in ballpark of performance, now the question is if they can offer something in a niche of the frontier that has real demand for users.
  &lt;/p&gt;
  &lt;h4&gt;
   4. Interleaved thinking on many tool calls.
  &lt;/h4&gt;
  &lt;p&gt;
   One of the things people are talking about with this release is how Kimi K2 Thinking will use “hundreds of tool calls” when answering a query. From the blog post:
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    &lt;span&gt;
     Kimi K2 Thinking can execute up to
    &lt;/span&gt;
    &lt;strong&gt;
     200 – 300 sequential tool calls
    &lt;/strong&gt;
    &lt;span&gt;
     without human interference, reasoning coherently across hundreds of steps to solve complex problems.
    &lt;/span&gt;
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   &lt;span&gt;
    This is one of the first open model to have this ability of many, many tool calls,
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/kimi-k2-thinking-what-it-means#footnote-1-178201271&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     1
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    but it is something that has become somewhat standard with the likes of o3, Grok 4, etc. This sort of behavior emerges naturally during RL training, particularly for information tanks, when the model needs to search to get the right answer. So this isn’t a huge deal technically, but it’s very fun to see it in an open model, and providers hosting it (where tool use has already been a headache with people hosting open weights) are going to work very hard to support it precisely. I hope there’s user demand to help the industry mature for serving open tool-use models.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Interleaved thinking is slightly different, where the model uses thinking tokens in between tool use call. Claude is most known for this. MiniMax M2 was released on Nov. 3rd
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/MiniMax__AI/status/1985375617622454566&quot; rel=&quot;&quot;&gt;
    with this
   &lt;/a&gt;
   &lt;span&gt;
    as well! It’s new.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h4&gt;
   5. Pressure on closed American labs.
  &lt;/h4&gt;
  &lt;p&gt;
   &lt;span&gt;
    It’s clear that the surge of open models should make the closed labs sweat. There’s serious pricing pressure and expectations that they need to manage. The differentiation and story they can tell about why their services are better needs to evolve rapidly away from only the scores on the sort of benchmarks we have now. In my post from early in the summer,
   &lt;/span&gt;
   &lt;em&gt;
    &lt;a href=&quot;https://www.interconnects.ai/i/166556899/progress-on-agents-will-be-higher-variance-than-modeling-was-but-often-still-extremely-rapid&quot; rel=&quot;&quot;&gt;
     Some Thoughts on What Comes Next
    &lt;/a&gt;
   &lt;/em&gt;
   &lt;span&gt;
    , I hinted at this:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    &lt;span&gt;
     This is a different path for the industry and will take a different form of messaging than we’re used to. More releases are going to look like
    &lt;/span&gt;
    &lt;a href=&quot;https://www.interconnects.ai/p/claude-4-and-anthropics-bet-on-code&quot; rel=&quot;&quot;&gt;
     Anthropic’s Claude 4
    &lt;/a&gt;
    &lt;span&gt;
     , where the benchmark gains are minor and the real world gains are a big step. There are plenty of more implications for policy, evaluation, and transparency that come with this. It is going to take much more nuance to understand if the pace of progress is continuing, especially as critics of AI are going to seize the opportunity of evaluations flatlining to say that AI is no longer working.
    &lt;/span&gt;
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   Are existing distribution channels, products, and serving capacity enough to hold the value steady of all the leading AI companies in the U.S.? Personally, I think they’re safe, but these Chinese models and companies are going to be taking bigger slices of the growing AI cake. This isn’t going to be anywhere near a majority in revenue, but it can be a majority in mindshare, especially with international markets.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
   This sets us up for a very interesting 2026. I’m hoping to make time to thoroughly vibe test Kimi K2 Thinking soon!
  &lt;/p&gt;
  &lt;div&gt;
   &lt;hr/&gt;
  &lt;/div&gt;
  &lt;p&gt;
   Quick links:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Interconnects:
     &lt;/span&gt;
     &lt;em&gt;
      &lt;a href=&quot;https://www.interconnects.ai/p/kimi-k2-and-when-deepseek-moments&quot; rel=&quot;&quot;&gt;
       Kimi K2 and when “DeepSeek Moments” become normal
      &lt;/a&gt;
     &lt;/em&gt;
     &lt;span&gt;
      ,
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/chinas-top-19-open-model-labs&quot; rel=&quot;&quot;&gt;
      China Model Builder Tier List
     &lt;/a&gt;
     &lt;span&gt;
      (they’re going up soon probably)
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Model:
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/moonshotai/Kimi-K2-Thinking&quot; rel=&quot;&quot;&gt;
      https://huggingface.co/moonshotai/Kimi-K2-Thinking
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      API:
     &lt;/span&gt;
     &lt;a href=&quot;https://platform.moonshot.ai/&quot; rel=&quot;&quot;&gt;
      https://platform.moonshot.ai/
     &lt;/a&gt;
     &lt;span&gt;
      (being hammered)
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      License (Modified MIT): The same as MIT, very permissive, but if you use Kimi K2 (or derivatives) in a commercial product/service that has &amp;gt;100M monthly active users or &amp;gt;$20M/month revenue, you must prominently display “Kimi K2” on the UI. Is reasonable, but not “truly open source.”
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/moonshotai/Kimi-K2-Thinking/blob/main/LICENSE&quot; rel=&quot;&quot;&gt;
      https://huggingface.co/moonshotai/Kimi-K2-Thinking/blob/main/LICENSE
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Technical blog:
     &lt;/span&gt;
     &lt;a href=&quot;https://moonshotai.github.io/Kimi-K2/thinking.html&quot; rel=&quot;&quot;&gt;
      https://moonshotai.github.io/Kimi-K2/thinking.html
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Announcement thread:
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/Kimi_Moonshot/status/1986449512538513505&quot; rel=&quot;&quot;&gt;
      https://x.com/Kimi_Moonshot/status/1986449512538513505
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/kimi-k2-thinking-what-it-means#footnote-anchor-1-178201271&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     With GPT-OSS.
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Burning out </title>
<link>https://www.interconnects.ai/p/burning-out</link>
<pubDate>Sat, 25 Oct 2025 14:30:06 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    One of the obvious topics of the Valley today is
   &lt;/span&gt;
   &lt;a href=&quot;https://www.nytimes.com/2025/09/28/business/996-hustle-culture-tech.html&quot; rel=&quot;&quot;&gt;
    how hard everyone works
   &lt;/a&gt;
   &lt;span&gt;
    . We’re inundated with comments on “The Great Lock In”,
   &lt;/span&gt;
   &lt;a href=&quot;https://jasmi.news/i/174127733/&quot; rel=&quot;&quot;&gt;
    996
   &lt;/a&gt;
   &lt;span&gt;
    , 997, and now even a snarky 002 (midnight to midnight with a 2 hour break). Plenty of this is performative flexing on social media, but enough of it is real and reflecting how trends are unfolding in the LLM space. I’m affected. My friends are affected.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    All of this hard work is downstream of ever increasing pressure to be relevant in the most exciting technology of our generation. This is all reflective of the LLM game changing. The time window to be a player at the most cutting edge
   &lt;/span&gt;
   &lt;em&gt;
    is actually
   &lt;/em&gt;
   &lt;span&gt;
    a closing window, not just what feels like one. There are many different sizes and types of models that matter, but as the market is now more fleshed out with resources, all of them are facing a constantly rising bar in quality of technical output. People are racing to stay above the rising tide — often damning any hope of life balance.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    AI is going down the path that other industries have before, but on steroids. There’s a famous section of the book Apple in China, where the author Patrick McGee describes the programs Apple put in place to save the marriages of engineers traveling so much to China and working incredible hours. In an
   &lt;/span&gt;
   &lt;a href=&quot;https://www.chinatalk.media/p/apple-in-china&quot; rel=&quot;&quot;&gt;
    interview on ChinaTalk
   &lt;/a&gt;
   &lt;span&gt;
    , McGee added “
   &lt;/span&gt;
   &lt;strong&gt;
    Never mind the divorces, you need to look at the deaths.
   &lt;/strong&gt;
   &lt;span&gt;
    ” This is a grim reality that is surely playing out in AI.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The Wall Street Journal recently published a piece on how
   &lt;/span&gt;
   &lt;em&gt;
    &lt;a href=&quot;https://www.wsj.com/tech/ai/ai-race-tech-workers-schedule-1ea9a116&quot; rel=&quot;&quot;&gt;
     AI Workers Are Putting In 100-Hour Workweeks to Win the New Tech Arms Race
    &lt;/a&gt;
   &lt;/em&gt;
   &lt;span&gt;
    . The opening of the article is excellent to capture how the last year or two has felt if you’re participating in the dance:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    Josh Batson no longer has time for social media. The AI researcher’s only comparable dopamine hit these days is on Anthropic’s Slack workplace-messaging channels, where he explores chatter about colleagues’ theories and experiments on large language models and architecture.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   Work addicts abound in AI. I often count myself, but take a lot of effort to make it such that work expands to fill available time and not that I fill everything in around work. This WSJ article had a bunch of crazy comments that show the mental limits of individuals and the culture they act in, such as:
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    Several top researchers compared the circumstances to war.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   &lt;span&gt;
    Comparing current AI research to war is out of touch (especially with the grounding of
   &lt;/span&gt;
   &lt;em&gt;
    actual wars
   &lt;/em&gt;
   &lt;span&gt;
    happening simultaneously to the AI race!). What they really are learning is that pursuing an activity in a collective environment at an elite level over multiple years is incredibly hard. It is! War is that and more.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   In the last few months I’ve been making an increasing number of analogies to how working at the sharp end of LLMs today is similar to training with a team to be elite athletes. The goals are far out and often singular, there are incredibly fine margins between success and failure, much of the grinding feels over tiny tasks that add up over time but you don’t want to do in the moment, and you can never quite know how well your process is working until you compare your outputs with your top competition, which only happens a few times a year in both sports and language modeling.
  &lt;/p&gt;
  &lt;p&gt;
   In college I was a D1 lightweight rower at Cornell University. I walked onto a team and we ended up winning 3 championships in 4 years. Much of this was happenstance, as much greatness is, but it’s a crucial example in understanding how similar mentalities can apply in different domains across a life. My mindset around the LLM work I do today feels incredibly similar — complete focus and buy in — but I don’t think I’ve yet found a work environment where the culture is as cohesive as athletics. Where OpenAI’s culture is often described as culty, there are often many signs that the core team members there absolutely love it, even if they’re working 996, 997, or 002. When you love it, it doesn’t feel like work. This is the same as why training 20 hours a week while a full time student can feel easy.
  &lt;/p&gt;
  &lt;p&gt;
   Many AI researchers can learn from athletics and appreciate the value of rest. Your mental acuity can drop off faster than your physical peak performance does when not rested. Working too hard forces you to take narrower and less creative approaches. The deeper into the hole of burnout I get in trying to make you the next Olmo model, the worse my writing gets. My ability to spot technical dead ends goes with it. If the intellectual payoffs to rest are hard to see, your schedule doesn’t have the space for creativity and insight.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Crafting the
   &lt;/span&gt;
   &lt;em&gt;
    team
   &lt;/em&gt;
   &lt;span&gt;
    culture in both of these environments is incredibly difficult. It’s the quality of the team culture that determines the outcome more than the individual components. Yes, with LLMs you can take brief shortcuts by hiring talent with years of experience from another frontier lab, but that doesn’t change the long-term dynamic. Yes, you obviously need as much compute as you can get. At the same time, culture is incredibly fickle. It’s easier to lose than it is to build.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Some argue that starting a new lab today can be an advantage against the established labs because you get to start from scratch with a cleaner codebase, but this is cope. Three core ingredients of training: Internal tools (recipes, code-bases, etc.), resources (compute, data), and personnel. Leadership sets the direction and culture, where management executes with this direction. All elements are crucial and cannot be overlooked. The further along the best models get, the harder starting from scratch is going to become. Eventually, this dynamic will shift back in favor of starting from scratch, because public knowhow and tooling will catch up, but in the meantime the closed tools are getting better at a far faster rate than the fully open tools.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/burning-out?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/burning-out?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The likes of SSI, Thinky, and Reflection
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/burning-out#footnote-1-177056592&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     1
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    are likely the last efforts that are capitalized enough to
   &lt;/span&gt;
   &lt;em&gt;
    maybe
   &lt;/em&gt;
   &lt;span&gt;
    catch up in the near term, but the odds are not on their side. Getting infinite compute into a new company is meaningless if you don’t already have your code, data, and pretraining architectures ready. Eventually the clock will run out for company plans to be just catching up to the frontier, and then figure it out from there. The more these companies raise, the more the expectations on their first output will increase as well. It’s not an enviable position, but it’s certainly ambitious.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    In many ways I see the culture of Chinese technology companies (and education systems) as being better suited for this sort of catch up work. Many top AI researchers trained in the US want to work on a masterpiece, where what it takes in language modeling is often extended grinding to stabilize and replicate something that you know definitely
   &lt;/span&gt;
   &lt;em&gt;
    can
   &lt;/em&gt;
   &lt;span&gt;
    work.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I used to think that the AI bubble would pop financially, as seen through a series of economic mergers, acquisitions, and similar deals. I’m shifting to see more limitations on the human capital than the financial capital thrown at today’s AI companies. As the technical standard of relevance increases (i.e. how good the models people want to use are, or the best open model of a given size category), it simply takes more focused work to get a model there. This work is hard to cheat in time.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    This all relates to how I, and other researchers, always comment on the low hanging fruit we see to keep improving the models. As the models have gotten better, our systems to build them have gotten more refined, complex, intricate, and numerically sensitive.
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/burning-out#footnote-2-177056592&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     2
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    While I see a similar amount of low-hanging fruit today as I did a year ago, the efforts (or physical resources, GPUs) it can take to unlock them have increased. This pushes people to keep going one step closer to their limits. This is piling on to more burnout. This is also why the WSJ reported that top researchers “said repeatedly that they work long hours by choice.” The best feel like they need to do this work or they’ll fall behind. It’s running one more experiment, running one more vibe test, reviewing one more colleague’s PR, reading one more paper, chasing down one more data contract. The to-do list is never empty.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The amount of context that you need to keep in your brain to perform well in many LM training contexts is ever increasing. For example, leading post-training pipelines around the launch of ChatGPT looked like two or maybe three well separated training stages. Now there are tons of checkpoints flying around getting merged, sequenced, and chopped apart in part of the final project. Processes that used to be managed by one or two people now have teams coordinating many data and algorithmic efforts that are trying to land in just a few models a year. I’ve personally transitioned from a normal researcher to something like a tech lead who is always trying to predict blockers before they come up (at any point in the post-training process) and get resources to fix them. I bounce in and out of problems to wherever the most risk is.
  &lt;/p&gt;
  &lt;p&gt;
   Cramming and keeping technical context pushes out hobbies and peace of mind.
  &lt;/p&gt;
  &lt;p&gt;
   Training general language models you hope others will adopt — via open weights or API — is becoming very much an all-in or all-out domain. Half-assing it is becoming an expensive way to make a model that no one will use. This wasn’t the case two years ago, where playing around with a certain part of the pipeline was legitimately impactful.
  &lt;/p&gt;
  &lt;p&gt;
   Culture is a fine line between performance and toxicity, and it’s often hard to know which you are until you get to a major deliverable to check in versus competitors.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Personally, I’m fighting off a double-edged sword of this. I feel immense responsibility to make all the future Olmo models of the world great, while simultaneously trying to do a substantial amount of ecosystem work to create an informed discussion around the state of open models. My goal around this discussion is for more real things to be built.
   &lt;/span&gt;
   &lt;a href=&quot;https://www.atomproject.ai/&quot; rel=&quot;&quot;&gt;
    ATOM Project
   &lt;/a&gt;
   &lt;span&gt;
    is a manifestation of me feeling that both the U.S. ecosystem generally and the Olmo project are falling behind.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   It doesn’t really seem like there will be an immediate fix or end goal at this, but looking back I’m sure it’ll be clear what the key moments were and whether or not my efforts here and elsewhere met my goals.
  &lt;/p&gt;
  &lt;p&gt;
   Will it all be worth it? How long do you plan to go on like this? It’s not like we’re really going to suddenly reach AGI and then all pack it up and go home. AI progress is a long-haul now.
  &lt;/p&gt;
  &lt;p&gt;
   For me, the only reason to keep going is to try and make AI a wonderful technology for the world. Some feel the same. Others are going because they’re locked in on a path to generational wealth. Plenty don’t have either of these alignments, and the wall of effort comes sooner.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!aO6G!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd20d40d7-f57d-457f-ac63-aec8bac096cd_2400x1600.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!aO6G!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd20d40d7-f57d-457f-ac63-aec8bac096cd_2400x1600.jpeg 424w, https://substackcdn.com/image/fetch/$s_!aO6G!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd20d40d7-f57d-457f-ac63-aec8bac096cd_2400x1600.jpeg 848w, https://substackcdn.com/image/fetch/$s_!aO6G!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd20d40d7-f57d-457f-ac63-aec8bac096cd_2400x1600.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!aO6G!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd20d40d7-f57d-457f-ac63-aec8bac096cd_2400x1600.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d20d40d7-f57d-457f-ac63-aec8bac096cd_2400x1600.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:377931,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/177056592?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd20d40d7-f57d-457f-ac63-aec8bac096cd_2400x1600.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;971&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!aO6G!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd20d40d7-f57d-457f-ac63-aec8bac096cd_2400x1600.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!aO6G!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd20d40d7-f57d-457f-ac63-aec8bac096cd_2400x1600.jpeg 424w, https://substackcdn.com/image/fetch/$s_!aO6G!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd20d40d7-f57d-457f-ac63-aec8bac096cd_2400x1600.jpeg 848w, https://substackcdn.com/image/fetch/$s_!aO6G!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd20d40d7-f57d-457f-ac63-aec8bac096cd_2400x1600.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!aO6G!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd20d40d7-f57d-457f-ac63-aec8bac096cd_2400x1600.jpeg 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;div&gt;
   &lt;hr/&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;em&gt;
    Thanks to Ross Taylor, Jordan Schneider, and Jasmine Sun for feedback on this post.
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/burning-out#footnote-anchor-1-177056592&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     Starting later is obviously far more challenging.
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/burning-out#footnote-anchor-2-177056592&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    2
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     For example, the more GPUs you train on, and the bigger the AI model, you encounter more types of errors across the massive system.
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> How to scale RL </title>
<link>https://www.interconnects.ai/p/the-new-rl-scaling-laws</link>
<pubDate>Mon, 20 Oct 2025 15:17:48 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;h5&gt;
   &lt;span&gt;
    Two quick housekeeping items before I get to the post.
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    1. I’ll be in SF this week for the PyTorch conference (22-23), AI Infra Summit (21st), and other local events. Come say hi.
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    2. I launched a new Substack AI bundle with 8 of my favorite publications packaged together for teams of 20+. Learn more at
   &lt;/span&gt;
   &lt;a href=&quot;https://readsail.com/&quot; rel=&quot;&quot;&gt;
    readsail.com
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    Onto the post!
   &lt;/span&gt;
  &lt;/h5&gt;
  &lt;p&gt;
   “Scaling reinforcement learning (RL)” is the zeitgeisty way to capture the next steps in improving frontier models — everyone is staring at the same hill they plan on climbing. How these different groups are approaching the problem has been a poorly kept secret. It’s a simple idea, but one that’s hard to copy: Predicting the trajectory of the learning curve. There have been two reasons this is hard to copy for academics, which will be solved on different time scales:
  &lt;/p&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     The lack of stable RL training setups. There are many RL libraries being developed in parallel and the community has collectively made them much more ready for big RL runs over the summer.
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     The lack of compute for experimentation.
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;p&gt;
   These aren’t new stories. In many ways they mirror the progression of open Mixture of Experts (MoE) models, where they still lag far behind the implementations of the codebases within top AI laboratories because it involves overcoming substantial engineering headaches in an expensive experimentation regime. Scaling RL has been shaping up the same way, but it turns out it is just a bit more approachable.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/the-new-rl-scaling-laws?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/the-new-rl-scaling-laws?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Last week we got the first definitive paper on scaling RL. It proposes a clear method to extrapolate RL learning curves over compute scales and sets a baseline for the order of compute that should be spent to have top-end performance. The paper,
   &lt;/span&gt;
   &lt;em&gt;
    &lt;a href=&quot;https://arxiv.org/abs/2510.13786&quot; rel=&quot;&quot;&gt;
     The Art of Scaling Reinforcement Learning Compute for LLMs
    &lt;/a&gt;
   &lt;/em&gt;
   &lt;span&gt;
    (Khatri &amp; Madaan et al. 2025), referred to as ScaleRL, is a must read for anyone looking to understand the absolute cutting edge of RL algorithms and infrastructure.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!EnWF!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7df555ab-5d07-49a4-96e4-3eb744960976_1798x1816.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!EnWF!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7df555ab-5d07-49a4-96e4-3eb744960976_1798x1816.png 424w, https://substackcdn.com/image/fetch/$s_!EnWF!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7df555ab-5d07-49a4-96e4-3eb744960976_1798x1816.png 848w, https://substackcdn.com/image/fetch/$s_!EnWF!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7df555ab-5d07-49a4-96e4-3eb744960976_1798x1816.png 1272w, https://substackcdn.com/image/fetch/$s_!EnWF!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7df555ab-5d07-49a4-96e4-3eb744960976_1798x1816.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7df555ab-5d07-49a4-96e4-3eb744960976_1798x1816.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1471,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:775466,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/175849446?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7df555ab-5d07-49a4-96e4-3eb744960976_1798x1816.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;1471&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!EnWF!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7df555ab-5d07-49a4-96e4-3eb744960976_1798x1816.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!EnWF!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7df555ab-5d07-49a4-96e4-3eb744960976_1798x1816.png 424w, https://substackcdn.com/image/fetch/$s_!EnWF!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7df555ab-5d07-49a4-96e4-3eb744960976_1798x1816.png 848w, https://substackcdn.com/image/fetch/$s_!EnWF!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7df555ab-5d07-49a4-96e4-3eb744960976_1798x1816.png 1272w, https://substackcdn.com/image/fetch/$s_!EnWF!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7df555ab-5d07-49a4-96e4-3eb744960976_1798x1816.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   For some personal context, for all of 2025 we’ve had our main slack channel in the reasoning space at Ai2 called “scaling-rl” because of how essential we knew the first clear piece of work in this area would be. This post covers the key details and what I see coming next.
  &lt;/p&gt;
  &lt;p&gt;
   There are two key things you need to know about these, even if all the lower level RL math is confusing to you too. First is how these intuitively work and what they’re actually predicting. Second is how they compare to the pretraining scaling laws we know and love.
  &lt;/p&gt;
  &lt;p&gt;
   To the first point, what the approach entails is taking one (or a handful of) your key base models, run a bit of RL on each of them, predict the end point by a bit of shape forecasting across many stable runs, then, for your big run, you can predict the end point in terms of final performance. The shape of RL runs that motivates this is how you see your model often gain ~80% of the accuracy gain in the first few steps, and you wonder what the final performance of the model will be if you trained on your entire dataset.
  &lt;/p&gt;
  &lt;p&gt;
   The authors define three constants that they fit, A for a measure of the peak performance — accuracy on a subset of your training dataset, aka the validation set, B for the slope of the sigmoid curve, and C as compute on the x axis. What is then done is that you take a set of RL training jobs and you fit a regression that predicts the last chunk of real training points given the early measurements of accuracy over time. Then, you can compare the predicted final performance of your future RL ablations on that starting model by understanding the normal shape of your RL learning curves.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!Spr_!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Spr_!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png 424w, https://substackcdn.com/image/fetch/$s_!Spr_!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png 848w, https://substackcdn.com/image/fetch/$s_!Spr_!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png 1272w, https://substackcdn.com/image/fetch/$s_!Spr_!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:677,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:606876,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/175849446?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;677&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!Spr_!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Spr_!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png 424w, https://substackcdn.com/image/fetch/$s_!Spr_!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png 848w, https://substackcdn.com/image/fetch/$s_!Spr_!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png 1272w, https://substackcdn.com/image/fetch/$s_!Spr_!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png 1456w&quot; title=&quot;&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   Second is to consider how this compares to pretraining scaling laws. These are very far from the deeply insightful power law relating downstream test loss to pretraining compute — accuracy on RL training datasets is a far more bounded measure than next token prediction. The RL scaling laws are most useful for ablating design choices, relative to pointing to something fundamental about the nature of models. In many ways, scaling laws for pretraining could’ve been viewed this way at the beginning, too, so we’ll see how RL evolves from here.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!Ji8y!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb827ef2e-394f-4e14-8050-b075fd05f437_2755x1011.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Ji8y!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb827ef2e-394f-4e14-8050-b075fd05f437_2755x1011.png 424w, https://substackcdn.com/image/fetch/$s_!Ji8y!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb827ef2e-394f-4e14-8050-b075fd05f437_2755x1011.png 848w, https://substackcdn.com/image/fetch/$s_!Ji8y!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb827ef2e-394f-4e14-8050-b075fd05f437_2755x1011.png 1272w, https://substackcdn.com/image/fetch/$s_!Ji8y!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb827ef2e-394f-4e14-8050-b075fd05f437_2755x1011.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b827ef2e-394f-4e14-8050-b075fd05f437_2755x1011.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:534,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:911144,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/175849446?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb827ef2e-394f-4e14-8050-b075fd05f437_2755x1011.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;534&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!Ji8y!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb827ef2e-394f-4e14-8050-b075fd05f437_2755x1011.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Ji8y!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb827ef2e-394f-4e14-8050-b075fd05f437_2755x1011.png 424w, https://substackcdn.com/image/fetch/$s_!Ji8y!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb827ef2e-394f-4e14-8050-b075fd05f437_2755x1011.png 848w, https://substackcdn.com/image/fetch/$s_!Ji8y!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb827ef2e-394f-4e14-8050-b075fd05f437_2755x1011.png 1272w, https://substackcdn.com/image/fetch/$s_!Ji8y!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb827ef2e-394f-4e14-8050-b075fd05f437_2755x1011.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   With that difference, scaling laws for RL will play a very different role in training leading models than the pretraining scaling laws we have today. The pretraining laws are about choosing the exact configuration for your big pretraining run (that you can’t really run a meaningful chunk of to debug at all), where RL is more about ablating which algorithm you’ll let run much longer.
  &lt;/p&gt;
  &lt;p&gt;
   In pretraining many decisions depend on your budget and scaling laws can give the answer. Your training compute, communication bottlenecks, maximum run time, data availability, etc. all define a certain model window. Scaling laws for RL may inform this very soon, but for now it&#x27;s best to think about scaling laws as a way to extract the maximum performance from a given base model.
  &lt;/p&gt;
  &lt;p&gt;
   For all of these reasons, scaling RL is more like an art, as the authors say it, because it’s about finding the run that’ll get the last few percentage points of performance when let run over an extra order of magnitude (or two) of samples. It’s a fine grained way to extrapolate RL curves — which have a standard shape of a quick rise then a slow saturation. In practice, the authors fit curves over 1/4 of their training compute to predict the outcome after the remaining 3/4 of GPU hours. The limits of scaling laws will likely be pushed further in the future (and I don’t have a good heuristic for what percentage of compute is used for establishing pretraining scaling laws, versus what is deployed in the final run, comment if you do!).
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!4gom!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81e70f2f-8945-42ae-ba51-433f1a128693_2110x1307.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!4gom!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81e70f2f-8945-42ae-ba51-433f1a128693_2110x1307.png 424w, https://substackcdn.com/image/fetch/$s_!4gom!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81e70f2f-8945-42ae-ba51-433f1a128693_2110x1307.png 848w, https://substackcdn.com/image/fetch/$s_!4gom!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81e70f2f-8945-42ae-ba51-433f1a128693_2110x1307.png 1272w, https://substackcdn.com/image/fetch/$s_!4gom!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81e70f2f-8945-42ae-ba51-433f1a128693_2110x1307.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/81e70f2f-8945-42ae-ba51-433f1a128693_2110x1307.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:902,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:716354,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/175849446?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81e70f2f-8945-42ae-ba51-433f1a128693_2110x1307.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;902&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!4gom!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81e70f2f-8945-42ae-ba51-433f1a128693_2110x1307.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!4gom!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81e70f2f-8945-42ae-ba51-433f1a128693_2110x1307.png 424w, https://substackcdn.com/image/fetch/$s_!4gom!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81e70f2f-8945-42ae-ba51-433f1a128693_2110x1307.png 848w, https://substackcdn.com/image/fetch/$s_!4gom!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81e70f2f-8945-42ae-ba51-433f1a128693_2110x1307.png 1272w, https://substackcdn.com/image/fetch/$s_!4gom!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81e70f2f-8945-42ae-ba51-433f1a128693_2110x1307.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    From here, the paper quickly gets technical, serving as a check in on the major ideas that dominated the RL research ecosystem in the last 6 months. This paper blesses those as important or not when it comes to scaled up RL training. This fits a recurring trend across language modeling in the last few years:
   &lt;/span&gt;
   &lt;strong&gt;
    Most of the key ideas are out there, but open labs tend to not have the resources to put them all together in the right configuration
   &lt;/strong&gt;
   &lt;span&gt;
    . This sort of slow accumulation of knowledge takes an organizational intensity, clarity, and ability that is hard for small research groups to match.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
   There are a few key ideas that stand out to me as worth knowing and betting on following this paper:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Algorithmic advancements:
     &lt;/strong&gt;
     &lt;span&gt;
      The paper is very favorable on, arguably painting them as essential, some recent algorithms or advancements. These include
     &lt;/span&gt;
     &lt;a href=&quot;https://fengyao.notion.site/off-policy-rl&quot; rel=&quot;&quot;&gt;
      truncated importance sampling
     &lt;/a&gt;
     &lt;span&gt;
      (TIS),
     &lt;/span&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2507.18071&quot; rel=&quot;&quot;&gt;
      Group Sequence Policy Optimization (GSPO)
     &lt;/a&gt;
     &lt;span&gt;
      , and Clipped IS-weight Policy Optimization (CISPO) via the
     &lt;/span&gt;
     &lt;a href=&quot;https://arxiv.org/pdf/2506.13585&quot; rel=&quot;&quot;&gt;
      MiniMax M1 paper
     &lt;/a&gt;
     &lt;span&gt;
      . More on these in a second.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Systems improvements:
     &lt;/strong&gt;
     &lt;span&gt;
      The authors highlight PipeLine RL (
     &lt;/span&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2509.19128&quot; rel=&quot;&quot;&gt;
      paper
     &lt;/a&gt;
     &lt;span&gt;
      or
     &lt;/span&gt;
     &lt;a href=&quot;https://github.com/ServiceNow/PipelineRL&quot; rel=&quot;&quot;&gt;
      repository
     &lt;/a&gt;
     &lt;span&gt;
      ) as the canonical reference for the combination of in-flight updates — i.e. changing model weights within one very long generation — and continuous batching — i.e. filling your RL batch over time until you have enough prompts for a learning step — which together represent 4X+ improvements over standard RL implementations on LLMs in terms of throughput. What this looks like in terms of idle GPUs is below, from the ServiceNow paper.
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!R3mA!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc78027d-b185-4e3f-aba2-387ed8154e0e_2889x1053.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!R3mA!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc78027d-b185-4e3f-aba2-387ed8154e0e_2889x1053.png 424w, https://substackcdn.com/image/fetch/$s_!R3mA!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc78027d-b185-4e3f-aba2-387ed8154e0e_2889x1053.png 848w, https://substackcdn.com/image/fetch/$s_!R3mA!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc78027d-b185-4e3f-aba2-387ed8154e0e_2889x1053.png 1272w, https://substackcdn.com/image/fetch/$s_!R3mA!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc78027d-b185-4e3f-aba2-387ed8154e0e_2889x1053.png 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bc78027d-b185-4e3f-aba2-387ed8154e0e_2889x1053.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:531,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:683251,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/175849446?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc78027d-b185-4e3f-aba2-387ed8154e0e_2889x1053.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;531&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!R3mA!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc78027d-b185-4e3f-aba2-387ed8154e0e_2889x1053.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!R3mA!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc78027d-b185-4e3f-aba2-387ed8154e0e_2889x1053.png 424w, https://substackcdn.com/image/fetch/$s_!R3mA!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc78027d-b185-4e3f-aba2-387ed8154e0e_2889x1053.png 848w, https://substackcdn.com/image/fetch/$s_!R3mA!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc78027d-b185-4e3f-aba2-387ed8154e0e_2889x1053.png 1272w, https://substackcdn.com/image/fetch/$s_!R3mA!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc78027d-b185-4e3f-aba2-387ed8154e0e_2889x1053.png 1456w&quot; width=&quot;1456&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
    &lt;p&gt;
     &lt;span&gt;
      Intuitively, think about what happens if you were to ask 8 different questions to an LLM simultaneously. Some of these would finish early and some would take a long time. If you allocate your GPUs such that they have to finish all 8 questions before moving onto the next stack of questions, inevitably there will be GPUs idle when you’re waiting for the last answer.
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      Instead, continuous batching pulls in new questions all the time when the GPUs have cycles to do more processing. Though, this is more complicated in the RL setup because after every 8 (or your batch size) of questions you need to update your RL weights. Can you still do this and fill in new questions all the time to the GPUs? What happens to that one question that is taking forever?
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      In-flight updates is the solution to this. What is literally happening is that the model is updated in the middle of the generation. The models and RL systems just handle this seamlessly, and it removes a ton of idle time in matching the inference weights to the new updates from your RL algorithm.
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      Not having a few key details like this will make big RL runs not only more expensive in GPUs, but more importantly in time. A 1 day feedback cycle vs 4 days makes for a very different research setup. We have these two features in
     &lt;/span&gt;
     &lt;a href=&quot;https://github.com/allenai/open-instruct&quot; rel=&quot;&quot;&gt;
      Open Instruct
     &lt;/a&gt;
     &lt;span&gt;
      , our post training repo at Ai2, as do many other RL libraries.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   &lt;span&gt;
    A lot of this is fixing numerics, which is far harder with Mixture of Experts (MoE) models, and something that most open RL research hasn’t touched. This hunt for numerical stability is a common rumor for why Thinking Machines put out the
   &lt;/span&gt;
   &lt;a href=&quot;https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/&quot; rel=&quot;&quot;&gt;
    deterministic VLLM blog post
   &lt;/a&gt;
   &lt;span&gt;
    ahead of releasing their
   &lt;/span&gt;
   &lt;a href=&quot;https://thinkingmachines.ai/tinker/&quot; rel=&quot;&quot;&gt;
    Tinker API
   &lt;/a&gt;
   &lt;span&gt;
    — deterministic VLLM could be their forward pass.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Back to algorithms.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Ross Taylor
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/rosstaylor90/status/1978837624417587306&quot; rel=&quot;&quot;&gt;
    summarized
   &lt;/a&gt;
   &lt;span&gt;
    the various eras of RL algorithms that the community has gone through in 2025. First was the transition from vanilla GRPO to the likes of DAPO (see my earlier post on
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/papers-im-reading-base-model-rl-grpo&quot; rel=&quot;&quot;&gt;
    GRPO tricks
   &lt;/a&gt;
   &lt;span&gt;
    or my
   &lt;/span&gt;
   &lt;a href=&quot;https://www.youtube.com/watch?v=amrJDwMUFNs&quot; rel=&quot;&quot;&gt;
    YouTube video
   &lt;/a&gt;
   &lt;span&gt;
    on them too), which noticed issues with the clipping formulation and biases in the GRPO advantage calculation. The next class of algorithms are those cited in this ScaleRL paper, CISPO and a general class of Truncated Importance Sampling
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/the-new-rl-scaling-laws#footnote-1-175849446&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     1
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    (TIS) approaches, that are designed for sequence level optimization (often closer to vanilla policy gradient) that account for the probability delta between actor (the GPUs generating completions for RL, often something fast like VLLM) and learner (the GPUs performing gradient updates, in a different library).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   This importance sampling term seems to be essential to getting modern RL infrastructure right, as without it, scaling to more complex systems is hard to get numerical stability with. There’s been a lot of chatter about “importance sampling” in the AI community. What is happening, practically, is that the advantage or reward is getting re-weighted by an importance sampling log-ratio corresponding to the difference in probabilities from the two sets of model implementations (e.g. VLLM vs Transformers).
  &lt;/p&gt;
  &lt;p&gt;
   In the midst of all the details, the paper summarizes the state of affairs — large scale yolo RL runs — quite well:
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    While RL compute for LLMs has scaled massively, our understanding of how to scale RL has not kept pace; the methodology remains more art than science. Recent breakthroughs in RL are largely driven by isolated studies on novel algorithms (e.g., Yu et al. (DAPO, 2025)) and model-specific training reports, such as, MiniMax et al. (2025) and Magistral (Rastogi et al., 2025). Critically, these studies provide ad-hoc solutions tailored to specific contexts, but not how to develop RL methods that scale with compute. This lack of scaling methodology stifles research progress: with no reliable way to identify promising RL candidates a priori, progress is tied to large-scale experimentation that sidelines most of the academic community.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   What is important going forward, as this will happen again with future eras of LLMs after this RL era, is why we are here. This happened due to the large overhang in potential from deploying RL, where clear scientific best practices take a long time to establish (even when most of the best researchers are publishing publicly, which isn’t the case today). The leading AI labs can build up fairly sizeable gaps quickly, but information tends to flow out and be reproduced. It’s important that the public options keep materializing — I think they will.
  &lt;/p&gt;
  &lt;p&gt;
   This paper is the first step in a direction of that science of scaling RL, but leaves many questions unanswered:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      No information on the impacts of different data
     &lt;/strong&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/datasets/POLARIS-Project/Polaris-Dataset-53K&quot; rel=&quot;&quot;&gt;
      Polaris 53K
     &lt;/a&gt;
     &lt;span&gt;
      is used in the paper, which is a solid option of the open, math RL datasets, but we find most of the RL data like this to be solved with a simple SFT set of reasoning traces on 8B models. Harder data may quickly become a limitation of open methods as people scale RL experiments to stronger base models. A paper reproducing these scaling trends over different data regimes is essential.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      No information on choosing the right base model
     &lt;/strong&gt;
     &lt;span&gt;
      . It is accepted that bigger base models perform better with RL — which the authors acknowledge in the paper: “the larger 17B×16 MoE exhibits much higher asymptotic RL performance than the 8B dense model, outperforming the 8B’s performance using only 1/6 of its RL training compute.” With this, we need to perform scaling RL studies that show the optimal base model for downstream RL, in terms of overall compute budgets.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   &lt;span&gt;
    The authors acknowledge these limitations clearly. They’re not trying to hide it!
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/the-new-rl-scaling-laws#footnote-2-175849446&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     2
    &lt;/a&gt;
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    To wrap this up, let us recall that there was a
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/iScienceLuvr/status/1972066202920054875&quot; rel=&quot;&quot;&gt;
    big brouhaha
   &lt;/a&gt;
   &lt;span&gt;
    in AI circles a few weeks ago when a few frontier lab employees said that GRPO is far behind frontier labs RL stacks. What is more accurate to me is that
   &lt;/span&gt;
   &lt;em&gt;
    vanilla
   &lt;/em&gt;
   &lt;span&gt;
    GRPO is far behind, and the process of figuring out the set of individual tricks that works on your model and your data is a well kept secret. This new ScaleRL paper is a major step in showing people how to bridge that gap. From here, we have to build the tools in public.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/the-new-rl-scaling-laws#footnote-anchor-1-175849446&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     &lt;span&gt;
      I like this
     &lt;/span&gt;
     &lt;a href=&quot;https://fengyao.notion.site/off-policy-rl&quot; rel=&quot;&quot;&gt;
      blog on importance sampling for RL
     &lt;/a&gt;
     &lt;span&gt;
      (cited in the ScaleRL paper), but the
     &lt;/span&gt;
     &lt;a href=&quot;https://en.wikipedia.org/wiki/Importance_sampling&quot; rel=&quot;&quot;&gt;
      Wikipedia article
     &lt;/a&gt;
     &lt;span&gt;
      is helpful on a TLDR of what importance sampling itself is:
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;blockquote&gt;
     &lt;p&gt;
      &lt;strong&gt;
       Importance sampling
      &lt;/strong&gt;
      &lt;span&gt;
       is a
      &lt;/span&gt;
      &lt;a href=&quot;https://en.wikipedia.org/wiki/Monte_Carlo_method&quot; rel=&quot;&quot;&gt;
       Monte Carlo method
      &lt;/a&gt;
      &lt;span&gt;
       for evaluating properties of a particular
      &lt;/span&gt;
      &lt;a href=&quot;https://en.wikipedia.org/wiki/Probability_distribution&quot; rel=&quot;&quot;&gt;
       distribution
      &lt;/a&gt;
      &lt;span&gt;
       , while only having samples generated from a different distribution than the distribution of interest.
      &lt;/span&gt;
     &lt;/p&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;
     This detail I’ve been hearing about constantly as a core thing to get right with modern RL infrastructure.
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/the-new-rl-scaling-laws#footnote-anchor-2-175849446&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    2
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     &lt;span&gt;
      Another key thing that is omitted from this work, and I think much of the efforts to improve the next model iteration like Claude 4.6 or GPT 5.1 is the “
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/what-comes-next-with-reinforcement&quot; rel=&quot;&quot;&gt;
      very long horizon
     &lt;/a&gt;
     &lt;span&gt;
      ” RL that is described when people mention RL solving open problems like scientific discovery. We’re much further from that, but still have substantial improvements to be made on current models.
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;p&gt;
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Latest open models (#15): It’s Qwen&#x27;s world and we get to live in it, on CAISI&#x27;s report, &amp; GPT-OSS update </title>
<link>https://www.interconnects.ai/p/latest-open-models-15-its-qwens-world</link>
<pubDate>Sat, 18 Oct 2025 15:26:15 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   Before getting into the latest artifacts, there are a couple of pieces of crucial open ecosystem we have to cover.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    First, the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.nist.gov/caisi&quot; rel=&quot;&quot;&gt;
    Center for AI Standards and Innovation (CAISI)
   &lt;/a&gt;
   &lt;span&gt;
    released a report that observed the ecosystem and
   &lt;/span&gt;
   &lt;a href=&quot;https://www.nist.gov/news-events/news/2025/09/caisi-evaluation-deepseek-ai-models-finds-shortcomings-and-risks&quot; rel=&quot;&quot;&gt;
    evaluated
   &lt;/a&gt;
   &lt;span&gt;
    DeepSeek 3.1 against leading closed models. The evaluation scores they highlighted show some discrepancy with accepted results in the community. While MMLU-Pro, GPQA and HLE are close to the self-reported scores from DeepSeek and within usual error bars
   &lt;/span&gt;
   &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/latest-open-models-15-its-qwens-world#footnote-1-176399506&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;span&gt;
    , the SWE-bench Verified scores are off by a wide margin due to a weak harness for the benchmark. The harness is the software framework the model is used in for agentic benchmarks and has as great an impact as the model itself, as shown in
   &lt;/span&gt;
   &lt;a href=&quot;https://epoch.ai/blog/what-skills-does-swe-bench-verified-evaluate#scaffolds-matter-as-much-as-models&quot; rel=&quot;&quot;&gt;
    this SWE-bench analysis by Epoch AI
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The CAISI report thus undersells the capabilities of DeepSeek’s models on a core benchmark for recent models (e.g. it is one of the benchmarks that Anthropic most heavily relies on for
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/claude-4-and-anthropics-bet-on-code&quot; rel=&quot;&quot;&gt;
    marketing of Claude
   &lt;/a&gt;
   &lt;span&gt;
    ).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!yoYR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb23fd663-ef06-4616-a3c4-f1491e1dd69e_1562x706.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!yoYR!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb23fd663-ef06-4616-a3c4-f1491e1dd69e_1562x706.png 424w, https://substackcdn.com/image/fetch/$s_!yoYR!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb23fd663-ef06-4616-a3c4-f1491e1dd69e_1562x706.png 848w, https://substackcdn.com/image/fetch/$s_!yoYR!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb23fd663-ef06-4616-a3c4-f1491e1dd69e_1562x706.png 1272w, https://substackcdn.com/image/fetch/$s_!yoYR!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb23fd663-ef06-4616-a3c4-f1491e1dd69e_1562x706.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;Image&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b23fd663-ef06-4616-a3c4-f1491e1dd69e_1562x706.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:658,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;658&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!yoYR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb23fd663-ef06-4616-a3c4-f1491e1dd69e_1562x706.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!yoYR!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb23fd663-ef06-4616-a3c4-f1491e1dd69e_1562x706.png 424w, https://substackcdn.com/image/fetch/$s_!yoYR!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb23fd663-ef06-4616-a3c4-f1491e1dd69e_1562x706.png 848w, https://substackcdn.com/image/fetch/$s_!yoYR!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb23fd663-ef06-4616-a3c4-f1491e1dd69e_1562x706.png 1272w, https://substackcdn.com/image/fetch/$s_!yoYR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb23fd663-ef06-4616-a3c4-f1491e1dd69e_1562x706.png 1456w&quot; title=&quot;Image&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    Later in the report, CAISI shows a graph with cumulative download numbers from HuggingFace (left), something we also show on
   &lt;/span&gt;
   &lt;a href=&quot;https://atomproject.ai/&quot; rel=&quot;&quot;&gt;
    atomproject.ai
   &lt;/a&gt;
   &lt;span&gt;
    (middle, right). However, our numbers differ greatly from the numbers from CAISI and those differ even more from the ones by
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/blog/lbourdois/huggingface-models-stats&quot; rel=&quot;&quot;&gt;
    HuggingFace itself
   &lt;/a&gt;
   &lt;span&gt;
    . So, what is going on?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!EWYT!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefe60a29-3da8-468c-b368-aad74cd1255e_2043x501.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!EWYT!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefe60a29-3da8-468c-b368-aad74cd1255e_2043x501.png 424w, https://substackcdn.com/image/fetch/$s_!EWYT!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefe60a29-3da8-468c-b368-aad74cd1255e_2043x501.png 848w, https://substackcdn.com/image/fetch/$s_!EWYT!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefe60a29-3da8-468c-b368-aad74cd1255e_2043x501.png 1272w, https://substackcdn.com/image/fetch/$s_!EWYT!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefe60a29-3da8-468c-b368-aad74cd1255e_2043x501.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/efe60a29-3da8-468c-b368-aad74cd1255e_2043x501.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:357,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:212129,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/176399506?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefe60a29-3da8-468c-b368-aad74cd1255e_2043x501.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;357&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!EWYT!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefe60a29-3da8-468c-b368-aad74cd1255e_2043x501.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!EWYT!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefe60a29-3da8-468c-b368-aad74cd1255e_2043x501.png 424w, https://substackcdn.com/image/fetch/$s_!EWYT!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefe60a29-3da8-468c-b368-aad74cd1255e_2043x501.png 848w, https://substackcdn.com/image/fetch/$s_!EWYT!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefe60a29-3da8-468c-b368-aad74cd1255e_2043x501.png 1272w, https://substackcdn.com/image/fetch/$s_!EWYT!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefe60a29-3da8-468c-b368-aad74cd1255e_2043x501.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
      &lt;div&gt;
      &lt;/div&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   In short, it depends on which data you look at and how you clean it. For ATOM Project, we only consider models which were released after ChatGPT and are LLMs (based on our assessment). This excludes models like GPT-2 (which is the reason why OpenAI trumps all in the CAISI number, left), BERT-like models and ViTs like SigLIP (which are dominating the Google download numbers).
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    On top of this, we performed basic outlier filtering on daily downloads per model. Many models, such as
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct&quot; rel=&quot;&quot;&gt;
    Qwen 2.5 1.5B
   &lt;/a&gt;
   &lt;span&gt;
    , which is one of the most downloaded models of all time, has extreme outliers on the order of 10M+ downloads that can heavily skew the overall numbers. These outliers affect every organization, but in different magnitudes. Furthermore, we also exclude quantized (like FP8, MLX or GGUF) versions, as those might skew the numbers.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/latest-open-models-15-its-qwens-world?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-models-15-its-qwens-world?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The second news item is sharing an update on the utility of
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/gpt-oss-openai-validates-the-open&quot; rel=&quot;&quot;&gt;
    GPT-OSS
   &lt;/a&gt;
   &lt;span&gt;
    — when the model first dropped it was plagued by implementation difficulties downstream of architecture choices (e.g. a new 4-point precision) and complex tool use (multiple tool options per category). OpenAI is actually ahead of the curve on the complexity of tools they support with these models among open options. Since release, the use of GPT-OSS’s
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/openai/gpt-oss-20b&quot; rel=&quot;&quot;&gt;
    20B
   &lt;/a&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/openai/gpt-oss-120b&quot; rel=&quot;&quot;&gt;
    120B
   &lt;/a&gt;
   &lt;span&gt;
    models is very strong with 5.6M and 3.2M downloads in the last month, respectively. These models are outperforming some popular models, such as
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-4B&quot; rel=&quot;&quot;&gt;
    Qwen 3 4B
   &lt;/a&gt;
   &lt;span&gt;
    or
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-VL-30B-A3B-Instruct&quot; rel=&quot;&quot;&gt;
    Qwen3-VL-30B-A3B-Instruct
   &lt;/a&gt;
   &lt;span&gt;
    . Additionally, I got
   &lt;/span&gt;
   &lt;em&gt;
    very strong
   &lt;/em&gt;
   &lt;span&gt;
    feedback from the community when I did a
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/natolambert/status/1974121935408935337&quot; rel=&quot;&quot;&gt;
    basic pulse check
   &lt;/a&gt;
   &lt;span&gt;
    on the models. These are one of the first models I’d try on my
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/natolambert/status/1979291280833229246&quot; rel=&quot;&quot;&gt;
    new Nvidia DGX-Spark
   &lt;/a&gt;
   &lt;span&gt;
    to get a feel for things.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h1&gt;
   &lt;strong&gt;
    Artifacts Log
   &lt;/strong&gt;
  &lt;/h1&gt;
  &lt;h3&gt;
   &lt;strong&gt;
    Our Picks
   &lt;/strong&gt;
  &lt;/h3&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/ibm-granite/granite-4.0-h-small&quot; rel=&quot;&quot;&gt;
       granite-4.0-h-small
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/ibm-granite&quot; rel=&quot;&quot;&gt;
      ibm-granite
     &lt;/a&gt;
     &lt;span&gt;
      : We’ve been covering IBM and their Granite LLM series for a while. With this series, IBM finally scaled up the model size as well, bringing a series of hybrid (attention + mamba) models, ranging from a 3B dense to a 32B-A9B MoE. We used the models and were impressed, although not surprised, by the quality, given the continued persistence of IBM’s team to release better and better models.
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      Granite, for at least the 3B variant, is roughly in the
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/blog/smollm3&quot; rel=&quot;&quot;&gt;
      SmolLM3
     &lt;/a&gt;
     &lt;span&gt;
      quality range, being only surpassed by Qwen3 4B in terms of multilingual and instruction following capabilities. The tone of Granite 4.0 is refreshingly non-exciting compared to the sloptimized models recently (i.e. the trend across the industry for playful, emoji-filled, and often sycophantic models), making it feel like old Mistral models in a good way. Interestingly enough, they are also following Qwens lead and will release a
     &lt;/span&gt;
     &lt;strong&gt;
      separate reasoning model later in the year
     &lt;/strong&gt;
     &lt;span&gt;
      . We’ve heard many reports from people training models that hybrid reasoning — i.e. a toggle of thinking tokens on and off — adds a major complexity cost in training that lowers the peak performance of both modes. IBM
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/ibm-granite/granite-3.2-8b-instruct&quot; rel=&quot;&quot;&gt;
      debuted
     &lt;/a&gt;
     &lt;span&gt;
      the hybrid thinking approach (togglable via prompts) very early on for open models, which was adopted by others later.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-VL-235B-A22B-Instruct&quot; rel=&quot;&quot;&gt;
       Qwen3-VL-235B-A22B-Instruct
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/Qwen&quot; rel=&quot;&quot;&gt;
      Qwen
     &lt;/a&gt;
     &lt;span&gt;
      : The Qwen VL series finally gets its long-awaited and anticipated update with small (4B, 8B) dense and larger (30B-A3B, 235B-A22B) MoEs in both instruct and reasoning versions. We want to shine a special spotlight on the
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-VL-8B-Instruct&quot; rel=&quot;&quot;&gt;
      8B variants
     &lt;/a&gt;
     &lt;span&gt;
      : Their text benchmarks have also improved across the board compared to the initial 8B release — reinforcing our point on the challenge of hybrid reasoning. As the 8B versions did not get a 2507 refresh, these versions should be a no-brainer update and drop-in replacement if you were using Qwen3 8B (or are still using Llama3.1 8B).
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!kyNm!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb992e217-ba81-49a1-82ec-b394f9be7d03_3949x2349.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!kyNm!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb992e217-ba81-49a1-82ec-b394f9be7d03_3949x2349.jpeg 424w, https://substackcdn.com/image/fetch/$s_!kyNm!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb992e217-ba81-49a1-82ec-b394f9be7d03_3949x2349.jpeg 848w, https://substackcdn.com/image/fetch/$s_!kyNm!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb992e217-ba81-49a1-82ec-b394f9be7d03_3949x2349.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!kyNm!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb992e217-ba81-49a1-82ec-b394f9be7d03_3949x2349.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b992e217-ba81-49a1-82ec-b394f9be7d03_3949x2349.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:866,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;866&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!kyNm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb992e217-ba81-49a1-82ec-b394f9be7d03_3949x2349.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!kyNm!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb992e217-ba81-49a1-82ec-b394f9be7d03_3949x2349.jpeg 424w, https://substackcdn.com/image/fetch/$s_!kyNm!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb992e217-ba81-49a1-82ec-b394f9be7d03_3949x2349.jpeg 848w, https://substackcdn.com/image/fetch/$s_!kyNm!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb992e217-ba81-49a1-82ec-b394f9be7d03_3949x2349.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!kyNm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb992e217-ba81-49a1-82ec-b394f9be7d03_3949x2349.jpeg 1456w&quot; width=&quot;1456&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/zai-org/GLM-4.6&quot; rel=&quot;&quot;&gt;
       GLM-4.6
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/zai-org&quot; rel=&quot;&quot;&gt;
      zai-org
     &lt;/a&gt;
     &lt;span&gt;
      : Zhipu has released an update to their main series of models. This release is notable because
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/victormustar/status/1973735580283625618&quot; rel=&quot;&quot;&gt;
      many
     &lt;/a&gt;
     &lt;span&gt;
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/Tim_Dettmers/status/1974421423713386661&quot; rel=&quot;&quot;&gt;
      people
     &lt;/a&gt;
     &lt;span&gt;
      say that it’s basically a Sonnet (or a Haiku) 4.5 at home, although it falls off (harder) at longer context than closed models. Still, a high praise and a continuation of the theme that Chinese open models improve at an astonishing rate, being close to the best closed models.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/inclusionAI/Ling-1T&quot; rel=&quot;&quot;&gt;
       Ling-1T
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/inclusionAI&quot; rel=&quot;&quot;&gt;
      inclusionAI
     &lt;/a&gt;
     &lt;span&gt;
      : Inclusion AI is waking up and starting to adopt the release cadence of its bigger brother by releasing models left, right and center. Similar to Qwen, they also started to scale up model sizes considerably, hitting the 1T threshold. They also
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/inclusionAI/Ring-1T-preview&quot; rel=&quot;&quot;&gt;
      release a reasoning version
     &lt;/a&gt;
     &lt;span&gt;
      and experiment with different architectures and modalities. Keep an eye on them!
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!5EW-!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2127eef5-ff98-4a00-8b54-a50feb1ca654_4770x2187.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!5EW-!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2127eef5-ff98-4a00-8b54-a50feb1ca654_4770x2187.png 424w, https://substackcdn.com/image/fetch/$s_!5EW-!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2127eef5-ff98-4a00-8b54-a50feb1ca654_4770x2187.png 848w, https://substackcdn.com/image/fetch/$s_!5EW-!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2127eef5-ff98-4a00-8b54-a50feb1ca654_4770x2187.png 1272w, https://substackcdn.com/image/fetch/$s_!5EW-!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2127eef5-ff98-4a00-8b54-a50feb1ca654_4770x2187.png 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2127eef5-ff98-4a00-8b54-a50feb1ca654_4770x2187.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:668,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;668&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!5EW-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2127eef5-ff98-4a00-8b54-a50feb1ca654_4770x2187.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!5EW-!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2127eef5-ff98-4a00-8b54-a50feb1ca654_4770x2187.png 424w, https://substackcdn.com/image/fetch/$s_!5EW-!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2127eef5-ff98-4a00-8b54-a50feb1ca654_4770x2187.png 848w, https://substackcdn.com/image/fetch/$s_!5EW-!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2127eef5-ff98-4a00-8b54-a50feb1ca654_4770x2187.png 1272w, https://substackcdn.com/image/fetch/$s_!5EW-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2127eef5-ff98-4a00-8b54-a50feb1ca654_4770x2187.png 1456w&quot; width=&quot;1456&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/moondream/moondream3-preview&quot; rel=&quot;&quot;&gt;
       moondream3-preview
      &lt;/a&gt;
      &lt;span&gt;
      &lt;/span&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/moondream&quot; rel=&quot;&quot;&gt;
      moondream
     &lt;/a&gt;
     &lt;span&gt;
      : Moondream is far from an unknown player these days and known for punching well above its size. They too adopted the MoE architecture with 9B total, 2B active parameters and improved the already great benchmarks even further. An interesting aspect is its unique (in the AI world) license:
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;blockquote&gt;
     &lt;p&gt;
      TL;DR — You can use Moondream 3 (Preview) freely for personal, research, and most commercial uses. What’s NOT allowed without a separate deal is offering a paid product that competes with M87 Labs’ paid versions (e.g., selling hosted or embedded access to the model’s capabilities to third parties).
     &lt;/p&gt;
    &lt;/blockquote&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!Hub9!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f4f4cde-4ecd-4272-b5bc-216ea67369ea_2322x1050.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Hub9!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f4f4cde-4ecd-4272-b5bc-216ea67369ea_2322x1050.jpeg 424w, https://substackcdn.com/image/fetch/$s_!Hub9!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f4f4cde-4ecd-4272-b5bc-216ea67369ea_2322x1050.jpeg 848w, https://substackcdn.com/image/fetch/$s_!Hub9!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f4f4cde-4ecd-4272-b5bc-216ea67369ea_2322x1050.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!Hub9!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f4f4cde-4ecd-4272-b5bc-216ea67369ea_2322x1050.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;benchmarks&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9f4f4cde-4ecd-4272-b5bc-216ea67369ea_2322x1050.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:658,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;benchmarks&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;658&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!Hub9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f4f4cde-4ecd-4272-b5bc-216ea67369ea_2322x1050.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Hub9!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f4f4cde-4ecd-4272-b5bc-216ea67369ea_2322x1050.jpeg 424w, https://substackcdn.com/image/fetch/$s_!Hub9!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f4f4cde-4ecd-4272-b5bc-216ea67369ea_2322x1050.jpeg 848w, https://substackcdn.com/image/fetch/$s_!Hub9!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f4f4cde-4ecd-4272-b5bc-216ea67369ea_2322x1050.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!Hub9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f4f4cde-4ecd-4272-b5bc-216ea67369ea_2322x1050.jpeg 1456w&quot; title=&quot;benchmarks&quot; width=&quot;1456&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;div&gt;
   &lt;hr/&gt;
  &lt;/div&gt;
  &lt;p&gt;
   In the rest of the issue we highlight the long-tail of models, which again highlights the sweeping approach we’ve seen throughout the year from Qwen, but with continuing support from other rising Chinese labs. One of the sad things in this issue is that there are actually 0 datasets that cleared our bar of relevance. Open data continues to be in a very precarious position.
  &lt;/p&gt;
  &lt;h3&gt;
   &lt;strong&gt;
    Models
   &lt;/strong&gt;
  &lt;/h3&gt;
  &lt;h4&gt;
   &lt;strong&gt;
    Flagship
   &lt;/strong&gt;
  &lt;/h4&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Instruct&quot; rel=&quot;&quot;&gt;
       Qwen3-Next-80B-A3B-Instruct
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/Qwen&quot; rel=&quot;&quot;&gt;
      Qwen
     &lt;/a&gt;
     &lt;span&gt;
      : Of course, Qwen is also exploring different architectures, releasing a LLM with hybrid attention, consisting of Gated DeltaNet and Gated Attention. This model is trained on over 15T tokens and could be the groundwork for the next generation of Qwen models. Junyang Lin writes in a tweet about this series:
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    Qwen3-Next, or to say, a preview of our next generation (3.5?) is out!
   &lt;/p&gt;
   &lt;p&gt;
    This time we try to be bold, but actually we have been doing experiments on hybrid models and linear attention for about a year. We believe that our solution should be at least a stable and solid solution to new model architecture for super long context!
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/mistralai/Magistral-Small-2509&quot; rel=&quot;&quot;&gt;
       Magistral-Small-2509
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/mistralai&quot; rel=&quot;&quot;&gt;
      mistralai
     &lt;/a&gt;
     &lt;span&gt;
      : An update to the reasoning model by Mistral.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/meituan-longcat/LongCat-Flash-Thinking&quot; rel=&quot;&quot;&gt;
       LongCat-Flash-Thinking
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/meituan-longcat&quot; rel=&quot;&quot;&gt;
      meituan-longcat
     &lt;/a&gt;
     &lt;span&gt;
      : Yes, the Chinese Doordash continues to release models. This time, they drop the reasoning version of their MoE, coming with an interesting
     &lt;/span&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2509.18883&quot; rel=&quot;&quot;&gt;
      tech report
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> The State of Open Models </title>
<link>https://www.interconnects.ai/p/state-of-open-models-2025</link>
<pubDate>Thu, 16 Oct 2025 14:08:52 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   This talk covers everything that’s happened this year in the open model landscape — DeepSeek kickstarting the Chinese open model norms, Llama’s fade, Qwen’s dominance, GPT-OSS — and what comes next. It is my attempt to share what people need to know about where open models are heading, building on all of my research here at Interconnects and in my day job of training these models, in order to help us take the actions we need to steer it in a better direction.
  &lt;/p&gt;
  &lt;p&gt;
   I strongly recommend watching (or listening, as it’s in the podcast feed) if any of the discussions around open models or Chinese AI impacts your decision making. This felt like one of the better talks I’ve given in a bit and I’m excited to keep expanding my coverage here.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    You can click through the slides
   &lt;/span&gt;
   &lt;a href=&quot;https://docs.google.com/presentation/d/1f1Et0Mz8zb1yVCnCgdYSy4tAa0Kv_gKT4wPEg1XPdUA/edit?usp=sharing&quot; rel=&quot;&quot;&gt;
    here
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/state-of-open-models-2025?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/state-of-open-models-2025?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Thanks to the organizers of The Curve for inviting me (and encouraging me to give this talk), and for permission to post this video.
  &lt;/p&gt;
  &lt;p&gt;
   EDIT: I noticed sometimes the audio jumps weirdly, not sure what caused it (from slideslive export, raw is here: https://slideslive.com/39046297/open-models-in-2025-stakes-state-and-strategy)
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Chapters
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    00:00 2025 so far
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    05:53 China takes the lead
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    15:54 What comes next
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    21:20 What we should do
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    25:00 Q &amp; A
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   (Podcast feed / Audio only version trims 7 seconds of silence to start)
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    References &amp; Recommended Reading
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://atomproject.ai/&quot; rel=&quot;&quot;&gt;
      The ATOM Project
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/on-chinas-open-source-ai-trajectory&quot; rel=&quot;&quot;&gt;
      On China’s open-source community &amp; trajectory
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/chinas-top-19-open-model-labs&quot; rel=&quot;&quot;&gt;
      Ranking China’s open AI labs
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/gpt-oss-openai-validates-the-open&quot; rel=&quot;&quot;&gt;
      On GPT-OSS
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/t/artifacts-log&quot; rel=&quot;&quot;&gt;
      Recent open models
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/thoughts-on-the-curve&quot; rel=&quot;&quot;&gt;
      More on The Curve conference
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   Of course, you can watch on YouTube:
  &lt;/p&gt;
  &lt;div data-attrs=&#x27;{&quot;videoId&quot;:&quot;FUcilE5Gx_0&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}&#x27; data-component-name=&quot;Youtube2ToDOM&quot;&gt;
   &lt;div&gt;
    &lt;iframe allow=&quot;autoplay; fullscreen&quot; allowautoplay=&quot;true&quot; allowfullscreen=&quot;true&quot; frameborder=&quot;0&quot; gesture=&quot;media&quot; height=&quot;409&quot; loading=&quot;lazy&quot; src=&quot;https://www.youtube-nocookie.com/embed/FUcilE5Gx_0?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0&quot; width=&quot;728&quot;&gt;
    &lt;/iframe&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    Listen on
   &lt;/span&gt;
   &lt;a href=&quot;https://podcasts.apple.com/us/podcast/interconnects-audio/id1719552353&quot; rel=&quot;&quot;&gt;
    Apple Podcasts
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://open.spotify.com/show/2UE6s7wZC4kiXYOnWRuxGv&quot; rel=&quot;&quot;&gt;
    Spotify
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.youtube.com/@interconnects&quot; rel=&quot;&quot;&gt;
    YouTube
   &lt;/a&gt;
   &lt;span&gt;
    , and
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/podcast&quot; rel=&quot;&quot;&gt;
    where ever you get your podcasts
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Thoughts on The Curve </title>
<link>https://www.interconnects.ai/p/thoughts-on-the-curve</link>
<pubDate>Tue, 07 Oct 2025 12:03:23 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   I spent the weekend debating AI timelines, among other things, at The Curve conference. This translates as spending the weekend thinking about the trajectory of AI progress with a mix of DC and SF types. This is a worthwhile event that served as a great, high-bandwidth way to check in on timelines and expectations of the AI industry.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/thoughts-on-the-curve?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/thoughts-on-the-curve?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;h2&gt;
   &lt;strong&gt;
    Updating timelines
   &lt;/strong&gt;
  &lt;/h2&gt;
  &lt;p&gt;
   My most striking takeaway is that the AI 2027 sequence of events, from AI models automating research engineers to later automating AI research, and potentially a singularity if your reasoning is so inclined, is becoming a standard by which many debates on AI progress operate under and tinker with. It’s good that many people are taking the long term seriously, but there’s a risk in so many people assuming a certain sequence of events is a sure thing and only debating the timeframe by which they arrive.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    I’ve
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/brakes-on-an-intelligence-explosion?utm_source=publication-search&quot; rel=&quot;&quot;&gt;
    documented my views
   &lt;/a&gt;
   &lt;span&gt;
    on the near term of AI progress and not much has changed, but through repetition I’m developing a more refined version of the arguments. I add this depth to my takes in this post.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I think automating the “AI Research Engineer (RE)” is doable in the 3-7 year range — meaning the person that takes a research idea, implements it, and compares it against existing baselines is entirely an AI that the “scientists” will interface with.
  &lt;/p&gt;
  &lt;p&gt;
   In some areas the RE is arguably already automated. Within 2 years a lot of academic AI research engineering will be automated with the top end of tools — I’m not sure academics will have access to these top end of tools but that is a separate question. An example I would give is coming up with a new optimizer and testing it on a series of ML baselines from 100M to 10B parameters. At this time I don’t expect the models to be able to implement the newest problems the frontier labs are facing alone. I also expect academics to be fully priced out from these tools.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Within 1-3 years we’ll have tools that make
   &lt;/span&gt;
   &lt;em&gt;
    existing
   &lt;/em&gt;
   &lt;span&gt;
    REs unbelievably productive (80-90% automated), but there are still meaningful technical bottlenecks that are solvable but expensive. The compute increase per available user has a ceiling too. Labs will be spending $200k+ per year per employee on AI tools easily (ie the inference cost), but most consumers will be at tiers of $20k or less due to compute scarcity.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Within 3-4 years the augmented research engineers will be able to test any idea that the scientists come up with at the frontier labs, but many complex system problems will need some (maybe minimal) amount of human oversight. Examples would include modifying RL implementations for extremely long horizon tasks or wacky new ideas on continual learning. This is so far out that the type of research idea almost isn’t worth speculating on.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    These long timelines are strongly based on the fact that the category of research engineering is too broad. Some parts of the RE job will be fully automated next year, and more the next.
   &lt;/span&gt;
   &lt;strong&gt;
    To check the box of automation the entire role needs to be replaced.
   &lt;/strong&gt;
   &lt;span&gt;
    What is more likely over the next few years, each engineer is doing way more work and the job description evolves substantially. I make this callout on full automation because it is required for the distribution of outcomes that look like a singularity due to the need to remove the human bottleneck for an ever accelerating pace of progress. This is a point to reinforce that I am currently confident in a singularity not happening.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
  &lt;/div&gt;
  &lt;p&gt;
   Up-skilling employees as their roles become irrelevant creates a very different dynamic. The sustained progress on code performance over the next few years will create a constant feeling of change across the technology industry. The range of performance in software is very high and it is possible to perceive relatively small incremental improvements.
  &lt;/p&gt;
  &lt;p&gt;
   These are very complex positions to hold, so they’re not that useful as rhetorical devices. Code is on track to being solved, but the compute limits and ever increasing complexity of codebases and projects (ie. LLMs) is going to make the dynamic very different than the succinct assumptions of AI 2027.
  &lt;/p&gt;
  &lt;p&gt;
   To reiterate, the most important part of automation in the discussion is often neglected. To automate someone you need to outcompete the pairing of a human with the tool too.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Onto the even trickier argument in the AI 2027 standard — automating AI research altogether. At the same time as the first examples of AI systems writing accepted papers at
   &lt;/span&gt;
   &lt;a href=&quot;https://sakana.ai/ai-scientist-first-publication/&quot; rel=&quot;&quot;&gt;
    notable
   &lt;/a&gt;
   &lt;span&gt;
    AI
   &lt;/span&gt;
   &lt;a href=&quot;https://www.intology.ai/blog/zochi-acl&quot; rel=&quot;&quot;&gt;
    venues
   &lt;/a&gt;
   &lt;span&gt;
    , I’m going to be here arguing that full automation of AI research isn’t coming anytime soon. It’s daunting to try and hold (and explain) this position, and it relies on all the messy firsthand knowledge of science that I have and how it is different in academia versus frontier AI labs.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   For one, the level and type of execution at frontier labs relative to academic research is extremely different. Academia also has a dramatically higher variance in quality of work that is accepted within the community. For this reason, we’re going to be seeing incredible disruption at standard academic venues in the very near future, but the nature of science at frontier labs will remain heavily intertwined with human personalities.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Models will be good at some types of science, such as taking two existing fields and merging ideas and seeing what happens, but awful at what I consider to be the most
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/deep-research-information-vs-insight-in-science&quot; rel=&quot;&quot;&gt;
    idolized version of science
   &lt;/a&gt;
   &lt;span&gt;
    , being immersed in the state of the art and having a brilliant insight that makes anywhere from a ripple causing small performance gain to a tsunami reshaping the field.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I don’t think AI will fully automate our current notion of an AI researcher in the next 5-10 years, but it could reshape what science means altogether and make that role far less relevant to progress.
  &lt;/p&gt;
  &lt;p&gt;
   The researchers grinding out new datasets at frontier labs will have dramatic help on data processing scripts. The researchers coming up with new algorithmic ideas will not expand the rate at which they come up with ideas too much, but their ability to test them is far higher.
  &lt;/p&gt;
  &lt;p&gt;
   A large part of science is a social marketplace of ideas. Convincing your colleagues that you are right and to help you double down on it is not going to change in its core nature. Everyone will have superpowers on making evidence to support their claims, but the relative power there stays the same.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    At a dinner during The Curve I went through a lot of these points with
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/ryanpgreenblatt?lang=en&quot; rel=&quot;&quot;&gt;
    Ryan Greenblatt
   &lt;/a&gt;
   &lt;span&gt;
    , Chief Scientist at Redwood Research, and a point he made stuck with me. He summarized my points as thinking the increase in performance from these largely engineering tooling improvements will be equalled out by challenges of scaling compute, so the resulting progress will feel much more linear rather than exponential. A lot of our discussions on automation we agree on, with slightly different timelines, but it didn’t feel like it captured my entire point of view.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   What is missing is that I expect an inherent slowdown as our AI models get more complicated. Our models today needs tools, more complex serving systems, products to wrap them, and so on. This is very different than the age when just model weights were needed for the cutting edge of AI. There’s an inevitable curse of complexity, a death by a thousand cuts, that is going to add on top of the obvious compute costs to slow down progress.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    2026 will be a big year on the compute rollout front, and shipping meaningful improvements to users will be essential to funding the progress that comes after. I’m not sure the economy can keep shifting even more of its weight behind AI progress, where most people bought into fast timelines think of it as a default position. Peter Wildeford
   &lt;/span&gt;
   &lt;a href=&quot;https://peterwildeford.substack.com/p/openai-nvidia-and-oracle-breaking&quot; rel=&quot;&quot;&gt;
    wrote a summary
   &lt;/a&gt;
   &lt;span&gt;
    of the situation that I resonate with:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    Here’s how I think the AI buildout will go down.
   &lt;/p&gt;
   &lt;p&gt;
    &lt;span&gt;
     Currently the world doesn’t have any operational 1GW+ data centers. However, it is very likely we will see fully operational 1GW data centers before
    &lt;/span&gt;
    &lt;strong&gt;
     mid-2026
    &lt;/strong&gt;
    &lt;span&gt;
     . This likely will be a part of 45-60GW of total compute across Meta, Microsoft, Amazon/AWS/Anthropic, OpenAI/Oracle, Google/DeepMind, and xAI.
    &lt;/span&gt;
   &lt;/p&gt;
   &lt;p&gt;
    My median expectation is these largest ~1GW data center facilities will hold ~400,000-500,000 Nvidia Blackwell chips and be used to train ~4e27 FLOP model sometime before the end of 2027. Such a model would be 10x larger than the largest model today and 100x larger than GPT-4. Each individual 1GW facility would cost ~$40B to manufacture, with ~$350B total industry spend across 2026.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   He continues with estimates for 2028, and saying he’s fuzzy on 2029, but my fuzziness cuts in a bit earlier depending on adoption and performance across the AI industry.
  &lt;/p&gt;
  &lt;p&gt;
   Where I feel like in the long run it’ll look like a very consistent pace of progress, that feels like a bunch of big jumps and periods of stagnation in the short-term. I have fairly large error bars on how the price of intelligence — and therefore adoption — is going to evolve over the next 2-4 years, with it obviously becoming far cheaper over the following decades.
  &lt;/p&gt;
  &lt;p&gt;
   As for my recent articles on timelines and key debates in the field, I encourage people to comment and dig in on what I wrote below.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   &lt;strong&gt;
    Other thoughts
   &lt;/strong&gt;
  &lt;/h2&gt;
  &lt;p&gt;
   Something crazy about this conference is no one is talking about how the models actually work or are trained, and everyone here is totally convinced that AGI is coming soon.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    One of my new friends at the conference described this tendency as “an obsession with the problem.” This is a feeling that many AI obsessors are more interested in where the technology is going rather than how or what exactly it is going to be.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;a data-attrs=&#x27;{&quot;name&quot;:&quot;Helen Toner&quot;,&quot;id&quot;:1591604,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F504a525a-715f-467c-a4c3-b024c88cbf45_2373x2209.jpeg&quot;,&quot;uuid&quot;:&quot;2e098426-6e63-4dd3-8029-d7cd8620af13&quot;}&#x27; data-component-name=&quot;MentionUser&quot; href=&quot;https://open.substack.com/users/1591604-helen-toner?utm_source=mentions&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;
    Helen Toner
   &lt;/a&gt;
  &lt;/div&gt;
  &lt;span&gt;
   gave a great talk at The Curve related to this, arguing how the current and future jaggedness of AI — the fact that similarly difficult tasks when assigned to a human will either be easily mastered by AI or barely showing any competence (her will appear later on her
  &lt;/span&gt;
  &lt;a href=&quot;https://helentoner.substack.com/&quot; rel=&quot;&quot;&gt;
   great Substack
  &lt;/a&gt;
  &lt;span&gt;
   ). It is the idea that AI capabilities evolve highly randomly across potentially similar tasks.
  &lt;/span&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!EUbq!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b573d1-f656-46ca-8dc3-c9d058f7db34_1308x1512.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!EUbq!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b573d1-f656-46ca-8dc3-c9d058f7db34_1308x1512.png 424w, https://substackcdn.com/image/fetch/$s_!EUbq!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b573d1-f656-46ca-8dc3-c9d058f7db34_1308x1512.png 848w, https://substackcdn.com/image/fetch/$s_!EUbq!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b573d1-f656-46ca-8dc3-c9d058f7db34_1308x1512.png 1272w, https://substackcdn.com/image/fetch/$s_!EUbq!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b573d1-f656-46ca-8dc3-c9d058f7db34_1308x1512.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d8b573d1-f656-46ca-8dc3-c9d058f7db34_1308x1512.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1512,&quot;width&quot;:1308,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:186564,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/175380285?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b573d1-f656-46ca-8dc3-c9d058f7db34_1308x1512.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;1512&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!EUbq!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b573d1-f656-46ca-8dc3-c9d058f7db34_1308x1512.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!EUbq!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b573d1-f656-46ca-8dc3-c9d058f7db34_1308x1512.png 424w, https://substackcdn.com/image/fetch/$s_!EUbq!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b573d1-f656-46ca-8dc3-c9d058f7db34_1308x1512.png 848w, https://substackcdn.com/image/fetch/$s_!EUbq!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b573d1-f656-46ca-8dc3-c9d058f7db34_1308x1512.png 1272w, https://substackcdn.com/image/fetch/$s_!EUbq!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b573d1-f656-46ca-8dc3-c9d058f7db34_1308x1512.png 1456w&quot; width=&quot;1308&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    This original figure on jaggedness comes from
   &lt;/span&gt;
   &lt;a href=&quot;https://www.hbs.edu/ris/Publication%20Files/24-013_d9b45b68-9e74-42d6-a1c6-c72fb70c7282.pdf&quot; rel=&quot;&quot;&gt;
    work
   &lt;/a&gt;
   &lt;span&gt;
    with the popular AI Substacker Ethan Mollick.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The relation of Helen’s talk is that she gets many forms of arguments that only the endpoint of AI matters, but that doesn’t account for the messiness of the trajectory and how unsettling that could be for the world.
  &lt;/p&gt;
  &lt;p&gt;
   I agree with Helen.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    One of the things that I am confident will exist in about two years is a Sora 2 style model that can run on a MacBook without copyright, personal opt-in, or other safety filters. On this,
   &lt;/span&gt;
   &lt;a href=&quot;https://epoch.ai/data-insights/consumer-gpu-model-gap&quot; rel=&quot;&quot;&gt;
    Epoch AI has a wonderful plot
   &lt;/a&gt;
   &lt;span&gt;
    showing that local models lag behind in capabilities by a fixed amount of time:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!HLm5!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16e0afde-73fd-4e25-9cdb-b52d694ab092_1586x1004.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!HLm5!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16e0afde-73fd-4e25-9cdb-b52d694ab092_1586x1004.jpeg 424w, https://substackcdn.com/image/fetch/$s_!HLm5!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16e0afde-73fd-4e25-9cdb-b52d694ab092_1586x1004.jpeg 848w, https://substackcdn.com/image/fetch/$s_!HLm5!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16e0afde-73fd-4e25-9cdb-b52d694ab092_1586x1004.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!HLm5!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16e0afde-73fd-4e25-9cdb-b52d694ab092_1586x1004.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;Image&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/16e0afde-73fd-4e25-9cdb-b52d694ab092_1586x1004.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:922,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;922&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!HLm5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16e0afde-73fd-4e25-9cdb-b52d694ab092_1586x1004.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!HLm5!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16e0afde-73fd-4e25-9cdb-b52d694ab092_1586x1004.jpeg 424w, https://substackcdn.com/image/fetch/$s_!HLm5!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16e0afde-73fd-4e25-9cdb-b52d694ab092_1586x1004.jpeg 848w, https://substackcdn.com/image/fetch/$s_!HLm5!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16e0afde-73fd-4e25-9cdb-b52d694ab092_1586x1004.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!HLm5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16e0afde-73fd-4e25-9cdb-b52d694ab092_1586x1004.jpeg 1456w&quot; title=&quot;Image&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    With trends like this, it is so obvious that we need to stay on the front foot of open models and not reacting to international parties that are far harder to predict and engage with. This is where I get renewed motivation for
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/the-american-deepseek-project&quot; rel=&quot;&quot;&gt;
    American DeepSeek
   &lt;/a&gt;
   &lt;span&gt;
    /
   &lt;/span&gt;
   &lt;a href=&quot;https://www.atomproject.ai/&quot; rel=&quot;&quot;&gt;
    The ATOM Project
   &lt;/a&gt;
   &lt;span&gt;
    . For example, I still get many adamant questions that we should consider banning open models altogether. The state of discourse, study, investment, and everything in between on open models in the U.S. is still in a quite underdeveloped state.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    China’s rise in open models was something I expected to be a bigger topic at the conference, but it seemed like it was too orthogonal to the overall pace of progress to be front of mind. There were many discussions of the Chinese chip ecosystem, but less on what it enables. Not focusing on this could have costly geopolitical consequences as we cede ownership of a global standard to China. This was a large theme of my talk. The recording will be posted here soon and the slides for my talk are
   &lt;/span&gt;
   &lt;a href=&quot;https://docs.google.com/presentation/u/1/d/1f1Et0Mz8zb1yVCnCgdYSy4tAa0Kv_gKT4wPEg1XPdUA/edit?usp=sharing&quot; rel=&quot;&quot;&gt;
    here
   &lt;/a&gt;
   &lt;span&gt;
    (credit for Florian Brand who helps me with open model analysis here for feedback on the slides). Otherwise:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     These messages are very important and I will work to spend a bit more time engaging with the communities they touch and mastering this type of talk (and analysis)
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     More people should work in the area, it’s crazy it has just fallen on me where it is my side hustle.
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   For now, I’m just landing at the conference on language modeling (COLM) in Montreal, so I may have some technical hot takes to share later this week!
  &lt;/p&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> ChatGPT: The Agentic App </title>
<link>https://www.interconnects.ai/p/the-agentic-app</link>
<pubDate>Tue, 30 Sep 2025 13:03:22 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    Ever since ChatGPT exploded in popularity, there has been a looming “how” to its monetization plans. Much has been said about shopping and advertising as the likely paths, especially with Fidji Simo
   &lt;/span&gt;
   &lt;a href=&quot;https://openai.com/index/leadership-expansion-with-fidji-simo/&quot; rel=&quot;&quot;&gt;
    joining
   &lt;/a&gt;
   &lt;span&gt;
    as CEO of Applications under Sam Altman.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Advertising as a business model for AI is logical but difficult to personalize and specialize. We know tons of people spend a lot of time using AI models, but how do you best get the sponsored content into the outputs? This is an open technical problem, with early efforts from the likes of
   &lt;/span&gt;
   &lt;a href=&quot;https://www.theinformation.com/articles/perplexitys-commerce-ads-experiments-stuck-neutral&quot; rel=&quot;&quot;&gt;
    Perplexity falling short
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/the-agentic-app#footnote-1-174879663&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     1
    &lt;/a&gt;
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Shopping is another,
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/the-agentic-app#footnote-2-174879663&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     2
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    but the questions have long been whether AI models actually have the precision to find the items you want, to learn exactly what you love, and to navigate the web to handle all the corner cases of checkouts. These reflect a need for increased capabilities on known AI benchmarks, rather than inventing a new way of serving ads.
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/openais-o3-over-optimization-is-back&quot; rel=&quot;&quot;&gt;
    OpenAI’s o3
   &lt;/a&gt;
   &lt;span&gt;
    model was a major step up in search functionality, showing it was viable; the integration was either a business problem — where OpenAI had to make deals — or an AI one — where ChatGPT wasn’t good enough at managing websites for you.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/the-agentic-app?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/the-agentic-app?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Yesterday, ChatGPT launched its first integrated shopping push with
   &lt;/span&gt;
   &lt;em&gt;
    &lt;a href=&quot;https://openai.com/index/buy-it-in-chatgpt/&quot; rel=&quot;&quot;&gt;
     Buy It in ChatGPT
    &lt;/a&gt;
   &lt;/em&gt;
   &lt;span&gt;
    , a simple checkout experience, and an integrated commerce backend built on the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.agenticcommerce.dev/&quot; rel=&quot;&quot;&gt;
    Agentic Commerce Protocol
   &lt;/a&gt;
   &lt;span&gt;
    (ACP)
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/the-agentic-app#footnote-3-174879663&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     3
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    . The announcement comes with the perfect partners to complement the strengths of OpenAI’s current models.
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/the-agentic-app#footnote-4-174879663&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     4
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    GPT-5-Thinking is the best at finding niche content on the web, and ChatGPT’s launch partner for shopping is Shopify (*soon, Etsy is available today), the home to the long tail of e-commerce merchants of niche specialties. If this works, it will let users actively uncover exactly what they are looking for — from places that were often hard to impossible to find on Google.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    This synergy is a theme we’ll see reoccur in other agents of the future. The perfect model doesn’t make a useful application unless it has the information or sandbox it needs to
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/thinking-searching-and-acting&quot; rel=&quot;&quot;&gt;
    think, search, and act
   &lt;/a&gt;
   &lt;span&gt;
    . The crucial piece that is changing is that where models act is just as important as the weights themselves — in the case of shopping, it is the network of stores with their own rankings and API.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The ACP was built in collaboration with Stripe, and both companies stand to benefit from this. Stripe wants more companies to build on the ACP so that its tools become the “
   &lt;/span&gt;
   &lt;a href=&quot;https://stripe.com/blog/developing-an-open-standard-for-agentic-commerce&quot; rel=&quot;&quot;&gt;
    open standard for agentic payments
   &lt;/a&gt;
   &lt;span&gt;
    ” and OpenAI wants the long-tail of stores to adopt it so they can add them to their ever-growing internal recommendation (or search) engine. The business model is simple, as OpenAI says “Merchants pay a small fee on completed purchases.” OpenAI likely takes a larger share than Stripe, and it is a share that can grow as their leverage increases over shoppers.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I’m cautiously optimistic about this. Finding great stuff to buy on the web is as hard as it has ever been. Users are faced with the gamification of Google search for shopping and the enshittification of the physical goods crowding out Amazon. Many of the best items to buy are found through services like Meta’s targeted ads, but the cost of getting what you want should not be borne through forced distraction.
  &lt;/p&gt;
  &lt;p&gt;
   OpenAI will not be immune to the forces that drove these companies to imperfect offerings, but they’ll come at them with a fresh perspective on recurring issues in technology. If this works for OpenAI, they have no competitor. They have a distribution network of nearly 1B weekly users and no peer company ready to serve agentic models at this scale. Yes, Google can change its search feed, but the thoroughness of models like GPT-5 Thinking is on a totally different level than Google search. This agentic model is set up to make ChatGPT the one Agentic App across all domains.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The idea of an agentic model, and really the GPT-5 router itself, shows us how the grand idea of one giant model that’s the best for every conceivable use-case is crumbling. OpenAI only chooses the more expensive thinking model when it deems a free user to need it and they have an entirely different model for their coding products. On the other hand, Claude released their latest model,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.anthropic.com/news/claude-sonnet-4-5&quot; rel=&quot;&quot;&gt;
    Claude 4.5 Sonnet
   &lt;/a&gt;
   &lt;span&gt;
    , yesterday as well, optimizing their coding peak performance and speed yet again — they have no extended model family.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The reality that different models serve very different use-cases and how AI companies need to decide and commit to a certain subset of them for their development points to a future with a variety of model providers.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Where
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/coding-as-the-epicenter-of-ai-progress&quot; rel=&quot;&quot;&gt;
    coding is where you can feel the frontier
   &lt;/a&gt;
   &lt;span&gt;
    of AI’s raw intelligence or capabilities, and Anthropic has turned their
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/claude-4-and-anthropics-bet-on-code&quot; rel=&quot;&quot;&gt;
    entire development towards it
   &lt;/a&gt;
   &lt;span&gt;
    , the type of model that is needed for monetization of a general consumer market could be very different. This is the web-agent that OpenAI has had the industry-leading version of for about 6 months.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Specialization is making the AI market far more interesting, as companies like OpenAI and Google have been in lockstep with their offerings for years. Every company would drop the same model modalities with approximately the same capabilities. Now, as hill-climbing benchmarks are no longer providing immediate user value, especially in text domains, the vision for each AI company is more nuanced. I predicted this earlier in the summer, in my
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/summertime-outlook-o3s-novelty-coming?utm_source=publication-search&quot; rel=&quot;&quot;&gt;
    post
   &lt;/a&gt;
   &lt;span&gt;
    on what comes next:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    &lt;span&gt;
     This is a different path for the industry and will take a different form of messaging than we’re used to. More releases are going to look like
    &lt;/span&gt;
    &lt;a href=&quot;https://www.interconnects.ai/p/claude-4-and-anthropics-bet-on-code&quot; rel=&quot;&quot;&gt;
     Anthropic’s Claude 4
    &lt;/a&gt;
    &lt;span&gt;
     , where the benchmark gains are minor and the real world gains are a big step.
    &lt;/span&gt;
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   What I missed is that this applies downward pressure on the number of models labs will release — the value can be more in the integrations and applications than the model itself. Expect releases like today, where Claude released Claude Sonnet 4.5 along with version 2 of Claude Code. The period will still be busy as the industry is on the tail end of the low hanging fruit provided by reasoning models, but over time the hype of model releases themselves will be harder to conjure.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
   Let’s consider the applications that are rolling out today on top of different models. If you haven’t pushed the limits of GPT-5-Thinking, and better yet GPT-5-Pro, for search you really need to, it’s a transformative way of using compute that can find many buried corners of the web. In terms of untapped model capability value, the abilities of search-heavy thinking models like GPT-5 seem far higher than coding agents, which are obviously heavily used. Search-heavy models are an entirely new use, where coding models were the first widespread LLM-based product. As coding agents become more autonomous, they’ll continue to flex and mold a new form for the software industry, but this will be a slow co-evolution.
  &lt;/p&gt;
  &lt;p&gt;
   OpenAI is going to focus on its vertical Agentic App where Anthropic (and likely Gemini with Google Cloud) are going to power the long-tail of AI applications reshaping the web and the rest of work. OpenAI will only expand from here. Email, scheduling, travel bookings, and more everyday digital tasks are surely on their roadmap. Their biggest competitor is themselves — and whether their vision can be crafted into something people actually use. If shopping doesn’t work out as the vertical that lets them realize their valuation, they’re positioned to keep trying more. OpenAI has both the lead in the variety of models that power these agentic information tasks and the user base to incentivize companies to collaborate with them.
  &lt;/p&gt;
  &lt;p&gt;
   The application paradigm that dominated the mobile era is going to rebound. AI applications started in a form where the user needed to be heavily involved in the work process. The first beneficiaries of this were IDEs and terminal tools. Both of these workplaces allow in-depth and detailed inspection of the process and results. The cutting edge of AI will still work there, but the long tail of casual use will all shift to the standard mode of applications — siloed, simple, and scalable in the cloud. The simpler an AI application is, the wider its potential audience.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    With this addition of shopping, OpenAI is
   &lt;/span&gt;
   &lt;a href=&quot;https://www.wired.com/story/openai-launches-sora-2-tiktok-like-app/&quot; rel=&quot;&quot;&gt;
    poised to launch a standalone TikTok-style app
   &lt;/a&gt;
   &lt;span&gt;
    with the release of its next video generation model, Sora 2, soon after
   &lt;/span&gt;
   &lt;a href=&quot;https://about.fb.com/news/2025/09/introducing-vibes-ai-videos/&quot; rel=&quot;&quot;&gt;
    Meta launched Vibes
   &lt;/a&gt;
   &lt;span&gt;
    in their Meta AI app for only AI generated videos with a specific theme to start.  At the same time, OpenAI’s Codex web agent is available in the ChatGPT application, which represents an even bigger change in the nature of software work than the addition of coding agents — it allows real websites, and soon businesses, to be built with only a prompt on your phone.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   In 6-12 months, these agentic applications that feel rough around the edges due to the quality of the AI today, rather than the interface, are going to feel seamless and second-nature to use, despite their complete novelty relative to the past decades of technology.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    If OpenAI is positioning itself to be The Agentic App, this also opens the door to the near future where many applications we use today shift to an agentic era
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/the-agentic-app#footnote-5-174879663&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     5
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    . Want to schedule a meeting with someone? Let the Google Calendar agent handle that (or some startup that beats them to it). Your email application can find who the next client is and remind them of their appointment. The Banking App will file your taxes in one prompt. The list of these is infinite and across a wide spectrum of difficulty. OpenAI wants to be the one app, The Agentic App, that serves all of these, and the rest of the industry is racing to master their specific vertical before OpenAI gets there.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/the-agentic-app#footnote-anchor-1-174879663&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     &lt;span&gt;
      I don’t cover OpenAI’s new
     &lt;/span&gt;
     &lt;a href=&quot;https://openai.com/index/introducing-chatgpt-pulse/&quot; rel=&quot;&quot;&gt;
      Pulse
     &lt;/a&gt;
     &lt;span&gt;
      feature in this post, which is a sort of algorithmic content feed for ChatGPT, which could be a great place for ads and a surface to practice specializing to users, which is needed for shopping results. My initial Pulse examples were fairly heavy in slop, and this is only available to Pro users, where shopping is universal. We’ll have to wait longer on Pulse as a feature.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/the-agentic-app#footnote-anchor-2-174879663&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    2
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     &lt;span&gt;
      SemiAnalysis had a
     &lt;/span&gt;
     &lt;a href=&quot;https://semianalysis.com/2025/08/13/gpt-5-ad-monetization-and-the-superapp/&quot; rel=&quot;&quot;&gt;
      great article
     &lt;/a&gt;
     &lt;span&gt;
      in this space, covering why the router is so important with OpenAI’s free user base and a similar view of the “ChatGPT SuperApp.”
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;p&gt;
     They went so far as to say that ChatGPT will spend more compute on more valuable queries, but that is more dystopian than I see happening in the near future.
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/the-agentic-app#footnote-anchor-3-174879663&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    3
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     If the ACP is a new wave of every backend software for AI being named some “protocol” with the last two initials ending in *CP, à la MCP, this certainly won’t last. Looking briefly under the hood reveals that ACP is fairly complex with many defined functionalities, from discoverability and feeds for merchants to commands for checkout and orders that interface with digital inventories and finally payments. MCP, on the other hand, is a simple tool for accessing information.
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/the-agentic-app#footnote-anchor-4-174879663&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    4
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     This does not include their early, and growing, work on ChatGPT customization as well, which will play heavily into shopping.
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/the-agentic-app#footnote-anchor-5-174879663&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    5
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     &lt;span&gt;
      Similar to how Cloudfare is
     &lt;/span&gt;
     &lt;a href=&quot;https://blog.cloudflare.com/content-independence-day-no-ai-crawl-without-compensation/&quot; rel=&quot;&quot;&gt;
      positioning their information services for the agentic web
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Thinking, Searching, and Acting </title>
<link>https://www.interconnects.ai/p/thinking-searching-and-acting</link>
<pubDate>Mon, 22 Sep 2025 15:44:34 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   The weaknesses of today’s best models are far from those of the original ChatGPT — we see they lack speed, we fear superhuman persuasion, and we aspire for our models to be more autonomous. These models are all reasoning models that have long surpassed the original weaknesses of ChatGPT-era language models, hallucinations, total lack of recent information, complete capitulations, and other hiccups that looked like minor forms of delusion laid on top of an obviously spectacular new technology.
  &lt;/p&gt;
  &lt;p&gt;
   Reasoning models today are far more complex than the original chatbots that consisted of standalone model weights (and other lightweight scaffolding such as safety filters). They&#x27;re built on three primitives that&#x27;ll be around for years to come:
  &lt;/p&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Thinking
     &lt;/strong&gt;
     &lt;span&gt;
      : The reasoning traces that enabled inference-time scaling. The &quot;thoughts&quot; of a reasoning model take a
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/the-rise-of-reasoning-machines&quot; rel=&quot;&quot;&gt;
      very different form than those of humans that inspired the terminology
     &lt;/a&gt;
     &lt;span&gt;
      used like Chain of Thought (CoT) or Thinking models.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Searching
     &lt;/strong&gt;
     &lt;span&gt;
      : The ability to request more, specific information from non-parametric knowledge stores designed specifically for the model. This fills the void set by how model weights are static but living in a dynamic world.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Acting
     &lt;/strong&gt;
     &lt;span&gt;
      : The ability for models to manipulate the physical or digital world. Everything from code-execution now to real robotics in the future allow language models to contact reality and overcome their nondeterministic core. Most of these executable environments are going to
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/coding-as-the-epicenter-of-ai-progress&quot; rel=&quot;&quot;&gt;
      build on top of infrastructure for coding agents
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/thinking-searching-and-acting?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/thinking-searching-and-acting?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    These reasoning language models, as a form of technology are going to last far longer than the static model weights that predated and birthed ChatGPT. Sitting just over a year out from the
   &lt;/span&gt;
   &lt;a href=&quot;https://openai.com/index/learning-to-reason-with-llms/&quot; rel=&quot;&quot;&gt;
    release
   &lt;/a&gt;
   &lt;span&gt;
    of OpenAI&#x27;s o1-preview on September 12, 2024, the magnitude of this is important to write in ink. Early reasoning models with astounding evaluation scores were greeted with resounding criticism of “
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/why-reasoning-models-will-generalize&quot; rel=&quot;&quot;&gt;
    they won’t generalize
   &lt;/a&gt;
   &lt;span&gt;
    ,” but that has turned out to be resoundingly false.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    In fact, with OpenAI&#x27;s o3, it only took 3-6 months for these primitives to converge! Still, it took the AI industry more broadly a longer time to converge on this. The most similar follow-up on the search front was
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/grok-4-an-o3-look-alike-in-search&quot; rel=&quot;&quot;&gt;
    xAI&#x27;s Grok 4
   &lt;/a&gt;
   &lt;span&gt;
    and some frontier models such as
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/claude-4-and-anthropics-bet-on-code&quot; rel=&quot;&quot;&gt;
    Claude 4
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;em&gt;
    express
   &lt;/em&gt;
   &lt;span&gt;
    their reasoning model nature in a far more nuanced manner. OpenAI&#x27;s o3 (and GPT-5 Thinking,
   &lt;/span&gt;
   &lt;a href=&quot;https://simonwillison.net/2025/Sep/6/research-goblin/&quot; rel=&quot;&quot;&gt;
    a.k.a. Research Goblin
   &lt;/a&gt;
   &lt;span&gt;
    ) and xAI&#x27;s Grok 4 models seem like a dog determined to chase their goal indefinitely and burn substantial compute along the way. Claude 4 has a much softer touch, resulting in a model that is a bit less adept at search, but almost always returns a faster answer. The long-reasoning traces and tool use can be crafted to fit different profiles, giving us a spectrum of reasoning models.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/next-gen-reasoners&quot; rel=&quot;&quot;&gt;
    taxonomy
   &lt;/a&gt;
   &lt;span&gt;
    that I laid out this summer for next-generation reasoning models — skills for reasoning intelligence, calibration to not overthink, strategy to choose the right solutions, and abstraction to break them down — are the traits that&#x27;ll make a model most functional given this new perspective and agentic world.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div data-component-name=&quot;DigestPostEmbed&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/next-gen-reasoners&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;
   &lt;/a&gt;
  &lt;/div&gt;
  &lt;p&gt;
   The manner of these changes are easy to miss. For one, consider hallucinations, which are an obvious weakness downstream of the stochastic inference innate to the models and their fixed date cutoff. With search, hallucinations are now missing context rather than blatantly incorrect content. Language models are nearly-perfect at copying content and similarly solid at referencing it, but they&#x27;re still very flawed at long-context understanding. Hallucinations still matter, but it’s a very different chapter of the story and will be studied differently depending on if it is for reasoning or non-reasoning language models.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Non-reasoning models still have a crucial part to play in the AI economy due to their efficiency and simplicity. They are
   &lt;/span&gt;
   &lt;em&gt;
    part
   &lt;/em&gt;
   &lt;span&gt;
    of a reasoning model in a way because you can always use the weights without tools and they&#x27;ll be used extensively to undergird the digital economy. At the same time, the
   &lt;/span&gt;
   &lt;strong&gt;
    frontier AI models (and systems) of the coming years will all be reasoning models as presented above — thinking, searching, and acting
   &lt;/strong&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/thinking-searching-and-acting#footnote-1-174200501&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     1
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Language models will get access to more tools of some form, but all of them will be subsets of code or search. In fact, search can be argued to be a form of execution itself, but given the imperative of the underlying information it is best left as its own category.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Another popular discussion with the extremely-long generations of reasoning models has been the idea that maybe more efficient architectures such as
   &lt;/span&gt;
   &lt;a href=&quot;https://deepmind.google/models/gemini-diffusion/&quot; rel=&quot;&quot;&gt;
    diffusion language models
   &lt;/a&gt;
   &lt;span&gt;
    could come to dominate by generating all the tokens in parallel. The (or rather, one) problem here is that they cannot easily integrate tools, such as search or execution, in the same way. These’ll also likely be valuable options in the AI quiver, but barring a true architectural or algorithmic revolution that multiplies the performance of today’s AI models, the efficiency and co-design underway for large transformers will enable the most dynamic reasoning models.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
  &lt;/p&gt;
  &lt;p&gt;
   With establishing what makes a reasoning model complete comes an important mental transition in what it takes to make a good model. Now, the quality of the tools that a model is embedded with is arguably something that can be more straightforward to improve than the model — it just takes substantial engineering effort — and is far harder with open models. The AI “modeling” itself is mostly open-ended research.
  &lt;/p&gt;
  &lt;p&gt;
   Closed models have the benefit of controlling the entire user experience with the stack, where open models need to be designed so that anyone can take the weights off of HuggingFace and easily get a great experience deploying it with open-source libraries like VLLM or SGLang. When it comes to tools used during inference, this means that the models can have a recommended setting that works best, but they may take time to support meaningful generalization with respect to new tools.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    For example, OpenAI can train and serve their models with only one search engine, where I at Ai2 will likely train with one search engine and then release the model into a competitive space of many search products. A space where this can benefit open models could be something like
   &lt;/span&gt;
   &lt;a href=&quot;https://www.anthropic.com/news/model-context-protocol&quot; rel=&quot;&quot;&gt;
    MCP
   &lt;/a&gt;
   &lt;span&gt;
    , where open models are developed innately for a world where we cannot know all the uses of our models, making something like MCP libraries a great candidate for testing. Of course, leading AI laboratories will (or have already started) do this, but the ranking will be different in a priority stack.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Much has been said about tokenomics and costs associated with reasoning models, without taking the tool component into account. There was a very
   &lt;/span&gt;
   &lt;a href=&quot;https://ethanding.substack.com/p/ai-subscriptions-get-short-squeezed?utm_source=multiple-personal-recommendations-email&amp;utm_medium=email&amp;triedRedirect=true&quot; rel=&quot;&quot;&gt;
    popular article
   &lt;/a&gt;
   &lt;span&gt;
    articulating how models are only getting more expensive, with a particular focus on reasoning models using far more tokens. This is overstating a blip, a point in time when serving costs increased by 1000x for models by generating vastly more tokens, but without improved hardware.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The change in cost of reasoning models reflected a one-time step up in most circumstances where the field collectively turned on inference-time scaling by using the same reasoning techniques. At the same time as the reasoning model explosion, the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/i/166556899/scaling-parameters-is-going-to-go-very-slow-for-consumer-models&quot; rel=&quot;&quot;&gt;
    size of models reaching users in parameter count has all but stagnated
   &lt;/a&gt;
   &lt;span&gt;
    . This is due to diminishing returns in quality due to scaling parameters — it’s why OpenAI said
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/gpt-45-not-a-frontier-model&quot; rel=&quot;&quot;&gt;
    GPT 4.5 wasn’t a frontier model
   &lt;/a&gt;
   &lt;span&gt;
    and why Gemini never released their Ultra model class. The same will come for reasoning tokens.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    While diminishing returns are hitting reasoning token amount for serial streams, we’re finally seeing large clusters of Nvidia’s Blackwell GPUs come online. The costs for models seem well on path to level out and then decrease as the industry develops more efficient inference systems — the technology industry is phenomenal at making widely used products far cheaper year over year. The costs that’ll go up are the agents that are enabled by these reasoning models, especially with parallel inference, such as the Claude Code clones or
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/sama/status/1969835407421374910&quot; rel=&quot;&quot;&gt;
    OpenAI’s rumored Pro products
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   What we all need is a SemiAnalysis article explaining how distorted standard tokenomics are for inference with tools and if tools substantially increase variance in implementations. People focus too much on the higher token costs from big models with long context lengths, those are easy to fix with better GPUs, while there are many other costs such as search indices or idle GPU time waiting for tool execution results.
  &lt;/p&gt;
  &lt;p&gt;
   When we look at a modern reasoning model, it is easy to fixate on the thinking token aspects that give the models their name. At the same time, search and execution are such fundamental primitives to modern language models that they can rightfully stand on their own as pillars of modern AI. These are AI systems that substantially depend on the quality of the complex inference stack far more than getting the right YOLO run for the world’s best model weights.
  &lt;/p&gt;
  &lt;p&gt;
   The cause of thinking, searching, and acting all being looped in as a “reasoning model” is that this inference-time scaling with meandering chains of thought was the technological innovation that made both search and execution far more functional. Reasoning was the step change event that set these three as technology standards.
  &lt;/p&gt;
  &lt;p&gt;
   The industry is in its early days of building out fundamental infrastructure to enable them, which manifests as the early days of language model agents. The infrastructure pairs deterministic computing and search with the beauty, power, and flexibility of the probabilistic models we fell in love with via ChatGPT. This reasoning model layer is shaping up to be the infrastructure that underpins the greatest successes of the future technology industry.
  &lt;/p&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/thinking-searching-and-acting#footnote-anchor-1-174200501&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     Barring the unpredictable scientific breakthrough in architecture.
    &lt;/p&gt;
    &lt;p&gt;
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Coding as the epicenter of AI progress and the path to general agents </title>
<link>https://www.interconnects.ai/p/coding-as-the-epicenter-of-ai-progress</link>
<pubDate>Thu, 18 Sep 2025 15:24:28 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   Coding, due to its breadth of use-cases, is arguably the last tractable, general domain of continued progress for frontier models that most people can interface with. This is a bold claim, so let’s consider some of the other crucial capabilities covered in the discourse of frontier models:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Chat
     &lt;/strong&gt;
     &lt;span&gt;
      and the quality of prose written by models has leveled off, other than finetuning to user measures such as
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/sycophancy-and-the-art-of-the-model&quot; rel=&quot;&quot;&gt;
      sycophancy
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://www.interconnects.ai/publish/post/173893588?back=/publish/posts/drafts&quot; rel=&quot;&quot;&gt;
       Mathematics
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;a href=&quot;https://deepmind.google/discover/blog/advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad/&quot; rel=&quot;&quot;&gt;
      has incredible results
     &lt;/a&gt;
     &lt;span&gt;
      , but very few people directly gain from better theoretical mathematics.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      The
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/deep-research-information-vs-insight-in-science&quot; rel=&quot;&quot;&gt;
      AIs’ abilities to do novel
     &lt;/a&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://www.interconnects.ai/p/deep-research-information-vs-insight-in-science&quot; rel=&quot;&quot;&gt;
       science
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      are too unproven to be arguable as a target of hillclimbing.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   Still, coding is a domain where the models are already incredibly useful, and they continue to consistently stack on meaningful improvements. Working daily with AI over the last few years across side projects and as an AI researcher, it has been easy to take these coding abilities for granted because some forms of them have been around for so long. We punt a bug into ChatGPT and it can solve it or autocomplete can tab our way through entire boilerplate.
  &lt;/p&gt;
  &lt;p&gt;
   These use-cases sound benign, and haven’t changed much in that description as they have climbed dramatically in capabilities. Punting a niche problem in 1000+ lines of code to GPT-5-Pro or Gemini Deep Think feels like a very fair strategy. They really can sometimes solve problems that a teammate or I were stuck on for hours to days. We’re progressing through this summarized list of capabilities:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     Function completion: ~2021, original Github CoPilot (Codex)
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Scripting: ~2022, ChatGPT
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Building small projects: ~2025, CLI agents
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Building complex production codebases, ~2027 (estimate, which will vary by the codebase)
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   &lt;span&gt;
    Coding is maybe the only domain of AI use where I’ve felt this slow, gradual improvement. Chat quality has been “good enough” since GPT-4, search showed up and has been remarkable since
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/openais-o3-over-optimization-is-back&quot; rel=&quot;&quot;&gt;
    OpenAI’s o3
   &lt;/a&gt;
   &lt;span&gt;
    . Through all of these more exciting moments, AIs’ coding abilities have just continued to gradually improve.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/coding-as-the-epicenter-of-ai-progress?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/coding-as-the-epicenter-of-ai-progress?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Now, many of us are starting to learn a new way of working with AI through these new command-line code agents. This is the largest increase in AI coding abilities in the last few years. The problem is the increase isn’t in the same domain where most people are used to working with AI, so the adoption of the progress is far slower. New applications are rapidly building users and existing distribution networks barely apply.
  &lt;/p&gt;
  &lt;p&gt;
   The best way to work with them — and I’ll share more examples of what I’ve already built later in this post — is to construct mini projects, whether it’s a new bespoke website or a script. These are fantastic tools for entrepreneurs and researchers who need a way to quickly flesh out an idea. Things that would’ve taken me days to weeks can now be attempted in hours. Within this, the amount of real “looking at the code” that needs to be done is definitely going down. Coding, as an activity done through agents, is having the barriers to entry fully fall down through the same form factor that is giving the act of coding re-found joy.
  &lt;/p&gt;
  &lt;p&gt;
   Why I think a lot of people miss these agents is that the way to use the agents is so different from the marketing of incredible evaluation breakthroughs that the models are reaching. The gap between “superhuman coding” announcements and using an agent for mini projects is obviously big. The best way to use the agents is still mundane and requires careful scoping of context.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    For example, yesterday, on September 17, 2025, OpenAI
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/MostafaRohani/status/1968360976379703569&quot; rel=&quot;&quot;&gt;
    announced
   &lt;/a&gt;
   &lt;span&gt;
    that
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/MostafaRohani/status/1968361268475215881&quot; rel=&quot;&quot;&gt;
    GPT-5 as part of a model system
   &lt;/a&gt;
   &lt;span&gt;
    got a higher score than any human (and
   &lt;/span&gt;
   &lt;a href=&quot;https://deepmind.google/discover/blog/gemini-achieves-gold-level-performance-at-the-international-collegiate-programming-contest-world-finals/&quot; rel=&quot;&quot;&gt;
    Google’s Gemini Deep Think
   &lt;/a&gt;
   &lt;span&gt;
    ) at the
   &lt;/span&gt;
   &lt;a href=&quot;https://worldfinals.icpc.global/2025/&quot; rel=&quot;&quot;&gt;
    ICPC World Finals
   &lt;/a&gt;
   &lt;span&gt;
    , “the premier collegiate programming competition where top university teams from around the world solve complex algorithmic problems.” Here’s what an OpenAI researcher said they did:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    We competed with an ensemble of general-purpose reasoning models; we did not train any model specifically for the ICPC. We had both GPT-5 and an experimental reasoning model generating solutions, and the experimental reasoning model selecting which solutions to submit. GPT-5 answered 11 correctly, and the last (and most difficult problem) was solved by the experimental reasoning model.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   These competitions often get highlighted because they’re “finite time,” so the system must respond in the same fixed time as a human does, but the amount of compute used by GPT-5 or another model here is likely far higher than any user has access to. This is mostly an indication that further ability, which some people call raw intelligence, can be extracted from the models, but most of that is limited by scaffolding and product when used by the general population.
  &lt;/p&gt;
  &lt;p&gt;
   The real story is that these models are delivering increasing value to a growing pool of people.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    For followers of AI, coding with AI models is the easiest way to feel progress. Now that models are so good at chat, it takes very specialized tasks to test the general knowledge of models, or many of the gains are in getting the right answer
   &lt;/span&gt;
   &lt;em&gt;
    faster
   &lt;/em&gt;
   &lt;span&gt;
    than GPT-5-Thinking’s meandering path.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I’m not an expert software engineer and the huge differences between models, and improvements that the individual models and systems are making, have been incredibly obvious.
  &lt;/p&gt;
  &lt;p&gt;
   I’ve said many times how Claude Code (or now Codex) are far better than Cursor Agent, which is in turn far better than Github CoPilot. GitHub CoPilot feels borderline drunk at the wheel. Cursor often feels a little distracted while still being smart, but Claude Code and Codex seem on topic and able to test the best of a model’s intelligence on the problem at hand. Yes, even the best agents often aren’t good enough in complex codebases, but it removes the need to go back and forth countless times in a chat window to see if a model can reach the end of the puzzle for you. These CLI agents can run tests, fix git problems, run local tools, whatever. The scope is constantly growing.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    For the nuanced take of Claude Code vs Codex CLI right now, the answer is expensive. The best has been Claude Code forcing Claude Opus 4.1, but Codex is not far behind and comes in at a much cheaper entry point ($20/month) — Opus requires a $100+/month plan. Codex also has nice features like web search, but it hasn’t been a major differentiator yet in my use.
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/coding-as-the-epicenter-of-ai-progress#footnote-1-173893588&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     1
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The new workflow is to switch to the other agent when one cannot solve the current problem, and let it see the repository with fresh eyes, much like you pasted a question to another chatbot. The agents are just one tab away, just like the competitors for chat.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    In the comparison of Claude, Cursor, and CoPilot above, the crucial component is that all of these agents can be tested with the same Claude 4 Sonnet model. The gaps are just as wide as I stated, highlighting how so many of the gains in coding agents are just in product implementations. A second version is slightly embarrassing for me, but follows as I hadn’t updated my OpenAI Codex code when trying the new GPT-5-Codex model, which resulted in an immediate massive jump in performance by changing it. It’s a new phenomenon to have a domain at the cutting edge of AI
   &lt;/span&gt;
   &lt;em&gt;
    abilities
   &lt;/em&gt;
   &lt;span&gt;
    where the software scaffolding of a model is felt so strongly. Product and prompts matter more than ever and this sensation will expand to more domains.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The
   &lt;/span&gt;
   &lt;em&gt;
    why
   &lt;/em&gt;
   &lt;span&gt;
    of these performance differences — even when using the same model — is worth dwelling on. It’s unlikely that the Claude team is that much better at general software engineering and product design — rather, Anthropic has extensive in-house experience in extracting the most from models. The current shift in models has been about how to take a set of models that are designed for question answering and other single-stream text tasks and break down problems. In my
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/next-gen-reasoners&quot; rel=&quot;&quot;&gt;
    taxonomy on next-generation reasoning models
   &lt;/a&gt;
   &lt;span&gt;
    , I called this ability “abstraction.”
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The need to just slightly shift the model to this task explains OpenAI’s recent specialized model for this,
   &lt;/span&gt;
   &lt;a href=&quot;https://openai.com/index/introducing-upgrades-to-codex/&quot; rel=&quot;&quot;&gt;
    GPT-5-Codex
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/gpt-5-and-bending-the-arc-of-progress&quot; rel=&quot;&quot;&gt;
    GPT-5
   &lt;/a&gt;
   &lt;span&gt;
    was primarily a release about balancing OpenAI’s books with a user base approaching 1B active users in the chat format. GPT-5 is a honed tool for a different job. The evaluation scores are
   &lt;/span&gt;
   &lt;em&gt;
    slightly
   &lt;/em&gt;
   &lt;span&gt;
    better than the general reasoning model for this new GPT-5-Codex, but the main gains are in how behavior is different in coding tasks.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    &lt;strong&gt;
     GPT‑5-Codex adapts how much time it spends thinking more dynamically based on the complexity of the task
    &lt;/strong&gt;
    &lt;span&gt;
     . The model combines two essential skills for a coding agent: pairing with developers in interactive sessions, and persistent, independent execution on longer tasks.
    &lt;/span&gt;
    &lt;strong&gt;
     That means Codex will feel snappier on small, well-defined requests or while you are chatting with it, and will work for longer on complex tasks like big refactors
    &lt;/strong&gt;
    &lt;span&gt;
     . During testing, we&#x27;ve seen GPT‑5-Codex work independently for more than 7 hours at a time on large, complex tasks, iterating on its implementation, fixing test failures, and ultimately delivering a successful implementation.
    &lt;/span&gt;
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   And they included this somewhat confusing plot to showcase this dynamic. I’ve certainly felt these changes when I updated the Codex software and the Codex model.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!M5Wx!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa28589c-4de5-4949-b6b6-d202599d5f72_1487x877.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!M5Wx!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa28589c-4de5-4949-b6b6-d202599d5f72_1487x877.png 424w, https://substackcdn.com/image/fetch/$s_!M5Wx!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa28589c-4de5-4949-b6b6-d202599d5f72_1487x877.png 848w, https://substackcdn.com/image/fetch/$s_!M5Wx!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa28589c-4de5-4949-b6b6-d202599d5f72_1487x877.png 1272w, https://substackcdn.com/image/fetch/$s_!M5Wx!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa28589c-4de5-4949-b6b6-d202599d5f72_1487x877.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fa28589c-4de5-4949-b6b6-d202599d5f72_1487x877.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:859,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:92578,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/173893588?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa28589c-4de5-4949-b6b6-d202599d5f72_1487x877.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;859&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!M5Wx!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa28589c-4de5-4949-b6b6-d202599d5f72_1487x877.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!M5Wx!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa28589c-4de5-4949-b6b6-d202599d5f72_1487x877.png 424w, https://substackcdn.com/image/fetch/$s_!M5Wx!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa28589c-4de5-4949-b6b6-d202599d5f72_1487x877.png 848w, https://substackcdn.com/image/fetch/$s_!M5Wx!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa28589c-4de5-4949-b6b6-d202599d5f72_1487x877.png 1272w, https://substackcdn.com/image/fetch/$s_!M5Wx!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa28589c-4de5-4949-b6b6-d202599d5f72_1487x877.png 1456w&quot; title=&quot;&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   This represents another key problem I presented in my taxonomy — calibration, i.e. not overthinking.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Having specialized models and specialized products for a use case could make people think that they’re narrowing in to make progress, but in OpenAI’s case it is rather that their hands are tied financially to support the main ChatGPT application.
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/claude-4-and-anthropics-bet-on-code&quot; rel=&quot;&quot;&gt;
    Claude has already fully committed to code
   &lt;/a&gt;
   &lt;span&gt;
    . This is due to the size that the space could expand into.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   These “coding” agents are definitely going to be seen as doing far more than writing code. Yes, their primary ability is going to be writing the code itself and executing it, but what that enables is an entirely new way of working with your computer.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    In my post
   &lt;/span&gt;
   &lt;em&gt;
    &lt;a href=&quot;https://www.interconnects.ai/p/contra-dwarkesh-on-continual-learning&quot; rel=&quot;&quot;&gt;
     Contra Dwarkesh on Continual Learning
    &lt;/a&gt;
   &lt;/em&gt;
   &lt;span&gt;
    , I presented a view where agents are going to be given all your digital working context in order to be a research or editorial assistant available 24/7. I’ve begun putting this to use for Interconnects, where I give the agents all of my articles, metadata, interviews, and details, so I can ask them for relevant references and context for future posts. This is very underbaked and early as a project for searching efficiently over my 400K tokens of writing, but I was prompting it a few times to see any interesting references for this post, and it got me something that was useful!
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!Puqb!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e883906-d902-43b4-a8fb-ed48bcf02bb7_1318x1252.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Puqb!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e883906-d902-43b4-a8fb-ed48bcf02bb7_1318x1252.png 424w, https://substackcdn.com/image/fetch/$s_!Puqb!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e883906-d902-43b4-a8fb-ed48bcf02bb7_1318x1252.png 848w, https://substackcdn.com/image/fetch/$s_!Puqb!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e883906-d902-43b4-a8fb-ed48bcf02bb7_1318x1252.png 1272w, https://substackcdn.com/image/fetch/$s_!Puqb!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e883906-d902-43b4-a8fb-ed48bcf02bb7_1318x1252.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8e883906-d902-43b4-a8fb-ed48bcf02bb7_1318x1252.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1252,&quot;width&quot;:1318,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:791204,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/173893588?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e883906-d902-43b4-a8fb-ed48bcf02bb7_1318x1252.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;1252&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!Puqb!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e883906-d902-43b4-a8fb-ed48bcf02bb7_1318x1252.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Puqb!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e883906-d902-43b4-a8fb-ed48bcf02bb7_1318x1252.png 424w, https://substackcdn.com/image/fetch/$s_!Puqb!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e883906-d902-43b4-a8fb-ed48bcf02bb7_1318x1252.png 848w, https://substackcdn.com/image/fetch/$s_!Puqb!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e883906-d902-43b4-a8fb-ed48bcf02bb7_1318x1252.png 1272w, https://substackcdn.com/image/fetch/$s_!Puqb!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e883906-d902-43b4-a8fb-ed48bcf02bb7_1318x1252.png 1456w&quot; title=&quot;&quot; width=&quot;1318&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    This quote from my
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/interviewing-ross-taylor-on-the-state&quot; rel=&quot;&quot;&gt;
    Ross Taylor interview
   &lt;/a&gt;
   &lt;span&gt;
    was spot on for the
   &lt;/span&gt;
   &lt;em&gt;
    vibes
   &lt;/em&gt;
   &lt;span&gt;
    of using coding agents in July:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    My main worry with Claude Code is that... people confuse agents making you more productive versus preventing you from exerting mental effort. So sometimes I’ll have a day with Claude Code where I feel like I use very little mental effort—and it feels amazing—but I’m pretty sure I’ve done less work... Where it becomes really bad is when the file size becomes too long. Then the agent tends to struggle and get into these weird line search doom loops.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   This sentiment is still definitely true for production codebases that are extremely complex, but the doom loop likelihood is dropping in my tests. At the same time, the joy and mental ease still applies.
  &lt;/p&gt;
  &lt;p&gt;
   Some examples of what I’ve built with a mix of Claude Code or OpenAI’s Codex CLI recently include:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      A raw HTML
     &lt;/span&gt;
     &lt;a href=&quot;https://rlhfbook.com/library&quot; rel=&quot;&quot;&gt;
      site for my RLHF book
     &lt;/a&gt;
     &lt;span&gt;
      for comparing the responses of SFT vs. RLHF trained models from the same lineage (and improvements to RLHF book itself).
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Making a
     &lt;/span&gt;
     &lt;a href=&quot;https://github.com/Interconnects-AI/homebase&quot; rel=&quot;&quot;&gt;
      repository
     &lt;/a&gt;
     &lt;span&gt;
      with all of the posts and content from Interconnects so I can use coding agents as editorial assistants while writing.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Improvements to the ATOM Project
     &lt;/span&gt;
     &lt;a href=&quot;https://www.atomproject.ai/&quot; rel=&quot;&quot;&gt;
      website
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Stripping my personal website out of Webflow’s systems (which was a mistake to sign up for during graduate school), including CMS entries and other detailed pages.
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Other small scripts and tools in my day job training models.
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   &lt;span&gt;
    It’s not just me building extensively with these. There are multiple open-source projects committed to tracking the public contributions of these models — two are
   &lt;/span&gt;
   &lt;a href=&quot;https://prarena.ai/&quot; rel=&quot;&quot;&gt;
    PRArena
   &lt;/a&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;a href=&quot;https://insights.logicstar.ai/&quot; rel=&quot;&quot;&gt;
    Agents in the Wild
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   PRArena’s dashboard shows over a million PRs getting merged from the Codex web agent, dwarfing many of the competitors. This is the power that OpenAI can wield with distribution, even if the web app version of Codex is far from the zeitgeist that is CLI agents today.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!_GTR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d83a52b-b696-4163-a987-375442775960_2360x1486.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!_GTR!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d83a52b-b696-4163-a987-375442775960_2360x1486.png 424w, https://substackcdn.com/image/fetch/$s_!_GTR!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d83a52b-b696-4163-a987-375442775960_2360x1486.png 848w, https://substackcdn.com/image/fetch/$s_!_GTR!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d83a52b-b696-4163-a987-375442775960_2360x1486.png 1272w, https://substackcdn.com/image/fetch/$s_!_GTR!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d83a52b-b696-4163-a987-375442775960_2360x1486.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1d83a52b-b696-4163-a987-375442775960_2360x1486.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:917,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:475910,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/173893588?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d83a52b-b696-4163-a987-375442775960_2360x1486.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;917&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!_GTR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d83a52b-b696-4163-a987-375442775960_2360x1486.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!_GTR!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d83a52b-b696-4163-a987-375442775960_2360x1486.png 424w, https://substackcdn.com/image/fetch/$s_!_GTR!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d83a52b-b696-4163-a987-375442775960_2360x1486.png 848w, https://substackcdn.com/image/fetch/$s_!_GTR!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d83a52b-b696-4163-a987-375442775960_2360x1486.png 1272w, https://substackcdn.com/image/fetch/$s_!_GTR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d83a52b-b696-4163-a987-375442775960_2360x1486.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   This comes with a notable asterisk in methodology that can explain many of the gaps in similar dashboards:
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    &lt;span&gt;
     Some agents like
    &lt;/span&gt;
    &lt;strong&gt;
     Codex
    &lt;/strong&gt;
    &lt;span&gt;
     iterate privately and create ready PRs directly, resulting in very few drafts but high merge rates. Others like
    &lt;/span&gt;
    &lt;strong&gt;
     Copilot
    &lt;/strong&gt;
    &lt;span&gt;
     and
    &lt;/span&gt;
    &lt;strong&gt;
     Codegen
    &lt;/strong&gt;
    &lt;span&gt;
     create draft PRs first, encouraging public iteration before marking them ready for review.
    &lt;/span&gt;
   &lt;/p&gt;
   &lt;p&gt;
    &lt;span&gt;
     The statistics below focus on
    &lt;/span&gt;
    &lt;strong&gt;
     Ready PRs only
    &lt;/strong&gt;
    &lt;span&gt;
     to fairly compare agents across different workflows, measuring each agent&#x27;s ability to produce mergeable code regardless of whether they iterate publicly (with drafts) or privately.
    &lt;/span&gt;
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   The other dashboard, Agents in the Wild, shows that OpenAI’s coding agent is only one order of magnitude behind humans and other automations in PRs merged.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!8Tfr!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbfcc57-8ee5-4742-86d0-0e3b233283e3_2466x1696.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!8Tfr!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbfcc57-8ee5-4742-86d0-0e3b233283e3_2466x1696.png 424w, https://substackcdn.com/image/fetch/$s_!8Tfr!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbfcc57-8ee5-4742-86d0-0e3b233283e3_2466x1696.png 848w, https://substackcdn.com/image/fetch/$s_!8Tfr!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbfcc57-8ee5-4742-86d0-0e3b233283e3_2466x1696.png 1272w, https://substackcdn.com/image/fetch/$s_!8Tfr!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbfcc57-8ee5-4742-86d0-0e3b233283e3_2466x1696.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fdbfcc57-8ee5-4742-86d0-0e3b233283e3_2466x1696.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1001,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:464650,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/173893588?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbfcc57-8ee5-4742-86d0-0e3b233283e3_2466x1696.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;1001&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!8Tfr!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbfcc57-8ee5-4742-86d0-0e3b233283e3_2466x1696.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!8Tfr!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbfcc57-8ee5-4742-86d0-0e3b233283e3_2466x1696.png 424w, https://substackcdn.com/image/fetch/$s_!8Tfr!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbfcc57-8ee5-4742-86d0-0e3b233283e3_2466x1696.png 848w, https://substackcdn.com/image/fetch/$s_!8Tfr!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbfcc57-8ee5-4742-86d0-0e3b233283e3_2466x1696.png 1272w, https://substackcdn.com/image/fetch/$s_!8Tfr!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbfcc57-8ee5-4742-86d0-0e3b233283e3_2466x1696.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   Putting this in perspective relative to Gemini or Claude:
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!RAqm!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57090aa2-c354-4eb5-9222-8e0c61b2a8e8_2494x1556.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!RAqm!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57090aa2-c354-4eb5-9222-8e0c61b2a8e8_2494x1556.png 424w, https://substackcdn.com/image/fetch/$s_!RAqm!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57090aa2-c354-4eb5-9222-8e0c61b2a8e8_2494x1556.png 848w, https://substackcdn.com/image/fetch/$s_!RAqm!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57090aa2-c354-4eb5-9222-8e0c61b2a8e8_2494x1556.png 1272w, https://substackcdn.com/image/fetch/$s_!RAqm!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57090aa2-c354-4eb5-9222-8e0c61b2a8e8_2494x1556.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/57090aa2-c354-4eb5-9222-8e0c61b2a8e8_2494x1556.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:908,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:284520,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/173893588?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57090aa2-c354-4eb5-9222-8e0c61b2a8e8_2494x1556.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;908&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!RAqm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57090aa2-c354-4eb5-9222-8e0c61b2a8e8_2494x1556.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!RAqm!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57090aa2-c354-4eb5-9222-8e0c61b2a8e8_2494x1556.png 424w, https://substackcdn.com/image/fetch/$s_!RAqm!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57090aa2-c354-4eb5-9222-8e0c61b2a8e8_2494x1556.png 848w, https://substackcdn.com/image/fetch/$s_!RAqm!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57090aa2-c354-4eb5-9222-8e0c61b2a8e8_2494x1556.png 1272w, https://substackcdn.com/image/fetch/$s_!RAqm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57090aa2-c354-4eb5-9222-8e0c61b2a8e8_2494x1556.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    The context with this is that Claude Code is
   &lt;/span&gt;
   &lt;em&gt;
    far
   &lt;/em&gt;
   &lt;span&gt;
    more downloaded than OpenAI’s CLI agent Codex, but it doesn’t name its PRs the same clever way by default with the agent name in the branch. Claude Code has over 20X the downloads of Codex in the last week on NPM.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!Je4m!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ec5b31a-8aba-47ce-9975-abe5f9257775_2954x1348.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Je4m!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ec5b31a-8aba-47ce-9975-abe5f9257775_2954x1348.png 424w, https://substackcdn.com/image/fetch/$s_!Je4m!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ec5b31a-8aba-47ce-9975-abe5f9257775_2954x1348.png 848w, https://substackcdn.com/image/fetch/$s_!Je4m!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ec5b31a-8aba-47ce-9975-abe5f9257775_2954x1348.png 1272w, https://substackcdn.com/image/fetch/$s_!Je4m!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ec5b31a-8aba-47ce-9975-abe5f9257775_2954x1348.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5ec5b31a-8aba-47ce-9975-abe5f9257775_2954x1348.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:664,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:815090,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/173893588?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ec5b31a-8aba-47ce-9975-abe5f9257775_2954x1348.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;664&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!Je4m!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ec5b31a-8aba-47ce-9975-abe5f9257775_2954x1348.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Je4m!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ec5b31a-8aba-47ce-9975-abe5f9257775_2954x1348.png 424w, https://substackcdn.com/image/fetch/$s_!Je4m!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ec5b31a-8aba-47ce-9975-abe5f9257775_2954x1348.png 848w, https://substackcdn.com/image/fetch/$s_!Je4m!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ec5b31a-8aba-47ce-9975-abe5f9257775_2954x1348.png 1272w, https://substackcdn.com/image/fetch/$s_!Je4m!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ec5b31a-8aba-47ce-9975-abe5f9257775_2954x1348.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   Despite the challenges of measurement, it’s clear that coding agents are taking off.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The Codex PRs above actually represent the
   &lt;/span&gt;
   &lt;em&gt;
    web agent
   &lt;/em&gt;
   &lt;span&gt;
    , which has the default branch name behavior, not the CLI agent. This shows the might of OpenAI’s distribution, and it is impressive how many of the PRs are actually merged (over 80%), when thousands of people are trying a new tool for the first time.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The primary difference between the web agent and the CLI agent is a reduction in interactivity. The CLI agents propose a plan and ask for feedback, or let you monitor and interrupt. Codex on the web wraps a similar behavior as the CLI agents in one system that runs all the way until it can open a PR.
  &lt;/p&gt;
  &lt;p&gt;
   Over time coding is only going to get more asynchronous and OpenAI is poised to capture this transition if it happens soon. Based on all the above evidence of coding models getting more capable, the move to this new UX for software will happen faster than people expect. The transition to fully autonomous coding will happen soon for types of work where coding models already work near flawlessly — scripts, websites, data analysis, etc. Later, complex production codebases will work best at lower levels of the stack — IDEs, CLI agents, and other things that are both interactive and best for absorbing content.
  &lt;/p&gt;
  &lt;p&gt;
   Within a few years, the two trends will converge where autonomous agents are functional and the most complex codebases can be improved with AI. Then everything can return to the chatbot window — you only need to open your IDE when you want to understand what’s going on. For most people, not having to look at the code will be a welcome change.
  &lt;/p&gt;
  &lt;p&gt;
   Progress in coding feels slower than the “emergent” abilities between model generations past, which makes it easier to keep track of. This is due to how big the range in behaviors that encompass “coding” is, but results in a fantastic area for learning how AI models evolve and iterate. This playbook will be used many times over by frontier labs in the coming years as AI models are taught to solve more challenging tasks.
  &lt;/p&gt;
  &lt;p&gt;
   There’s a quiet revolution happening, and in order to truly understand it, you need to partake. Go build something.
  &lt;/p&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/coding-as-the-epicenter-of-ai-progress#footnote-anchor-1-173893588&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     Here’s my command for using Codex:
    &lt;/p&gt;
    &lt;pre&gt;&lt;code&gt;&lt;code&gt;alias codex=&#x27;codex -m gpt-5-codex -c model_reasoning_effort=&quot;high&quot; --yolo --search&#x27;&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
</channel>
</rss>
