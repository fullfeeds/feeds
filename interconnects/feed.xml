<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0" version="2.0">
<channel><title>Interconnects</title>
<lastBuildDate>Sat, 01 Nov 2025 17:56:28 -0000</lastBuildDate>
<item>
<title> How to scale RL </title>
<link>https://www.interconnects.ai/p/the-new-rl-scaling-laws</link>
<pubDate>Mon, 20 Oct 2025 15:17:48 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;h5&gt;
   &lt;span&gt;
    Two quick housekeeping items before I get to the post.
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    1. I’ll be in SF this week for the PyTorch conference (22-23), AI Infra Summit (21st), and other local events. Come say hi.
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    2. I launched a new Substack AI bundle with 8 of my favorite publications packaged together for teams of 20+. Learn more at
   &lt;/span&gt;
   &lt;a href=&quot;https://readsail.com/&quot; rel=&quot;&quot;&gt;
    readsail.com
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    Onto the post!
   &lt;/span&gt;
  &lt;/h5&gt;
  &lt;p&gt;
   “Scaling reinforcement learning (RL)” is the zeitgeisty way to capture the next steps in improving frontier models — everyone is staring at the same hill they plan on climbing. How these different groups are approaching the problem has been a poorly kept secret. It’s a simple idea, but one that’s hard to copy: Predicting the trajectory of the learning curve. There have been two reasons this is hard to copy for academics, which will be solved on different time scales:
  &lt;/p&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     The lack of stable RL training setups. There are many RL libraries being developed in parallel and the community has collectively made them much more ready for big RL runs over the summer.
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     The lack of compute for experimentation.
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;p&gt;
   These aren’t new stories. In many ways they mirror the progression of open Mixture of Experts (MoE) models, where they still lag far behind the implementations of the codebases within top AI laboratories because it involves overcoming substantial engineering headaches in an expensive experimentation regime. Scaling RL has been shaping up the same way, but it turns out it is just a bit more approachable.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/the-new-rl-scaling-laws?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/the-new-rl-scaling-laws?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Last week we got the first definitive paper on scaling RL. It proposes a clear method to extrapolate RL learning curves over compute scales and sets a baseline for the order of compute that should be spent to have top-end performance. The paper,
   &lt;/span&gt;
   &lt;em&gt;
    &lt;a href=&quot;https://arxiv.org/abs/2510.13786&quot; rel=&quot;&quot;&gt;
     The Art of Scaling Reinforcement Learning Compute for LLMs
    &lt;/a&gt;
   &lt;/em&gt;
   &lt;span&gt;
    (Khatri &amp; Madaan et al. 2025), referred to as ScaleRL, is a must read for anyone looking to understand the absolute cutting edge of RL algorithms and infrastructure.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!EnWF!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7df555ab-5d07-49a4-96e4-3eb744960976_1798x1816.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!EnWF!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7df555ab-5d07-49a4-96e4-3eb744960976_1798x1816.png 424w, https://substackcdn.com/image/fetch/$s_!EnWF!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7df555ab-5d07-49a4-96e4-3eb744960976_1798x1816.png 848w, https://substackcdn.com/image/fetch/$s_!EnWF!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7df555ab-5d07-49a4-96e4-3eb744960976_1798x1816.png 1272w, https://substackcdn.com/image/fetch/$s_!EnWF!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7df555ab-5d07-49a4-96e4-3eb744960976_1798x1816.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7df555ab-5d07-49a4-96e4-3eb744960976_1798x1816.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1471,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:775466,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/175849446?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7df555ab-5d07-49a4-96e4-3eb744960976_1798x1816.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;1471&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!EnWF!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7df555ab-5d07-49a4-96e4-3eb744960976_1798x1816.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!EnWF!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7df555ab-5d07-49a4-96e4-3eb744960976_1798x1816.png 424w, https://substackcdn.com/image/fetch/$s_!EnWF!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7df555ab-5d07-49a4-96e4-3eb744960976_1798x1816.png 848w, https://substackcdn.com/image/fetch/$s_!EnWF!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7df555ab-5d07-49a4-96e4-3eb744960976_1798x1816.png 1272w, https://substackcdn.com/image/fetch/$s_!EnWF!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7df555ab-5d07-49a4-96e4-3eb744960976_1798x1816.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   For some personal context, for all of 2025 we’ve had our main slack channel in the reasoning space at Ai2 called “scaling-rl” because of how essential we knew the first clear piece of work in this area would be. This post covers the key details and what I see coming next.
  &lt;/p&gt;
  &lt;p&gt;
   There are two key things you need to know about these, even if all the lower level RL math is confusing to you too. First is how these intuitively work and what they’re actually predicting. Second is how they compare to the pretraining scaling laws we know and love.
  &lt;/p&gt;
  &lt;p&gt;
   To the first point, what the approach entails is taking one (or a handful of) your key base models, run a bit of RL on each of them, predict the end point by a bit of shape forecasting across many stable runs, then, for your big run, you can predict the end point in terms of final performance. The shape of RL runs that motivates this is how you see your model often gain ~80% of the accuracy gain in the first few steps, and you wonder what the final performance of the model will be if you trained on your entire dataset.
  &lt;/p&gt;
  &lt;p&gt;
   The authors define three constants that they fit, A for a measure of the peak performance — accuracy on a subset of your training dataset, aka the validation set, B for the slope of the sigmoid curve, and C as compute on the x axis. What is then done is that you take a set of RL training jobs and you fit a regression that predicts the last chunk of real training points given the early measurements of accuracy over time. Then, you can compare the predicted final performance of your future RL ablations on that starting model by understanding the normal shape of your RL learning curves.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!Spr_!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Spr_!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png 424w, https://substackcdn.com/image/fetch/$s_!Spr_!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png 848w, https://substackcdn.com/image/fetch/$s_!Spr_!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png 1272w, https://substackcdn.com/image/fetch/$s_!Spr_!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:677,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:606876,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/175849446?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;677&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!Spr_!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Spr_!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png 424w, https://substackcdn.com/image/fetch/$s_!Spr_!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png 848w, https://substackcdn.com/image/fetch/$s_!Spr_!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png 1272w, https://substackcdn.com/image/fetch/$s_!Spr_!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfe9831b-6398-4046-8ee5-c5ef1f502758_2695x1253.png 1456w&quot; title=&quot;&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   Second is to consider how this compares to pretraining scaling laws. These are very far from the deeply insightful power law relating downstream test loss to pretraining compute — accuracy on RL training datasets is a far more bounded measure than next token prediction. The RL scaling laws are most useful for ablating design choices, relative to pointing to something fundamental about the nature of models. In many ways, scaling laws for pretraining could’ve been viewed this way at the beginning, too, so we’ll see how RL evolves from here.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!Ji8y!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb827ef2e-394f-4e14-8050-b075fd05f437_2755x1011.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Ji8y!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb827ef2e-394f-4e14-8050-b075fd05f437_2755x1011.png 424w, https://substackcdn.com/image/fetch/$s_!Ji8y!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb827ef2e-394f-4e14-8050-b075fd05f437_2755x1011.png 848w, https://substackcdn.com/image/fetch/$s_!Ji8y!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb827ef2e-394f-4e14-8050-b075fd05f437_2755x1011.png 1272w, https://substackcdn.com/image/fetch/$s_!Ji8y!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb827ef2e-394f-4e14-8050-b075fd05f437_2755x1011.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b827ef2e-394f-4e14-8050-b075fd05f437_2755x1011.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:534,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:911144,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/175849446?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb827ef2e-394f-4e14-8050-b075fd05f437_2755x1011.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;534&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!Ji8y!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb827ef2e-394f-4e14-8050-b075fd05f437_2755x1011.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Ji8y!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb827ef2e-394f-4e14-8050-b075fd05f437_2755x1011.png 424w, https://substackcdn.com/image/fetch/$s_!Ji8y!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb827ef2e-394f-4e14-8050-b075fd05f437_2755x1011.png 848w, https://substackcdn.com/image/fetch/$s_!Ji8y!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb827ef2e-394f-4e14-8050-b075fd05f437_2755x1011.png 1272w, https://substackcdn.com/image/fetch/$s_!Ji8y!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb827ef2e-394f-4e14-8050-b075fd05f437_2755x1011.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   With that difference, scaling laws for RL will play a very different role in training leading models than the pretraining scaling laws we have today. The pretraining laws are about choosing the exact configuration for your big pretraining run (that you can’t really run a meaningful chunk of to debug at all), where RL is more about ablating which algorithm you’ll let run much longer.
  &lt;/p&gt;
  &lt;p&gt;
   In pretraining many decisions depend on your budget and scaling laws can give the answer. Your training compute, communication bottlenecks, maximum run time, data availability, etc. all define a certain model window. Scaling laws for RL may inform this very soon, but for now it&#x27;s best to think about scaling laws as a way to extract the maximum performance from a given base model.
  &lt;/p&gt;
  &lt;p&gt;
   For all of these reasons, scaling RL is more like an art, as the authors say it, because it’s about finding the run that’ll get the last few percentage points of performance when let run over an extra order of magnitude (or two) of samples. It’s a fine grained way to extrapolate RL curves — which have a standard shape of a quick rise then a slow saturation. In practice, the authors fit curves over 1/4 of their training compute to predict the outcome after the remaining 3/4 of GPU hours. The limits of scaling laws will likely be pushed further in the future (and I don’t have a good heuristic for what percentage of compute is used for establishing pretraining scaling laws, versus what is deployed in the final run, comment if you do!).
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!4gom!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81e70f2f-8945-42ae-ba51-433f1a128693_2110x1307.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!4gom!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81e70f2f-8945-42ae-ba51-433f1a128693_2110x1307.png 424w, https://substackcdn.com/image/fetch/$s_!4gom!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81e70f2f-8945-42ae-ba51-433f1a128693_2110x1307.png 848w, https://substackcdn.com/image/fetch/$s_!4gom!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81e70f2f-8945-42ae-ba51-433f1a128693_2110x1307.png 1272w, https://substackcdn.com/image/fetch/$s_!4gom!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81e70f2f-8945-42ae-ba51-433f1a128693_2110x1307.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/81e70f2f-8945-42ae-ba51-433f1a128693_2110x1307.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:902,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:716354,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/175849446?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81e70f2f-8945-42ae-ba51-433f1a128693_2110x1307.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;902&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!4gom!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81e70f2f-8945-42ae-ba51-433f1a128693_2110x1307.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!4gom!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81e70f2f-8945-42ae-ba51-433f1a128693_2110x1307.png 424w, https://substackcdn.com/image/fetch/$s_!4gom!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81e70f2f-8945-42ae-ba51-433f1a128693_2110x1307.png 848w, https://substackcdn.com/image/fetch/$s_!4gom!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81e70f2f-8945-42ae-ba51-433f1a128693_2110x1307.png 1272w, https://substackcdn.com/image/fetch/$s_!4gom!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81e70f2f-8945-42ae-ba51-433f1a128693_2110x1307.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    From here, the paper quickly gets technical, serving as a check in on the major ideas that dominated the RL research ecosystem in the last 6 months. This paper blesses those as important or not when it comes to scaled up RL training. This fits a recurring trend across language modeling in the last few years:
   &lt;/span&gt;
   &lt;strong&gt;
    Most of the key ideas are out there, but open labs tend to not have the resources to put them all together in the right configuration
   &lt;/strong&gt;
   &lt;span&gt;
    . This sort of slow accumulation of knowledge takes an organizational intensity, clarity, and ability that is hard for small research groups to match.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
   There are a few key ideas that stand out to me as worth knowing and betting on following this paper:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Algorithmic advancements:
     &lt;/strong&gt;
     &lt;span&gt;
      The paper is very favorable on, arguably painting them as essential, some recent algorithms or advancements. These include
     &lt;/span&gt;
     &lt;a href=&quot;https://fengyao.notion.site/off-policy-rl&quot; rel=&quot;&quot;&gt;
      truncated importance sampling
     &lt;/a&gt;
     &lt;span&gt;
      (TIS),
     &lt;/span&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2507.18071&quot; rel=&quot;&quot;&gt;
      Group Sequence Policy Optimization (GSPO)
     &lt;/a&gt;
     &lt;span&gt;
      , and Clipped IS-weight Policy Optimization (CISPO) via the
     &lt;/span&gt;
     &lt;a href=&quot;https://arxiv.org/pdf/2506.13585&quot; rel=&quot;&quot;&gt;
      MiniMax M1 paper
     &lt;/a&gt;
     &lt;span&gt;
      . More on these in a second.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Systems improvements:
     &lt;/strong&gt;
     &lt;span&gt;
      The authors highlight PipeLine RL (
     &lt;/span&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2509.19128&quot; rel=&quot;&quot;&gt;
      paper
     &lt;/a&gt;
     &lt;span&gt;
      or
     &lt;/span&gt;
     &lt;a href=&quot;https://github.com/ServiceNow/PipelineRL&quot; rel=&quot;&quot;&gt;
      repository
     &lt;/a&gt;
     &lt;span&gt;
      ) as the canonical reference for the combination of in-flight updates — i.e. changing model weights within one very long generation — and continuous batching — i.e. filling your RL batch over time until you have enough prompts for a learning step — which together represent 4X+ improvements over standard RL implementations on LLMs in terms of throughput. What this looks like in terms of idle GPUs is below, from the ServiceNow paper.
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!R3mA!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc78027d-b185-4e3f-aba2-387ed8154e0e_2889x1053.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!R3mA!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc78027d-b185-4e3f-aba2-387ed8154e0e_2889x1053.png 424w, https://substackcdn.com/image/fetch/$s_!R3mA!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc78027d-b185-4e3f-aba2-387ed8154e0e_2889x1053.png 848w, https://substackcdn.com/image/fetch/$s_!R3mA!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc78027d-b185-4e3f-aba2-387ed8154e0e_2889x1053.png 1272w, https://substackcdn.com/image/fetch/$s_!R3mA!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc78027d-b185-4e3f-aba2-387ed8154e0e_2889x1053.png 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bc78027d-b185-4e3f-aba2-387ed8154e0e_2889x1053.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:531,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:683251,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/175849446?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc78027d-b185-4e3f-aba2-387ed8154e0e_2889x1053.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;531&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!R3mA!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc78027d-b185-4e3f-aba2-387ed8154e0e_2889x1053.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!R3mA!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc78027d-b185-4e3f-aba2-387ed8154e0e_2889x1053.png 424w, https://substackcdn.com/image/fetch/$s_!R3mA!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc78027d-b185-4e3f-aba2-387ed8154e0e_2889x1053.png 848w, https://substackcdn.com/image/fetch/$s_!R3mA!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc78027d-b185-4e3f-aba2-387ed8154e0e_2889x1053.png 1272w, https://substackcdn.com/image/fetch/$s_!R3mA!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc78027d-b185-4e3f-aba2-387ed8154e0e_2889x1053.png 1456w&quot; width=&quot;1456&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
    &lt;p&gt;
     &lt;span&gt;
      Intuitively, think about what happens if you were to ask 8 different questions to an LLM simultaneously. Some of these would finish early and some would take a long time. If you allocate your GPUs such that they have to finish all 8 questions before moving onto the next stack of questions, inevitably there will be GPUs idle when you’re waiting for the last answer.
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      Instead, continuous batching pulls in new questions all the time when the GPUs have cycles to do more processing. Though, this is more complicated in the RL setup because after every 8 (or your batch size) of questions you need to update your RL weights. Can you still do this and fill in new questions all the time to the GPUs? What happens to that one question that is taking forever?
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      In-flight updates is the solution to this. What is literally happening is that the model is updated in the middle of the generation. The models and RL systems just handle this seamlessly, and it removes a ton of idle time in matching the inference weights to the new updates from your RL algorithm.
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      Not having a few key details like this will make big RL runs not only more expensive in GPUs, but more importantly in time. A 1 day feedback cycle vs 4 days makes for a very different research setup. We have these two features in
     &lt;/span&gt;
     &lt;a href=&quot;https://github.com/allenai/open-instruct&quot; rel=&quot;&quot;&gt;
      Open Instruct
     &lt;/a&gt;
     &lt;span&gt;
      , our post training repo at Ai2, as do many other RL libraries.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   &lt;span&gt;
    A lot of this is fixing numerics, which is far harder with Mixture of Experts (MoE) models, and something that most open RL research hasn’t touched. This hunt for numerical stability is a common rumor for why Thinking Machines put out the
   &lt;/span&gt;
   &lt;a href=&quot;https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/&quot; rel=&quot;&quot;&gt;
    deterministic VLLM blog post
   &lt;/a&gt;
   &lt;span&gt;
    ahead of releasing their
   &lt;/span&gt;
   &lt;a href=&quot;https://thinkingmachines.ai/tinker/&quot; rel=&quot;&quot;&gt;
    Tinker API
   &lt;/a&gt;
   &lt;span&gt;
    — deterministic VLLM could be their forward pass.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Back to algorithms.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Ross Taylor
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/rosstaylor90/status/1978837624417587306&quot; rel=&quot;&quot;&gt;
    summarized
   &lt;/a&gt;
   &lt;span&gt;
    the various eras of RL algorithms that the community has gone through in 2025. First was the transition from vanilla GRPO to the likes of DAPO (see my earlier post on
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/papers-im-reading-base-model-rl-grpo&quot; rel=&quot;&quot;&gt;
    GRPO tricks
   &lt;/a&gt;
   &lt;span&gt;
    or my
   &lt;/span&gt;
   &lt;a href=&quot;https://www.youtube.com/watch?v=amrJDwMUFNs&quot; rel=&quot;&quot;&gt;
    YouTube video
   &lt;/a&gt;
   &lt;span&gt;
    on them too), which noticed issues with the clipping formulation and biases in the GRPO advantage calculation. The next class of algorithms are those cited in this ScaleRL paper, CISPO and a general class of Truncated Importance Sampling
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/the-new-rl-scaling-laws#footnote-1-175849446&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     1
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    (TIS) approaches, that are designed for sequence level optimization (often closer to vanilla policy gradient) that account for the probability delta between actor (the GPUs generating completions for RL, often something fast like VLLM) and learner (the GPUs performing gradient updates, in a different library).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   This importance sampling term seems to be essential to getting modern RL infrastructure right, as without it, scaling to more complex systems is hard to get numerical stability with. There’s been a lot of chatter about “importance sampling” in the AI community. What is happening, practically, is that the advantage or reward is getting re-weighted by an importance sampling log-ratio corresponding to the difference in probabilities from the two sets of model implementations (e.g. VLLM vs Transformers).
  &lt;/p&gt;
  &lt;p&gt;
   In the midst of all the details, the paper summarizes the state of affairs — large scale yolo RL runs — quite well:
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    While RL compute for LLMs has scaled massively, our understanding of how to scale RL has not kept pace; the methodology remains more art than science. Recent breakthroughs in RL are largely driven by isolated studies on novel algorithms (e.g., Yu et al. (DAPO, 2025)) and model-specific training reports, such as, MiniMax et al. (2025) and Magistral (Rastogi et al., 2025). Critically, these studies provide ad-hoc solutions tailored to specific contexts, but not how to develop RL methods that scale with compute. This lack of scaling methodology stifles research progress: with no reliable way to identify promising RL candidates a priori, progress is tied to large-scale experimentation that sidelines most of the academic community.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   What is important going forward, as this will happen again with future eras of LLMs after this RL era, is why we are here. This happened due to the large overhang in potential from deploying RL, where clear scientific best practices take a long time to establish (even when most of the best researchers are publishing publicly, which isn’t the case today). The leading AI labs can build up fairly sizeable gaps quickly, but information tends to flow out and be reproduced. It’s important that the public options keep materializing — I think they will.
  &lt;/p&gt;
  &lt;p&gt;
   This paper is the first step in a direction of that science of scaling RL, but leaves many questions unanswered:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      No information on the impacts of different data
     &lt;/strong&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/datasets/POLARIS-Project/Polaris-Dataset-53K&quot; rel=&quot;&quot;&gt;
      Polaris 53K
     &lt;/a&gt;
     &lt;span&gt;
      is used in the paper, which is a solid option of the open, math RL datasets, but we find most of the RL data like this to be solved with a simple SFT set of reasoning traces on 8B models. Harder data may quickly become a limitation of open methods as people scale RL experiments to stronger base models. A paper reproducing these scaling trends over different data regimes is essential.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      No information on choosing the right base model
     &lt;/strong&gt;
     &lt;span&gt;
      . It is accepted that bigger base models perform better with RL — which the authors acknowledge in the paper: “the larger 17B×16 MoE exhibits much higher asymptotic RL performance than the 8B dense model, outperforming the 8B’s performance using only 1/6 of its RL training compute.” With this, we need to perform scaling RL studies that show the optimal base model for downstream RL, in terms of overall compute budgets.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   &lt;span&gt;
    The authors acknowledge these limitations clearly. They’re not trying to hide it!
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/the-new-rl-scaling-laws#footnote-2-175849446&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     2
    &lt;/a&gt;
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    To wrap this up, let us recall that there was a
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/iScienceLuvr/status/1972066202920054875&quot; rel=&quot;&quot;&gt;
    big brouhaha
   &lt;/a&gt;
   &lt;span&gt;
    in AI circles a few weeks ago when a few frontier lab employees said that GRPO is far behind frontier labs RL stacks. What is more accurate to me is that
   &lt;/span&gt;
   &lt;em&gt;
    vanilla
   &lt;/em&gt;
   &lt;span&gt;
    GRPO is far behind, and the process of figuring out the set of individual tricks that works on your model and your data is a well kept secret. This new ScaleRL paper is a major step in showing people how to bridge that gap. From here, we have to build the tools in public.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/the-new-rl-scaling-laws#footnote-anchor-1-175849446&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     &lt;span&gt;
      I like this
     &lt;/span&gt;
     &lt;a href=&quot;https://fengyao.notion.site/off-policy-rl&quot; rel=&quot;&quot;&gt;
      blog on importance sampling for RL
     &lt;/a&gt;
     &lt;span&gt;
      (cited in the ScaleRL paper), but the
     &lt;/span&gt;
     &lt;a href=&quot;https://en.wikipedia.org/wiki/Importance_sampling&quot; rel=&quot;&quot;&gt;
      Wikipedia article
     &lt;/a&gt;
     &lt;span&gt;
      is helpful on a TLDR of what importance sampling itself is:
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;blockquote&gt;
     &lt;p&gt;
      &lt;strong&gt;
       Importance sampling
      &lt;/strong&gt;
      &lt;span&gt;
       is a
      &lt;/span&gt;
      &lt;a href=&quot;https://en.wikipedia.org/wiki/Monte_Carlo_method&quot; rel=&quot;&quot;&gt;
       Monte Carlo method
      &lt;/a&gt;
      &lt;span&gt;
       for evaluating properties of a particular
      &lt;/span&gt;
      &lt;a href=&quot;https://en.wikipedia.org/wiki/Probability_distribution&quot; rel=&quot;&quot;&gt;
       distribution
      &lt;/a&gt;
      &lt;span&gt;
       , while only having samples generated from a different distribution than the distribution of interest.
      &lt;/span&gt;
     &lt;/p&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;
     This detail I’ve been hearing about constantly as a core thing to get right with modern RL infrastructure.
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/the-new-rl-scaling-laws#footnote-anchor-2-175849446&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    2
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     &lt;span&gt;
      Another key thing that is omitted from this work, and I think much of the efforts to improve the next model iteration like Claude 4.6 or GPT 5.1 is the “
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/what-comes-next-with-reinforcement&quot; rel=&quot;&quot;&gt;
      very long horizon
     &lt;/a&gt;
     &lt;span&gt;
      ” RL that is described when people mention RL solving open problems like scientific discovery. We’re much further from that, but still have substantial improvements to be made on current models.
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;p&gt;
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Latest open models (#15): It’s Qwen&#x27;s world and we get to live in it, on CAISI&#x27;s report, &amp; GPT-OSS update </title>
<link>https://www.interconnects.ai/p/latest-open-models-15-its-qwens-world</link>
<pubDate>Sat, 18 Oct 2025 15:26:15 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   Before getting into the latest artifacts, there are a couple of pieces of crucial open ecosystem we have to cover.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    First, the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.nist.gov/caisi&quot; rel=&quot;&quot;&gt;
    Center for AI Standards and Innovation (CAISI)
   &lt;/a&gt;
   &lt;span&gt;
    released a report that observed the ecosystem and
   &lt;/span&gt;
   &lt;a href=&quot;https://www.nist.gov/news-events/news/2025/09/caisi-evaluation-deepseek-ai-models-finds-shortcomings-and-risks&quot; rel=&quot;&quot;&gt;
    evaluated
   &lt;/a&gt;
   &lt;span&gt;
    DeepSeek 3.1 against leading closed models. The evaluation scores they highlighted show some discrepancy with accepted results in the community. While MMLU-Pro, GPQA and HLE are close to the self-reported scores from DeepSeek and within usual error bars
   &lt;/span&gt;
   &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/latest-open-models-15-its-qwens-world#footnote-1-176399506&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;span&gt;
    , the SWE-bench Verified scores are off by a wide margin due to a weak harness for the benchmark. The harness is the software framework the model is used in for agentic benchmarks and has as great an impact as the model itself, as shown in
   &lt;/span&gt;
   &lt;a href=&quot;https://epoch.ai/blog/what-skills-does-swe-bench-verified-evaluate#scaffolds-matter-as-much-as-models&quot; rel=&quot;&quot;&gt;
    this SWE-bench analysis by Epoch AI
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The CAISI report thus undersells the capabilities of DeepSeek’s models on a core benchmark for recent models (e.g. it is one of the benchmarks that Anthropic most heavily relies on for
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/claude-4-and-anthropics-bet-on-code&quot; rel=&quot;&quot;&gt;
    marketing of Claude
   &lt;/a&gt;
   &lt;span&gt;
    ).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!yoYR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb23fd663-ef06-4616-a3c4-f1491e1dd69e_1562x706.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!yoYR!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb23fd663-ef06-4616-a3c4-f1491e1dd69e_1562x706.png 424w, https://substackcdn.com/image/fetch/$s_!yoYR!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb23fd663-ef06-4616-a3c4-f1491e1dd69e_1562x706.png 848w, https://substackcdn.com/image/fetch/$s_!yoYR!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb23fd663-ef06-4616-a3c4-f1491e1dd69e_1562x706.png 1272w, https://substackcdn.com/image/fetch/$s_!yoYR!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb23fd663-ef06-4616-a3c4-f1491e1dd69e_1562x706.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;Image&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b23fd663-ef06-4616-a3c4-f1491e1dd69e_1562x706.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:658,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;658&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!yoYR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb23fd663-ef06-4616-a3c4-f1491e1dd69e_1562x706.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!yoYR!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb23fd663-ef06-4616-a3c4-f1491e1dd69e_1562x706.png 424w, https://substackcdn.com/image/fetch/$s_!yoYR!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb23fd663-ef06-4616-a3c4-f1491e1dd69e_1562x706.png 848w, https://substackcdn.com/image/fetch/$s_!yoYR!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb23fd663-ef06-4616-a3c4-f1491e1dd69e_1562x706.png 1272w, https://substackcdn.com/image/fetch/$s_!yoYR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb23fd663-ef06-4616-a3c4-f1491e1dd69e_1562x706.png 1456w&quot; title=&quot;Image&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    Later in the report, CAISI shows a graph with cumulative download numbers from HuggingFace (left), something we also show on
   &lt;/span&gt;
   &lt;a href=&quot;https://atomproject.ai/&quot; rel=&quot;&quot;&gt;
    atomproject.ai
   &lt;/a&gt;
   &lt;span&gt;
    (middle, right). However, our numbers differ greatly from the numbers from CAISI and those differ even more from the ones by
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/blog/lbourdois/huggingface-models-stats&quot; rel=&quot;&quot;&gt;
    HuggingFace itself
   &lt;/a&gt;
   &lt;span&gt;
    . So, what is going on?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!EWYT!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefe60a29-3da8-468c-b368-aad74cd1255e_2043x501.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!EWYT!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefe60a29-3da8-468c-b368-aad74cd1255e_2043x501.png 424w, https://substackcdn.com/image/fetch/$s_!EWYT!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefe60a29-3da8-468c-b368-aad74cd1255e_2043x501.png 848w, https://substackcdn.com/image/fetch/$s_!EWYT!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefe60a29-3da8-468c-b368-aad74cd1255e_2043x501.png 1272w, https://substackcdn.com/image/fetch/$s_!EWYT!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefe60a29-3da8-468c-b368-aad74cd1255e_2043x501.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/efe60a29-3da8-468c-b368-aad74cd1255e_2043x501.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:357,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:212129,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/176399506?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefe60a29-3da8-468c-b368-aad74cd1255e_2043x501.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;357&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!EWYT!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefe60a29-3da8-468c-b368-aad74cd1255e_2043x501.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!EWYT!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefe60a29-3da8-468c-b368-aad74cd1255e_2043x501.png 424w, https://substackcdn.com/image/fetch/$s_!EWYT!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefe60a29-3da8-468c-b368-aad74cd1255e_2043x501.png 848w, https://substackcdn.com/image/fetch/$s_!EWYT!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefe60a29-3da8-468c-b368-aad74cd1255e_2043x501.png 1272w, https://substackcdn.com/image/fetch/$s_!EWYT!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefe60a29-3da8-468c-b368-aad74cd1255e_2043x501.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
      &lt;div&gt;
      &lt;/div&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   In short, it depends on which data you look at and how you clean it. For ATOM Project, we only consider models which were released after ChatGPT and are LLMs (based on our assessment). This excludes models like GPT-2 (which is the reason why OpenAI trumps all in the CAISI number, left), BERT-like models and ViTs like SigLIP (which are dominating the Google download numbers).
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    On top of this, we performed basic outlier filtering on daily downloads per model. Many models, such as
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct&quot; rel=&quot;&quot;&gt;
    Qwen 2.5 1.5B
   &lt;/a&gt;
   &lt;span&gt;
    , which is one of the most downloaded models of all time, has extreme outliers on the order of 10M+ downloads that can heavily skew the overall numbers. These outliers affect every organization, but in different magnitudes. Furthermore, we also exclude quantized (like FP8, MLX or GGUF) versions, as those might skew the numbers.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/latest-open-models-15-its-qwens-world?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-models-15-its-qwens-world?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The second news item is sharing an update on the utility of
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/gpt-oss-openai-validates-the-open&quot; rel=&quot;&quot;&gt;
    GPT-OSS
   &lt;/a&gt;
   &lt;span&gt;
    — when the model first dropped it was plagued by implementation difficulties downstream of architecture choices (e.g. a new 4-point precision) and complex tool use (multiple tool options per category). OpenAI is actually ahead of the curve on the complexity of tools they support with these models among open options. Since release, the use of GPT-OSS’s
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/openai/gpt-oss-20b&quot; rel=&quot;&quot;&gt;
    20B
   &lt;/a&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/openai/gpt-oss-120b&quot; rel=&quot;&quot;&gt;
    120B
   &lt;/a&gt;
   &lt;span&gt;
    models is very strong with 5.6M and 3.2M downloads in the last month, respectively. These models are outperforming some popular models, such as
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-4B&quot; rel=&quot;&quot;&gt;
    Qwen 3 4B
   &lt;/a&gt;
   &lt;span&gt;
    or
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-VL-30B-A3B-Instruct&quot; rel=&quot;&quot;&gt;
    Qwen3-VL-30B-A3B-Instruct
   &lt;/a&gt;
   &lt;span&gt;
    . Additionally, I got
   &lt;/span&gt;
   &lt;em&gt;
    very strong
   &lt;/em&gt;
   &lt;span&gt;
    feedback from the community when I did a
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/natolambert/status/1974121935408935337&quot; rel=&quot;&quot;&gt;
    basic pulse check
   &lt;/a&gt;
   &lt;span&gt;
    on the models. These are one of the first models I’d try on my
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/natolambert/status/1979291280833229246&quot; rel=&quot;&quot;&gt;
    new Nvidia DGX-Spark
   &lt;/a&gt;
   &lt;span&gt;
    to get a feel for things.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h1&gt;
   &lt;strong&gt;
    Artifacts Log
   &lt;/strong&gt;
  &lt;/h1&gt;
  &lt;h3&gt;
   &lt;strong&gt;
    Our Picks
   &lt;/strong&gt;
  &lt;/h3&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/ibm-granite/granite-4.0-h-small&quot; rel=&quot;&quot;&gt;
       granite-4.0-h-small
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/ibm-granite&quot; rel=&quot;&quot;&gt;
      ibm-granite
     &lt;/a&gt;
     &lt;span&gt;
      : We’ve been covering IBM and their Granite LLM series for a while. With this series, IBM finally scaled up the model size as well, bringing a series of hybrid (attention + mamba) models, ranging from a 3B dense to a 32B-A9B MoE. We used the models and were impressed, although not surprised, by the quality, given the continued persistence of IBM’s team to release better and better models.
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      Granite, for at least the 3B variant, is roughly in the
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/blog/smollm3&quot; rel=&quot;&quot;&gt;
      SmolLM3
     &lt;/a&gt;
     &lt;span&gt;
      quality range, being only surpassed by Qwen3 4B in terms of multilingual and instruction following capabilities. The tone of Granite 4.0 is refreshingly non-exciting compared to the sloptimized models recently (i.e. the trend across the industry for playful, emoji-filled, and often sycophantic models), making it feel like old Mistral models in a good way. Interestingly enough, they are also following Qwens lead and will release a
     &lt;/span&gt;
     &lt;strong&gt;
      separate reasoning model later in the year
     &lt;/strong&gt;
     &lt;span&gt;
      . We’ve heard many reports from people training models that hybrid reasoning — i.e. a toggle of thinking tokens on and off — adds a major complexity cost in training that lowers the peak performance of both modes. IBM
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/ibm-granite/granite-3.2-8b-instruct&quot; rel=&quot;&quot;&gt;
      debuted
     &lt;/a&gt;
     &lt;span&gt;
      the hybrid thinking approach (togglable via prompts) very early on for open models, which was adopted by others later.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-VL-235B-A22B-Instruct&quot; rel=&quot;&quot;&gt;
       Qwen3-VL-235B-A22B-Instruct
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/Qwen&quot; rel=&quot;&quot;&gt;
      Qwen
     &lt;/a&gt;
     &lt;span&gt;
      : The Qwen VL series finally gets its long-awaited and anticipated update with small (4B, 8B) dense and larger (30B-A3B, 235B-A22B) MoEs in both instruct and reasoning versions. We want to shine a special spotlight on the
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-VL-8B-Instruct&quot; rel=&quot;&quot;&gt;
      8B variants
     &lt;/a&gt;
     &lt;span&gt;
      : Their text benchmarks have also improved across the board compared to the initial 8B release — reinforcing our point on the challenge of hybrid reasoning. As the 8B versions did not get a 2507 refresh, these versions should be a no-brainer update and drop-in replacement if you were using Qwen3 8B (or are still using Llama3.1 8B).
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!kyNm!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb992e217-ba81-49a1-82ec-b394f9be7d03_3949x2349.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!kyNm!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb992e217-ba81-49a1-82ec-b394f9be7d03_3949x2349.jpeg 424w, https://substackcdn.com/image/fetch/$s_!kyNm!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb992e217-ba81-49a1-82ec-b394f9be7d03_3949x2349.jpeg 848w, https://substackcdn.com/image/fetch/$s_!kyNm!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb992e217-ba81-49a1-82ec-b394f9be7d03_3949x2349.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!kyNm!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb992e217-ba81-49a1-82ec-b394f9be7d03_3949x2349.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b992e217-ba81-49a1-82ec-b394f9be7d03_3949x2349.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:866,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;866&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!kyNm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb992e217-ba81-49a1-82ec-b394f9be7d03_3949x2349.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!kyNm!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb992e217-ba81-49a1-82ec-b394f9be7d03_3949x2349.jpeg 424w, https://substackcdn.com/image/fetch/$s_!kyNm!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb992e217-ba81-49a1-82ec-b394f9be7d03_3949x2349.jpeg 848w, https://substackcdn.com/image/fetch/$s_!kyNm!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb992e217-ba81-49a1-82ec-b394f9be7d03_3949x2349.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!kyNm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb992e217-ba81-49a1-82ec-b394f9be7d03_3949x2349.jpeg 1456w&quot; width=&quot;1456&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/zai-org/GLM-4.6&quot; rel=&quot;&quot;&gt;
       GLM-4.6
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/zai-org&quot; rel=&quot;&quot;&gt;
      zai-org
     &lt;/a&gt;
     &lt;span&gt;
      : Zhipu has released an update to their main series of models. This release is notable because
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/victormustar/status/1973735580283625618&quot; rel=&quot;&quot;&gt;
      many
     &lt;/a&gt;
     &lt;span&gt;
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/Tim_Dettmers/status/1974421423713386661&quot; rel=&quot;&quot;&gt;
      people
     &lt;/a&gt;
     &lt;span&gt;
      say that it’s basically a Sonnet (or a Haiku) 4.5 at home, although it falls off (harder) at longer context than closed models. Still, a high praise and a continuation of the theme that Chinese open models improve at an astonishing rate, being close to the best closed models.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/inclusionAI/Ling-1T&quot; rel=&quot;&quot;&gt;
       Ling-1T
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/inclusionAI&quot; rel=&quot;&quot;&gt;
      inclusionAI
     &lt;/a&gt;
     &lt;span&gt;
      : Inclusion AI is waking up and starting to adopt the release cadence of its bigger brother by releasing models left, right and center. Similar to Qwen, they also started to scale up model sizes considerably, hitting the 1T threshold. They also
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/inclusionAI/Ring-1T-preview&quot; rel=&quot;&quot;&gt;
      release a reasoning version
     &lt;/a&gt;
     &lt;span&gt;
      and experiment with different architectures and modalities. Keep an eye on them!
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!5EW-!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2127eef5-ff98-4a00-8b54-a50feb1ca654_4770x2187.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!5EW-!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2127eef5-ff98-4a00-8b54-a50feb1ca654_4770x2187.png 424w, https://substackcdn.com/image/fetch/$s_!5EW-!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2127eef5-ff98-4a00-8b54-a50feb1ca654_4770x2187.png 848w, https://substackcdn.com/image/fetch/$s_!5EW-!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2127eef5-ff98-4a00-8b54-a50feb1ca654_4770x2187.png 1272w, https://substackcdn.com/image/fetch/$s_!5EW-!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2127eef5-ff98-4a00-8b54-a50feb1ca654_4770x2187.png 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2127eef5-ff98-4a00-8b54-a50feb1ca654_4770x2187.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:668,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;668&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!5EW-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2127eef5-ff98-4a00-8b54-a50feb1ca654_4770x2187.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!5EW-!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2127eef5-ff98-4a00-8b54-a50feb1ca654_4770x2187.png 424w, https://substackcdn.com/image/fetch/$s_!5EW-!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2127eef5-ff98-4a00-8b54-a50feb1ca654_4770x2187.png 848w, https://substackcdn.com/image/fetch/$s_!5EW-!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2127eef5-ff98-4a00-8b54-a50feb1ca654_4770x2187.png 1272w, https://substackcdn.com/image/fetch/$s_!5EW-!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2127eef5-ff98-4a00-8b54-a50feb1ca654_4770x2187.png 1456w&quot; width=&quot;1456&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/moondream/moondream3-preview&quot; rel=&quot;&quot;&gt;
       moondream3-preview
      &lt;/a&gt;
      &lt;span&gt;
      &lt;/span&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/moondream&quot; rel=&quot;&quot;&gt;
      moondream
     &lt;/a&gt;
     &lt;span&gt;
      : Moondream is far from an unknown player these days and known for punching well above its size. They too adopted the MoE architecture with 9B total, 2B active parameters and improved the already great benchmarks even further. An interesting aspect is its unique (in the AI world) license:
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;blockquote&gt;
     &lt;p&gt;
      TL;DR — You can use Moondream 3 (Preview) freely for personal, research, and most commercial uses. What’s NOT allowed without a separate deal is offering a paid product that competes with M87 Labs’ paid versions (e.g., selling hosted or embedded access to the model’s capabilities to third parties).
     &lt;/p&gt;
    &lt;/blockquote&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!Hub9!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f4f4cde-4ecd-4272-b5bc-216ea67369ea_2322x1050.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Hub9!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f4f4cde-4ecd-4272-b5bc-216ea67369ea_2322x1050.jpeg 424w, https://substackcdn.com/image/fetch/$s_!Hub9!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f4f4cde-4ecd-4272-b5bc-216ea67369ea_2322x1050.jpeg 848w, https://substackcdn.com/image/fetch/$s_!Hub9!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f4f4cde-4ecd-4272-b5bc-216ea67369ea_2322x1050.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!Hub9!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f4f4cde-4ecd-4272-b5bc-216ea67369ea_2322x1050.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;benchmarks&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9f4f4cde-4ecd-4272-b5bc-216ea67369ea_2322x1050.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:658,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;benchmarks&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;658&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!Hub9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f4f4cde-4ecd-4272-b5bc-216ea67369ea_2322x1050.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Hub9!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f4f4cde-4ecd-4272-b5bc-216ea67369ea_2322x1050.jpeg 424w, https://substackcdn.com/image/fetch/$s_!Hub9!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f4f4cde-4ecd-4272-b5bc-216ea67369ea_2322x1050.jpeg 848w, https://substackcdn.com/image/fetch/$s_!Hub9!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f4f4cde-4ecd-4272-b5bc-216ea67369ea_2322x1050.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!Hub9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f4f4cde-4ecd-4272-b5bc-216ea67369ea_2322x1050.jpeg 1456w&quot; title=&quot;benchmarks&quot; width=&quot;1456&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;div&gt;
   &lt;hr/&gt;
  &lt;/div&gt;
  &lt;p&gt;
   In the rest of the issue we highlight the long-tail of models, which again highlights the sweeping approach we’ve seen throughout the year from Qwen, but with continuing support from other rising Chinese labs. One of the sad things in this issue is that there are actually 0 datasets that cleared our bar of relevance. Open data continues to be in a very precarious position.
  &lt;/p&gt;
  &lt;h3&gt;
   &lt;strong&gt;
    Models
   &lt;/strong&gt;
  &lt;/h3&gt;
  &lt;h4&gt;
   &lt;strong&gt;
    Flagship
   &lt;/strong&gt;
  &lt;/h4&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Instruct&quot; rel=&quot;&quot;&gt;
       Qwen3-Next-80B-A3B-Instruct
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/Qwen&quot; rel=&quot;&quot;&gt;
      Qwen
     &lt;/a&gt;
     &lt;span&gt;
      : Of course, Qwen is also exploring different architectures, releasing a LLM with hybrid attention, consisting of Gated DeltaNet and Gated Attention. This model is trained on over 15T tokens and could be the groundwork for the next generation of Qwen models. Junyang Lin writes in a tweet about this series:
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    Qwen3-Next, or to say, a preview of our next generation (3.5?) is out!
   &lt;/p&gt;
   &lt;p&gt;
    This time we try to be bold, but actually we have been doing experiments on hybrid models and linear attention for about a year. We believe that our solution should be at least a stable and solid solution to new model architecture for super long context!
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/mistralai/Magistral-Small-2509&quot; rel=&quot;&quot;&gt;
       Magistral-Small-2509
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/mistralai&quot; rel=&quot;&quot;&gt;
      mistralai
     &lt;/a&gt;
     &lt;span&gt;
      : An update to the reasoning model by Mistral.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/meituan-longcat/LongCat-Flash-Thinking&quot; rel=&quot;&quot;&gt;
       LongCat-Flash-Thinking
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/meituan-longcat&quot; rel=&quot;&quot;&gt;
      meituan-longcat
     &lt;/a&gt;
     &lt;span&gt;
      : Yes, the Chinese Doordash continues to release models. This time, they drop the reasoning version of their MoE, coming with an interesting
     &lt;/span&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2509.18883&quot; rel=&quot;&quot;&gt;
      tech report
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> The State of Open Models </title>
<link>https://www.interconnects.ai/p/state-of-open-models-2025</link>
<pubDate>Thu, 16 Oct 2025 14:08:52 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   This talk covers everything that’s happened this year in the open model landscape — DeepSeek kickstarting the Chinese open model norms, Llama’s fade, Qwen’s dominance, GPT-OSS — and what comes next. It is my attempt to share what people need to know about where open models are heading, building on all of my research here at Interconnects and in my day job of training these models, in order to help us take the actions we need to steer it in a better direction.
  &lt;/p&gt;
  &lt;p&gt;
   I strongly recommend watching (or listening, as it’s in the podcast feed) if any of the discussions around open models or Chinese AI impacts your decision making. This felt like one of the better talks I’ve given in a bit and I’m excited to keep expanding my coverage here.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    You can click through the slides
   &lt;/span&gt;
   &lt;a href=&quot;https://docs.google.com/presentation/d/1f1Et0Mz8zb1yVCnCgdYSy4tAa0Kv_gKT4wPEg1XPdUA/edit?usp=sharing&quot; rel=&quot;&quot;&gt;
    here
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/state-of-open-models-2025?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/state-of-open-models-2025?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Thanks to the organizers of The Curve for inviting me (and encouraging me to give this talk), and for permission to post this video.
  &lt;/p&gt;
  &lt;p&gt;
   EDIT: I noticed sometimes the audio jumps weirdly, not sure what caused it (from slideslive export, raw is here: https://slideslive.com/39046297/open-models-in-2025-stakes-state-and-strategy)
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Chapters
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    00:00 2025 so far
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    05:53 China takes the lead
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    15:54 What comes next
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    21:20 What we should do
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    25:00 Q &amp; A
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   (Podcast feed / Audio only version trims 7 seconds of silence to start)
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    References &amp; Recommended Reading
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://atomproject.ai/&quot; rel=&quot;&quot;&gt;
      The ATOM Project
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/on-chinas-open-source-ai-trajectory&quot; rel=&quot;&quot;&gt;
      On China’s open-source community &amp; trajectory
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/chinas-top-19-open-model-labs&quot; rel=&quot;&quot;&gt;
      Ranking China’s open AI labs
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/gpt-oss-openai-validates-the-open&quot; rel=&quot;&quot;&gt;
      On GPT-OSS
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/t/artifacts-log&quot; rel=&quot;&quot;&gt;
      Recent open models
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/thoughts-on-the-curve&quot; rel=&quot;&quot;&gt;
      More on The Curve conference
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   Of course, you can watch on YouTube:
  &lt;/p&gt;
  &lt;div data-attrs=&#x27;{&quot;videoId&quot;:&quot;FUcilE5Gx_0&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}&#x27; data-component-name=&quot;Youtube2ToDOM&quot;&gt;
   &lt;div&gt;
    &lt;iframe allow=&quot;autoplay; fullscreen&quot; allowautoplay=&quot;true&quot; allowfullscreen=&quot;true&quot; frameborder=&quot;0&quot; gesture=&quot;media&quot; height=&quot;409&quot; loading=&quot;lazy&quot; src=&quot;https://www.youtube-nocookie.com/embed/FUcilE5Gx_0?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0&quot; width=&quot;728&quot;&gt;
    &lt;/iframe&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    Listen on
   &lt;/span&gt;
   &lt;a href=&quot;https://podcasts.apple.com/us/podcast/interconnects-audio/id1719552353&quot; rel=&quot;&quot;&gt;
    Apple Podcasts
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://open.spotify.com/show/2UE6s7wZC4kiXYOnWRuxGv&quot; rel=&quot;&quot;&gt;
    Spotify
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.youtube.com/@interconnects&quot; rel=&quot;&quot;&gt;
    YouTube
   &lt;/a&gt;
   &lt;span&gt;
    , and
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/podcast&quot; rel=&quot;&quot;&gt;
    where ever you get your podcasts
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Thoughts on The Curve </title>
<link>https://www.interconnects.ai/p/thoughts-on-the-curve</link>
<pubDate>Tue, 07 Oct 2025 12:03:23 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   I spent the weekend debating AI timelines, among other things, at The Curve conference. This translates as spending the weekend thinking about the trajectory of AI progress with a mix of DC and SF types. This is a worthwhile event that served as a great, high-bandwidth way to check in on timelines and expectations of the AI industry.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/thoughts-on-the-curve?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/thoughts-on-the-curve?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;h2&gt;
   &lt;strong&gt;
    Updating timelines
   &lt;/strong&gt;
  &lt;/h2&gt;
  &lt;p&gt;
   My most striking takeaway is that the AI 2027 sequence of events, from AI models automating research engineers to later automating AI research, and potentially a singularity if your reasoning is so inclined, is becoming a standard by which many debates on AI progress operate under and tinker with. It’s good that many people are taking the long term seriously, but there’s a risk in so many people assuming a certain sequence of events is a sure thing and only debating the timeframe by which they arrive.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    I’ve
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/brakes-on-an-intelligence-explosion?utm_source=publication-search&quot; rel=&quot;&quot;&gt;
    documented my views
   &lt;/a&gt;
   &lt;span&gt;
    on the near term of AI progress and not much has changed, but through repetition I’m developing a more refined version of the arguments. I add this depth to my takes in this post.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I think automating the “AI Research Engineer (RE)” is doable in the 3-7 year range — meaning the person that takes a research idea, implements it, and compares it against existing baselines is entirely an AI that the “scientists” will interface with.
  &lt;/p&gt;
  &lt;p&gt;
   In some areas the RE is arguably already automated. Within 2 years a lot of academic AI research engineering will be automated with the top end of tools — I’m not sure academics will have access to these top end of tools but that is a separate question. An example I would give is coming up with a new optimizer and testing it on a series of ML baselines from 100M to 10B parameters. At this time I don’t expect the models to be able to implement the newest problems the frontier labs are facing alone. I also expect academics to be fully priced out from these tools.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Within 1-3 years we’ll have tools that make
   &lt;/span&gt;
   &lt;em&gt;
    existing
   &lt;/em&gt;
   &lt;span&gt;
    REs unbelievably productive (80-90% automated), but there are still meaningful technical bottlenecks that are solvable but expensive. The compute increase per available user has a ceiling too. Labs will be spending $200k+ per year per employee on AI tools easily (ie the inference cost), but most consumers will be at tiers of $20k or less due to compute scarcity.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Within 3-4 years the augmented research engineers will be able to test any idea that the scientists come up with at the frontier labs, but many complex system problems will need some (maybe minimal) amount of human oversight. Examples would include modifying RL implementations for extremely long horizon tasks or wacky new ideas on continual learning. This is so far out that the type of research idea almost isn’t worth speculating on.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    These long timelines are strongly based on the fact that the category of research engineering is too broad. Some parts of the RE job will be fully automated next year, and more the next.
   &lt;/span&gt;
   &lt;strong&gt;
    To check the box of automation the entire role needs to be replaced.
   &lt;/strong&gt;
   &lt;span&gt;
    What is more likely over the next few years, each engineer is doing way more work and the job description evolves substantially. I make this callout on full automation because it is required for the distribution of outcomes that look like a singularity due to the need to remove the human bottleneck for an ever accelerating pace of progress. This is a point to reinforce that I am currently confident in a singularity not happening.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
  &lt;/div&gt;
  &lt;p&gt;
   Up-skilling employees as their roles become irrelevant creates a very different dynamic. The sustained progress on code performance over the next few years will create a constant feeling of change across the technology industry. The range of performance in software is very high and it is possible to perceive relatively small incremental improvements.
  &lt;/p&gt;
  &lt;p&gt;
   These are very complex positions to hold, so they’re not that useful as rhetorical devices. Code is on track to being solved, but the compute limits and ever increasing complexity of codebases and projects (ie. LLMs) is going to make the dynamic very different than the succinct assumptions of AI 2027.
  &lt;/p&gt;
  &lt;p&gt;
   To reiterate, the most important part of automation in the discussion is often neglected. To automate someone you need to outcompete the pairing of a human with the tool too.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Onto the even trickier argument in the AI 2027 standard — automating AI research altogether. At the same time as the first examples of AI systems writing accepted papers at
   &lt;/span&gt;
   &lt;a href=&quot;https://sakana.ai/ai-scientist-first-publication/&quot; rel=&quot;&quot;&gt;
    notable
   &lt;/a&gt;
   &lt;span&gt;
    AI
   &lt;/span&gt;
   &lt;a href=&quot;https://www.intology.ai/blog/zochi-acl&quot; rel=&quot;&quot;&gt;
    venues
   &lt;/a&gt;
   &lt;span&gt;
    , I’m going to be here arguing that full automation of AI research isn’t coming anytime soon. It’s daunting to try and hold (and explain) this position, and it relies on all the messy firsthand knowledge of science that I have and how it is different in academia versus frontier AI labs.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   For one, the level and type of execution at frontier labs relative to academic research is extremely different. Academia also has a dramatically higher variance in quality of work that is accepted within the community. For this reason, we’re going to be seeing incredible disruption at standard academic venues in the very near future, but the nature of science at frontier labs will remain heavily intertwined with human personalities.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Models will be good at some types of science, such as taking two existing fields and merging ideas and seeing what happens, but awful at what I consider to be the most
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/deep-research-information-vs-insight-in-science&quot; rel=&quot;&quot;&gt;
    idolized version of science
   &lt;/a&gt;
   &lt;span&gt;
    , being immersed in the state of the art and having a brilliant insight that makes anywhere from a ripple causing small performance gain to a tsunami reshaping the field.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I don’t think AI will fully automate our current notion of an AI researcher in the next 5-10 years, but it could reshape what science means altogether and make that role far less relevant to progress.
  &lt;/p&gt;
  &lt;p&gt;
   The researchers grinding out new datasets at frontier labs will have dramatic help on data processing scripts. The researchers coming up with new algorithmic ideas will not expand the rate at which they come up with ideas too much, but their ability to test them is far higher.
  &lt;/p&gt;
  &lt;p&gt;
   A large part of science is a social marketplace of ideas. Convincing your colleagues that you are right and to help you double down on it is not going to change in its core nature. Everyone will have superpowers on making evidence to support their claims, but the relative power there stays the same.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    At a dinner during The Curve I went through a lot of these points with
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/ryanpgreenblatt?lang=en&quot; rel=&quot;&quot;&gt;
    Ryan Greenblatt
   &lt;/a&gt;
   &lt;span&gt;
    , Chief Scientist at Redwood Research, and a point he made stuck with me. He summarized my points as thinking the increase in performance from these largely engineering tooling improvements will be equalled out by challenges of scaling compute, so the resulting progress will feel much more linear rather than exponential. A lot of our discussions on automation we agree on, with slightly different timelines, but it didn’t feel like it captured my entire point of view.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   What is missing is that I expect an inherent slowdown as our AI models get more complicated. Our models today needs tools, more complex serving systems, products to wrap them, and so on. This is very different than the age when just model weights were needed for the cutting edge of AI. There’s an inevitable curse of complexity, a death by a thousand cuts, that is going to add on top of the obvious compute costs to slow down progress.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    2026 will be a big year on the compute rollout front, and shipping meaningful improvements to users will be essential to funding the progress that comes after. I’m not sure the economy can keep shifting even more of its weight behind AI progress, where most people bought into fast timelines think of it as a default position. Peter Wildeford
   &lt;/span&gt;
   &lt;a href=&quot;https://peterwildeford.substack.com/p/openai-nvidia-and-oracle-breaking&quot; rel=&quot;&quot;&gt;
    wrote a summary
   &lt;/a&gt;
   &lt;span&gt;
    of the situation that I resonate with:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    Here’s how I think the AI buildout will go down.
   &lt;/p&gt;
   &lt;p&gt;
    &lt;span&gt;
     Currently the world doesn’t have any operational 1GW+ data centers. However, it is very likely we will see fully operational 1GW data centers before
    &lt;/span&gt;
    &lt;strong&gt;
     mid-2026
    &lt;/strong&gt;
    &lt;span&gt;
     . This likely will be a part of 45-60GW of total compute across Meta, Microsoft, Amazon/AWS/Anthropic, OpenAI/Oracle, Google/DeepMind, and xAI.
    &lt;/span&gt;
   &lt;/p&gt;
   &lt;p&gt;
    My median expectation is these largest ~1GW data center facilities will hold ~400,000-500,000 Nvidia Blackwell chips and be used to train ~4e27 FLOP model sometime before the end of 2027. Such a model would be 10x larger than the largest model today and 100x larger than GPT-4. Each individual 1GW facility would cost ~$40B to manufacture, with ~$350B total industry spend across 2026.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   He continues with estimates for 2028, and saying he’s fuzzy on 2029, but my fuzziness cuts in a bit earlier depending on adoption and performance across the AI industry.
  &lt;/p&gt;
  &lt;p&gt;
   Where I feel like in the long run it’ll look like a very consistent pace of progress, that feels like a bunch of big jumps and periods of stagnation in the short-term. I have fairly large error bars on how the price of intelligence — and therefore adoption — is going to evolve over the next 2-4 years, with it obviously becoming far cheaper over the following decades.
  &lt;/p&gt;
  &lt;p&gt;
   As for my recent articles on timelines and key debates in the field, I encourage people to comment and dig in on what I wrote below.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   &lt;strong&gt;
    Other thoughts
   &lt;/strong&gt;
  &lt;/h2&gt;
  &lt;p&gt;
   Something crazy about this conference is no one is talking about how the models actually work or are trained, and everyone here is totally convinced that AGI is coming soon.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    One of my new friends at the conference described this tendency as “an obsession with the problem.” This is a feeling that many AI obsessors are more interested in where the technology is going rather than how or what exactly it is going to be.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;a data-attrs=&#x27;{&quot;name&quot;:&quot;Helen Toner&quot;,&quot;id&quot;:1591604,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F504a525a-715f-467c-a4c3-b024c88cbf45_2373x2209.jpeg&quot;,&quot;uuid&quot;:&quot;2e098426-6e63-4dd3-8029-d7cd8620af13&quot;}&#x27; data-component-name=&quot;MentionUser&quot; href=&quot;https://open.substack.com/users/1591604-helen-toner?utm_source=mentions&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;
    Helen Toner
   &lt;/a&gt;
  &lt;/div&gt;
  &lt;span&gt;
   gave a great talk at The Curve related to this, arguing how the current and future jaggedness of AI — the fact that similarly difficult tasks when assigned to a human will either be easily mastered by AI or barely showing any competence (her will appear later on her
  &lt;/span&gt;
  &lt;a href=&quot;https://helentoner.substack.com/&quot; rel=&quot;&quot;&gt;
   great Substack
  &lt;/a&gt;
  &lt;span&gt;
   ). It is the idea that AI capabilities evolve highly randomly across potentially similar tasks.
  &lt;/span&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!EUbq!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b573d1-f656-46ca-8dc3-c9d058f7db34_1308x1512.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!EUbq!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b573d1-f656-46ca-8dc3-c9d058f7db34_1308x1512.png 424w, https://substackcdn.com/image/fetch/$s_!EUbq!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b573d1-f656-46ca-8dc3-c9d058f7db34_1308x1512.png 848w, https://substackcdn.com/image/fetch/$s_!EUbq!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b573d1-f656-46ca-8dc3-c9d058f7db34_1308x1512.png 1272w, https://substackcdn.com/image/fetch/$s_!EUbq!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b573d1-f656-46ca-8dc3-c9d058f7db34_1308x1512.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d8b573d1-f656-46ca-8dc3-c9d058f7db34_1308x1512.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1512,&quot;width&quot;:1308,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:186564,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/175380285?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b573d1-f656-46ca-8dc3-c9d058f7db34_1308x1512.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;1512&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!EUbq!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b573d1-f656-46ca-8dc3-c9d058f7db34_1308x1512.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!EUbq!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b573d1-f656-46ca-8dc3-c9d058f7db34_1308x1512.png 424w, https://substackcdn.com/image/fetch/$s_!EUbq!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b573d1-f656-46ca-8dc3-c9d058f7db34_1308x1512.png 848w, https://substackcdn.com/image/fetch/$s_!EUbq!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b573d1-f656-46ca-8dc3-c9d058f7db34_1308x1512.png 1272w, https://substackcdn.com/image/fetch/$s_!EUbq!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b573d1-f656-46ca-8dc3-c9d058f7db34_1308x1512.png 1456w&quot; width=&quot;1308&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    This original figure on jaggedness comes from
   &lt;/span&gt;
   &lt;a href=&quot;https://www.hbs.edu/ris/Publication%20Files/24-013_d9b45b68-9e74-42d6-a1c6-c72fb70c7282.pdf&quot; rel=&quot;&quot;&gt;
    work
   &lt;/a&gt;
   &lt;span&gt;
    with the popular AI Substacker Ethan Mollick.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The relation of Helen’s talk is that she gets many forms of arguments that only the endpoint of AI matters, but that doesn’t account for the messiness of the trajectory and how unsettling that could be for the world.
  &lt;/p&gt;
  &lt;p&gt;
   I agree with Helen.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    One of the things that I am confident will exist in about two years is a Sora 2 style model that can run on a MacBook without copyright, personal opt-in, or other safety filters. On this,
   &lt;/span&gt;
   &lt;a href=&quot;https://epoch.ai/data-insights/consumer-gpu-model-gap&quot; rel=&quot;&quot;&gt;
    Epoch AI has a wonderful plot
   &lt;/a&gt;
   &lt;span&gt;
    showing that local models lag behind in capabilities by a fixed amount of time:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!HLm5!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16e0afde-73fd-4e25-9cdb-b52d694ab092_1586x1004.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!HLm5!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16e0afde-73fd-4e25-9cdb-b52d694ab092_1586x1004.jpeg 424w, https://substackcdn.com/image/fetch/$s_!HLm5!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16e0afde-73fd-4e25-9cdb-b52d694ab092_1586x1004.jpeg 848w, https://substackcdn.com/image/fetch/$s_!HLm5!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16e0afde-73fd-4e25-9cdb-b52d694ab092_1586x1004.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!HLm5!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16e0afde-73fd-4e25-9cdb-b52d694ab092_1586x1004.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;Image&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/16e0afde-73fd-4e25-9cdb-b52d694ab092_1586x1004.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:922,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;922&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!HLm5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16e0afde-73fd-4e25-9cdb-b52d694ab092_1586x1004.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!HLm5!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16e0afde-73fd-4e25-9cdb-b52d694ab092_1586x1004.jpeg 424w, https://substackcdn.com/image/fetch/$s_!HLm5!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16e0afde-73fd-4e25-9cdb-b52d694ab092_1586x1004.jpeg 848w, https://substackcdn.com/image/fetch/$s_!HLm5!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16e0afde-73fd-4e25-9cdb-b52d694ab092_1586x1004.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!HLm5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16e0afde-73fd-4e25-9cdb-b52d694ab092_1586x1004.jpeg 1456w&quot; title=&quot;Image&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    With trends like this, it is so obvious that we need to stay on the front foot of open models and not reacting to international parties that are far harder to predict and engage with. This is where I get renewed motivation for
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/the-american-deepseek-project&quot; rel=&quot;&quot;&gt;
    American DeepSeek
   &lt;/a&gt;
   &lt;span&gt;
    /
   &lt;/span&gt;
   &lt;a href=&quot;https://www.atomproject.ai/&quot; rel=&quot;&quot;&gt;
    The ATOM Project
   &lt;/a&gt;
   &lt;span&gt;
    . For example, I still get many adamant questions that we should consider banning open models altogether. The state of discourse, study, investment, and everything in between on open models in the U.S. is still in a quite underdeveloped state.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    China’s rise in open models was something I expected to be a bigger topic at the conference, but it seemed like it was too orthogonal to the overall pace of progress to be front of mind. There were many discussions of the Chinese chip ecosystem, but less on what it enables. Not focusing on this could have costly geopolitical consequences as we cede ownership of a global standard to China. This was a large theme of my talk. The recording will be posted here soon and the slides for my talk are
   &lt;/span&gt;
   &lt;a href=&quot;https://docs.google.com/presentation/u/1/d/1f1Et0Mz8zb1yVCnCgdYSy4tAa0Kv_gKT4wPEg1XPdUA/edit?usp=sharing&quot; rel=&quot;&quot;&gt;
    here
   &lt;/a&gt;
   &lt;span&gt;
    (credit for Florian Brand who helps me with open model analysis here for feedback on the slides). Otherwise:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     These messages are very important and I will work to spend a bit more time engaging with the communities they touch and mastering this type of talk (and analysis)
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     More people should work in the area, it’s crazy it has just fallen on me where it is my side hustle.
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   For now, I’m just landing at the conference on language modeling (COLM) in Montreal, so I may have some technical hot takes to share later this week!
  &lt;/p&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> ChatGPT: The Agentic App </title>
<link>https://www.interconnects.ai/p/the-agentic-app</link>
<pubDate>Tue, 30 Sep 2025 13:03:22 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    Ever since ChatGPT exploded in popularity, there has been a looming “how” to its monetization plans. Much has been said about shopping and advertising as the likely paths, especially with Fidji Simo
   &lt;/span&gt;
   &lt;a href=&quot;https://openai.com/index/leadership-expansion-with-fidji-simo/&quot; rel=&quot;&quot;&gt;
    joining
   &lt;/a&gt;
   &lt;span&gt;
    as CEO of Applications under Sam Altman.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Advertising as a business model for AI is logical but difficult to personalize and specialize. We know tons of people spend a lot of time using AI models, but how do you best get the sponsored content into the outputs? This is an open technical problem, with early efforts from the likes of
   &lt;/span&gt;
   &lt;a href=&quot;https://www.theinformation.com/articles/perplexitys-commerce-ads-experiments-stuck-neutral&quot; rel=&quot;&quot;&gt;
    Perplexity falling short
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/the-agentic-app#footnote-1-174879663&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     1
    &lt;/a&gt;
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Shopping is another,
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/the-agentic-app#footnote-2-174879663&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     2
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    but the questions have long been whether AI models actually have the precision to find the items you want, to learn exactly what you love, and to navigate the web to handle all the corner cases of checkouts. These reflect a need for increased capabilities on known AI benchmarks, rather than inventing a new way of serving ads.
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/openais-o3-over-optimization-is-back&quot; rel=&quot;&quot;&gt;
    OpenAI’s o3
   &lt;/a&gt;
   &lt;span&gt;
    model was a major step up in search functionality, showing it was viable; the integration was either a business problem — where OpenAI had to make deals — or an AI one — where ChatGPT wasn’t good enough at managing websites for you.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/the-agentic-app?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/the-agentic-app?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Yesterday, ChatGPT launched its first integrated shopping push with
   &lt;/span&gt;
   &lt;em&gt;
    &lt;a href=&quot;https://openai.com/index/buy-it-in-chatgpt/&quot; rel=&quot;&quot;&gt;
     Buy It in ChatGPT
    &lt;/a&gt;
   &lt;/em&gt;
   &lt;span&gt;
    , a simple checkout experience, and an integrated commerce backend built on the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.agenticcommerce.dev/&quot; rel=&quot;&quot;&gt;
    Agentic Commerce Protocol
   &lt;/a&gt;
   &lt;span&gt;
    (ACP)
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/the-agentic-app#footnote-3-174879663&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     3
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    . The announcement comes with the perfect partners to complement the strengths of OpenAI’s current models.
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/the-agentic-app#footnote-4-174879663&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     4
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    GPT-5-Thinking is the best at finding niche content on the web, and ChatGPT’s launch partner for shopping is Shopify (*soon, Etsy is available today), the home to the long tail of e-commerce merchants of niche specialties. If this works, it will let users actively uncover exactly what they are looking for — from places that were often hard to impossible to find on Google.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    This synergy is a theme we’ll see reoccur in other agents of the future. The perfect model doesn’t make a useful application unless it has the information or sandbox it needs to
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/thinking-searching-and-acting&quot; rel=&quot;&quot;&gt;
    think, search, and act
   &lt;/a&gt;
   &lt;span&gt;
    . The crucial piece that is changing is that where models act is just as important as the weights themselves — in the case of shopping, it is the network of stores with their own rankings and API.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The ACP was built in collaboration with Stripe, and both companies stand to benefit from this. Stripe wants more companies to build on the ACP so that its tools become the “
   &lt;/span&gt;
   &lt;a href=&quot;https://stripe.com/blog/developing-an-open-standard-for-agentic-commerce&quot; rel=&quot;&quot;&gt;
    open standard for agentic payments
   &lt;/a&gt;
   &lt;span&gt;
    ” and OpenAI wants the long-tail of stores to adopt it so they can add them to their ever-growing internal recommendation (or search) engine. The business model is simple, as OpenAI says “Merchants pay a small fee on completed purchases.” OpenAI likely takes a larger share than Stripe, and it is a share that can grow as their leverage increases over shoppers.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I’m cautiously optimistic about this. Finding great stuff to buy on the web is as hard as it has ever been. Users are faced with the gamification of Google search for shopping and the enshittification of the physical goods crowding out Amazon. Many of the best items to buy are found through services like Meta’s targeted ads, but the cost of getting what you want should not be borne through forced distraction.
  &lt;/p&gt;
  &lt;p&gt;
   OpenAI will not be immune to the forces that drove these companies to imperfect offerings, but they’ll come at them with a fresh perspective on recurring issues in technology. If this works for OpenAI, they have no competitor. They have a distribution network of nearly 1B weekly users and no peer company ready to serve agentic models at this scale. Yes, Google can change its search feed, but the thoroughness of models like GPT-5 Thinking is on a totally different level than Google search. This agentic model is set up to make ChatGPT the one Agentic App across all domains.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The idea of an agentic model, and really the GPT-5 router itself, shows us how the grand idea of one giant model that’s the best for every conceivable use-case is crumbling. OpenAI only chooses the more expensive thinking model when it deems a free user to need it and they have an entirely different model for their coding products. On the other hand, Claude released their latest model,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.anthropic.com/news/claude-sonnet-4-5&quot; rel=&quot;&quot;&gt;
    Claude 4.5 Sonnet
   &lt;/a&gt;
   &lt;span&gt;
    , yesterday as well, optimizing their coding peak performance and speed yet again — they have no extended model family.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The reality that different models serve very different use-cases and how AI companies need to decide and commit to a certain subset of them for their development points to a future with a variety of model providers.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Where
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/coding-as-the-epicenter-of-ai-progress&quot; rel=&quot;&quot;&gt;
    coding is where you can feel the frontier
   &lt;/a&gt;
   &lt;span&gt;
    of AI’s raw intelligence or capabilities, and Anthropic has turned their
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/claude-4-and-anthropics-bet-on-code&quot; rel=&quot;&quot;&gt;
    entire development towards it
   &lt;/a&gt;
   &lt;span&gt;
    , the type of model that is needed for monetization of a general consumer market could be very different. This is the web-agent that OpenAI has had the industry-leading version of for about 6 months.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Specialization is making the AI market far more interesting, as companies like OpenAI and Google have been in lockstep with their offerings for years. Every company would drop the same model modalities with approximately the same capabilities. Now, as hill-climbing benchmarks are no longer providing immediate user value, especially in text domains, the vision for each AI company is more nuanced. I predicted this earlier in the summer, in my
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/summertime-outlook-o3s-novelty-coming?utm_source=publication-search&quot; rel=&quot;&quot;&gt;
    post
   &lt;/a&gt;
   &lt;span&gt;
    on what comes next:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    &lt;span&gt;
     This is a different path for the industry and will take a different form of messaging than we’re used to. More releases are going to look like
    &lt;/span&gt;
    &lt;a href=&quot;https://www.interconnects.ai/p/claude-4-and-anthropics-bet-on-code&quot; rel=&quot;&quot;&gt;
     Anthropic’s Claude 4
    &lt;/a&gt;
    &lt;span&gt;
     , where the benchmark gains are minor and the real world gains are a big step.
    &lt;/span&gt;
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   What I missed is that this applies downward pressure on the number of models labs will release — the value can be more in the integrations and applications than the model itself. Expect releases like today, where Claude released Claude Sonnet 4.5 along with version 2 of Claude Code. The period will still be busy as the industry is on the tail end of the low hanging fruit provided by reasoning models, but over time the hype of model releases themselves will be harder to conjure.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
   Let’s consider the applications that are rolling out today on top of different models. If you haven’t pushed the limits of GPT-5-Thinking, and better yet GPT-5-Pro, for search you really need to, it’s a transformative way of using compute that can find many buried corners of the web. In terms of untapped model capability value, the abilities of search-heavy thinking models like GPT-5 seem far higher than coding agents, which are obviously heavily used. Search-heavy models are an entirely new use, where coding models were the first widespread LLM-based product. As coding agents become more autonomous, they’ll continue to flex and mold a new form for the software industry, but this will be a slow co-evolution.
  &lt;/p&gt;
  &lt;p&gt;
   OpenAI is going to focus on its vertical Agentic App where Anthropic (and likely Gemini with Google Cloud) are going to power the long-tail of AI applications reshaping the web and the rest of work. OpenAI will only expand from here. Email, scheduling, travel bookings, and more everyday digital tasks are surely on their roadmap. Their biggest competitor is themselves — and whether their vision can be crafted into something people actually use. If shopping doesn’t work out as the vertical that lets them realize their valuation, they’re positioned to keep trying more. OpenAI has both the lead in the variety of models that power these agentic information tasks and the user base to incentivize companies to collaborate with them.
  &lt;/p&gt;
  &lt;p&gt;
   The application paradigm that dominated the mobile era is going to rebound. AI applications started in a form where the user needed to be heavily involved in the work process. The first beneficiaries of this were IDEs and terminal tools. Both of these workplaces allow in-depth and detailed inspection of the process and results. The cutting edge of AI will still work there, but the long tail of casual use will all shift to the standard mode of applications — siloed, simple, and scalable in the cloud. The simpler an AI application is, the wider its potential audience.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    With this addition of shopping, OpenAI is
   &lt;/span&gt;
   &lt;a href=&quot;https://www.wired.com/story/openai-launches-sora-2-tiktok-like-app/&quot; rel=&quot;&quot;&gt;
    poised to launch a standalone TikTok-style app
   &lt;/a&gt;
   &lt;span&gt;
    with the release of its next video generation model, Sora 2, soon after
   &lt;/span&gt;
   &lt;a href=&quot;https://about.fb.com/news/2025/09/introducing-vibes-ai-videos/&quot; rel=&quot;&quot;&gt;
    Meta launched Vibes
   &lt;/a&gt;
   &lt;span&gt;
    in their Meta AI app for only AI generated videos with a specific theme to start.  At the same time, OpenAI’s Codex web agent is available in the ChatGPT application, which represents an even bigger change in the nature of software work than the addition of coding agents — it allows real websites, and soon businesses, to be built with only a prompt on your phone.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   In 6-12 months, these agentic applications that feel rough around the edges due to the quality of the AI today, rather than the interface, are going to feel seamless and second-nature to use, despite their complete novelty relative to the past decades of technology.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    If OpenAI is positioning itself to be The Agentic App, this also opens the door to the near future where many applications we use today shift to an agentic era
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/the-agentic-app#footnote-5-174879663&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     5
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    . Want to schedule a meeting with someone? Let the Google Calendar agent handle that (or some startup that beats them to it). Your email application can find who the next client is and remind them of their appointment. The Banking App will file your taxes in one prompt. The list of these is infinite and across a wide spectrum of difficulty. OpenAI wants to be the one app, The Agentic App, that serves all of these, and the rest of the industry is racing to master their specific vertical before OpenAI gets there.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/the-agentic-app#footnote-anchor-1-174879663&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     &lt;span&gt;
      I don’t cover OpenAI’s new
     &lt;/span&gt;
     &lt;a href=&quot;https://openai.com/index/introducing-chatgpt-pulse/&quot; rel=&quot;&quot;&gt;
      Pulse
     &lt;/a&gt;
     &lt;span&gt;
      feature in this post, which is a sort of algorithmic content feed for ChatGPT, which could be a great place for ads and a surface to practice specializing to users, which is needed for shopping results. My initial Pulse examples were fairly heavy in slop, and this is only available to Pro users, where shopping is universal. We’ll have to wait longer on Pulse as a feature.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/the-agentic-app#footnote-anchor-2-174879663&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    2
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     &lt;span&gt;
      SemiAnalysis had a
     &lt;/span&gt;
     &lt;a href=&quot;https://semianalysis.com/2025/08/13/gpt-5-ad-monetization-and-the-superapp/&quot; rel=&quot;&quot;&gt;
      great article
     &lt;/a&gt;
     &lt;span&gt;
      in this space, covering why the router is so important with OpenAI’s free user base and a similar view of the “ChatGPT SuperApp.”
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;p&gt;
     They went so far as to say that ChatGPT will spend more compute on more valuable queries, but that is more dystopian than I see happening in the near future.
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/the-agentic-app#footnote-anchor-3-174879663&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    3
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     If the ACP is a new wave of every backend software for AI being named some “protocol” with the last two initials ending in *CP, à la MCP, this certainly won’t last. Looking briefly under the hood reveals that ACP is fairly complex with many defined functionalities, from discoverability and feeds for merchants to commands for checkout and orders that interface with digital inventories and finally payments. MCP, on the other hand, is a simple tool for accessing information.
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/the-agentic-app#footnote-anchor-4-174879663&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    4
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     This does not include their early, and growing, work on ChatGPT customization as well, which will play heavily into shopping.
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/the-agentic-app#footnote-anchor-5-174879663&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    5
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     &lt;span&gt;
      Similar to how Cloudfare is
     &lt;/span&gt;
     &lt;a href=&quot;https://blog.cloudflare.com/content-independence-day-no-ai-crawl-without-compensation/&quot; rel=&quot;&quot;&gt;
      positioning their information services for the agentic web
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Thinking, Searching, and Acting </title>
<link>https://www.interconnects.ai/p/thinking-searching-and-acting</link>
<pubDate>Mon, 22 Sep 2025 15:44:34 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   The weaknesses of today’s best models are far from those of the original ChatGPT — we see they lack speed, we fear superhuman persuasion, and we aspire for our models to be more autonomous. These models are all reasoning models that have long surpassed the original weaknesses of ChatGPT-era language models, hallucinations, total lack of recent information, complete capitulations, and other hiccups that looked like minor forms of delusion laid on top of an obviously spectacular new technology.
  &lt;/p&gt;
  &lt;p&gt;
   Reasoning models today are far more complex than the original chatbots that consisted of standalone model weights (and other lightweight scaffolding such as safety filters). They&#x27;re built on three primitives that&#x27;ll be around for years to come:
  &lt;/p&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Thinking
     &lt;/strong&gt;
     &lt;span&gt;
      : The reasoning traces that enabled inference-time scaling. The &quot;thoughts&quot; of a reasoning model take a
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/the-rise-of-reasoning-machines&quot; rel=&quot;&quot;&gt;
      very different form than those of humans that inspired the terminology
     &lt;/a&gt;
     &lt;span&gt;
      used like Chain of Thought (CoT) or Thinking models.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Searching
     &lt;/strong&gt;
     &lt;span&gt;
      : The ability to request more, specific information from non-parametric knowledge stores designed specifically for the model. This fills the void set by how model weights are static but living in a dynamic world.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Acting
     &lt;/strong&gt;
     &lt;span&gt;
      : The ability for models to manipulate the physical or digital world. Everything from code-execution now to real robotics in the future allow language models to contact reality and overcome their nondeterministic core. Most of these executable environments are going to
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/coding-as-the-epicenter-of-ai-progress&quot; rel=&quot;&quot;&gt;
      build on top of infrastructure for coding agents
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/thinking-searching-and-acting?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/thinking-searching-and-acting?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    These reasoning language models, as a form of technology are going to last far longer than the static model weights that predated and birthed ChatGPT. Sitting just over a year out from the
   &lt;/span&gt;
   &lt;a href=&quot;https://openai.com/index/learning-to-reason-with-llms/&quot; rel=&quot;&quot;&gt;
    release
   &lt;/a&gt;
   &lt;span&gt;
    of OpenAI&#x27;s o1-preview on September 12, 2024, the magnitude of this is important to write in ink. Early reasoning models with astounding evaluation scores were greeted with resounding criticism of “
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/why-reasoning-models-will-generalize&quot; rel=&quot;&quot;&gt;
    they won’t generalize
   &lt;/a&gt;
   &lt;span&gt;
    ,” but that has turned out to be resoundingly false.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    In fact, with OpenAI&#x27;s o3, it only took 3-6 months for these primitives to converge! Still, it took the AI industry more broadly a longer time to converge on this. The most similar follow-up on the search front was
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/grok-4-an-o3-look-alike-in-search&quot; rel=&quot;&quot;&gt;
    xAI&#x27;s Grok 4
   &lt;/a&gt;
   &lt;span&gt;
    and some frontier models such as
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/claude-4-and-anthropics-bet-on-code&quot; rel=&quot;&quot;&gt;
    Claude 4
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;em&gt;
    express
   &lt;/em&gt;
   &lt;span&gt;
    their reasoning model nature in a far more nuanced manner. OpenAI&#x27;s o3 (and GPT-5 Thinking,
   &lt;/span&gt;
   &lt;a href=&quot;https://simonwillison.net/2025/Sep/6/research-goblin/&quot; rel=&quot;&quot;&gt;
    a.k.a. Research Goblin
   &lt;/a&gt;
   &lt;span&gt;
    ) and xAI&#x27;s Grok 4 models seem like a dog determined to chase their goal indefinitely and burn substantial compute along the way. Claude 4 has a much softer touch, resulting in a model that is a bit less adept at search, but almost always returns a faster answer. The long-reasoning traces and tool use can be crafted to fit different profiles, giving us a spectrum of reasoning models.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/next-gen-reasoners&quot; rel=&quot;&quot;&gt;
    taxonomy
   &lt;/a&gt;
   &lt;span&gt;
    that I laid out this summer for next-generation reasoning models — skills for reasoning intelligence, calibration to not overthink, strategy to choose the right solutions, and abstraction to break them down — are the traits that&#x27;ll make a model most functional given this new perspective and agentic world.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div data-component-name=&quot;DigestPostEmbed&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/next-gen-reasoners&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;
   &lt;/a&gt;
  &lt;/div&gt;
  &lt;p&gt;
   The manner of these changes are easy to miss. For one, consider hallucinations, which are an obvious weakness downstream of the stochastic inference innate to the models and their fixed date cutoff. With search, hallucinations are now missing context rather than blatantly incorrect content. Language models are nearly-perfect at copying content and similarly solid at referencing it, but they&#x27;re still very flawed at long-context understanding. Hallucinations still matter, but it’s a very different chapter of the story and will be studied differently depending on if it is for reasoning or non-reasoning language models.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Non-reasoning models still have a crucial part to play in the AI economy due to their efficiency and simplicity. They are
   &lt;/span&gt;
   &lt;em&gt;
    part
   &lt;/em&gt;
   &lt;span&gt;
    of a reasoning model in a way because you can always use the weights without tools and they&#x27;ll be used extensively to undergird the digital economy. At the same time, the
   &lt;/span&gt;
   &lt;strong&gt;
    frontier AI models (and systems) of the coming years will all be reasoning models as presented above — thinking, searching, and acting
   &lt;/strong&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/thinking-searching-and-acting#footnote-1-174200501&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     1
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Language models will get access to more tools of some form, but all of them will be subsets of code or search. In fact, search can be argued to be a form of execution itself, but given the imperative of the underlying information it is best left as its own category.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Another popular discussion with the extremely-long generations of reasoning models has been the idea that maybe more efficient architectures such as
   &lt;/span&gt;
   &lt;a href=&quot;https://deepmind.google/models/gemini-diffusion/&quot; rel=&quot;&quot;&gt;
    diffusion language models
   &lt;/a&gt;
   &lt;span&gt;
    could come to dominate by generating all the tokens in parallel. The (or rather, one) problem here is that they cannot easily integrate tools, such as search or execution, in the same way. These’ll also likely be valuable options in the AI quiver, but barring a true architectural or algorithmic revolution that multiplies the performance of today’s AI models, the efficiency and co-design underway for large transformers will enable the most dynamic reasoning models.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
  &lt;/p&gt;
  &lt;p&gt;
   With establishing what makes a reasoning model complete comes an important mental transition in what it takes to make a good model. Now, the quality of the tools that a model is embedded with is arguably something that can be more straightforward to improve than the model — it just takes substantial engineering effort — and is far harder with open models. The AI “modeling” itself is mostly open-ended research.
  &lt;/p&gt;
  &lt;p&gt;
   Closed models have the benefit of controlling the entire user experience with the stack, where open models need to be designed so that anyone can take the weights off of HuggingFace and easily get a great experience deploying it with open-source libraries like VLLM or SGLang. When it comes to tools used during inference, this means that the models can have a recommended setting that works best, but they may take time to support meaningful generalization with respect to new tools.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    For example, OpenAI can train and serve their models with only one search engine, where I at Ai2 will likely train with one search engine and then release the model into a competitive space of many search products. A space where this can benefit open models could be something like
   &lt;/span&gt;
   &lt;a href=&quot;https://www.anthropic.com/news/model-context-protocol&quot; rel=&quot;&quot;&gt;
    MCP
   &lt;/a&gt;
   &lt;span&gt;
    , where open models are developed innately for a world where we cannot know all the uses of our models, making something like MCP libraries a great candidate for testing. Of course, leading AI laboratories will (or have already started) do this, but the ranking will be different in a priority stack.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Much has been said about tokenomics and costs associated with reasoning models, without taking the tool component into account. There was a very
   &lt;/span&gt;
   &lt;a href=&quot;https://ethanding.substack.com/p/ai-subscriptions-get-short-squeezed?utm_source=multiple-personal-recommendations-email&amp;utm_medium=email&amp;triedRedirect=true&quot; rel=&quot;&quot;&gt;
    popular article
   &lt;/a&gt;
   &lt;span&gt;
    articulating how models are only getting more expensive, with a particular focus on reasoning models using far more tokens. This is overstating a blip, a point in time when serving costs increased by 1000x for models by generating vastly more tokens, but without improved hardware.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The change in cost of reasoning models reflected a one-time step up in most circumstances where the field collectively turned on inference-time scaling by using the same reasoning techniques. At the same time as the reasoning model explosion, the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/i/166556899/scaling-parameters-is-going-to-go-very-slow-for-consumer-models&quot; rel=&quot;&quot;&gt;
    size of models reaching users in parameter count has all but stagnated
   &lt;/a&gt;
   &lt;span&gt;
    . This is due to diminishing returns in quality due to scaling parameters — it’s why OpenAI said
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/gpt-45-not-a-frontier-model&quot; rel=&quot;&quot;&gt;
    GPT 4.5 wasn’t a frontier model
   &lt;/a&gt;
   &lt;span&gt;
    and why Gemini never released their Ultra model class. The same will come for reasoning tokens.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    While diminishing returns are hitting reasoning token amount for serial streams, we’re finally seeing large clusters of Nvidia’s Blackwell GPUs come online. The costs for models seem well on path to level out and then decrease as the industry develops more efficient inference systems — the technology industry is phenomenal at making widely used products far cheaper year over year. The costs that’ll go up are the agents that are enabled by these reasoning models, especially with parallel inference, such as the Claude Code clones or
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/sama/status/1969835407421374910&quot; rel=&quot;&quot;&gt;
    OpenAI’s rumored Pro products
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   What we all need is a SemiAnalysis article explaining how distorted standard tokenomics are for inference with tools and if tools substantially increase variance in implementations. People focus too much on the higher token costs from big models with long context lengths, those are easy to fix with better GPUs, while there are many other costs such as search indices or idle GPU time waiting for tool execution results.
  &lt;/p&gt;
  &lt;p&gt;
   When we look at a modern reasoning model, it is easy to fixate on the thinking token aspects that give the models their name. At the same time, search and execution are such fundamental primitives to modern language models that they can rightfully stand on their own as pillars of modern AI. These are AI systems that substantially depend on the quality of the complex inference stack far more than getting the right YOLO run for the world’s best model weights.
  &lt;/p&gt;
  &lt;p&gt;
   The cause of thinking, searching, and acting all being looped in as a “reasoning model” is that this inference-time scaling with meandering chains of thought was the technological innovation that made both search and execution far more functional. Reasoning was the step change event that set these three as technology standards.
  &lt;/p&gt;
  &lt;p&gt;
   The industry is in its early days of building out fundamental infrastructure to enable them, which manifests as the early days of language model agents. The infrastructure pairs deterministic computing and search with the beauty, power, and flexibility of the probabilistic models we fell in love with via ChatGPT. This reasoning model layer is shaping up to be the infrastructure that underpins the greatest successes of the future technology industry.
  &lt;/p&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/thinking-searching-and-acting#footnote-anchor-1-174200501&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     Barring the unpredictable scientific breakthrough in architecture.
    &lt;/p&gt;
    &lt;p&gt;
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Coding as the epicenter of AI progress and the path to general agents </title>
<link>https://www.interconnects.ai/p/coding-as-the-epicenter-of-ai-progress</link>
<pubDate>Thu, 18 Sep 2025 15:24:28 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   Coding, due to its breadth of use-cases, is arguably the last tractable, general domain of continued progress for frontier models that most people can interface with. This is a bold claim, so let’s consider some of the other crucial capabilities covered in the discourse of frontier models:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Chat
     &lt;/strong&gt;
     &lt;span&gt;
      and the quality of prose written by models has leveled off, other than finetuning to user measures such as
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/sycophancy-and-the-art-of-the-model&quot; rel=&quot;&quot;&gt;
      sycophancy
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://www.interconnects.ai/publish/post/173893588?back=/publish/posts/drafts&quot; rel=&quot;&quot;&gt;
       Mathematics
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;a href=&quot;https://deepmind.google/discover/blog/advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad/&quot; rel=&quot;&quot;&gt;
      has incredible results
     &lt;/a&gt;
     &lt;span&gt;
      , but very few people directly gain from better theoretical mathematics.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      The
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/deep-research-information-vs-insight-in-science&quot; rel=&quot;&quot;&gt;
      AIs’ abilities to do novel
     &lt;/a&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://www.interconnects.ai/p/deep-research-information-vs-insight-in-science&quot; rel=&quot;&quot;&gt;
       science
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      are too unproven to be arguable as a target of hillclimbing.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   Still, coding is a domain where the models are already incredibly useful, and they continue to consistently stack on meaningful improvements. Working daily with AI over the last few years across side projects and as an AI researcher, it has been easy to take these coding abilities for granted because some forms of them have been around for so long. We punt a bug into ChatGPT and it can solve it or autocomplete can tab our way through entire boilerplate.
  &lt;/p&gt;
  &lt;p&gt;
   These use-cases sound benign, and haven’t changed much in that description as they have climbed dramatically in capabilities. Punting a niche problem in 1000+ lines of code to GPT-5-Pro or Gemini Deep Think feels like a very fair strategy. They really can sometimes solve problems that a teammate or I were stuck on for hours to days. We’re progressing through this summarized list of capabilities:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     Function completion: ~2021, original Github CoPilot (Codex)
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Scripting: ~2022, ChatGPT
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Building small projects: ~2025, CLI agents
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Building complex production codebases, ~2027 (estimate, which will vary by the codebase)
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   &lt;span&gt;
    Coding is maybe the only domain of AI use where I’ve felt this slow, gradual improvement. Chat quality has been “good enough” since GPT-4, search showed up and has been remarkable since
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/openais-o3-over-optimization-is-back&quot; rel=&quot;&quot;&gt;
    OpenAI’s o3
   &lt;/a&gt;
   &lt;span&gt;
    . Through all of these more exciting moments, AIs’ coding abilities have just continued to gradually improve.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/coding-as-the-epicenter-of-ai-progress?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/coding-as-the-epicenter-of-ai-progress?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Now, many of us are starting to learn a new way of working with AI through these new command-line code agents. This is the largest increase in AI coding abilities in the last few years. The problem is the increase isn’t in the same domain where most people are used to working with AI, so the adoption of the progress is far slower. New applications are rapidly building users and existing distribution networks barely apply.
  &lt;/p&gt;
  &lt;p&gt;
   The best way to work with them — and I’ll share more examples of what I’ve already built later in this post — is to construct mini projects, whether it’s a new bespoke website or a script. These are fantastic tools for entrepreneurs and researchers who need a way to quickly flesh out an idea. Things that would’ve taken me days to weeks can now be attempted in hours. Within this, the amount of real “looking at the code” that needs to be done is definitely going down. Coding, as an activity done through agents, is having the barriers to entry fully fall down through the same form factor that is giving the act of coding re-found joy.
  &lt;/p&gt;
  &lt;p&gt;
   Why I think a lot of people miss these agents is that the way to use the agents is so different from the marketing of incredible evaluation breakthroughs that the models are reaching. The gap between “superhuman coding” announcements and using an agent for mini projects is obviously big. The best way to use the agents is still mundane and requires careful scoping of context.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    For example, yesterday, on September 17, 2025, OpenAI
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/MostafaRohani/status/1968360976379703569&quot; rel=&quot;&quot;&gt;
    announced
   &lt;/a&gt;
   &lt;span&gt;
    that
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/MostafaRohani/status/1968361268475215881&quot; rel=&quot;&quot;&gt;
    GPT-5 as part of a model system
   &lt;/a&gt;
   &lt;span&gt;
    got a higher score than any human (and
   &lt;/span&gt;
   &lt;a href=&quot;https://deepmind.google/discover/blog/gemini-achieves-gold-level-performance-at-the-international-collegiate-programming-contest-world-finals/&quot; rel=&quot;&quot;&gt;
    Google’s Gemini Deep Think
   &lt;/a&gt;
   &lt;span&gt;
    ) at the
   &lt;/span&gt;
   &lt;a href=&quot;https://worldfinals.icpc.global/2025/&quot; rel=&quot;&quot;&gt;
    ICPC World Finals
   &lt;/a&gt;
   &lt;span&gt;
    , “the premier collegiate programming competition where top university teams from around the world solve complex algorithmic problems.” Here’s what an OpenAI researcher said they did:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    We competed with an ensemble of general-purpose reasoning models; we did not train any model specifically for the ICPC. We had both GPT-5 and an experimental reasoning model generating solutions, and the experimental reasoning model selecting which solutions to submit. GPT-5 answered 11 correctly, and the last (and most difficult problem) was solved by the experimental reasoning model.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   These competitions often get highlighted because they’re “finite time,” so the system must respond in the same fixed time as a human does, but the amount of compute used by GPT-5 or another model here is likely far higher than any user has access to. This is mostly an indication that further ability, which some people call raw intelligence, can be extracted from the models, but most of that is limited by scaffolding and product when used by the general population.
  &lt;/p&gt;
  &lt;p&gt;
   The real story is that these models are delivering increasing value to a growing pool of people.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    For followers of AI, coding with AI models is the easiest way to feel progress. Now that models are so good at chat, it takes very specialized tasks to test the general knowledge of models, or many of the gains are in getting the right answer
   &lt;/span&gt;
   &lt;em&gt;
    faster
   &lt;/em&gt;
   &lt;span&gt;
    than GPT-5-Thinking’s meandering path.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I’m not an expert software engineer and the huge differences between models, and improvements that the individual models and systems are making, have been incredibly obvious.
  &lt;/p&gt;
  &lt;p&gt;
   I’ve said many times how Claude Code (or now Codex) are far better than Cursor Agent, which is in turn far better than Github CoPilot. GitHub CoPilot feels borderline drunk at the wheel. Cursor often feels a little distracted while still being smart, but Claude Code and Codex seem on topic and able to test the best of a model’s intelligence on the problem at hand. Yes, even the best agents often aren’t good enough in complex codebases, but it removes the need to go back and forth countless times in a chat window to see if a model can reach the end of the puzzle for you. These CLI agents can run tests, fix git problems, run local tools, whatever. The scope is constantly growing.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    For the nuanced take of Claude Code vs Codex CLI right now, the answer is expensive. The best has been Claude Code forcing Claude Opus 4.1, but Codex is not far behind and comes in at a much cheaper entry point ($20/month) — Opus requires a $100+/month plan. Codex also has nice features like web search, but it hasn’t been a major differentiator yet in my use.
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/coding-as-the-epicenter-of-ai-progress#footnote-1-173893588&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     1
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The new workflow is to switch to the other agent when one cannot solve the current problem, and let it see the repository with fresh eyes, much like you pasted a question to another chatbot. The agents are just one tab away, just like the competitors for chat.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    In the comparison of Claude, Cursor, and CoPilot above, the crucial component is that all of these agents can be tested with the same Claude 4 Sonnet model. The gaps are just as wide as I stated, highlighting how so many of the gains in coding agents are just in product implementations. A second version is slightly embarrassing for me, but follows as I hadn’t updated my OpenAI Codex code when trying the new GPT-5-Codex model, which resulted in an immediate massive jump in performance by changing it. It’s a new phenomenon to have a domain at the cutting edge of AI
   &lt;/span&gt;
   &lt;em&gt;
    abilities
   &lt;/em&gt;
   &lt;span&gt;
    where the software scaffolding of a model is felt so strongly. Product and prompts matter more than ever and this sensation will expand to more domains.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The
   &lt;/span&gt;
   &lt;em&gt;
    why
   &lt;/em&gt;
   &lt;span&gt;
    of these performance differences — even when using the same model — is worth dwelling on. It’s unlikely that the Claude team is that much better at general software engineering and product design — rather, Anthropic has extensive in-house experience in extracting the most from models. The current shift in models has been about how to take a set of models that are designed for question answering and other single-stream text tasks and break down problems. In my
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/next-gen-reasoners&quot; rel=&quot;&quot;&gt;
    taxonomy on next-generation reasoning models
   &lt;/a&gt;
   &lt;span&gt;
    , I called this ability “abstraction.”
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The need to just slightly shift the model to this task explains OpenAI’s recent specialized model for this,
   &lt;/span&gt;
   &lt;a href=&quot;https://openai.com/index/introducing-upgrades-to-codex/&quot; rel=&quot;&quot;&gt;
    GPT-5-Codex
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/gpt-5-and-bending-the-arc-of-progress&quot; rel=&quot;&quot;&gt;
    GPT-5
   &lt;/a&gt;
   &lt;span&gt;
    was primarily a release about balancing OpenAI’s books with a user base approaching 1B active users in the chat format. GPT-5 is a honed tool for a different job. The evaluation scores are
   &lt;/span&gt;
   &lt;em&gt;
    slightly
   &lt;/em&gt;
   &lt;span&gt;
    better than the general reasoning model for this new GPT-5-Codex, but the main gains are in how behavior is different in coding tasks.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    &lt;strong&gt;
     GPT‑5-Codex adapts how much time it spends thinking more dynamically based on the complexity of the task
    &lt;/strong&gt;
    &lt;span&gt;
     . The model combines two essential skills for a coding agent: pairing with developers in interactive sessions, and persistent, independent execution on longer tasks.
    &lt;/span&gt;
    &lt;strong&gt;
     That means Codex will feel snappier on small, well-defined requests or while you are chatting with it, and will work for longer on complex tasks like big refactors
    &lt;/strong&gt;
    &lt;span&gt;
     . During testing, we&#x27;ve seen GPT‑5-Codex work independently for more than 7 hours at a time on large, complex tasks, iterating on its implementation, fixing test failures, and ultimately delivering a successful implementation.
    &lt;/span&gt;
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   And they included this somewhat confusing plot to showcase this dynamic. I’ve certainly felt these changes when I updated the Codex software and the Codex model.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!M5Wx!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa28589c-4de5-4949-b6b6-d202599d5f72_1487x877.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!M5Wx!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa28589c-4de5-4949-b6b6-d202599d5f72_1487x877.png 424w, https://substackcdn.com/image/fetch/$s_!M5Wx!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa28589c-4de5-4949-b6b6-d202599d5f72_1487x877.png 848w, https://substackcdn.com/image/fetch/$s_!M5Wx!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa28589c-4de5-4949-b6b6-d202599d5f72_1487x877.png 1272w, https://substackcdn.com/image/fetch/$s_!M5Wx!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa28589c-4de5-4949-b6b6-d202599d5f72_1487x877.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fa28589c-4de5-4949-b6b6-d202599d5f72_1487x877.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:859,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:92578,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/173893588?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa28589c-4de5-4949-b6b6-d202599d5f72_1487x877.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;859&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!M5Wx!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa28589c-4de5-4949-b6b6-d202599d5f72_1487x877.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!M5Wx!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa28589c-4de5-4949-b6b6-d202599d5f72_1487x877.png 424w, https://substackcdn.com/image/fetch/$s_!M5Wx!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa28589c-4de5-4949-b6b6-d202599d5f72_1487x877.png 848w, https://substackcdn.com/image/fetch/$s_!M5Wx!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa28589c-4de5-4949-b6b6-d202599d5f72_1487x877.png 1272w, https://substackcdn.com/image/fetch/$s_!M5Wx!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa28589c-4de5-4949-b6b6-d202599d5f72_1487x877.png 1456w&quot; title=&quot;&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   This represents another key problem I presented in my taxonomy — calibration, i.e. not overthinking.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Having specialized models and specialized products for a use case could make people think that they’re narrowing in to make progress, but in OpenAI’s case it is rather that their hands are tied financially to support the main ChatGPT application.
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/claude-4-and-anthropics-bet-on-code&quot; rel=&quot;&quot;&gt;
    Claude has already fully committed to code
   &lt;/a&gt;
   &lt;span&gt;
    . This is due to the size that the space could expand into.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   These “coding” agents are definitely going to be seen as doing far more than writing code. Yes, their primary ability is going to be writing the code itself and executing it, but what that enables is an entirely new way of working with your computer.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    In my post
   &lt;/span&gt;
   &lt;em&gt;
    &lt;a href=&quot;https://www.interconnects.ai/p/contra-dwarkesh-on-continual-learning&quot; rel=&quot;&quot;&gt;
     Contra Dwarkesh on Continual Learning
    &lt;/a&gt;
   &lt;/em&gt;
   &lt;span&gt;
    , I presented a view where agents are going to be given all your digital working context in order to be a research or editorial assistant available 24/7. I’ve begun putting this to use for Interconnects, where I give the agents all of my articles, metadata, interviews, and details, so I can ask them for relevant references and context for future posts. This is very underbaked and early as a project for searching efficiently over my 400K tokens of writing, but I was prompting it a few times to see any interesting references for this post, and it got me something that was useful!
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!Puqb!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e883906-d902-43b4-a8fb-ed48bcf02bb7_1318x1252.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Puqb!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e883906-d902-43b4-a8fb-ed48bcf02bb7_1318x1252.png 424w, https://substackcdn.com/image/fetch/$s_!Puqb!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e883906-d902-43b4-a8fb-ed48bcf02bb7_1318x1252.png 848w, https://substackcdn.com/image/fetch/$s_!Puqb!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e883906-d902-43b4-a8fb-ed48bcf02bb7_1318x1252.png 1272w, https://substackcdn.com/image/fetch/$s_!Puqb!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e883906-d902-43b4-a8fb-ed48bcf02bb7_1318x1252.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8e883906-d902-43b4-a8fb-ed48bcf02bb7_1318x1252.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1252,&quot;width&quot;:1318,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:791204,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/173893588?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e883906-d902-43b4-a8fb-ed48bcf02bb7_1318x1252.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;1252&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!Puqb!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e883906-d902-43b4-a8fb-ed48bcf02bb7_1318x1252.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Puqb!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e883906-d902-43b4-a8fb-ed48bcf02bb7_1318x1252.png 424w, https://substackcdn.com/image/fetch/$s_!Puqb!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e883906-d902-43b4-a8fb-ed48bcf02bb7_1318x1252.png 848w, https://substackcdn.com/image/fetch/$s_!Puqb!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e883906-d902-43b4-a8fb-ed48bcf02bb7_1318x1252.png 1272w, https://substackcdn.com/image/fetch/$s_!Puqb!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e883906-d902-43b4-a8fb-ed48bcf02bb7_1318x1252.png 1456w&quot; title=&quot;&quot; width=&quot;1318&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    This quote from my
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/interviewing-ross-taylor-on-the-state&quot; rel=&quot;&quot;&gt;
    Ross Taylor interview
   &lt;/a&gt;
   &lt;span&gt;
    was spot on for the
   &lt;/span&gt;
   &lt;em&gt;
    vibes
   &lt;/em&gt;
   &lt;span&gt;
    of using coding agents in July:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    My main worry with Claude Code is that... people confuse agents making you more productive versus preventing you from exerting mental effort. So sometimes I’ll have a day with Claude Code where I feel like I use very little mental effort—and it feels amazing—but I’m pretty sure I’ve done less work... Where it becomes really bad is when the file size becomes too long. Then the agent tends to struggle and get into these weird line search doom loops.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   This sentiment is still definitely true for production codebases that are extremely complex, but the doom loop likelihood is dropping in my tests. At the same time, the joy and mental ease still applies.
  &lt;/p&gt;
  &lt;p&gt;
   Some examples of what I’ve built with a mix of Claude Code or OpenAI’s Codex CLI recently include:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      A raw HTML
     &lt;/span&gt;
     &lt;a href=&quot;https://rlhfbook.com/library&quot; rel=&quot;&quot;&gt;
      site for my RLHF book
     &lt;/a&gt;
     &lt;span&gt;
      for comparing the responses of SFT vs. RLHF trained models from the same lineage (and improvements to RLHF book itself).
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Making a
     &lt;/span&gt;
     &lt;a href=&quot;https://github.com/Interconnects-AI/homebase&quot; rel=&quot;&quot;&gt;
      repository
     &lt;/a&gt;
     &lt;span&gt;
      with all of the posts and content from Interconnects so I can use coding agents as editorial assistants while writing.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Improvements to the ATOM Project
     &lt;/span&gt;
     &lt;a href=&quot;https://www.atomproject.ai/&quot; rel=&quot;&quot;&gt;
      website
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Stripping my personal website out of Webflow’s systems (which was a mistake to sign up for during graduate school), including CMS entries and other detailed pages.
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Other small scripts and tools in my day job training models.
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   &lt;span&gt;
    It’s not just me building extensively with these. There are multiple open-source projects committed to tracking the public contributions of these models — two are
   &lt;/span&gt;
   &lt;a href=&quot;https://prarena.ai/&quot; rel=&quot;&quot;&gt;
    PRArena
   &lt;/a&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;a href=&quot;https://insights.logicstar.ai/&quot; rel=&quot;&quot;&gt;
    Agents in the Wild
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   PRArena’s dashboard shows over a million PRs getting merged from the Codex web agent, dwarfing many of the competitors. This is the power that OpenAI can wield with distribution, even if the web app version of Codex is far from the zeitgeist that is CLI agents today.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!_GTR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d83a52b-b696-4163-a987-375442775960_2360x1486.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!_GTR!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d83a52b-b696-4163-a987-375442775960_2360x1486.png 424w, https://substackcdn.com/image/fetch/$s_!_GTR!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d83a52b-b696-4163-a987-375442775960_2360x1486.png 848w, https://substackcdn.com/image/fetch/$s_!_GTR!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d83a52b-b696-4163-a987-375442775960_2360x1486.png 1272w, https://substackcdn.com/image/fetch/$s_!_GTR!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d83a52b-b696-4163-a987-375442775960_2360x1486.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1d83a52b-b696-4163-a987-375442775960_2360x1486.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:917,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:475910,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/173893588?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d83a52b-b696-4163-a987-375442775960_2360x1486.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;917&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!_GTR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d83a52b-b696-4163-a987-375442775960_2360x1486.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!_GTR!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d83a52b-b696-4163-a987-375442775960_2360x1486.png 424w, https://substackcdn.com/image/fetch/$s_!_GTR!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d83a52b-b696-4163-a987-375442775960_2360x1486.png 848w, https://substackcdn.com/image/fetch/$s_!_GTR!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d83a52b-b696-4163-a987-375442775960_2360x1486.png 1272w, https://substackcdn.com/image/fetch/$s_!_GTR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d83a52b-b696-4163-a987-375442775960_2360x1486.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   This comes with a notable asterisk in methodology that can explain many of the gaps in similar dashboards:
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    &lt;span&gt;
     Some agents like
    &lt;/span&gt;
    &lt;strong&gt;
     Codex
    &lt;/strong&gt;
    &lt;span&gt;
     iterate privately and create ready PRs directly, resulting in very few drafts but high merge rates. Others like
    &lt;/span&gt;
    &lt;strong&gt;
     Copilot
    &lt;/strong&gt;
    &lt;span&gt;
     and
    &lt;/span&gt;
    &lt;strong&gt;
     Codegen
    &lt;/strong&gt;
    &lt;span&gt;
     create draft PRs first, encouraging public iteration before marking them ready for review.
    &lt;/span&gt;
   &lt;/p&gt;
   &lt;p&gt;
    &lt;span&gt;
     The statistics below focus on
    &lt;/span&gt;
    &lt;strong&gt;
     Ready PRs only
    &lt;/strong&gt;
    &lt;span&gt;
     to fairly compare agents across different workflows, measuring each agent&#x27;s ability to produce mergeable code regardless of whether they iterate publicly (with drafts) or privately.
    &lt;/span&gt;
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   The other dashboard, Agents in the Wild, shows that OpenAI’s coding agent is only one order of magnitude behind humans and other automations in PRs merged.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!8Tfr!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbfcc57-8ee5-4742-86d0-0e3b233283e3_2466x1696.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!8Tfr!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbfcc57-8ee5-4742-86d0-0e3b233283e3_2466x1696.png 424w, https://substackcdn.com/image/fetch/$s_!8Tfr!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbfcc57-8ee5-4742-86d0-0e3b233283e3_2466x1696.png 848w, https://substackcdn.com/image/fetch/$s_!8Tfr!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbfcc57-8ee5-4742-86d0-0e3b233283e3_2466x1696.png 1272w, https://substackcdn.com/image/fetch/$s_!8Tfr!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbfcc57-8ee5-4742-86d0-0e3b233283e3_2466x1696.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fdbfcc57-8ee5-4742-86d0-0e3b233283e3_2466x1696.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1001,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:464650,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/173893588?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbfcc57-8ee5-4742-86d0-0e3b233283e3_2466x1696.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;1001&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!8Tfr!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbfcc57-8ee5-4742-86d0-0e3b233283e3_2466x1696.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!8Tfr!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbfcc57-8ee5-4742-86d0-0e3b233283e3_2466x1696.png 424w, https://substackcdn.com/image/fetch/$s_!8Tfr!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbfcc57-8ee5-4742-86d0-0e3b233283e3_2466x1696.png 848w, https://substackcdn.com/image/fetch/$s_!8Tfr!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbfcc57-8ee5-4742-86d0-0e3b233283e3_2466x1696.png 1272w, https://substackcdn.com/image/fetch/$s_!8Tfr!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbfcc57-8ee5-4742-86d0-0e3b233283e3_2466x1696.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   Putting this in perspective relative to Gemini or Claude:
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!RAqm!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57090aa2-c354-4eb5-9222-8e0c61b2a8e8_2494x1556.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!RAqm!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57090aa2-c354-4eb5-9222-8e0c61b2a8e8_2494x1556.png 424w, https://substackcdn.com/image/fetch/$s_!RAqm!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57090aa2-c354-4eb5-9222-8e0c61b2a8e8_2494x1556.png 848w, https://substackcdn.com/image/fetch/$s_!RAqm!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57090aa2-c354-4eb5-9222-8e0c61b2a8e8_2494x1556.png 1272w, https://substackcdn.com/image/fetch/$s_!RAqm!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57090aa2-c354-4eb5-9222-8e0c61b2a8e8_2494x1556.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/57090aa2-c354-4eb5-9222-8e0c61b2a8e8_2494x1556.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:908,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:284520,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/173893588?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57090aa2-c354-4eb5-9222-8e0c61b2a8e8_2494x1556.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;908&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!RAqm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57090aa2-c354-4eb5-9222-8e0c61b2a8e8_2494x1556.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!RAqm!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57090aa2-c354-4eb5-9222-8e0c61b2a8e8_2494x1556.png 424w, https://substackcdn.com/image/fetch/$s_!RAqm!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57090aa2-c354-4eb5-9222-8e0c61b2a8e8_2494x1556.png 848w, https://substackcdn.com/image/fetch/$s_!RAqm!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57090aa2-c354-4eb5-9222-8e0c61b2a8e8_2494x1556.png 1272w, https://substackcdn.com/image/fetch/$s_!RAqm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57090aa2-c354-4eb5-9222-8e0c61b2a8e8_2494x1556.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    The context with this is that Claude Code is
   &lt;/span&gt;
   &lt;em&gt;
    far
   &lt;/em&gt;
   &lt;span&gt;
    more downloaded than OpenAI’s CLI agent Codex, but it doesn’t name its PRs the same clever way by default with the agent name in the branch. Claude Code has over 20X the downloads of Codex in the last week on NPM.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!Je4m!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ec5b31a-8aba-47ce-9975-abe5f9257775_2954x1348.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Je4m!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ec5b31a-8aba-47ce-9975-abe5f9257775_2954x1348.png 424w, https://substackcdn.com/image/fetch/$s_!Je4m!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ec5b31a-8aba-47ce-9975-abe5f9257775_2954x1348.png 848w, https://substackcdn.com/image/fetch/$s_!Je4m!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ec5b31a-8aba-47ce-9975-abe5f9257775_2954x1348.png 1272w, https://substackcdn.com/image/fetch/$s_!Je4m!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ec5b31a-8aba-47ce-9975-abe5f9257775_2954x1348.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5ec5b31a-8aba-47ce-9975-abe5f9257775_2954x1348.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:664,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:815090,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/173893588?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ec5b31a-8aba-47ce-9975-abe5f9257775_2954x1348.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;664&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!Je4m!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ec5b31a-8aba-47ce-9975-abe5f9257775_2954x1348.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Je4m!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ec5b31a-8aba-47ce-9975-abe5f9257775_2954x1348.png 424w, https://substackcdn.com/image/fetch/$s_!Je4m!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ec5b31a-8aba-47ce-9975-abe5f9257775_2954x1348.png 848w, https://substackcdn.com/image/fetch/$s_!Je4m!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ec5b31a-8aba-47ce-9975-abe5f9257775_2954x1348.png 1272w, https://substackcdn.com/image/fetch/$s_!Je4m!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ec5b31a-8aba-47ce-9975-abe5f9257775_2954x1348.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   Despite the challenges of measurement, it’s clear that coding agents are taking off.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The Codex PRs above actually represent the
   &lt;/span&gt;
   &lt;em&gt;
    web agent
   &lt;/em&gt;
   &lt;span&gt;
    , which has the default branch name behavior, not the CLI agent. This shows the might of OpenAI’s distribution, and it is impressive how many of the PRs are actually merged (over 80%), when thousands of people are trying a new tool for the first time.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The primary difference between the web agent and the CLI agent is a reduction in interactivity. The CLI agents propose a plan and ask for feedback, or let you monitor and interrupt. Codex on the web wraps a similar behavior as the CLI agents in one system that runs all the way until it can open a PR.
  &lt;/p&gt;
  &lt;p&gt;
   Over time coding is only going to get more asynchronous and OpenAI is poised to capture this transition if it happens soon. Based on all the above evidence of coding models getting more capable, the move to this new UX for software will happen faster than people expect. The transition to fully autonomous coding will happen soon for types of work where coding models already work near flawlessly — scripts, websites, data analysis, etc. Later, complex production codebases will work best at lower levels of the stack — IDEs, CLI agents, and other things that are both interactive and best for absorbing content.
  &lt;/p&gt;
  &lt;p&gt;
   Within a few years, the two trends will converge where autonomous agents are functional and the most complex codebases can be improved with AI. Then everything can return to the chatbot window — you only need to open your IDE when you want to understand what’s going on. For most people, not having to look at the code will be a welcome change.
  &lt;/p&gt;
  &lt;p&gt;
   Progress in coding feels slower than the “emergent” abilities between model generations past, which makes it easier to keep track of. This is due to how big the range in behaviors that encompass “coding” is, but results in a fantastic area for learning how AI models evolve and iterate. This playbook will be used many times over by frontier labs in the coming years as AI models are taught to solve more challenging tasks.
  &lt;/p&gt;
  &lt;p&gt;
   There’s a quiet revolution happening, and in order to truly understand it, you need to partake. Go build something.
  &lt;/p&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/coding-as-the-epicenter-of-ai-progress#footnote-anchor-1-173893588&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     Here’s my command for using Codex:
    &lt;/p&gt;
    &lt;pre&gt;&lt;code&gt;&lt;code&gt;alias codex=&#x27;codex -m gpt-5-codex -c model_reasoning_effort=&quot;high&quot; --yolo --search&#x27;&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Latest open artifacts (#14): NVIDIA&#x27;s rise, &quot;Swiss &amp; UAE DeepSeek,&quot; and a resurgence of open data </title>
<link>https://www.interconnects.ai/p/latest-open-artifacts-14-nvidias</link>
<pubDate>Thu, 11 Sep 2025 14:41:39 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    At the end of the summer, the leading open models across the ecosystem are finally coming from somewhere other than Qwen (and other leading Chinese laboratories). While Qwen has been preparing a
   &lt;/span&gt;
   &lt;a href=&quot;https://github.com/huggingface/transformers/pull/40771&quot; rel=&quot;&quot;&gt;
    new architecture
   &lt;/a&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;a href=&quot;https://github.com/huggingface/transformers/pull/40795&quot; rel=&quot;&quot;&gt;
    vision models
   &lt;/a&gt;
   &lt;span&gt;
    , NVIDIA was releasing high-quality open artifacts at a record pace and we have plenty of new entrants in the space of training large models.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   NVIDIA is the current open model champion in the U.S. and is getting far less praise than Meta did with their Llama series. This is a trend that we have seen multiple times, and that other organizations such as OpenAI are going through — it takes multiple releases and sustained community engagement to build the habits of developers and researchers on top of these models.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    In this issue, we also have high-quality, sovereign AI releases from the UAE and Switzerland. We expect more players in this space. This represents the expected track for open models around the world — there will always be concentrated players that produce the highest quantity of artifacts, but the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/deepseek-v3-and-the-actual-cost-of&quot; rel=&quot;&quot;&gt;
    cost of training a singular, high-quality AI model
   &lt;/a&gt;
   &lt;span&gt;
    is very tractable for many organizations or nations.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    On top of all these developments is a (small) resurgence in the release of data with models. Multiple large-scale data releases from HuggingFace and NVIDIA are going to be heavily used by researchers. Additionally, there were a few “fully open” models released, such as a multilingual, 30B dense base model from TildeAI that was
   &lt;/span&gt;
   &lt;a href=&quot;https://www.amd.com/en/blogs/2025/tilde-trains-30b--balto-slavic-llm-on-amd-instinct---gpus.html&quot; rel=&quot;&quot;&gt;
    trained with AMD through an EU grant program
   &lt;/a&gt;
   &lt;span&gt;
    . A 30B model trained to 4T tokens popping up from a new entrant shows how the compute buildout is bringing many new players online into the open ecosystem
   &lt;/span&gt;
   &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/latest-open-artifacts-14-nvidias#footnote-1-173287973&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Many months can go by without meaningful data releases across the whole ecosystem, so these represent a notable reprieve from the trend.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/latest-open-artifacts-14-nvidias?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-artifacts-14-nvidias?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;h1&gt;
   &lt;strong&gt;
    Artifacts Log
   &lt;/strong&gt;
  &lt;/h1&gt;
  &lt;h3&gt;
   &lt;strong&gt;
    Our Picks
   &lt;/strong&gt;
  &lt;/h3&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/nvidia/parakeet-tdt-0.6b-v3&quot; rel=&quot;&quot;&gt;
       parakeet-tdt-0.6b-v3
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/nvidia&quot; rel=&quot;&quot;&gt;
      nvidia
     &lt;/a&gt;
     &lt;span&gt;
      : There are a few models which completely redefine their space and push the boundaries. For open models, this is even harder as the competition from closed models is fierce. However, Parakeet fits these criteria and will probably be overlooked by a lot of people. But for me (Florian), it has redefined how I use my MacBook. Last episode, I wrote the following about Qwen3 4B Instruct:
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;blockquote&gt;
     &lt;p&gt;
      I have started using it locally for simple tasks (like translation), as the model is really capable and the overall latency is faster than sending requests to the cloud.
     &lt;/p&gt;
    &lt;/blockquote&gt;
    &lt;p&gt;
     &lt;span&gt;
      The Qwen model gets complemented by this model perfectly when used in apps such as MacWhisper: Parakeet is used for the transcription, while Qwen 4B is used to clean up the raw transcripts. Both models are blazingly fast (and therefore beat cloud-based models in terms of overall latency), yet accurate.
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      This is the big selling point of local models on device: they are tiny niche models that are as capable as more general, closed models. And Parakeet fits this description perfectly. Since it launched, I am shifting more towards using my voice to write emails, long prompts for ChatGPT or Codex or this very blog post. For me as a multilingual speaker, I felt left behind with the
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/nvidia/parakeet-tdt-0.6b-v2&quot; rel=&quot;&quot;&gt;
      previous version
     &lt;/a&gt;
     &lt;span&gt;
      , which was English only.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/nvidia/NVIDIA-Nemotron-Nano-9B-v2&quot; rel=&quot;&quot;&gt;
       NVIDIA-Nemotron-Nano-9B-v2
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/nvidia&quot; rel=&quot;&quot;&gt;
      nvidia
     &lt;/a&gt;
     &lt;span&gt;
      : NVIDIA is one of the very few Western companies which continues to release a lot of open models and is often seen as a guest in the Artifact series. It is almost ironic that a company, which is arguably one of the most GPU-rich companies out there, continues to release models which run on limited hardware. Nemotron &quot;Nano&quot;, which comes in 9B and 12B sizes, is a hybrid model consisting of both attention and mamba layers. It is also hybrid in the sense that it supports a reasoning and non-reasoning model. They also share (the majority of the)
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/collections/nvidia/nemotron-pre-training-dataset-689d9de36f84279d83786b35&quot; rel=&quot;&quot;&gt;
      the pre-training data
     &lt;/a&gt;
     &lt;span&gt;
      . It is hard to say &quot;don&#x27;t sleep on NVIDIA&quot; as it is arguably one of the most important companies during the AI boom, but them continuing to release capable, small models AND open data with detailed papers is really commendable. On top of all of that, they make the model
     &lt;/span&gt;
     &lt;a href=&quot;https://openrouter.ai/nvidia/nemotron-nano-9b-v2:free&quot; rel=&quot;&quot;&gt;
      available for free
     &lt;/a&gt;
     &lt;span&gt;
      on OpenRouter.
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!kCbf!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d81ad1a-55e1-45db-8821-2f463df6dd29_1574x584.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!kCbf!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d81ad1a-55e1-45db-8821-2f463df6dd29_1574x584.png 424w, https://substackcdn.com/image/fetch/$s_!kCbf!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d81ad1a-55e1-45db-8821-2f463df6dd29_1574x584.png 848w, https://substackcdn.com/image/fetch/$s_!kCbf!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d81ad1a-55e1-45db-8821-2f463df6dd29_1574x584.png 1272w, https://substackcdn.com/image/fetch/$s_!kCbf!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d81ad1a-55e1-45db-8821-2f463df6dd29_1574x584.png 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4d81ad1a-55e1-45db-8821-2f463df6dd29_1574x584.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:540,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:114553,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/173287973?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d81ad1a-55e1-45db-8821-2f463df6dd29_1574x584.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;540&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!kCbf!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d81ad1a-55e1-45db-8821-2f463df6dd29_1574x584.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!kCbf!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d81ad1a-55e1-45db-8821-2f463df6dd29_1574x584.png 424w, https://substackcdn.com/image/fetch/$s_!kCbf!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d81ad1a-55e1-45db-8821-2f463df6dd29_1574x584.png 848w, https://substackcdn.com/image/fetch/$s_!kCbf!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d81ad1a-55e1-45db-8821-2f463df6dd29_1574x584.png 1272w, https://substackcdn.com/image/fetch/$s_!kCbf!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4d81ad1a-55e1-45db-8821-2f463df6dd29_1574x584.png 1456w&quot; width=&quot;1456&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/swiss-ai/Apertus-70B-Instruct-2509&quot; rel=&quot;&quot;&gt;
       Apertus-70B-Instruct-2509
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/swiss-ai&quot; rel=&quot;&quot;&gt;
      swiss-ai
     &lt;/a&gt;
     &lt;span&gt;
      : An open model by the Swiss EPFL, ETH Zürich, and Swiss National Supercomputing Centre, using 15T tokens from open datasets such as FineWeb, DCLM or The Stack. Importantly, they filtered this data by excluding domains which opted out of training. While this model itself is not pushing the open state of the art, it is an important first step towards a higher diversity, especially in the truly open model space.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/inclusionAI/Ling-mini-2.0&quot; rel=&quot;&quot;&gt;
       Ling-mini-2.0
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/inclusionAI&quot; rel=&quot;&quot;&gt;
      inclusionAI
     &lt;/a&gt;
     &lt;span&gt;
      : The Ant Group continues to fly under the radar, but this release is pretty interesting in our opinion: They train relatively small MoE models with only 16B total parameters, but they share different checkpoints during the training for 5, 10, 15 and 20 trillion tokens. Furthermore, they release
     &lt;/span&gt;
     &lt;a href=&quot;https://github.com/inclusionAI/Ling-V2/blob/main/docs/gpu_based_training.md&quot; rel=&quot;&quot;&gt;
      patches
     &lt;/a&gt;
     &lt;span&gt;
      for Megatron and TransformerEngine and guides how to train the models further. On top of all of that, they also release a
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/inclusionAI/Ring-mini-2.0&quot; rel=&quot;&quot;&gt;
      reasoning version
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!u7JM!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68308826-0518-472a-8cc2-fb4d9504910f_2418x1482.webp&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!u7JM!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68308826-0518-472a-8cc2-fb4d9504910f_2418x1482.webp 424w, https://substackcdn.com/image/fetch/$s_!u7JM!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68308826-0518-472a-8cc2-fb4d9504910f_2418x1482.webp 848w, https://substackcdn.com/image/fetch/$s_!u7JM!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68308826-0518-472a-8cc2-fb4d9504910f_2418x1482.webp 1272w, https://substackcdn.com/image/fetch/$s_!u7JM!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68308826-0518-472a-8cc2-fb4d9504910f_2418x1482.webp 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/68308826-0518-472a-8cc2-fb4d9504910f_2418x1482.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:892,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;892&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!u7JM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68308826-0518-472a-8cc2-fb4d9504910f_2418x1482.webp&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!u7JM!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68308826-0518-472a-8cc2-fb4d9504910f_2418x1482.webp 424w, https://substackcdn.com/image/fetch/$s_!u7JM!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68308826-0518-472a-8cc2-fb4d9504910f_2418x1482.webp 848w, https://substackcdn.com/image/fetch/$s_!u7JM!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68308826-0518-472a-8cc2-fb4d9504910f_2418x1482.webp 1272w, https://substackcdn.com/image/fetch/$s_!u7JM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68308826-0518-472a-8cc2-fb4d9504910f_2418x1482.webp 1456w&quot; width=&quot;1456&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/datasets/HuggingFaceM4/FineVision&quot; rel=&quot;&quot;&gt;
       FineVision
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/HuggingFaceM4&quot; rel=&quot;&quot;&gt;
      HuggingFaceM4
     &lt;/a&gt;
     &lt;span&gt;
      : A massive vision dataset, spanning over 17 million images, totaling over 5TB of data, which combines, cleans and augments over 200 image datasets. FineWeb is a widely used dataset in the community, so expect this dataset to be used a lot in the future. The
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/spaces/HuggingFaceM4/FineVision&quot; rel=&quot;&quot;&gt;
      blog post
     &lt;/a&gt;
     &lt;span&gt;
      goes into more details, including ablation studies against other datasets.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   The rest of the issue is packed with updates from Kimi, DeepSeek, ByteDance Seed, AI generated otters, and even the Chinese analog of DoorDash (Meituan).   The cadence of Artifacts Log is increasing to be faster than monthly due to the cadence of quality releases.
  &lt;/p&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> On China&#x27;s open source AI trajectory </title>
<link>https://www.interconnects.ai/p/on-chinas-open-source-ai-trajectory</link>
<pubDate>Tue, 09 Sep 2025 13:52:16 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   Hello everyone! I’m coming back online after two weeks of vacation. Thankfully it coincided with some of the slowest weeks of the year in the AI space. I’m excited to get back to writing and (soon) share projects that’ll wrap up in the last months of the year.
  &lt;/p&gt;
  &lt;p&gt;
   It seemed like a good time to remind people of the full set of housekeeping for  Interconnects.
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Many people love the audio version of the essays (read by me, not AI). You can get them in your podcast player
     &lt;/span&gt;
     &lt;a href=&quot;https://podcast.interconnects.ai/&quot; rel=&quot;&quot;&gt;
      here
     &lt;/a&gt;
     &lt;span&gt;
      . Paid subscribers can add private podcast feeds under “manage your subscription” where voiceover is available for paywalled posts.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      The
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/discord&quot; rel=&quot;&quot;&gt;
      Interconnects Discord
     &lt;/a&gt;
     &lt;span&gt;
      for paid subscribers continues to get better, and is potentially the leading paid perk amid the fragmentation of Twitter etc.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     We’re going to be rolling out more perks for group subscriptions and experimental products this fall. Stay tuned, or get in touch if group discounts are super exciting for your company.
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    For the time being, I’m planning trips and meetups across a few conferences in October. I’ll be speaking at
   &lt;/span&gt;
   &lt;a href=&quot;https://thecurve.goldengateinstitute.org/&quot; rel=&quot;&quot;&gt;
    The Curve
   &lt;/a&gt;
   &lt;span&gt;
    (Oct. 3-5, Berkeley),
   &lt;/span&gt;
   &lt;a href=&quot;https://colmweb.org/&quot; rel=&quot;&quot;&gt;
    COLM
   &lt;/a&gt;
   &lt;span&gt;
    (Oct. 7-10, Montreal,
   &lt;/span&gt;
   &lt;a href=&quot;https://colmweb.org/&quot; rel=&quot;&quot;&gt;
    interest form
   &lt;/a&gt;
   &lt;span&gt;
    ), and the
   &lt;/span&gt;
   &lt;a href=&quot;https://events.linuxfoundation.org/pytorch-conference/&quot; rel=&quot;&quot;&gt;
    PyTorch Conference
   &lt;/a&gt;
   &lt;span&gt;
    (Oct. 21-24, SF) on open models, Olmo, and the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.atomproject.ai/&quot; rel=&quot;&quot;&gt;
    ATOM Project
   &lt;/a&gt;
   &lt;span&gt;
    , so stay tuned for meetups and community opportunities. On to the post!
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;hr/&gt;
  &lt;/div&gt;
  &lt;p&gt;
   China is maneuvering to double down on its open AI ecosystem. Depending on how the U.S. and its allies change culture and mobilize investment, this could make the dominance of Chinese AI models this summer, from Qwen, Kimi, Z.ai, and DeepSeek, looks like foreshadowing rather than the maximum gap in open models between the U.S. and China.
  &lt;/p&gt;
  &lt;p&gt;
   Until the DeepSeek moment, AI was likely a fringe issue to the PRC Government. The central government will set guidelines, rules, budgets, and focus areas that will be distributed and enforced across the decentralized government power structures. AI wasn’t a political focus and the strategy of open-source was likely set by companies looking to close the gap with leading American competitors and achieve maximum market share in the minimum time. I hear all the time that most companies in the U.S. want to start with open models for IT and philosophical reasons, even when spinning up access to a new API model is almost effortless, and it’s likely this bias could be even higher internationally where spending on technology services is historically lower.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Most American startups are starting with Chinese models. I’ve been saying this for a while, but a more official reference for this comes from a recent quote from an a16z partner, Martin Casado, another vocal advocate of investment in open models in America. He was quoted in
   &lt;/span&gt;
   &lt;a href=&quot;https://www.economist.com/business/2025/08/21/china-is-quietly-upstaging-america-with-its-open-models&quot; rel=&quot;&quot;&gt;
    The Economist
   &lt;/a&gt;
   &lt;span&gt;
    with regards to his venture portfolio companies:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    “I’d say 80% chance [they are] using a Chinese open-source model.”
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   The crucial question for the next few years in the geopolitical evolution of AI is whether China will double down on this open-source strategy or change course. The difficulty with monitoring this position is that it could look like nothing is happening and China maintains its outputs, even when the processes for creating them are far different. Holding a position is still a decision.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    It’s feasible in the next decade that AI applications and open models are approached with the same vigor that China built public infrastructure over the last few decades (Yes, I’m reading Dan Wang’s new book
   &lt;/span&gt;
   &lt;a href=&quot;https://www.amazon.com/dp/1324106034/?bestFormat=true&amp;k=breakneck&amp;ref_=nb_sb_ss_w_scx-ent-pd-bk-d_k0_1_9_de&amp;crid=3BTUYHPR7V2P0&amp;sprefix=breakneck&quot; rel=&quot;&quot;&gt;
    Breakneck
   &lt;/a&gt;
   &lt;span&gt;
    ). It could become a new area that local officials compete in to prove their worth to the nation — I’m not sure even true China experts could make confident predictions here. A large source of uncertainty is whether the sort of top-down, PRC edicts can result in effective AI models and digital systems, where government officials succeeded in the past with physical infrastructure.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    At the same time as obvious pro-AI messaging, Chinese officials have warned of “
   &lt;/span&gt;
   &lt;a href=&quot;https://fortune.com/asia/2025/08/29/china-warns-against-disorderly-competition-ai-race/&quot; rel=&quot;&quot;&gt;
    disorderly competition
   &lt;/a&gt;
   &lt;span&gt;
    ” in the AI space, which is an indirect signal that could keep model providers releasing their models openly. Open models reduce duplicative costs of training, help the entire ecosystem monitor best practices, and force business models that aren’t reliant on simple race-to-the-bottom inference markets. Open model submarkets are emerging for every corner of the AI ecosystem, such as video generation or robotic action models, (see our coverage of open models,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/t/artifacts-log&quot; rel=&quot;&quot;&gt;
    Artifacts Logs
   &lt;/a&gt;
   &lt;span&gt;
    ) with a dramatic evolution from research ideas to mature, stable models in the last 12-18 months.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   China improving the open model ecosystem looks like the forced adoption of Chinese AI chips, further specialization of companies’ open models to evolving niches, and expanded influence on fundamental AI research shared internationally. All of these directions have early signs of occurring.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    If the PRC Government wanted to exert certain types of control on the AI ecosystem — they could. This
   &lt;/span&gt;
   &lt;a href=&quot;https://en.wikipedia.org/wiki/Doug_Guthrie&quot; rel=&quot;&quot;&gt;
    Doug Guthrie
   &lt;/a&gt;
   &lt;span&gt;
    excerpt from
   &lt;/span&gt;
   &lt;a href=&quot;https://www.amazon.com/Apple-China-Capture-Greatest-Company/dp/1668053373&quot; rel=&quot;&quot;&gt;
    Apple in China
   &lt;/a&gt;
   &lt;span&gt;
    tells the story from the perspective of international companies. Guthrie was a major player in advising on culture changes in Cupertino to better adapt Apple’s strategy to the Chinese market.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    “When you stake your life, your identity, on and around certain ideas, you sort of fight for them,” Guthrie says. “Xi Jinping kind of broke my heart… I was sitting there, in China, in my dream job, and I’m watching Xinjiang’s internment camps. I’m watching China tearing up a fifty-year agreement over Hong Kong.”
   &lt;/p&gt;
   &lt;p&gt;
    &lt;span&gt;
     Apple, meanwhile, had become too intertwined with China. Guthrie had been hired to help understand the country and to navigate it. And Apple had followed through—very successfully. But it had burned so many boats, as the saying goes, that Guthrie felt its fate was married to China’s and there was no way out. “
    &lt;/span&gt;
    &lt;strong&gt;
     The cost of doing business in China today is a high one, and it is paid by any and every company that comes looking to tap into its markets or leverage its workforce
    &lt;/strong&gt;
    &lt;span&gt;
     ,” he later wrote in a blog. “
    &lt;/span&gt;
    &lt;strong&gt;
     Quite simply, you don’t get to do business in China today without doing exactly what the Chinese government wants you to do. Period. No one is immune. No one.
    &lt;/strong&gt;
    &lt;span&gt;
     ”
    &lt;/span&gt;
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   &lt;span&gt;
    China famously
   &lt;/span&gt;
   &lt;a href=&quot;https://time.com/6973119/china-big-tech-crackdown-backfiring/&quot; rel=&quot;&quot;&gt;
    cracked down
   &lt;/a&gt;
   &lt;span&gt;
    on its largest technology companies in late 2020, stripping key figures of power and dramatic amounts of market value off the books. AI is not immune to this.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The primary read here is that the PRC leadership will decide on the role they want to have in the open-source AI ecosystem. The safe assumption has been that it would continue because the government picked up a high-impact national strategy when it first started focusing on the issue, already seeded with international influence.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/on-chinas-open-source-ai-trajectory?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/on-chinas-open-source-ai-trajectory?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    To formalize these intentions, the Chinese government has recently enacted an “AI+” plan that reads
   &lt;/span&gt;
   &lt;a href=&quot;https://www.justsecurity.org/119509/us-chinese-ai-playbooks/&quot; rel=&quot;&quot;&gt;
    very similarly
   &lt;/a&gt;
   &lt;span&gt;
    to the recent
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/the-white-houses-plan-for-open-models&quot; rel=&quot;&quot;&gt;
    White House AI Action Plan
   &lt;/a&gt;
   &lt;span&gt;
    when it comes to open models. The AI+ plan idea was
   &lt;/span&gt;
   &lt;a href=&quot;https://npcobserver.com/wp-content/uploads/2024/03/2024-Government-Work-Report_EN.pdf&quot; rel=&quot;&quot;&gt;
    first proposed in March 2024
   &lt;/a&gt;
   &lt;span&gt;
    and was just
   &lt;/span&gt;
   &lt;a href=&quot;https://www.gov.cn/zhengce/202507/content_7034734.htm&quot; rel=&quot;&quot;&gt;
    approved
   &lt;/a&gt;
   &lt;span&gt;
    in its full text on July 31, 2025. The AI+ plan, when enacted by local officials, lays out goals for the AI industry in how many open models to have at different tiers of performance and some funding mechanisms for nurturing them.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    This is right in line with other comments from party officials. Chinese Premier Li Qiang, second-ranking member of the Politburo Standing Committee, made comments in March directly supporting open-source models. From the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.wsj.com/economy/beijing-ramps-up-efforts-for-tech-independence-735affda?mod=article_inline&quot; rel=&quot;&quot;&gt;
    Wall Street Journal
   &lt;/a&gt;
   &lt;span&gt;
    :
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    Li pledged that China would boost support for applications of large-scale AI models and AI hardware, such as smartphones, robots, and smart cars.
   &lt;/p&gt;
   &lt;p&gt;
    China’s top economic planning body also said Wednesday that the country aimed to develop a system of open-source models while continuing to invest in computing power and data for AI.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   &lt;span&gt;
    An
   &lt;/span&gt;
   &lt;a href=&quot;https://www.gov.cn/zhengce/202507/content_7034734.htm&quot; rel=&quot;&quot;&gt;
    excerpt
   &lt;/a&gt;
   &lt;span&gt;
    from Beijing’s
   &lt;/span&gt;
   &lt;em&gt;
    city
   &lt;/em&gt;
   &lt;span&gt;
    plan as part of the overall AI+ initiative, translated by GPT-5 Pro, has interesting, specific goals:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    &lt;span&gt;
     By end-2025: implement 5 benchmark application projects at a world-leading level; organize 10 demonstration application projects that lead the nation; and promote a batch of commercializable results.
    &lt;/span&gt;
    &lt;strong&gt;
     Strive to form 3–5 advanced, usable, and self-controllable base large-model products, 100 excellent industry large-model products, and 1,000 industry success cases
    &lt;/strong&gt;
    &lt;span&gt;
     . Take the lead in building an AI-native city, making Beijing a globally influential AI innovation source and application high ground.
    &lt;/span&gt;
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   The goal of this is to:
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    Encourage open-source, high-parameter, ‘autonomous and controllable’ base foundation models, and support building cloud hosting platforms for models and datasets to facilitate developer sharing and collaboration.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   &lt;span&gt;
    Beyond the minor translation bumpiness, the intentions are clear. The goal of the A+ plan is clear with multiple mentions of both open-source models
   &lt;/span&gt;
   &lt;em&gt;
    and an open ecosystem
   &lt;/em&gt;
   &lt;span&gt;
    with them where the models can be adopted widely. The ecosystem of models can make the impact of any one individual model greater than it would be alone.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The Chinese government having centralized power has more direct levers to enact change than the White House, but this comes with the same trade-offs as all initiatives face when comparing the U.S. vs. China’s potential. I won’t review all of the differences in the approaches here.
  &lt;/p&gt;
  &lt;p&gt;
   Where the Chinese Government enacts top level edicts that’ll be harder to follow from the West, there are numerous anecdotes and interactions that highlight in plain terms the mood of the AI ecosystem in China. I’ve routinely been impressed by the level of direct engagement I have received from leading Chinese AI companies and news outlets. Interconnects’ readership has grown substantially in China.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Chinese companies are very sensitive to how their open contributions are viewed — highlighting great pride in both their work and approach. The latest case was via our
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/chinas-top-19-open-model-labs&quot; rel=&quot;&quot;&gt;
    China open model rankings
   &lt;/a&gt;
   &lt;span&gt;
    that got
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/Zai_org/status/1957302250100961555&quot; rel=&quot;&quot;&gt;
    direct engagement
   &lt;/a&gt;
   &lt;span&gt;
    from
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/InclusionAI666/status/1959965837160583349&quot; rel=&quot;&quot;&gt;
    multiple Chinese
   &lt;/a&gt;
   &lt;span&gt;
    AI labs and was
   &lt;/span&gt;
   &lt;a href=&quot;https://mp.weixin.qq.com/s/JhXtJ_b3VGD2PNSXj4zcjg&quot; rel=&quot;&quot;&gt;
    highlighted
   &lt;/a&gt;
   &lt;span&gt;
    by a prominent AI news outlet in China —
   &lt;/span&gt;
   &lt;strong&gt;
    机器之心/Synced
   &lt;/strong&gt;
   &lt;span&gt;
    . They described Interconnects as a “high-quality content platform deeply focused on frontier AI research.” (This Synced post was translated and discussed in the
   &lt;/span&gt;
   &lt;a href=&quot;https://chinai.substack.com/p/chinai-327-deciphering-chinas-ai&quot; rel=&quot;&quot;&gt;
    latest ChinaAI Newsletter
   &lt;/a&gt;
   &lt;span&gt;
    )
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    When intellectuals, influencers, and analysts I follow talk directly to technical members of the AI workforce in China, they sound like what we would expect — people who want to build a great technology.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;a data-attrs=&#x27;{&quot;name&quot;:&quot;Jasmine Sun&quot;,&quot;id&quot;:25322552,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F519d1e6e-ffad-4850-a5c9-fff32d621bc8_2300x2299.jpeg&quot;,&quot;uuid&quot;:&quot;281d3b21-6cd9-42ed-8655-afef2a07917f&quot;}&#x27; data-component-name=&quot;MentionUser&quot; href=&quot;https://open.substack.com/users/25322552-jasmine-sun?utm_source=mentions&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;
    Jasmine Sun
   &lt;/a&gt;
  &lt;/div&gt;
  &lt;span&gt;
   had a great
  &lt;/span&gt;
  &lt;a href=&quot;https://jasmi.news/p/china-2025&quot; rel=&quot;&quot;&gt;
   writeup
  &lt;/a&gt;
  &lt;span&gt;
   on her trip that had some  anecdotes on AI in China. She asked “Do you guys worry about AI safety?”
  &lt;/span&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    “We don’t think about risks at all.” …
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   Continuing from Jasmine:
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    This was the first of several conversations that gave us a distinct impression of the Chinese tech community. Spirits are high, and decoupling policies like export controls only fuel their patriotic drive.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   At the same time, America still represents a covetable life, despite the current political tumult:
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    To be clear, our researcher friend made clear that working at a top US AI lab was still the most desirable option.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   In so many ways, trying to precisely map China’s next steps in AI is extremely challenging. Can they convert their lead in energy infrastructure to more total AI compute? Can they build their own AI chips? Will they take the frontier of performance with their talented population and a different approach? All of this is up for debate.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The intrigue here is exemplified by the abundant interest in sparse
   &lt;/span&gt;
   &lt;a href=&quot;https://www.ft.com/content/eb984646-6320-4bfe-a78d-a1da2274b092?shareType=nongift&quot; rel=&quot;&quot;&gt;
    news
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;a href=&quot;https://www.theinformation.com/articles/deepseek-opts-huawei-chips-train-models&quot; rel=&quot;&quot;&gt;
    stories
   &lt;/a&gt;
   &lt;span&gt;
    on how DeepSeek is training
   &lt;/span&gt;
   &lt;em&gt;
    some
   &lt;/em&gt;
   &lt;span&gt;
    AI model with Huawei chips. In many ways, these new chips working would be a
   &lt;/span&gt;
   &lt;a href=&quot;https://interconnect.substack.com/p/the-real-deepseek-moment-just-arrived&quot; rel=&quot;&quot;&gt;
    bigger story than the original DeepSeek model
   &lt;/a&gt;
   &lt;span&gt;
    , but all signs point to expected experiments with domestic chips, where China’s leading AI models are likely to be trained on Nvidia and other Western chips for the foreseeable future. I do not expect DeepSeek R2 to be trained on Huawei’s hardware.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   China’s hardware investment will take a lot longer to play out than open model strategies, but if China pulls it off — along with its other investments, such as self-driving cars and robots — their practical lead in AI could come for more areas. Open models could be China’s beachhead in a bigger technological resurgence with AI.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Without
   &lt;/span&gt;
   &lt;a href=&quot;https://www.atomproject.ai/&quot; rel=&quot;&quot;&gt;
    major changes to Western investment in open models
   &lt;/a&gt;
   &lt;span&gt;
    , we’re approaching a status quo in 2026 and beyond where:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Chinese open models would continue to increase their lead in performance (and adoption) over American counterparts
     &lt;/strong&gt;
     &lt;span&gt;
      . This will manifest in many ways. One example is how startups in Silicon Valley built on stronger Chinese models will be offering services that compete with entrenched, handicapped Fortune 500 companies wary of adopting these models in their services. This could make some subareas of AI disruption feel particularly intense.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      The Chinese open ecosystem’s density of knowledge and sharing would translate into increased scientific and academic impact
     &lt;/strong&gt;
     &lt;span&gt;
      . China’s share of conference papers at leading AI conferences is already rapidly on the rise, and having an ecosystem built around substantially better models than their Western counterparts could lead this
     &lt;/span&gt;
     &lt;em&gt;
      numerous
     &lt;/em&gt;
     &lt;span&gt;
      research growing also to be
     &lt;/span&gt;
     &lt;em&gt;
      impactful
     &lt;/em&gt;
     &lt;span&gt;
      . Better base models allow more interesting RL and agentic research today, and the list of areas reliant on high-performance models is likely to only grow longer with time.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      A proliferation of strong open models would make it difficult to restrict the presence or availability of many forms of AI.
     &lt;/strong&gt;
     &lt;span&gt;
      We do not have the government tools, incentives, nor culture to successfully prevent digital goods from China (or elsewhere) entering the U.S. economy. Many forms of AI governance and regulation in the United States and the rest of the world may need to be reconsidered, where many jurisdictions have looked to control and understand the development of “frontier AI.” Regulation needs to be approached for a world enmeshed in powerful AI models, rather than trying to control access or the releases of a few.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   These realities all paint a clear picture that bends the association of open models from “soft power” to just “power.” Continuously releasing strong open AI models could allow Chinese companies to shape the technology interfaces, services and reality around the world. Where 2024 was about research on open models, and 2025 the professionalization of them, 2026 could be where we begin to see clear impacts of their power through endless distribution.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!JoT8!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90d5cee1-2f29-4197-8827-957377becfe9_2400x1350.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!JoT8!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90d5cee1-2f29-4197-8827-957377becfe9_2400x1350.png 424w, https://substackcdn.com/image/fetch/$s_!JoT8!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90d5cee1-2f29-4197-8827-957377becfe9_2400x1350.png 848w, https://substackcdn.com/image/fetch/$s_!JoT8!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90d5cee1-2f29-4197-8827-957377becfe9_2400x1350.png 1272w, https://substackcdn.com/image/fetch/$s_!JoT8!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90d5cee1-2f29-4197-8827-957377becfe9_2400x1350.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/90d5cee1-2f29-4197-8827-957377becfe9_2400x1350.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:298238,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/171165250?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90d5cee1-2f29-4197-8827-957377becfe9_2400x1350.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;819&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!JoT8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90d5cee1-2f29-4197-8827-957377becfe9_2400x1350.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!JoT8!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90d5cee1-2f29-4197-8827-957377becfe9_2400x1350.png 424w, https://substackcdn.com/image/fetch/$s_!JoT8!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90d5cee1-2f29-4197-8827-957377becfe9_2400x1350.png 848w, https://substackcdn.com/image/fetch/$s_!JoT8!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90d5cee1-2f29-4197-8827-957377becfe9_2400x1350.png 1272w, https://substackcdn.com/image/fetch/$s_!JoT8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90d5cee1-2f29-4197-8827-957377becfe9_2400x1350.png 1456w&quot; title=&quot;&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Ranking the Chinese Open Model Builders </title>
<link>https://www.interconnects.ai/p/chinas-top-19-open-model-labs</link>
<pubDate>Sun, 17 Aug 2025 15:38:01 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    The Chinese AI ecosystem has taken the AI world by storm this summer with an unrelenting pace of stellar open model releases. The flagship releases that got the most Western media coverage are the likes of
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/qwen-3-the-new-open-standard?utm_source=publication-search&quot; rel=&quot;&quot;&gt;
    Qwen 3
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/kimi-k2-and-when-deepseek-moments?utm_source=publication-search&quot; rel=&quot;&quot;&gt;
    Kimi K2
   &lt;/a&gt;
   &lt;span&gt;
    , or
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2508.06471&quot; rel=&quot;&quot;&gt;
    Zhipu GLM 4.5
   &lt;/a&gt;
   &lt;span&gt;
    , but there is a long-tail of providers close behind in both quality and cadence of releases.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    In this post we rank the top 19 Chinese labs by the
   &lt;/span&gt;
   &lt;strong&gt;
    quality and quantity of contributions to the open AI ecosystem
   &lt;/strong&gt;
   &lt;span&gt;
    — this is not a list of raw ability, but outputs — all the way from the top of DeepSeek to the emerging open research labs. For a more detailed coverage of all the specific models, we recommend studying our
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/t/artifacts-log&quot; rel=&quot;&quot;&gt;
    Artifacts Log
   &lt;/a&gt;
   &lt;span&gt;
    series, which chronicles all of the major open model releases every month. We plan to revisit this ranking and make note of major new players, so make sure to subscribe.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
  &lt;/div&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!y86L!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2aff76bf-bd04-46b7-89e0-ddbb0e198aa7_1326x812.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!y86L!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2aff76bf-bd04-46b7-89e0-ddbb0e198aa7_1326x812.png 424w, https://substackcdn.com/image/fetch/$s_!y86L!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2aff76bf-bd04-46b7-89e0-ddbb0e198aa7_1326x812.png 848w, https://substackcdn.com/image/fetch/$s_!y86L!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2aff76bf-bd04-46b7-89e0-ddbb0e198aa7_1326x812.png 1272w, https://substackcdn.com/image/fetch/$s_!y86L!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2aff76bf-bd04-46b7-89e0-ddbb0e198aa7_1326x812.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2aff76bf-bd04-46b7-89e0-ddbb0e198aa7_1326x812.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:812,&quot;width&quot;:1326,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:433312,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/171165224?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2aff76bf-bd04-46b7-89e0-ddbb0e198aa7_1326x812.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;812&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!y86L!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2aff76bf-bd04-46b7-89e0-ddbb0e198aa7_1326x812.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!y86L!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2aff76bf-bd04-46b7-89e0-ddbb0e198aa7_1326x812.png 424w, https://substackcdn.com/image/fetch/$s_!y86L!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2aff76bf-bd04-46b7-89e0-ddbb0e198aa7_1326x812.png 848w, https://substackcdn.com/image/fetch/$s_!y86L!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2aff76bf-bd04-46b7-89e0-ddbb0e198aa7_1326x812.png 1272w, https://substackcdn.com/image/fetch/$s_!y86L!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2aff76bf-bd04-46b7-89e0-ddbb0e198aa7_1326x812.png 1456w&quot; width=&quot;1326&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   At the frontier
  &lt;/h2&gt;
  &lt;p&gt;
   &lt;em&gt;
    These companies rival Western counterparts with the quality and frequency of their models.
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   DeepSeek
  &lt;/h3&gt;
  &lt;h6&gt;
   &lt;a href=&quot;https://www.deepseek.com/&quot; rel=&quot;&quot;&gt;
    deepseek.com
   &lt;/a&gt;
   &lt;span&gt;
    | 🤗
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/deepseek-ai&quot; rel=&quot;&quot;&gt;
    deepseek-ai
   &lt;/a&gt;
   &lt;span&gt;
    | X
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/DeepSeek_AI&quot; rel=&quot;&quot;&gt;
    @DeepSeek_AI
   &lt;/a&gt;
  &lt;/h6&gt;
  &lt;p&gt;
   &lt;span&gt;
    DeepSeek needs little introduction. Their
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/deepseek-v3-and-the-actual-cost-of&quot; rel=&quot;&quot;&gt;
    V3
   &lt;/a&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1&quot; rel=&quot;&quot;&gt;
    R1
   &lt;/a&gt;
   &lt;span&gt;
    models, and their impact, are still likely the biggest AI stories of 2025 — open, Chinese models at the frontier of performance with permissive licenses and the exposed model chains of thought that enamored users around the world.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    With all the attention following the breakthrough releases, a bit more has been said about DeepSeek in terms of operations,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.chinatalk.media/p/deepseek-ceo-interview-with-chinas&quot; rel=&quot;&quot;&gt;
    ideology
   &lt;/a&gt;
   &lt;span&gt;
    , and
   &lt;/span&gt;
   &lt;a href=&quot;https://semianalysis.com/2025/07/03/deepseek-debrief-128-days-later/#a-boom-and-bust&quot; rel=&quot;&quot;&gt;
    business model
   &lt;/a&gt;
   &lt;span&gt;
    relative to the other labs. They are very innovative technically and have not devoted extensive resources to their consumer chatbot or API hosting (as judged by higher than industry-standard performance degradation).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Over the last 18 months, DeepSeek was known for making “about one major release a month.” Since the updated releases of V3-0324 and R1-0528, many close observers have been surprised by their lack of contributions. This has let other players in the ecosystem close the gap, but in terms of impact and actual commercial usage, DeepSeek is still king.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    An important aspect of DeepSeek’s strategy is their focus on improving their core models at the frontier of performance. To complement this, they have experiments using their current generation to make fundamental research innovations, such as
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2504.21801&quot; rel=&quot;&quot;&gt;
    theorem proving
   &lt;/a&gt;
   &lt;span&gt;
    or math models, which ultimately get used for the next iteration of models. This is similar to how Western labs operate. First, you test a new idea as an experiment internally, then you fold it into the “main product” that most of your users see.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2402.03300&quot; rel=&quot;&quot;&gt;
    DeepSeekMath
   &lt;/a&gt;
   &lt;span&gt;
    , for example, used DeepSeek-Coder-Base-v1.5 7B and introduced the now famous reinforcement learning algorithm
   &lt;/span&gt;
   &lt;a href=&quot;https://rlhfbook.com/c/11-policy-gradients.html#group-relative-policy-optimization&quot; rel=&quot;&quot;&gt;
    Group Relative Policy Optimization
   &lt;/a&gt;
   &lt;span&gt;
    (GRPO), which is one of the main drivers of R1. The exception to this (at least today) is
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2410.13848&quot; rel=&quot;&quot;&gt;
    Janus
   &lt;/a&gt;
   &lt;span&gt;
    , their omni-modal series, which has not been used in their main line.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   Qwen
  &lt;/h3&gt;
  &lt;h6&gt;
   &lt;a href=&quot;https://qwenlm.ai/&quot; rel=&quot;&quot;&gt;
    qwenlm.ai
   &lt;/a&gt;
   &lt;span&gt;
    | 🤗
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/Qwen&quot; rel=&quot;&quot;&gt;
    Qwen
   &lt;/a&gt;
   &lt;span&gt;
    | X
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/Alibaba_Qwen/highlights&quot; rel=&quot;&quot;&gt;
    @Alibaba_Qwen
   &lt;/a&gt;
  &lt;/h6&gt;
  &lt;p&gt;
   &lt;span&gt;
    Tongyi Qianwen, the primary AI lab within Alibaba’s cloud division, is by far and away most known for their open language model series. They have been releasing many models across a range of sizes (quite similar to Llama 1 through 3) for years. Recently, their models from Qwen 2.5 and Qwen 3 have had
   &lt;/span&gt;
   &lt;a href=&quot;https://www.atomproject.ai/&quot; rel=&quot;&quot;&gt;
    accelerating market share among AI research and startup development
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Qwen is closer to American Big Tech companies than to other Chinese AI labs in terms of releases: They are covering the entire stack, from
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct&quot; rel=&quot;&quot;&gt;
    VLMs
   &lt;/a&gt;
   &lt;span&gt;
    to
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-Embedding-8B&quot; rel=&quot;&quot;&gt;
    embedding models
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct&quot; rel=&quot;&quot;&gt;
    coding models
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/Qwen/Qwen-Image&quot; rel=&quot;&quot;&gt;
    image
   &lt;/a&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/Wan-AI/Wan2.2-TI2V-5B&quot; rel=&quot;&quot;&gt;
    video generation
   &lt;/a&gt;
   &lt;span&gt;
    , and so on.
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;br/&gt;
   &lt;span&gt;
    They also cater to all possible customers (or rather every part of the open community) by releasing capable models of all sizes. Small dense models are important for academia to run experiments and for small/medium businesses to power their applications, so it comes to no surprise that Qwen-based models are exploding in popularity.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    On top of model releases for everyone, they also focused on supporting the (Western) community, releasing
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-8B-MLX-8bit&quot; rel=&quot;&quot;&gt;
    MLX
   &lt;/a&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-8B-GGUF&quot; rel=&quot;&quot;&gt;
    GGUF
   &lt;/a&gt;
   &lt;span&gt;
    versions of their models for local usage or a
   &lt;/span&gt;
   &lt;a href=&quot;https://github.com/QwenLM/qwen-code&quot; rel=&quot;&quot;&gt;
    CLI
   &lt;/a&gt;
   &lt;span&gt;
    for their coding models, which includes a generous amount of free requests.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Unlike some American companies, the core team seems to have stayed relatively small in terms of headcount, in line with other Chinese AI labs:
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2505.09388&quot; rel=&quot;&quot;&gt;
    Qwen3
   &lt;/a&gt;
   &lt;span&gt;
    has 177 contributors, whereas Llama 3 has thrice the amount, while Gemini 2.5 has over 3,000 people as part of the model.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!QxA6!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88e4d2b4-e5e5-49b0-855c-c12e4027986d_1152x666.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!QxA6!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88e4d2b4-e5e5-49b0-855c-c12e4027986d_1152x666.png 424w, https://substackcdn.com/image/fetch/$s_!QxA6!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88e4d2b4-e5e5-49b0-855c-c12e4027986d_1152x666.png 848w, https://substackcdn.com/image/fetch/$s_!QxA6!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88e4d2b4-e5e5-49b0-855c-c12e4027986d_1152x666.png 1272w, https://substackcdn.com/image/fetch/$s_!QxA6!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88e4d2b4-e5e5-49b0-855c-c12e4027986d_1152x666.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/88e4d2b4-e5e5-49b0-855c-c12e4027986d_1152x666.png&quot;,&quot;srcNoWatermark&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ca9f294b-7af4-40cc-b9d4-bc3fde7848e0_1152x666.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:666,&quot;width&quot;:1152,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:37876,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/171165224?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca9f294b-7af4-40cc-b9d4-bc3fde7848e0_1152x666.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;666&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!QxA6!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88e4d2b4-e5e5-49b0-855c-c12e4027986d_1152x666.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!QxA6!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88e4d2b4-e5e5-49b0-855c-c12e4027986d_1152x666.png 424w, https://substackcdn.com/image/fetch/$s_!QxA6!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88e4d2b4-e5e5-49b0-855c-c12e4027986d_1152x666.png 848w, https://substackcdn.com/image/fetch/$s_!QxA6!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88e4d2b4-e5e5-49b0-855c-c12e4027986d_1152x666.png 1272w, https://substackcdn.com/image/fetch/$s_!QxA6!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88e4d2b4-e5e5-49b0-855c-c12e4027986d_1152x666.png 1456w&quot; width=&quot;1152&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;div&gt;
   &lt;hr/&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   Close competitors
  &lt;/h2&gt;
  &lt;p&gt;
   &lt;em&gt;
    These companies have recently arrived at the frontier of performance and we will see if they have the capability to consistently release great models at a pace matching Qwen or DeepSeek.
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   Moonshot AI (Kimi)
  &lt;/h3&gt;
  &lt;h6&gt;
   &lt;a href=&quot;https://moonshot.cn/en&quot; rel=&quot;&quot;&gt;
    moonshot.cn
   &lt;/a&gt;
   &lt;span&gt;
    | 🤗
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/moonshotai&quot; rel=&quot;&quot;&gt;
    moonshotai
   &lt;/a&gt;
   &lt;span&gt;
    | X
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/Kimi_Moonshot/highlights&quot; rel=&quot;&quot;&gt;
    @Kimi_Moonshot
   &lt;/a&gt;
  &lt;/h6&gt;
  &lt;p&gt;
   &lt;span&gt;
    Moonshot AI is one of the so-called “AI tigers”, a group of hot Chinese AI startups determined by Chinese media and investors. This group consists of Baichuan, Zhipu AI, Moonshot AI, MiniMax, StepFun, and 01.AI — most of which have attracted investments by tech funds and other tech grants. For example, Alibaba is seen as a big winner in the AI space by having their own models and by
   &lt;/span&gt;
   &lt;a href=&quot;https://www.bloomberg.com/news/articles/2024-02-27/alibaba-leads-record-deal-to-create-2-5-billion-china-ai-player&quot; rel=&quot;&quot;&gt;
    being a lead investor in Moonshot
   &lt;/a&gt;
   &lt;span&gt;
    , sort of like how big tech companies in the U.S. are investing in fundraising rounds for newer AI labs.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    While their first models, K1 and K1.5, were closed and available
   &lt;/span&gt;
   &lt;a href=&quot;https://platform.moonshot.ai/docs/guide/choose-an-appropriate-kimi-model&quot; rel=&quot;&quot;&gt;
    on their API
   &lt;/a&gt;
   &lt;span&gt;
    , they started releasing open models after the R1 release with
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/moonshotai/Moonlight-16B-A3B&quot; rel=&quot;&quot;&gt;
    experimental models
   &lt;/a&gt;
   &lt;span&gt;
    using the Muon optimizer. Similar to DeepSeek, they focus on a single model line, with small experiments eventually feeding back into the main model. K2 is their “moonshot run,” a.k.a.
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/_jasonwei/status/1757486124082303073?lang=en&quot; rel=&quot;&quot;&gt;
    yolo run
   &lt;/a&gt;
   &lt;span&gt;
    , and quickly became a hit similar to R1 (see
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/kimi-k2-and-when-deepseek-moments&quot; rel=&quot;&quot;&gt;
    our report
   &lt;/a&gt;
   &lt;span&gt;
    from the release).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;a href=&quot;https://www.chinatalk.media/p/kimi-k2-the-open-source-way&quot; rel=&quot;&quot;&gt;
    Further
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;a href=&quot;https://www.chinatalk.media/p/moonshot-ais-agi-vision&quot; rel=&quot;&quot;&gt;
    reading
   &lt;/a&gt;
   &lt;span&gt;
    on Kimi can be found on ChinaTalk.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   Zhipu / Z.AI
  &lt;/h3&gt;
  &lt;h6&gt;
   &lt;a href=&quot;https://z.ai/&quot; rel=&quot;&quot;&gt;
    z.ai
   &lt;/a&gt;
   &lt;span&gt;
    | 🤗
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/zai-org&quot; rel=&quot;&quot;&gt;
    zai-org
   &lt;/a&gt;
   &lt;span&gt;
    | X
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/Zai_org/highlights&quot; rel=&quot;&quot;&gt;
    @Zai_org
   &lt;/a&gt;
  &lt;/h6&gt;
  &lt;p&gt;
   &lt;span&gt;
    Zhipu, known in the west as Z.ai, is a startup spinoff of Tsinghua University with
   &lt;/span&gt;
   &lt;a href=&quot;https://www.scmp.com/tech/big-tech/article/3321314/unicorn-zai-adapts-models-huawei-chips-drive-broaden-chinas-ai-ecosystem?utm_source=chatgpt.com&quot; rel=&quot;&quot;&gt;
    considerable investments
   &lt;/a&gt;
   &lt;span&gt;
    by Chinese companies and VCs. Currently, they are
   &lt;/span&gt;
   &lt;a href=&quot;https://www.reuters.com/world/china/zhipu-ai-ramps-up-overseas-expansion-strategy-ahead-ipo-2025-04-23/&quot; rel=&quot;&quot;&gt;
    even considering an IPO
   &lt;/a&gt;
   &lt;span&gt;
    , which would make them the first AI tiger to do so.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    In terms of models, they are mostly known for their recent release of
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/zai-org/GLM-4.5&quot; rel=&quot;&quot;&gt;
    GLM-4.5
   &lt;/a&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/zai-org/GLM-4.5V&quot; rel=&quot;&quot;&gt;
    GLM-4.5V
   &lt;/a&gt;
   &lt;span&gt;
    , which are all very capable for their sizes (both of which are fairly large mixture of expert models). However, they are not just releasing LLMs, but also
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/zai-org/CogView4-6B&quot; rel=&quot;&quot;&gt;
    image
   &lt;/a&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/zai-org/CogVideoX1.5-5B&quot; rel=&quot;&quot;&gt;
    video generation
   &lt;/a&gt;
   &lt;span&gt;
    models, setting them apart from pure-LLM companies and labs.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;hr/&gt;
  &lt;/div&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/chinas-top-19-open-model-labs?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/chinas-top-19-open-model-labs?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;h2&gt;
   Noteworthy
  &lt;/h2&gt;
  &lt;p&gt;
   &lt;em&gt;
    These companies are transitioning to open releases, have open models with inferior capabilities, or slightly different foci than the text-centric labs pushing the frontiers of intelligence.
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   StepFun
  &lt;/h3&gt;
  &lt;h6&gt;
   &lt;a href=&quot;https://stepfun.ai/&quot; rel=&quot;&quot;&gt;
    stepfun.ai
   &lt;/a&gt;
   &lt;span&gt;
    | 🤗
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/stepfun-ai&quot; rel=&quot;&quot;&gt;
    stepfun-ai
   &lt;/a&gt;
   &lt;span&gt;
    | X
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/StepFun_ai&quot; rel=&quot;&quot;&gt;
    @StepFun_ai
   &lt;/a&gt;
  &lt;/h6&gt;
  &lt;p&gt;
   &lt;span&gt;
    StepFun first started as a closed model provider, but pivoted to open model releases after DeepSeek R1 shook up the industry. They are mostly focusing on multi-modal model releases, with
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/stepfun-ai/step3&quot; rel=&quot;&quot;&gt;
    Step3
   &lt;/a&gt;
   &lt;span&gt;
    being their flagship VLM. They also have
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/stepfun-ai/NextStep-1-Large&quot; rel=&quot;&quot;&gt;
    image
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/stepfun-ai/Step-Audio-AQAA&quot; rel=&quot;&quot;&gt;
    audio
   &lt;/a&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/stepfun-ai/stepvideo-ti2v&quot; rel=&quot;&quot;&gt;
    video generation models
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   Tencent (Hunyuan)
  &lt;/h3&gt;
  &lt;h6&gt;
   &lt;a href=&quot;https://hunyuan.tencent.com/en&quot; rel=&quot;&quot;&gt;
    hunyuan.tencent.com
   &lt;/a&gt;
   &lt;span&gt;
    | 🤗
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/Tencent&quot; rel=&quot;&quot;&gt;
    Tencent
   &lt;/a&gt;
   &lt;span&gt;
    | X
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/TencentHunyuan/highlights&quot; rel=&quot;&quot;&gt;
    @TencentHunyuan
   &lt;/a&gt;
  &lt;/h6&gt;
  &lt;p&gt;
   &lt;span&gt;
    Hunyuan is mostly known for
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/tencent/HunyuanVideo&quot; rel=&quot;&quot;&gt;
    HunyuanVideo
   &lt;/a&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/tencent/Hunyuan3D-2.1&quot; rel=&quot;&quot;&gt;
    Hunyuan3D
   &lt;/a&gt;
   &lt;span&gt;
    . While they have released
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/tencent/Tencent-Hunyuan-Large&quot; rel=&quot;&quot;&gt;
    three
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/collections/tencent/hunyuan-a13b-685ec38e5b46321e3ea7c4be&quot; rel=&quot;&quot;&gt;
    series
   &lt;/a&gt;
   &lt;span&gt;
    of
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/collections/tencent/hunyuan-dense-model-6890632cda26b19119c9c5e7&quot; rel=&quot;&quot;&gt;
    different
   &lt;/a&gt;
   &lt;span&gt;
    LLMs, their releases come with very strict licenses, which is unusual for Chinese companies and dampens excitement when combined with performance levels that can be found elsewhere.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   RedNote (Xiaohongshu)
  &lt;/h3&gt;
  &lt;h6&gt;
   &lt;a href=&quot;https://www.xiaohongshu.com/&quot; rel=&quot;&quot;&gt;
    xiaohongshu.com
   &lt;/a&gt;
   &lt;span&gt;
    | 🤗
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/rednote-hilab&quot; rel=&quot;&quot;&gt;
    rednote-hilab
   &lt;/a&gt;
  &lt;/h6&gt;
  &lt;p&gt;
   &lt;span&gt;
    The Chinese version of Instagram, RedNote, recently joined the ranks of Chinese companies releasing open models. Especially their capable character recognition /
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/rednote-hilab/dots.ocr&quot; rel=&quot;&quot;&gt;
    OCR model
   &lt;/a&gt;
   &lt;span&gt;
    surprised many (see
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-artifacts-13-the-abundance&quot; rel=&quot;&quot;&gt;
    our coverage
   &lt;/a&gt;
   &lt;span&gt;
    ). Similar to Xiaomi and Baidu, it remains to be seen what their overall open strategy will be in the near and distant future and they have not competed in the large, frontier model space.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   MiniMax
  &lt;/h3&gt;
  &lt;h6&gt;
   &lt;a href=&quot;https://www.minimaxi.com/&quot; rel=&quot;&quot;&gt;
    minimaxi.com
   &lt;/a&gt;
   &lt;span&gt;
    | 🤗
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/MiniMaxAI&quot; rel=&quot;&quot;&gt;
    MiniMaxAI
   &lt;/a&gt;
   &lt;span&gt;
    | X
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/MiniMax__AI&quot; rel=&quot;&quot;&gt;
    @MiniMax__AI
   &lt;/a&gt;
  &lt;/h6&gt;
  &lt;p&gt;
   &lt;span&gt;
    MiniMax is another of the AI tigers and also started as a closed company. After the release of R1, they changed their strategy and released the weights of
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/MiniMaxAI/MiniMax-Text-01&quot; rel=&quot;&quot;&gt;
    Minimax-Text-01
   &lt;/a&gt;
   &lt;span&gt;
    , following up with
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/MiniMaxAI/MiniMax-M1-80k&quot; rel=&quot;&quot;&gt;
    reasoning models
   &lt;/a&gt;
   &lt;span&gt;
    building upon it. The unique selling point of these models are the 1M context window achieved with hybrid attention.
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/chinas-top-19-open-model-labs#footnote-1-171165224&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     1
    &lt;/a&gt;
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    These text models are not the only thing they are focusing on — they also have
   &lt;/span&gt;
   &lt;a href=&quot;https://hailuoai.video&quot; rel=&quot;&quot;&gt;
    image and video generation models
   &lt;/a&gt;
   &lt;span&gt;
    , but those remain closed and only available on their API. They are also promoting
   &lt;/span&gt;
   &lt;a href=&quot;https://agent.minimax.io&quot; rel=&quot;&quot;&gt;
    their consumer platform
   &lt;/a&gt;
   &lt;span&gt;
    heavily as they
   &lt;/span&gt;
   &lt;a href=&quot;https://www.reuters.com/world/asia-pacific/chinese-ai-firm-minimax-files-confidentially-hong-kong-ipo-sources-say-2025-07-16/&quot; rel=&quot;&quot;&gt;
    eye an IPO
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   OpenGVLab / InternLM
  &lt;/h3&gt;
  &lt;h6&gt;
   &lt;a href=&quot;https://internlm.intern-ai.org.cn/&quot; rel=&quot;&quot;&gt;
    internlm.intern-ai.org.cn
   &lt;/a&gt;
   &lt;span&gt;
    | 🤗
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/InternLM&quot; rel=&quot;&quot;&gt;
    InternLM
   &lt;/a&gt;
   &lt;span&gt;
    | X
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/opengvlab&quot; rel=&quot;&quot;&gt;
    @opengvlab
   &lt;/a&gt;
  &lt;/h6&gt;
  &lt;p&gt;
   &lt;span&gt;
    InternLM &amp; OpenGVLab have deep ties to the Shanghai AI Laboratory, with InternLM focusing on the language models, while OpenGVLab releases vision models. While they release a range of models such as
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/collections/internlm/intern-s1-6882e325e8ac1c58ba108aa5&quot; rel=&quot;&quot;&gt;
    S1
   &lt;/a&gt;
   &lt;span&gt;
    or
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/collections/internlm/internlm2-math-65b0ce88bf7d3327d0a5ad9f&quot; rel=&quot;&quot;&gt;
    InternLM-Math
   &lt;/a&gt;
   &lt;span&gt;
    , the orgs are mostly known for the strong
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/collections/OpenGVLab/internvl3-67f7f690be79c2fe9d74fe9d&quot; rel=&quot;&quot;&gt;
    InternVL
   &lt;/a&gt;
   &lt;span&gt;
    series. While the first versions mostly used their own InternLM pretrained models, later releases (such as InternVL3) rely on Qwen as the language backend.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   Skywork
  &lt;/h3&gt;
  &lt;h6&gt;
   &lt;a href=&quot;https://skywork.ai/&quot; rel=&quot;&quot;&gt;
    skywork.ai
   &lt;/a&gt;
   &lt;span&gt;
    | 🤗
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/Skywork&quot; rel=&quot;&quot;&gt;
    Skywork
   &lt;/a&gt;
   &lt;span&gt;
    | X
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/Skywork_AI&quot; rel=&quot;&quot;&gt;
    @Skywork_AI
   &lt;/a&gt;
  &lt;/h6&gt;
  &lt;p&gt;
   &lt;span&gt;
    The Singaporean Skywork first started out as an online karaoke company (yes,
   &lt;/span&gt;
   &lt;a href=&quot;https://play.google.com/store/apps/details/?hl=en-US&amp;id=com.starmakerinteractive.starmaker&quot; rel=&quot;&quot;&gt;
    really
   &lt;/a&gt;
   &lt;span&gt;
    ) before they pivoted to AI and being a competitor to
   &lt;/span&gt;
   &lt;a href=&quot;https://manus.im&quot; rel=&quot;&quot;&gt;
    Manus
   &lt;/a&gt;
   &lt;span&gt;
    , with their platform focusing on
   &lt;/span&gt;
   &lt;a href=&quot;https://skywork.ai/&quot; rel=&quot;&quot;&gt;
    agents for work-related tasks
   &lt;/a&gt;
   &lt;span&gt;
    , such as slide generation.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Their LLM journey started with them releasing their own pretrained
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/Skywork/Skywork-13B-base&quot; rel=&quot;&quot;&gt;
    dense
   &lt;/a&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/Skywork/Skywork-MoE-Base&quot; rel=&quot;&quot;&gt;
    MoE
   &lt;/a&gt;
   &lt;span&gt;
    models. However, they stopped pre-training their own models and instead started to fine-tune existing models: Their
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/Skywork/Skywork-OR1-32B&quot; rel=&quot;&quot;&gt;
    OR1 reasoning model
   &lt;/a&gt;
   &lt;span&gt;
    builds on top of DeepSeek-R1-Distill-Qwen-32B,
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/Skywork/Skywork-R1V3-38B&quot; rel=&quot;&quot;&gt;
    R1V3
   &lt;/a&gt;
   &lt;span&gt;
    uses InternVL3 (which itself uses Qwen2.5 as its LLM backend).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Aside from LLMs, they have a wide range of other models, from
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/Skywork/Matrix-3D&quot; rel=&quot;&quot;&gt;
    world models
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/Skywork/UniPic2-Metaquery-9B&quot; rel=&quot;&quot;&gt;
    image
   &lt;/a&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/Skywork/SkyReels-V1-Hunyuan-T2V&quot; rel=&quot;&quot;&gt;
    video generation models
   &lt;/a&gt;
   &lt;span&gt;
    , and
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/Skywork/Skywork-Reward-V2-Qwen3-8B&quot; rel=&quot;&quot;&gt;
    reward models
   &lt;/a&gt;
   &lt;span&gt;
    . Similar to their LLMs, they mostly build on top of other models. Unlike many labs, Skywork has released some datasets with their models, such as
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/datasets/Skywork/Skywork-Reward-Preference-80K-v0.2&quot; rel=&quot;&quot;&gt;
    preference
   &lt;/a&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/datasets/Skywork/Skywork-OR1-RL-Data&quot; rel=&quot;&quot;&gt;
    reasoning
   &lt;/a&gt;
   &lt;span&gt;
    training data.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;hr/&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   On the rise
  &lt;/h2&gt;
  &lt;p&gt;
   &lt;em&gt;
    These companies are either just getting their toes wet with open models or operating as more of academic research organizations than labs pushing the performance of models.
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   ByteDance Seed
  &lt;/h3&gt;
  &lt;h6&gt;
   &lt;a href=&quot;https://seed.bytedance.com/en&quot; rel=&quot;&quot;&gt;
    seed.bytedance.com
   &lt;/a&gt;
   &lt;span&gt;
    | 🤗
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/ByteDance-Seed&quot; rel=&quot;&quot;&gt;
    ByteDance-Seed
   &lt;/a&gt;
  &lt;/h6&gt;
  &lt;p&gt;
   Seed is the R&amp;D arm of ByteDance and eerily similar to Meta’s FAIR division: Diverse models with interesting research, with their papers garnering a ton of attention in the community. However, it remains to be seen whether they shoot for a Llama-style model release or continue to release research artifacts.
  &lt;/p&gt;
  &lt;p&gt;
   Here are some recent papers:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;em&gt;
      &lt;a href=&quot;https://arxiv.org/abs/2508.02193&quot; rel=&quot;&quot;&gt;
       Seed Diffusion: A Large-Scale Diffusion Language Model with High-Speed Inference
      &lt;/a&gt;
     &lt;/em&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;em&gt;
      &lt;a href=&quot;https://arxiv.org/abs/2507.23726&quot; rel=&quot;&quot;&gt;
       Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving
      &lt;/a&gt;
     &lt;/em&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;em&gt;
      &lt;a href=&quot;https://arxiv.org/abs/2507.13618&quot; rel=&quot;&quot;&gt;
       Seed-X: Building Strong Multilingual Translation LLM with 7B Parameters
      &lt;/a&gt;
     &lt;/em&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;em&gt;
      &lt;a href=&quot;https://arxiv.org/abs/2506.09113&quot; rel=&quot;&quot;&gt;
       Seedance 1.0: Exploring the Boundaries of Video Generation Models
      &lt;/a&gt;
     &lt;/em&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;em&gt;
      &lt;a href=&quot;https://arxiv.org/abs/2506.05083&quot; rel=&quot;&quot;&gt;
       SeedEdit 3.0: Fast and High-Quality Generative Image Editing
      &lt;/a&gt;
     &lt;/em&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;em&gt;
      &lt;a href=&quot;https://arxiv.org/abs/2505.07062&quot; rel=&quot;&quot;&gt;
       Seed1.5‑VL Technical Report
      &lt;/a&gt;
     &lt;/em&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;em&gt;
      &lt;a href=&quot;https://arxiv.org/abs/2505.05472&quot; rel=&quot;&quot;&gt;
       Mogao: An Omni Foundation Model for Interleaved Multi‑Modal Generation
      &lt;/a&gt;
     &lt;/em&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;em&gt;
      &lt;a href=&quot;https://arxiv.org/abs/2504.13914&quot; rel=&quot;&quot;&gt;
       Seed1.5‑Thinking: Advancing Superb Reasoning Models with Reinforcement Learning
      &lt;/a&gt;
     &lt;/em&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;em&gt;
      &lt;a href=&quot;https://arxiv.org/abs/2504.05118&quot; rel=&quot;&quot;&gt;
       VAPO: Efficient and Reliable Reinforcement Learning for Advanced Reasoning Tasks
      &lt;/a&gt;
     &lt;/em&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;em&gt;
      &lt;a href=&quot;https://arxiv.org/abs/2507.17527&quot; rel=&quot;&quot;&gt;
       Seed LiveInterpret 2.0: End‑to‑end Simultaneous Speech‑to‑speech Translation with Your Voice
      &lt;/a&gt;
     &lt;/em&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h3&gt;
   OpenBMB
  &lt;/h3&gt;
  &lt;h6&gt;
   &lt;a href=&quot;https://openbmb.ai/&quot; rel=&quot;&quot;&gt;
    openbmb.ai
   &lt;/a&gt;
   &lt;span&gt;
    | 🤗
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/openbmb&quot; rel=&quot;&quot;&gt;
    openbmb
   &lt;/a&gt;
   &lt;span&gt;
    | X
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/OpenBMB&quot; rel=&quot;&quot;&gt;
    @OpenBMB
   &lt;/a&gt;
  &lt;/h6&gt;
  &lt;p&gt;
   OpenBMB is an open-source community (comparable to BigScience) from Tsinghua University NLP Lab (the very same university where Zhipu was spun off from) with support from the Beijing Academy of Artificial Intelligence (BAAI) and ModelBest.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    They are mostly focusing on small multi-modal models for the edge, such as
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/collections/openbmb/minicpm-o-and-minicpm-v-65d48fa84e358ce02a92d004&quot; rel=&quot;&quot;&gt;
    MiniCPM-V-4
   &lt;/a&gt;
   &lt;span&gt;
    . However, the license is rather restrictive, which is surprising given the community-driven origins of the group. Aside from model releases, they also release frameworks and specialized
   &lt;/span&gt;
   &lt;a href=&quot;https://github.com/OpenBMB/CPM.cu&quot; rel=&quot;&quot;&gt;
    kernels
   &lt;/a&gt;
   &lt;span&gt;
    to make sure their models run on low-end hardware.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   Xiaomi (MiMo)
  &lt;/h3&gt;
  &lt;h6&gt;
   &lt;a href=&quot;https://www.mi.com/global/brand/ai/xiaomi-hyperai&quot; rel=&quot;&quot;&gt;
    mi.com
   &lt;/a&gt;
   &lt;span&gt;
    | 🤗
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/XiaomiMiMo&quot; rel=&quot;&quot;&gt;
    XiaomiMiMo
   &lt;/a&gt;
  &lt;/h6&gt;
  &lt;p&gt;
   &lt;span&gt;
    Xiaomi started releasing a bunch of small, capable models, ranging from
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/collections/XiaomiMiMo/mimo-6811688ee20ba7d0682f5cb9&quot; rel=&quot;&quot;&gt;
    LLMs
   &lt;/a&gt;
   &lt;span&gt;
    to
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/collections/XiaomiMiMo/mimo-vl-68382ccacc7c2875500cd212&quot; rel=&quot;&quot;&gt;
    VLMs
   &lt;/a&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/mispeech/midashenglm-7b&quot; rel=&quot;&quot;&gt;
    audio models
   &lt;/a&gt;
   &lt;span&gt;
    . Xiaomi updating the models quickly after an initial launch and releasing multiple variants of the models show that it is not a one-off foray into open models. However, it remains to be seen whether those are mostly research artifacts or whether they are serious about potentially pushing the frontier or competing for adoption.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   Baidu (ERNIE)
  &lt;/h3&gt;
  &lt;h6&gt;
   &lt;a href=&quot;https://yiyan.baidu.com/&quot; rel=&quot;&quot;&gt;
    yiyan.baidu.com
   &lt;/a&gt;
   &lt;span&gt;
    | 🤗
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/baidu&quot; rel=&quot;&quot;&gt;
    baidu
   &lt;/a&gt;
   &lt;span&gt;
    | X
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/Baidu_Inc&quot; rel=&quot;&quot;&gt;
    @Baidu_Inc
   &lt;/a&gt;
  &lt;/h6&gt;
  &lt;p&gt;
   &lt;span&gt;
    Baidu, one of the original names in the Chinese AI space, has only released the weights of
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/collections/baidu/ernie-45-6861cd4c9be84540645f35c9&quot; rel=&quot;&quot;&gt;
    ERNIE 4.5
   &lt;/a&gt;
   &lt;span&gt;
    . It remains to be seen whether they continue to release weights of newer releases as well.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
  &lt;/div&gt;
  &lt;div&gt;
   &lt;hr/&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   Honorable Mentions
  &lt;/h2&gt;
  &lt;p&gt;
   &lt;em&gt;
    The rest of the labs that we are watching.
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   Multimodal Art Projection
  &lt;/h3&gt;
  &lt;h6&gt;
   &lt;a href=&quot;https://m-a-p.ai/&quot; rel=&quot;&quot;&gt;
    m-a-p.ai
   &lt;/a&gt;
   &lt;span&gt;
    | 🤗
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/m-a-p&quot; rel=&quot;&quot;&gt;
    m-a-p
   &lt;/a&gt;
  &lt;/h6&gt;
  &lt;p&gt;
   &lt;span&gt;
    An open research community, releasing all kinds of models (including a
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/m-a-p/neo_7b&quot; rel=&quot;&quot;&gt;
    truly open 7B language model
   &lt;/a&gt;
   &lt;span&gt;
    with data, etc.). Now, they’re mostly known for the music generation model
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/collections/m-a-p/yue-6797d55e22990ae89b90a3d6&quot; rel=&quot;&quot;&gt;
    YuE
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   Alibaba International Digital Commerce Group
  &lt;/h3&gt;
  &lt;h6&gt;
   &lt;a href=&quot;https://aidc-ai.com/&quot; rel=&quot;&quot;&gt;
    aidc-ai.com
   &lt;/a&gt;
   &lt;span&gt;
    | 🤗
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/AIDC-AI&quot; rel=&quot;&quot;&gt;
    AIDC-AI
   &lt;/a&gt;
  &lt;/h6&gt;
  &lt;p&gt;
   Another R&amp;D arm of Alibaba, mostly releasing niche models building upon Qwen.
  &lt;/p&gt;
  &lt;h3&gt;
   Beijing Academy of Artificial Intelligence (BAAI)
  &lt;/h3&gt;
  &lt;h6&gt;
   &lt;a href=&quot;https://www.baai.ac.cn/en/&quot; rel=&quot;&quot;&gt;
    baai.ac.cn
   &lt;/a&gt;
   &lt;span&gt;
    | 🤗
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/BAAI&quot; rel=&quot;&quot;&gt;
    BAAI
   &lt;/a&gt;
   &lt;span&gt;
    | X
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/BAAIBeijing&quot; rel=&quot;&quot;&gt;
    @BAAIBeijing
   &lt;/a&gt;
  &lt;/h6&gt;
  &lt;p&gt;
   &lt;span&gt;
    As a university, the Beijing Academy of Artificial Intelligence has a high diversity of projects. They are mostly known for
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/collections/BAAI/bge-66797a74476eb1f085c7446d&quot; rel=&quot;&quot;&gt;
    BGE
   &lt;/a&gt;
   &lt;span&gt;
    , which are capable embedding models.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   inclusionAI
  &lt;/h3&gt;
  &lt;h6&gt;
   &lt;span&gt;
    🤗
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/inclusionAI&quot; rel=&quot;&quot;&gt;
    inclusionAI
   &lt;/a&gt;
   &lt;span&gt;
    | X
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/InclusionAI666&quot; rel=&quot;&quot;&gt;
    @InclusionAI666
   &lt;/a&gt;
  &lt;/h6&gt;
  &lt;p&gt;
   &lt;span&gt;
    The open weight arm from the Ant Group (an affiliate of Alibaba handling mobile payments and some financial industries), responsible for
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/collections/inclusionAI/ling-67c51c85b34a7ea0aba94c32&quot; rel=&quot;&quot;&gt;
    Ling Lite
   &lt;/a&gt;
   &lt;span&gt;
    , a series of LLMs.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   Pangu (Huawei)
  &lt;/h3&gt;
  &lt;h6&gt;
   &lt;a href=&quot;https://www.huaweicloud.com/&quot; rel=&quot;&quot;&gt;
    huaweicloud.com
   &lt;/a&gt;
   &lt;span&gt;
    | X
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/HuaweiCloud1&quot; rel=&quot;&quot;&gt;
    @HuaweiCloud1
   &lt;/a&gt;
  &lt;/h6&gt;
  &lt;p&gt;
   &lt;span&gt;
    Huawei is working on AI accelerators to threaten the market share of Nvidia GPUs, which are often targeted by regulations, both from the US and China. Their model releases are mostly to show what’s possible with their cards, but not
   &lt;/span&gt;
   &lt;a href=&quot;https://github.com/HW-whistleblower/True-Story-of-Pangu&quot; rel=&quot;&quot;&gt;
    without drama
   &lt;/a&gt;
   &lt;span&gt;
    accusing them of upcycling Qwen models and not stating it. We would expect them to continue to release more models in the near future.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/chinas-top-19-open-model-labs#footnote-anchor-1-171165224&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     Hybrid attention refers to models like Striped Hyena, which use some non-attention blocks to make long-context inference scale better.
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Contra Dwarkesh on Continual Learning </title>
<link>https://www.interconnects.ai/p/contra-dwarkesh-on-continual-learning</link>
<pubDate>Fri, 15 Aug 2025 13:40:06 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;a data-attrs=&#x27;{&quot;name&quot;:&quot;Dwarkesh Patel&quot;,&quot;id&quot;:4281466,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb715ffd1-f7d7-4755-af88-c48efe647f5b_400x400.jpeg&quot;,&quot;uuid&quot;:&quot;0444e292-9321-48be-91a7-5012613be0d8&quot;}&#x27; data-component-name=&quot;MentionUser&quot; href=&quot;https://open.substack.com/users/4281466-dwarkesh-patel?utm_source=mentions&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;
    Dwarkesh Patel
   &lt;/a&gt;
  &lt;/div&gt;
  &lt;span&gt;
   ’s now well-read
  &lt;/span&gt;
  &lt;a href=&quot;https://www.dwarkesh.com/p/timelines-june-2025&quot; rel=&quot;&quot;&gt;
   post
  &lt;/a&gt;
  &lt;span&gt;
   on why he is extending his AI timelines focuses on the idea of continual learning. If you ask me,
  &lt;/span&gt;
  &lt;a href=&quot;https://www.interconnects.ai/p/agi-is-what-you-want-it-to-be&quot; rel=&quot;&quot;&gt;
   what we have already is AGI
  &lt;/a&gt;
  &lt;span&gt;
   , so the core question is: Is continual learning a bottleneck on AI progress?
  &lt;/span&gt;
  &lt;p&gt;
   In this post, I argue that continual learning as he describes it actually doesn’t matter for the trajectory of AI progress that we are on. Continual learning will eventually be solved, but in the sort of way that a new type of AI will emerge from it, rather than continuing to refine what it means to host ever more powerful LLM-based systems.
  &lt;/p&gt;
  &lt;p&gt;
   Continual learning is the ultimate algorithmic nerd snipe for AI researchers, when in reality all we need to do is keep scaling systems and we’ll get something indistinguishable from how humans do it, for free.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/contra-dwarkesh-on-continual-learning?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/contra-dwarkesh-on-continual-learning?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   To start, here’s the core of the Dwarkesh piece as a refresher for what he means by continual learning.
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    Sometimes people say that even if all AI progress totally stopped, the systems of today would still be far more economically transformative than the internet. I disagree. I think the LLMs of today are magical. But the reason that the Fortune 500 aren’t using them to transform their workflows isn’t because the management is too stodgy. Rather, I think it’s genuinely hard to get normal humanlike labor out of LLMs. And this has to do with some fundamental capabilities these models lack.
   &lt;/p&gt;
   &lt;p&gt;
    I like to think I’m “AI forward” here at the Dwarkesh Podcast. I’ve probably spent over a hundred hours trying to build little LLM tools for my post production setup. And the experience of trying to get them to be useful has extended my timelines. I’ll try to get the LLMs to rewrite autogenerated transcripts for readability the way a human would. Or I’ll try to get them to identify clips from the transcript to tweet out. Sometimes I’ll try to get them to co-write an essay with me, passage by passage. These are simple, self contained, short horizon, language in-language out tasks - the kinds of assignments that should be dead center in the LLMs’ repertoire. And they&#x27;re 5/10 at them. Don’t get me wrong, that’s impressive.
   &lt;/p&gt;
   &lt;p&gt;
    But the fundamental problem is that LLMs don’t get better over time the way a human would. The lack of continual learning is a huge huge problem. The LLM baseline at many tasks might be higher than an average human&#x27;s. But there’s no way to give a model high level feedback. You’re stuck with the abilities you get out of the box. You can keep messing around with the system prompt. In practice this just doesn’t produce anything even close to the kind of learning and improvement that human employees experience.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   The core issue I have with this argument is the dream of making the LLMs we’re building today look more like humans. In many ways I’m surprised that Dwarkesh and other very AGI-focused AI researchers or commentators believe this — it’s the same root argument that AI critics use when they say AI models don’t reason. The goal to make AI more human is constraining the technological progress to a potentially impossible degree.
  &lt;/p&gt;
  &lt;p&gt;
   Human intelligence has long been the inspiration for AI, but we have long surpassed it being the mirror we look to for inspiration. Now the industry is all in on the expensive path to make the best language models it possibly can. We’re no longer trying to build the bird, we’re trying to transition the Wright Brothers’ invention into the 737 in the shortest time frame possible.
  &lt;/p&gt;
  &lt;p&gt;
   To put it succinctly. My argument very much rhymes with some of my past writing.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Do language models reason like humans? No.
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    Do language models reason? Yes.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Will language model systems continually learn like humans? No.
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    Will language model systems continually learn? Of course.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
   Dwarkesh writes “Rather, I think it’s genuinely hard to get normal humanlike labor out of LLMs.” This is because we’re still early on the buildout of the technology. Human labor takes an immense amount of context and quick thinking, both of which we’re starting to unlock with our language models. On top of this, human labor may not be what we want to create — we want to augment it.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Using LLMs as drop in replacements for humans is not a requirement for AGI nor is what Dwarkesh describes a fundamental limitation on AI progress. Francois Chollet cleverly poked at this weakness in his recent
   &lt;/span&gt;
   &lt;a href=&quot;https://youtu.be/1if6XbzD5Yg&quot; rel=&quot;&quot;&gt;
    conversation
   &lt;/a&gt;
   &lt;span&gt;
    with Dwarkesh at an ARC-AGI event:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    Well, how do you define the difference between the ability to adapt to a new task and learning on the fly? It&#x27;s, it sounds like the same thing to me.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   &lt;span&gt;
    Language models can already pick up subtle context extremely fast. ChatGPT’s memory feature has gotten far better for me. When we’re using the far more powerful models we can expect in the next 18 months this’ll already start to appear magical. Language models are extremely apt at
   &lt;/span&gt;
   &lt;em&gt;
    inferring
   &lt;/em&gt;
   &lt;span&gt;
    context even without us giving it to them. Soon we’ll be unlocking that subtle connection engine by providing immense, explicit context.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    I don’t know of anyone who has actually thoroughly digitized all the relevant context of their job and formatted it in a way that is easily readable by an LLM. GPT-5 Pro
   &lt;/span&gt;
   &lt;a href=&quot;https://chatgpt.com/share/689e683a-e28c-8005-b85d-5ae07fe0830b&quot; rel=&quot;&quot;&gt;
    estimates
   &lt;/a&gt;
   &lt;span&gt;
    that all of the writing on Interconnects would be only 500K tokens. That would fit into an
   &lt;/span&gt;
   &lt;em&gt;
    existing
   &lt;/em&gt;
   &lt;span&gt;
    LLM with no extra system, but I’ve never tried it.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The problem that Dwarkesh is facing is that we’re still using LLMs primarily in a single generation manner, which got far better with the introduction of reasoning models, but the economically useful way to use current tools in more complex intellectual domains will require a deep-research style approach over all of your recent work interactions. No one is giving language models that kind of context. None of the tools we use are set up properly to
   &lt;/span&gt;
   &lt;em&gt;
    accumulate
   &lt;/em&gt;
   &lt;span&gt;
    this type of context.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    I expect this to change rapidly. ChatGPT, Claude, and the likes are all
   &lt;/span&gt;
   &lt;a href=&quot;https://www.theverge.com/news/757743/anthropic-claude-ai-search-past-chats&quot; rel=&quot;&quot;&gt;
    adding memory features
   &lt;/a&gt;
   &lt;span&gt;
    across chats and countless connectors to other pieces of information in your professional life. These memory features will be omnimodal and essential to extracting the type of value Dwarkesh wants. Without them, I agree language models in their current form are hopeless at solving continual learning.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   This is what I would expect the rumored $2000/month ChatGPT level subscriptions to work with. Each of these bespoke tasks needs to absorb a ton of context and reasoning tokens in order to make a directionally right output. If someone built the Claude Code equivalent for my Substack, with every post tagged by topic and performance metrics, I bet the AI could easily make useful suggestions on how to format my content.
  &lt;/p&gt;
  &lt;p&gt;
   Continual learning in how Dwarkesh presents it is a systems problem rather than a learning problem. I expect better context management over my information ecosystem to exist in 2026, but more work to be needed for the AI companies to know how best to reference it and unlock in-context learning that feels like rapid adaptation. Call that 2027.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The models that have been released in 2025 will make this far more tractable in the near future. Reasoning models have made in-context learning far more powerful, resulting in rapid progress on held-out and complex domains such as
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/fchollet/status/1953511631054680085&quot; rel=&quot;&quot;&gt;
    ARC-AGI
   &lt;/a&gt;
   &lt;span&gt;
    . These models also have come with massive improvements in context length. Claude and Gemini have 1M+ token context lengths and GPT-5’s is at 400K — they’re all growing steadily. What is important with the context length numbers is that evaluations are showing that these are meaningful improvements that the models can leverage intelligently.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   With these reasoning models and smart retrieval of context, the systems we are building will look indistinguishable from continual learning. This will definitely be multiple LLMs working together and will operate very differently than the first versions of ChatGPT we were given (and often still use today).
  &lt;/p&gt;
  &lt;p&gt;
   The path to continual learning is more context and more horsepower. This is directly in line with the direction AI investment is going. This doesn’t feel like a bottleneck, rather another product problem that we are going to solve. This sort of continual learning may not enable the type of raw intelligence and autonomy that many vocal leaders in AI describe as “superintelligence.”
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Training models to be
   &lt;/span&gt;
   &lt;em&gt;
    smarter
   &lt;/em&gt;
   &lt;span&gt;
    on even more complex tasks — e.g. novel biological research — requires mastering agentic behaviors that need to be learned from scratch, as discussed in my post on “
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/what-comes-next-with-reinforcement&quot; rel=&quot;&quot;&gt;
    What comes next with RL
   &lt;/a&gt;
   &lt;span&gt;
    ”. There’s no internet scale pretraining data for such agentic tasks. My point is that not all jobs that require continual learning will require the frontiers of intelligence. I’m excited to write blog posts with the bliss of my ChatGPT 6 co-editor.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    This technology coming soon will not be without its challenges. My first reaction to the continual learning post was more in line with “society isn’t ready for this” rather than commentary on its feasibility. I’ll repeat
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/i/164894857/is-continual-learning-something-we-should-want&quot; rel=&quot;&quot;&gt;
    my warning
   &lt;/a&gt;
   &lt;span&gt;
    :
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    &lt;span&gt;
     For a long time I’ve written that AI models have a higher risk potential in terms of social outcomes because the modalities they interact with us in are far more personal… As AI is going to be so powerful as a standalone entity, breaking some of the symbiotic links will be good for adding friction that makes the technology easier to steer towards good outcomes. In short, be wary of wishing for end-to-end (reinforcement) learning when you’re part of the environment.
    &lt;/span&gt;
    &lt;a href=&quot;https://www.interconnects.ai/p/what-comes-next-with-reinforcement#footnote-2-164894857&quot; rel=&quot;&quot;&gt;
     &lt;sup&gt;
      2
     &lt;/sup&gt;
    &lt;/a&gt;
    &lt;span&gt;
     It’s a destiny to dystopia.
    &lt;/span&gt;
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   What we have today is a form of AGI and it’ll soon get much better with better context and memory. The industrialization of language models is giving us incredible improvements across a wide swath of use-cases. These will blow past many basic primitives of intelligence in humans that have motivated AI for decades. First was models reasoning, then will come systems with continual learning. This is exactly what most AI companies are actually building — regardless of what their superintelligence messaging is.
  &lt;/p&gt;
  &lt;h5&gt;
   Comments are open on this post, please continue the debate!
  &lt;/h5&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Latest open artifacts (#13): The abundance era of open models </title>
<link>https://www.interconnects.ai/p/latest-open-artifacts-13-the-abundance</link>
<pubDate>Mon, 11 Aug 2025 17:02:30 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    There has been a major shift in the open-weight AI ecosystem over the last 12 months from a research area and emerging industry into a functioning marketplace for ideas and adoption. If you look back to a similar
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/artifacts-log-3-synthetic-and-math&quot; rel=&quot;&quot;&gt;
    collection of open models from a year ago
   &lt;/a&gt;
   &lt;span&gt;
    the variance in artifact quality was extremely high and the total count of meaningful releases was far lower. There were some crucial models, i.e. the Qwens and Llamas of the world, but if one lab delayed their model or didn’t release anything, we didn’t really have much to cover.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Today, when reviewing the ecosystem with the team, we see incredible quality — and even hidden gems — across the board. Releasing certain models openly has shifted from a recruiting and marketing edge to a full-on industry standard. Many people outside of Silicon Valley will just always start with an open model for their domain due to trust, low cost of entry, and many other reasons linking back to open-source software. As of writing this, the only leading AI lab to not make a meaningful open weight release (or signal they should take it seriously, e.g. xAI) is now Anthropic.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    As the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/summertime-outlook-o3s-novelty-coming&quot; rel=&quot;&quot;&gt;
    average model size of daily drivers across the industry plateaus
   &lt;/a&gt;
   &lt;span&gt;
    , there’s even less risk of closed models “running away with it” in terms of performance relative to their open counterparts. The differentiating factor in this regime is shaping inference into new products, which can be better offloaded to the long-tail open community than skyrocketing training costs. We saw early signs of this with Qwen Coder and expect more to come.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   While many of us in the AI space focus on text-only models, as they’re positioned to be the next true platform for the broad buildout of AI, the small corners of multimodal generation models and specialized information processors represent many of the strengths of the ecosystem. This series covers it all.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/latest-open-artifacts-13-the-abundance?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-artifacts-13-the-abundance?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;h1&gt;
   &lt;strong&gt;
    Artifacts Log
   &lt;/strong&gt;
  &lt;/h1&gt;
  &lt;h3&gt;
   &lt;strong&gt;
    Our Picks
   &lt;/strong&gt;
  &lt;/h3&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct&quot; rel=&quot;&quot;&gt;
       Qwen3-Coder-480B-A35B-Instruct
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/Qwen&quot; rel=&quot;&quot;&gt;
      Qwen
     &lt;/a&gt;
     &lt;span&gt;
      : Besides all the Qwen models from the last episode, Qwen just can&#x27;t stop releasing new models. Qwen3 Coder comes in two different sizes — the larger of which is actually competitive with Sonnet in various tests. The model is so popular that inference providers offer
     &lt;/span&gt;
     &lt;a href=&quot;https://www.cerebras.ai/blog/introducing-cerebras-code&quot; rel=&quot;&quot;&gt;
      subscriptions
     &lt;/a&gt;
     &lt;span&gt;
      to use it akin to Claude Max to gain market share.
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      As we mentioned last time, Qwen is becoming increasingly professionalized and playing the Google playbook, offering 1,000-2,000 free requests per day (depending on location) for their
     &lt;/span&gt;
     &lt;a href=&quot;https://github.com/QwenLM/qwen-code?tab=readme-ov-file#-regional-free-tiers&quot; rel=&quot;&quot;&gt;
      Gemini CLI fork
     &lt;/a&gt;
     &lt;span&gt;
      . Qwen thus takes coding very seriously and is certainly a credible alternative to all those closed-source models.
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!iWq8!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1e8bc3f-98f6-406a-80db-d371b94c6309_3184x1817.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!iWq8!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1e8bc3f-98f6-406a-80db-d371b94c6309_3184x1817.jpeg 424w, https://substackcdn.com/image/fetch/$s_!iWq8!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1e8bc3f-98f6-406a-80db-d371b94c6309_3184x1817.jpeg 848w, https://substackcdn.com/image/fetch/$s_!iWq8!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1e8bc3f-98f6-406a-80db-d371b94c6309_3184x1817.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!iWq8!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1e8bc3f-98f6-406a-80db-d371b94c6309_3184x1817.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b1e8bc3f-98f6-406a-80db-d371b94c6309_3184x1817.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:831,&quot;width&quot;:1456,&quot;resizeWidth&quot;:680,&quot;bytes&quot;:653774,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/170685919?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1e8bc3f-98f6-406a-80db-d371b94c6309_3184x1817.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;388.1043956043956&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!iWq8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1e8bc3f-98f6-406a-80db-d371b94c6309_3184x1817.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!iWq8!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1e8bc3f-98f6-406a-80db-d371b94c6309_3184x1817.jpeg 424w, https://substackcdn.com/image/fetch/$s_!iWq8!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1e8bc3f-98f6-406a-80db-d371b94c6309_3184x1817.jpeg 848w, https://substackcdn.com/image/fetch/$s_!iWq8!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1e8bc3f-98f6-406a-80db-d371b94c6309_3184x1817.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!iWq8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1e8bc3f-98f6-406a-80db-d371b94c6309_3184x1817.jpeg 1456w&quot; width=&quot;680&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/rednote-hilab/dots.ocr&quot; rel=&quot;&quot;&gt;
       dots.ocr
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/rednote-hilab&quot; rel=&quot;&quot;&gt;
      rednote-hilab
     &lt;/a&gt;
     &lt;span&gt;
      : RedNote (the Chinese version of Instagram) continues to release open models. RedNote is a somewhat surprising participant in the AI space, but goes to show how pervasive open model releases are in China. This Optical Character Recognition (OCR) model, building on top of Qwen3 1.7B, is not only relatively small (compared to other models in the 7-8B range), but it is also really good! There are multiple people independently reporting about its performance and being impressed by it. Also, check out
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/wjb_mattingly/status/1953263017296056365&quot; rel=&quot;&quot;&gt;
      this Twitter thread
     &lt;/a&gt;
     &lt;span&gt;
      by William about his experience with fine-tuning the model.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!atQZ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342daa1e-965a-41b2-bf6d-5f7a2ff1e440_1062x716.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!atQZ!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342daa1e-965a-41b2-bf6d-5f7a2ff1e440_1062x716.png 424w, https://substackcdn.com/image/fetch/$s_!atQZ!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342daa1e-965a-41b2-bf6d-5f7a2ff1e440_1062x716.png 848w, https://substackcdn.com/image/fetch/$s_!atQZ!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342daa1e-965a-41b2-bf6d-5f7a2ff1e440_1062x716.png 1272w, https://substackcdn.com/image/fetch/$s_!atQZ!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342daa1e-965a-41b2-bf6d-5f7a2ff1e440_1062x716.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/342daa1e-965a-41b2-bf6d-5f7a2ff1e440_1062x716.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:716,&quot;width&quot;:1062,&quot;resizeWidth&quot;:668,&quot;bytes&quot;:486155,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/170685919?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342daa1e-965a-41b2-bf6d-5f7a2ff1e440_1062x716.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;450.3653483992467&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!atQZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342daa1e-965a-41b2-bf6d-5f7a2ff1e440_1062x716.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!atQZ!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342daa1e-965a-41b2-bf6d-5f7a2ff1e440_1062x716.png 424w, https://substackcdn.com/image/fetch/$s_!atQZ!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342daa1e-965a-41b2-bf6d-5f7a2ff1e440_1062x716.png 848w, https://substackcdn.com/image/fetch/$s_!atQZ!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342daa1e-965a-41b2-bf6d-5f7a2ff1e440_1062x716.png 1272w, https://substackcdn.com/image/fetch/$s_!atQZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342daa1e-965a-41b2-bf6d-5f7a2ff1e440_1062x716.png 1456w&quot; width=&quot;668&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507&quot; rel=&quot;&quot;&gt;
       Qwen3-4B-Instruct-2507
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/Qwen&quot; rel=&quot;&quot;&gt;
      Qwen
     &lt;/a&gt;
     &lt;span&gt;
      : In the last episode, we highlighted the new instruct version of their large MoEs, as Qwen moves away from hybrid reasoning models. This cycle we want to highlight the new 4B versions (
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507&quot; rel=&quot;&quot;&gt;
      Instruct-2507
     &lt;/a&gt;
     &lt;span&gt;
      ,
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507&quot; rel=&quot;&quot;&gt;
      Thinking-2507
     &lt;/a&gt;
     &lt;span&gt;
      ). While everyone keeps training and releasing MoE models for very good reasons, dense models are the backbone for academic research and the local community. Qwen3 4B, especially in the instruct-only version, is a great model and I (Florian) have started using it locally for simple tasks (like translation), as the model is really capable and the overall latency is faster than sending requests to the cloud.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/zai-org/GLM-4.5-V&quot; rel=&quot;&quot;&gt;
       GLM-4.5V
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/zai-org&quot; rel=&quot;&quot;&gt;
      zai-org
     &lt;/a&gt;
     &lt;span&gt;
      : While Zhipu/Z.ai isn&#x27;t exactly a newcomer to avid readers of Interconnects, the new GLM-4.5 model finally puts them into the well-deserved spotlight. Aside from LLMs, they also release a vision model, which, like many models, is a MoE-based model. The benchmark results are really impressive and are worth checking out.
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!8YHI!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1b3321-5142-496a-9bea-589089f3f6d5_6485x6353.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!8YHI!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1b3321-5142-496a-9bea-589089f3f6d5_6485x6353.png 424w, https://substackcdn.com/image/fetch/$s_!8YHI!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1b3321-5142-496a-9bea-589089f3f6d5_6485x6353.png 848w, https://substackcdn.com/image/fetch/$s_!8YHI!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1b3321-5142-496a-9bea-589089f3f6d5_6485x6353.png 1272w, https://substackcdn.com/image/fetch/$s_!8YHI!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1b3321-5142-496a-9bea-589089f3f6d5_6485x6353.png 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1f1b3321-5142-496a-9bea-589089f3f6d5_6485x6353.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1426,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:3924444,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/170685919?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1b3321-5142-496a-9bea-589089f3f6d5_6485x6353.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;1426&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!8YHI!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1b3321-5142-496a-9bea-589089f3f6d5_6485x6353.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!8YHI!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1b3321-5142-496a-9bea-589089f3f6d5_6485x6353.png 424w, https://substackcdn.com/image/fetch/$s_!8YHI!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1b3321-5142-496a-9bea-589089f3f6d5_6485x6353.png 848w, https://substackcdn.com/image/fetch/$s_!8YHI!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1b3321-5142-496a-9bea-589089f3f6d5_6485x6353.png 1272w, https://substackcdn.com/image/fetch/$s_!8YHI!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1b3321-5142-496a-9bea-589089f3f6d5_6485x6353.png 1456w&quot; width=&quot;1456&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/Qwen/Qwen-Image&quot; rel=&quot;&quot;&gt;
       Qwen-Image
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/Qwen&quot; rel=&quot;&quot;&gt;
      Qwen
     &lt;/a&gt;
     &lt;span&gt;
      : Yes, we know! Yet
     &lt;/span&gt;
     &lt;em&gt;
      another
     &lt;/em&gt;
     &lt;span&gt;
      Qwen model featured prominently in this series. But they are impossible to ignore, release model after model with (OSI-approved) licenses, and the models are good! For image generation,
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/black-forest-labs/FLUX.1-dev&quot; rel=&quot;&quot;&gt;
      FLUX.1 dev
     &lt;/a&gt;
     &lt;span&gt;
      racks up millions of downloads despite its non-commercial license. Qwen-Image uses Apache 2.0 and the outputs are really good. However, it is quite a chonky model, clocking in at 20B params (Flux.1 dev uses 13B params), which might hinder local adoption. However, there are first
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/lightx2v/Qwen-Image-Lightning&quot; rel=&quot;&quot;&gt;
      attempts
     &lt;/a&gt;
     &lt;span&gt;
      at distillation to run it quicker.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!cEY8!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9d02f0f8-1773-49f5-a05f-ca0db2e6f660_1024x768.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!cEY8!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9d02f0f8-1773-49f5-a05f-ca0db2e6f660_1024x768.png 424w, https://substackcdn.com/image/fetch/$s_!cEY8!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9d02f0f8-1773-49f5-a05f-ca0db2e6f660_1024x768.png 848w, https://substackcdn.com/image/fetch/$s_!cEY8!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9d02f0f8-1773-49f5-a05f-ca0db2e6f660_1024x768.png 1272w, https://substackcdn.com/image/fetch/$s_!cEY8!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9d02f0f8-1773-49f5-a05f-ca0db2e6f660_1024x768.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9d02f0f8-1773-49f5-a05f-ca0db2e6f660_1024x768.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:768,&quot;width&quot;:1024,&quot;resizeWidth&quot;:632,&quot;bytes&quot;:849587,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/170685919?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9d02f0f8-1773-49f5-a05f-ca0db2e6f660_1024x768.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;474&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!cEY8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9d02f0f8-1773-49f5-a05f-ca0db2e6f660_1024x768.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!cEY8!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9d02f0f8-1773-49f5-a05f-ca0db2e6f660_1024x768.png 424w, https://substackcdn.com/image/fetch/$s_!cEY8!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9d02f0f8-1773-49f5-a05f-ca0db2e6f660_1024x768.png 848w, https://substackcdn.com/image/fetch/$s_!cEY8!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9d02f0f8-1773-49f5-a05f-ca0db2e6f660_1024x768.png 1272w, https://substackcdn.com/image/fetch/$s_!cEY8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9d02f0f8-1773-49f5-a05f-ca0db2e6f660_1024x768.png 1456w&quot; width=&quot;632&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;h3&gt;
   &lt;strong&gt;
    Language Models
   &lt;/strong&gt;
  &lt;/h3&gt;
  &lt;h4&gt;
   &lt;strong&gt;
    Flagship
   &lt;/strong&gt;
  &lt;/h4&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507&quot; rel=&quot;&quot;&gt;
       Qwen3-235B-A22B-Thinking-2507
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/Qwen&quot; rel=&quot;&quot;&gt;
      Qwen
     &lt;/a&gt;
     &lt;span&gt;
      : Qwen also released the reasoning-only version of the large MoE. With a simple config change, these models
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/Alibaba_Qwen/status/1953760230141309354&quot; rel=&quot;&quot;&gt;
      support up to 1M context
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/inclusionAI/Ling-lite-1.5-2506&quot; rel=&quot;&quot;&gt;
       Ling-lite-1.5-2506
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/inclusionAI&quot; rel=&quot;&quot;&gt;
      inclusionAI
     &lt;/a&gt;
     &lt;span&gt;
      : A small-ish MoE model with 17B total, 2.8B active parameters, released under the MIT license.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/nvidia/Llama-3_3-Nemotron-Super-49B-v1_5&quot; rel=&quot;&quot;&gt;
       Llama-3_3-Nemotron-Super-49B-v1_5
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/nvidia&quot; rel=&quot;&quot;&gt;
      nvidia
     &lt;/a&gt;
     &lt;span&gt;
      : Nvidia is not just one of the few companies that still use Llama as a base model, it is also one of the few American model providers with a cadence and quality that matches Chinese companies, as this release proves yet again. Interestingly, it is way less censored than its predecessor as evaluated by
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/xlr8harder/status/1954205757777347014&quot; rel=&quot;&quot;&gt;
      SpeechMap
     &lt;/a&gt;
     &lt;span&gt;
      :
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!NOaJ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5126fdab-d3e7-4339-9526-285efe19703d_1227x796.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!NOaJ!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5126fdab-d3e7-4339-9526-285efe19703d_1227x796.jpeg 424w, https://substackcdn.com/image/fetch/$s_!NOaJ!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5126fdab-d3e7-4339-9526-285efe19703d_1227x796.jpeg 848w, https://substackcdn.com/image/fetch/$s_!NOaJ!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5126fdab-d3e7-4339-9526-285efe19703d_1227x796.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!NOaJ!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5126fdab-d3e7-4339-9526-285efe19703d_1227x796.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;Image&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5126fdab-d3e7-4339-9526-285efe19703d_1227x796.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:796,&quot;width&quot;:1227,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;796&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!NOaJ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5126fdab-d3e7-4339-9526-285efe19703d_1227x796.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!NOaJ!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5126fdab-d3e7-4339-9526-285efe19703d_1227x796.jpeg 424w, https://substackcdn.com/image/fetch/$s_!NOaJ!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5126fdab-d3e7-4339-9526-285efe19703d_1227x796.jpeg 848w, https://substackcdn.com/image/fetch/$s_!NOaJ!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5126fdab-d3e7-4339-9526-285efe19703d_1227x796.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!NOaJ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5126fdab-d3e7-4339-9526-285efe19703d_1227x796.jpeg 1456w&quot; title=&quot;Image&quot; width=&quot;1227&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/zai-org/GLM-4.5&quot; rel=&quot;&quot;&gt;
       GLM-4.5
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/zai-org&quot; rel=&quot;&quot;&gt;
      zai-org
     &lt;/a&gt;
     &lt;span&gt;
      : The new LLM series by Zhipu/Z.ai comes in two sizes: 355B-A32 and 106B-A12. Furthermore, they also release the base models (which is rare these days!) and a detailed
     &lt;/span&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2508.06471&quot; rel=&quot;&quot;&gt;
      paper
     &lt;/a&gt;
     &lt;span&gt;
      with some very nice RL experiments. Like their previous models, it is released under the MIT license.
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!TSG9!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa78f2130-8a09-44dd-ad52-e27df6bc8da1_1852x900.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!TSG9!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa78f2130-8a09-44dd-ad52-e27df6bc8da1_1852x900.png 424w, https://substackcdn.com/image/fetch/$s_!TSG9!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa78f2130-8a09-44dd-ad52-e27df6bc8da1_1852x900.png 848w, https://substackcdn.com/image/fetch/$s_!TSG9!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa78f2130-8a09-44dd-ad52-e27df6bc8da1_1852x900.png 1272w, https://substackcdn.com/image/fetch/$s_!TSG9!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa78f2130-8a09-44dd-ad52-e27df6bc8da1_1852x900.png 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a78f2130-8a09-44dd-ad52-e27df6bc8da1_1852x900.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:708,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:234774,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/170685919?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa78f2130-8a09-44dd-ad52-e27df6bc8da1_1852x900.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;708&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!TSG9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa78f2130-8a09-44dd-ad52-e27df6bc8da1_1852x900.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!TSG9!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa78f2130-8a09-44dd-ad52-e27df6bc8da1_1852x900.png 424w, https://substackcdn.com/image/fetch/$s_!TSG9!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa78f2130-8a09-44dd-ad52-e27df6bc8da1_1852x900.png 848w, https://substackcdn.com/image/fetch/$s_!TSG9!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa78f2130-8a09-44dd-ad52-e27df6bc8da1_1852x900.png 1272w, https://substackcdn.com/image/fetch/$s_!TSG9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa78f2130-8a09-44dd-ad52-e27df6bc8da1_1852x900.png 1456w&quot; width=&quot;1456&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-30B-A3B-Instruct-2507&quot; rel=&quot;&quot;&gt;
       Qwen3-30B-A3B-Instruct-2507
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/Qwen&quot; rel=&quot;&quot;&gt;
      Qwen
     &lt;/a&gt;
     &lt;span&gt;
      : The small MoE model also gets the same treatment as the large model: A split into a
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct&quot; rel=&quot;&quot;&gt;
      reasoning
     &lt;/a&gt;
     &lt;span&gt;
      and non-reasoning version, 1M context and a performance boost across the board.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/openai/gpt-oss-20b&quot; rel=&quot;&quot;&gt;
       gpt-oss-20b
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/openai&quot; rel=&quot;&quot;&gt;
      openai
     &lt;/a&gt;
     &lt;span&gt;
      : We wrote about the implications of the model
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/blog/gpt-oss-20b&quot; rel=&quot;&quot;&gt;
      in a separate post
     &lt;/a&gt;
     &lt;span&gt;
      . Aside from that, the model is different from other models and cannot be a drop-in replacement for Llama or Qwen in typical pipelines. It can be used as a substitute for o4-mini-like tasks when given appropriate tools —
     &lt;/span&gt;
     &lt;strong&gt;
      a reasoning engine with limited world knowledge
     &lt;/strong&gt;
     &lt;span&gt;
      . While the scores suggest a strong multilingual model, it fell short in our usage, with others on social media reporting similar experiences.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h4&gt;
   &lt;strong&gt;
    General Purpose
   &lt;/strong&gt;
  &lt;/h4&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> What I&#x27;ve been reading (#2): More on Kimi K2, how to build a bad research center, Pretraining with RL, and sporks of AGI </title>
<link>https://www.interconnects.ai/p/what-im-reading-2-more-on-kimi-k2</link>
<pubDate>Sun, 10 Aug 2025 13:19:48 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   Amid the chaos of my primary jobs in training language models and keeping up with the major releases, most of what I spend my time reading can fit into a few categories of understanding:
  &lt;/p&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     How AI companies operate,
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     How people use AI today, and
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     What is being solved at the cutting edge of AI tooling or training.
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;p&gt;
   And, of course, I’ll end this post with all the extra stuff that caught my eye.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/what-im-reading-2-more-on-kimi-k2?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/what-im-reading-2-more-on-kimi-k2?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   1. How AI companies operate
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;span&gt;
    Moonshot’s
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/kimi-k2-and-when-deepseek-moments&quot; rel=&quot;&quot;&gt;
    Kimi K2
   &lt;/a&gt;
   &lt;span&gt;
    model deserved more time in the limelight. It was the first strike in a rapid-fire summer of Chinese AI models. There are a few posts I recommend on the area that I wish I could’ve written myself.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The first is this post from ChinaTalk, where they built on a
   &lt;/span&gt;
   &lt;a href=&quot;https://www.chinatalk.media/p/moonshot-ais-agi-vision&quot; rel=&quot;&quot;&gt;
    translated interview
   &lt;/a&gt;
   &lt;span&gt;
    with the Moonshot CEO they posted in
   &lt;/span&gt;
   &lt;em&gt;
    March
   &lt;/em&gt;
   &lt;span&gt;
    , quite ahead of the wave.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div data-attrs=&#x27;{&quot;id&quot;:168585970,&quot;url&quot;:&quot;https://www.chinatalk.media/p/kimi-k2-the-open-source-way&quot;,&quot;publication_id&quot;:4220,&quot;publication_name&quot;:&quot;ChinaTalk&quot;,&quot;publication_logo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!6mVK!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9b5dde60-871d-48d4-9c21-e4f434b3f3c1_256x256.png&quot;,&quot;title&quot;:&quot;Kimi&quot;,&quot;truncated_body_text&quot;:&quot;An anon start-up conducting cutting-edge open-source research on China’s science, technology, and industrial ecosystems is looking for part-time China research analysts. You’ll be saving America with a firm run by someone I [Jordan] can vouch for being the literal best in the business.&quot;,&quot;date&quot;:&quot;2025-07-18T10:26:22.225Z&quot;,&quot;like_count&quot;:57,&quot;comment_count&quot;:3,&quot;bylines&quot;:[{&quot;id&quot;:12682021,&quot;name&quot;:&quot;Irene Zhang&quot;,&quot;handle&quot;:&quot;irenezhang&quot;,&quot;previous_name&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/af57f9bb-ce01-4a87-9ca9-13612d58e4d9_1168x930.png&quot;,&quot;bio&quot;:&quot;   &quot;,&quot;profile_set_up_at&quot;:&quot;2022-07-17T15:43:17.567Z&quot;,&quot;reader_installed_at&quot;:&quot;2022-07-19T00:59:11.253Z&quot;,&quot;publicationUsers&quot;:[{&quot;id&quot;:1128679,&quot;user_id&quot;:12682021,&quot;publication_id&quot;:1175441,&quot;role&quot;:&quot;admin&quot;,&quot;public&quot;:true,&quot;is_primary&quot;:true,&quot;publication&quot;:{&quot;id&quot;:1175441,&quot;name&quot;:&quot;Second Drafts&quot;,&quot;subdomain&quot;:&quot;irenezhang&quot;,&quot;custom_domain&quot;:null,&quot;custom_domain_optional&quot;:false,&quot;hero_text&quot;:&quot;no but actually, second drafts&quot;,&quot;logo_url&quot;:null,&quot;author_id&quot;:12682021,&quot;primary_user_id&quot;:12682021,&quot;theme_var_background_pop&quot;:&quot;#FF5CD7&quot;,&quot;created_at&quot;:&quot;2022-11-05T05:32:14.398Z&quot;,&quot;email_from_name&quot;:&quot;Irene from Second Drafts&quot;,&quot;copyright&quot;:&quot;Irene Zhang&quot;,&quot;founding_plan_name&quot;:null,&quot;community_enabled&quot;:true,&quot;invite_only&quot;:false,&quot;payments_state&quot;:&quot;disabled&quot;,&quot;language&quot;:null,&quot;explicit&quot;:false,&quot;homepage_type&quot;:&quot;newspaper&quot;,&quot;is_personal_mode&quot;:false}},{&quot;id&quot;:952652,&quot;user_id&quot;:12682021,&quot;publication_id&quot;:4220,&quot;role&quot;:&quot;contributor&quot;,&quot;public&quot;:true,&quot;is_primary&quot;:false,&quot;publication&quot;:{&quot;id&quot;:4220,&quot;name&quot;:&quot;ChinaTalk&quot;,&quot;subdomain&quot;:&quot;chinatalk&quot;,&quot;custom_domain&quot;:&quot;www.chinatalk.media&quot;,&quot;custom_domain_optional&quot;:false,&quot;hero_text&quot;:&quot;Deep coverage of technology, China, and US policy. We feature original analysis alongside interviews with leading thinkers and policymakers.&quot;,&quot;logo_url&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/9b5dde60-871d-48d4-9c21-e4f434b3f3c1_256x256.png&quot;,&quot;author_id&quot;:1145,&quot;primary_user_id&quot;:1145,&quot;theme_var_background_pop&quot;:&quot;#ff9900&quot;,&quot;created_at&quot;:&quot;2018-12-17T01:44:27.292Z&quot;,&quot;email_from_name&quot;:&quot;ChinaTalk&quot;,&quot;copyright&quot;:&quot;Jordan Schneider&quot;,&quot;founding_plan_name&quot;:&quot;Founding Member Plan&quot;,&quot;community_enabled&quot;:true,&quot;invite_only&quot;:false,&quot;payments_state&quot;:&quot;enabled&quot;,&quot;language&quot;:null,&quot;explicit&quot;:false,&quot;homepage_type&quot;:&quot;magaziney&quot;,&quot;is_personal_mode&quot;:false}}],&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:null}],&quot;utm_campaign&quot;:null,&quot;belowTheFold&quot;:false,&quot;type&quot;:&quot;newsletter&quot;,&quot;language&quot;:&quot;en&quot;}&#x27; data-component-name=&quot;EmbeddedPostToDOM&quot;&gt;
   &lt;a href=&quot;https://www.chinatalk.media/p/kimi-k2-the-open-source-way?utm_source=substack&amp;utm_campaign=post_embed&amp;utm_medium=web&quot; native=&quot;true&quot; rel=&quot;&quot;&gt;
    &lt;div&gt;
     &lt;img src=&quot;https://substackcdn.com/image/fetch/$s_!6mVK!,w_56,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9b5dde60-871d-48d4-9c21-e4f434b3f3c1_256x256.png&quot;/&gt;
     &lt;span&gt;
      ChinaTalk
     &lt;/span&gt;
    &lt;/div&gt;
    &lt;div&gt;
     &lt;div&gt;
      Kimi
     &lt;/div&gt;
    &lt;/div&gt;
    &lt;div&gt;
     An anon start-up conducting cutting-edge open-source research on China’s science, technology, and industrial ecosystems is looking for part-time China research analysts. You’ll be saving America with a firm run by someone I [Jordan] can vouch for being the literal best in the business…
    &lt;/div&gt;
    &lt;div&gt;
     &lt;span&gt;
      Read more
     &lt;/span&gt;
    &lt;/div&gt;
    &lt;div&gt;
     24 days ago · 57 likes · 3 comments · Irene Zhang
    &lt;/div&gt;
   &lt;/a&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    This post digs into Moonshot’s culture, features translated snippets of posts from Moonshot’s own researchers on “
   &lt;/span&gt;
   &lt;a href=&quot;https://bigeagle.me/2025/07/kimi-k2/&quot; rel=&quot;&quot;&gt;
    why they pursue the open model
   &lt;/a&gt;
   &lt;span&gt;
    ” or “
   &lt;/span&gt;
   &lt;a href=&quot;https://www.kimi.com/share/d1q8l75e09n7its6e7jg&quot; rel=&quot;&quot;&gt;
    why they chose their architecture
   &lt;/a&gt;
   &lt;span&gt;
    .” Something good to know is that Moonshot has a very different business model than DeepSeek (self-funded hedge fund) or Qwen (backed by cloud giant Alibaba), as a venture-backed company. ChinaTalk expands on this:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    Moonshot has no B2B offerings and does not build wrapper tools for corporate users, instead focusing directly on individual customers. From the beginning, Kimi’s selling point to Chinese users was its long context window, allowing users to upload dozens of documents and analyze long articles.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   &lt;span&gt;
    There’s
   &lt;/span&gt;
   &lt;em&gt;
    a lot
   &lt;/em&gt;
   &lt;span&gt;
    more great stuff coming out on the Chinese AI ecosystem that can be easy to miss. Some include this post from Kevin Xu on
   &lt;/span&gt;
   &lt;a href=&quot;https://interconnect.substack.com/p/chinas-structural-advantage-in-open?r=68gy5&amp;utm_medium=ios&amp;triedRedirect=true&quot; rel=&quot;&quot;&gt;
    why China is structurally set up to win open-source AI right now
   &lt;/a&gt;
   &lt;span&gt;
    (an outlet I rely on for much of my learnings in this space) or this in-depth
   &lt;/span&gt;
   &lt;a href=&quot;https://mp.weixin.qq.com/s/Xei9vXg8j5P9waVLoGUHNQ&quot; rel=&quot;&quot;&gt;
    WeChat post
   &lt;/a&gt;
   &lt;span&gt;
    on the current landscape of Chinese AI companies. I’m also finishing up reading
   &lt;/span&gt;
   &lt;a href=&quot;https://www.amazon.com/Apple-China-Capture-Greatest-Company/dp/1668053373&quot; rel=&quot;&quot;&gt;
    Apple in China
   &lt;/a&gt;
   &lt;span&gt;
    and it has been utterly fantastic for understanding how the tech ecosystem works in China.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Kevin’s post had a great anecdote from what the DeepSeek moment in January did
   &lt;/span&gt;
   &lt;em&gt;
    within China
   &lt;/em&gt;
   &lt;span&gt;
    , that made it clear most of us are just totally ignorant of the operations of Chinese AI companies:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    The only thing that the “DeepSeek moment” really messed with were the holiday plans of other Chinese AI labs, who were equally shocked by DeepSeek’s progress. One in particular, Alibaba’s AI team, apparently uttered a collective “holy sh*t”, called off everyone’s holiday travel plan, stayed at the office, and slept on the floor until a competitive model was shipped.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   It should be a given that they’re just as motivated as their American counterparts, but it makes me wonder — what are the key differences?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    In conversations with others about this question of “how to build a good AI research center” (or, how to build
   &lt;/span&gt;
   &lt;a href=&quot;https://www.atomproject.ai/&quot; rel=&quot;&quot;&gt;
    ATOM
   &lt;/a&gt;
   &lt;span&gt;
    ), I was pointed to a relevant old link, David Patterson on
   &lt;/span&gt;
   &lt;a href=&quot;https://www2.eecs.berkeley.edu/Pubs/TechRpts/2013/EECS-2013-123.pdf&quot; rel=&quot;&quot;&gt;
    How to Build a Bad Research Center
   &lt;/a&gt;
   &lt;span&gt;
    — a fun document that lists the common failure modes of ineffective research hubs.
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/what-im-reading-2-more-on-kimi-k2#footnote-1-170563070&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     1
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    For anyone in research and frustrated with their job, do give it a skim and you’re likely to validate yourself. You’re welcome.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    David Patterson has a lot of great stuff, such as his
   &lt;/span&gt;
   &lt;a href=&quot;https://cacm.acm.org/opinion/life-lessons-from-the-first-half-century-of-my-career/&quot; rel=&quot;&quot;&gt;
    general advice after 50 years of work
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!07vP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdcf9e75-0d26-4f7c-8bda-6f84f98ed363_1594x1494.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!07vP!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdcf9e75-0d26-4f7c-8bda-6f84f98ed363_1594x1494.png 424w, https://substackcdn.com/image/fetch/$s_!07vP!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdcf9e75-0d26-4f7c-8bda-6f84f98ed363_1594x1494.png 848w, https://substackcdn.com/image/fetch/$s_!07vP!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdcf9e75-0d26-4f7c-8bda-6f84f98ed363_1594x1494.png 1272w, https://substackcdn.com/image/fetch/$s_!07vP!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdcf9e75-0d26-4f7c-8bda-6f84f98ed363_1594x1494.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cdcf9e75-0d26-4f7c-8bda-6f84f98ed363_1594x1494.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1365,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:753966,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/170563070?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdcf9e75-0d26-4f7c-8bda-6f84f98ed363_1594x1494.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;1365&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!07vP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdcf9e75-0d26-4f7c-8bda-6f84f98ed363_1594x1494.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!07vP!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdcf9e75-0d26-4f7c-8bda-6f84f98ed363_1594x1494.png 424w, https://substackcdn.com/image/fetch/$s_!07vP!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdcf9e75-0d26-4f7c-8bda-6f84f98ed363_1594x1494.png 848w, https://substackcdn.com/image/fetch/$s_!07vP!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdcf9e75-0d26-4f7c-8bda-6f84f98ed363_1594x1494.png 1272w, https://substackcdn.com/image/fetch/$s_!07vP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdcf9e75-0d26-4f7c-8bda-6f84f98ed363_1594x1494.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;h3&gt;
   2. How people use AI today
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;span&gt;
    Coding is the most well-known, productive use case for today’s language models. The weird thing with that fact is that, due to how complex the act and practice of software development is, understanding exactly what it means to effectively code well with LLMs is not that well articulated. A few weeks ago, I came across this
   &lt;/span&gt;
   &lt;a href=&quot;https://antirez.com/news/154&quot; rel=&quot;&quot;&gt;
    post
   &lt;/a&gt;
   &lt;span&gt;
    which I felt nailed it exactly right.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The post highlights a few clear examples on the sort of things LLM-assisted coding can enhance, such as learning fast or detecting bugs, but the best part was the clear advice that we can take to others who ask us:
  &lt;/p&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     Use the right LLMs (which have been Gemini 2.5 Pro and Claude Opus 4 — I wonder if GPT-5 makes the author’s list),
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Provide large context — most people don’t give their tools enough information,
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Refuse vibe coding most of the time.
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;p&gt;
   I vibe code a lot, but only for projects I will never touch again after a day or week.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    This is all in contrast to the famous
   &lt;/span&gt;
   &lt;a href=&quot;https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/&quot; rel=&quot;&quot;&gt;
    METR study
   &lt;/a&gt;
   &lt;span&gt;
    that showed many people were less productive with AI-assisted coding. I didn’t comment on this because it mostly felt like it wasn’t measuring comprehensively enough. I vibe code because I can make slower progress, or extra progress, without taxing my brain.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!2vtx!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5b34277-a5a5-4a04-93c5-5646557eccf4_2562x1540.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!2vtx!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5b34277-a5a5-4a04-93c5-5646557eccf4_2562x1540.png 424w, https://substackcdn.com/image/fetch/$s_!2vtx!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5b34277-a5a5-4a04-93c5-5646557eccf4_2562x1540.png 848w, https://substackcdn.com/image/fetch/$s_!2vtx!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5b34277-a5a5-4a04-93c5-5646557eccf4_2562x1540.png 1272w, https://substackcdn.com/image/fetch/$s_!2vtx!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5b34277-a5a5-4a04-93c5-5646557eccf4_2562x1540.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b5b34277-a5a5-4a04-93c5-5646557eccf4_2562x1540.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:875,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:276280,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/170563070?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5b34277-a5a5-4a04-93c5-5646557eccf4_2562x1540.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;875&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!2vtx!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5b34277-a5a5-4a04-93c5-5646557eccf4_2562x1540.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!2vtx!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5b34277-a5a5-4a04-93c5-5646557eccf4_2562x1540.png 424w, https://substackcdn.com/image/fetch/$s_!2vtx!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5b34277-a5a5-4a04-93c5-5646557eccf4_2562x1540.png 848w, https://substackcdn.com/image/fetch/$s_!2vtx!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5b34277-a5a5-4a04-93c5-5646557eccf4_2562x1540.png 1272w, https://substackcdn.com/image/fetch/$s_!2vtx!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5b34277-a5a5-4a04-93c5-5646557eccf4_2562x1540.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    One of the developers in the study
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/ruben_bloom/status/1943532547935473800&quot; rel=&quot;&quot;&gt;
    spoke out
   &lt;/a&gt;
   &lt;span&gt;
    a bit on parts he found misleading.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    This last collection for this section doesn’t directly relate to which tools people are using, but rather how much people
   &lt;/span&gt;
   &lt;em&gt;
    are
   &lt;/em&gt;
   &lt;span&gt;
    using AI — supposedly
   &lt;/span&gt;
   &lt;a href=&quot;https://peterwildeford.substack.com/p/congress-has-started-taking-agi-more?r=68gy5&amp;utm_medium=ios&amp;triedRedirect=true&quot; rel=&quot;&quot;&gt;
    Congress is getting more AGI-pilled
   &lt;/a&gt;
   &lt;span&gt;
    . Between this, the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/the-white-houses-plan-for-open-models&quot; rel=&quot;&quot;&gt;
    AI Action Plan
   &lt;/a&gt;
   &lt;span&gt;
    , and countless people
   &lt;/span&gt;
   &lt;a href=&quot;https://www.thealgorithmicbridge.com/p/after-gpt-5-release-hundreds-begged&quot; rel=&quot;&quot;&gt;
    begging OpenAI to bring back GPT-4o
   &lt;/a&gt;
   &lt;span&gt;
    following the GPT-5 release — we can clearly expect the coming months to keep getting weirder with respect to AI.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   3. Tooling, techniques, and troubleshooting
  &lt;/h3&gt;
  &lt;p&gt;
   This section is mostly going to be a list of places to dive in and learn more about a certain training topic. Even though most leading researchers are in closed labs now, there’s still a lot of great technical work that goes under the radar. Choose what suits you, from:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Long-context training
     &lt;/strong&gt;
     &lt;span&gt;
      :
     &lt;/span&gt;
     &lt;a href=&quot;https://www.arcee.ai/blog/extending-afm-4-5b-to-64k-context-length&quot; rel=&quot;&quot;&gt;
      Arcee AI
     &lt;/a&gt;
     &lt;span&gt;
      and
     &lt;/span&gt;
     &lt;a href=&quot;https://www.snowflake.com/en/engineering-blog/arctic-long-sequence-training-multi-million-token-ai/&quot; rel=&quot;&quot;&gt;
      Snowflake
     &lt;/a&gt;
     &lt;span&gt;
      published blog posts on extending the context length of their models.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Fixing loss spikes at pretraining
     &lt;/strong&gt;
     &lt;span&gt;
      : The Marin project at Stanford
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/dlwh/status/1938282073296671045&quot; rel=&quot;&quot;&gt;
      shared
     &lt;/a&gt;
     &lt;span&gt;
      how they updated their trainer after getting feedback on socials about how “spiky” their 32B model training was.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      What weird fixes are needed to run new architectures in the open ecosystem
     &lt;/strong&gt;
     &lt;span&gt;
      : Daniel Han of Unsloth “
     &lt;/span&gt;
     &lt;a href=&quot;https://docs.unsloth.ai/basics/gpt-oss-how-to-run-and-fine-tune#unsloth-fixes-for-gpt-oss&quot; rel=&quot;&quot;&gt;
      fixed
     &lt;/a&gt;
     &lt;span&gt;
      ” (
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/danielhanchen/status/1953901104150065544&quot; rel=&quot;&quot;&gt;
      Twitter summary
     &lt;/a&gt;
     &lt;span&gt;
      ) much of OpenAI’s gpt-oss model. This normally involves precision or version issues, chat template misalignment, or other minor things as new architectures are getting implemented in 20+ libraries at once.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      The most serious experiment I’ve seen on a fairly unserious topic — RL pretraining
     &lt;/strong&gt;
     &lt;span&gt;
      in
     &lt;/span&gt;
     &lt;a href=&quot;https://tokenbender.com/post.html?id=avatarl&quot; rel=&quot;&quot;&gt;
      avataRL
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   &lt;span&gt;
    For some of everything, read the
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/blog/smollm3&quot; rel=&quot;&quot;&gt;
    SmolLM 3 report
   &lt;/a&gt;
   &lt;span&gt;
    — one of the open-source friends of OLMo.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   4. Extras
  &lt;/h3&gt;
  &lt;p&gt;
   There are two posts that didn’t really fit into the core themes that I would still recommend.
  &lt;/p&gt;
  &lt;p&gt;
   The first is this from Sergey Levine, where he talks about how a few priors people had for scaling robotics — like training on vast video data — haven’t been good enough to kickstart a revolution. Where modern LLMs are operating in the same domain that they’re trained on, in text, robots don’t have the same convenient reality, making the need for real-world data far higher.
  &lt;/p&gt;
  &lt;p&gt;
   He calls the attempted shortcuts people take in robotics:
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    surrogate data, a spork that tries to get the benefits of large-scale training without the cost of large-scale in-domain data collection.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;div data-attrs=&#x27;{&quot;id&quot;:168829883,&quot;url&quot;:&quot;https://sergeylevine.substack.com/p/sporks-of-agi&quot;,&quot;publication_id&quot;:1054969,&quot;publication_name&quot;:&quot;Learning and Control&quot;,&quot;publication_logo_url&quot;:null,&quot;title&quot;:&quot;Sporks of AGI&quot;,&quot;truncated_body_text&quot;:&quot;Training big models is really hard, and as the models get bigger and expand into new domains, it’s only getting harder. LLMs use lots of text data, while VLMs require data with text and images, and vision-language-action (VLA) models in robotics require lots of data of robots performing real tasks in the real world. This hits agents especially hard: whe…&quot;,&quot;date&quot;:&quot;2025-07-21T04:30:18.273Z&quot;,&quot;like_count&quot;:118,&quot;comment_count&quot;:10,&quot;bylines&quot;:[{&quot;id&quot;:15583187,&quot;name&quot;:&quot;Sergey Levine&quot;,&quot;handle&quot;:&quot;sergeylevine&quot;,&quot;previous_name&quot;:null,&quot;photo_url&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/44e4b94b-07c6-4315-ba54-38ebcd9fc9f2_355x357.png&quot;,&quot;bio&quot;:&quot;Sergey Levine is an Associate Professor at UC Berkeley and co-founder of Physical Intelligence. His work concerns machine learning, robotics, and other applications of learning-based decision making.&quot;,&quot;profile_set_up_at&quot;:&quot;2022-08-21T23:46:04.134Z&quot;,&quot;reader_installed_at&quot;:null,&quot;publicationUsers&quot;:[{&quot;id&quot;:1002637,&quot;user_id&quot;:15583187,&quot;publication_id&quot;:1054969,&quot;role&quot;:&quot;admin&quot;,&quot;public&quot;:true,&quot;is_primary&quot;:true,&quot;publication&quot;:{&quot;id&quot;:1054969,&quot;name&quot;:&quot;Learning and Control&quot;,&quot;subdomain&quot;:&quot;sergeylevine&quot;,&quot;custom_domain&quot;:null,&quot;custom_domain_optional&quot;:false,&quot;hero_text&quot;:&quot;Machine learning for robots and robots for machine learning&quot;,&quot;logo_url&quot;:null,&quot;author_id&quot;:15583187,&quot;primary_user_id&quot;:15583187,&quot;theme_var_background_pop&quot;:&quot;#D10000&quot;,&quot;created_at&quot;:&quot;2022-08-21T23:48:16.074Z&quot;,&quot;email_from_name&quot;:null,&quot;copyright&quot;:&quot;Sergey Levine&quot;,&quot;founding_plan_name&quot;:null,&quot;community_enabled&quot;:true,&quot;invite_only&quot;:false,&quot;payments_state&quot;:&quot;disabled&quot;,&quot;language&quot;:null,&quot;explicit&quot;:false,&quot;homepage_type&quot;:null,&quot;is_personal_mode&quot;:false}}],&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:null}],&quot;utm_campaign&quot;:null,&quot;belowTheFold&quot;:true,&quot;type&quot;:&quot;newsletter&quot;,&quot;language&quot;:&quot;en&quot;}&#x27; data-component-name=&quot;EmbeddedPostToDOM&quot;&gt;
   &lt;a href=&quot;https://sergeylevine.substack.com/p/sporks-of-agi?utm_source=substack&amp;utm_campaign=post_embed&amp;utm_medium=web&quot; native=&quot;true&quot; rel=&quot;&quot;&gt;
    &lt;div&gt;
     &lt;span&gt;
     &lt;/span&gt;
     &lt;span&gt;
      Learning and Control
     &lt;/span&gt;
    &lt;/div&gt;
    &lt;div&gt;
     &lt;div&gt;
      Sporks of AGI
     &lt;/div&gt;
    &lt;/div&gt;
    &lt;div&gt;
     Training big models is really hard, and as the models get bigger and expand into new domains, it’s only getting harder. LLMs use lots of text data, while VLMs require data with text and images, and vision-language-action (VLA) models in robotics require lots of data of robots performing real tasks in the real world. This hits agents especially hard: whe…
    &lt;/div&gt;
    &lt;div&gt;
     &lt;span&gt;
      Read more
     &lt;/span&gt;
    &lt;/div&gt;
    &lt;div&gt;
     21 days ago · 118 likes · 10 comments · Sergey Levine
    &lt;/div&gt;
   &lt;/a&gt;
  &lt;/div&gt;
  &lt;p&gt;
   The second is a piece by Ben Recht in partial response to my first post on The American DeepSeek Project. This was a feel-good read for me — if you’ve been fighting the same fight as me in search of more openness, or have considered it, I suggest giving it a read.
  &lt;/p&gt;
  &lt;div data-attrs=&#x27;{&quot;id&quot;:167992762,&quot;url&quot;:&quot;https://www.argmin.net/p/an-open-mindset&quot;,&quot;publication_id&quot;:1255585,&quot;publication_name&quot;:&quot;arg min&quot;,&quot;publication_logo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!MpqK!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5ecc065f-b4b4-488f-9ff9-d842d175475d_256x256.png&quot;,&quot;title&quot;:&quot;An open mindset&quot;,&quot;truncated_body_text&quot;:&quot;Over the 4th of July weekend, Nathan Lambert wrote a thoughtful post on “an American Deepseek Project,” posing the challenge of building a fully open, fully performant “frontier model” in the next two years. Deepseek, in case you’ve already forgotten, is a Chinese company that released a highly performing, open-source large language model chatbot in Jan…&quot;,&quot;date&quot;:&quot;2025-07-10T13:59:06.465Z&quot;,&quot;like_count&quot;:39,&quot;comment_count&quot;:7,&quot;bylines&quot;:[{&quot;id&quot;:42335610,&quot;name&quot;:&quot;Ben Recht&quot;,&quot;handle&quot;:&quot;beenwrekt&quot;,&quot;previous_name&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e4fe8c66-4c77-4977-b2aa-e29961f3b4fe_300x300.jpeg&quot;,&quot;bio&quot;:&quot;Ben is a Professor of Electrical Engineering and Computer Sciences at the University of California, Berkeley.&quot;,&quot;profile_set_up_at&quot;:&quot;2022-10-15T16:54:21.761Z&quot;,&quot;reader_installed_at&quot;:&quot;2023-10-11T15:04:28.530Z&quot;,&quot;publicationUsers&quot;:[{&quot;id&quot;:1212827,&quot;user_id&quot;:42335610,&quot;publication_id&quot;:1255585,&quot;role&quot;:&quot;admin&quot;,&quot;public&quot;:true,&quot;is_primary&quot;:true,&quot;publication&quot;:{&quot;id&quot;:1255585,&quot;name&quot;:&quot;arg min&quot;,&quot;subdomain&quot;:&quot;argmin&quot;,&quot;custom_domain&quot;:&quot;www.argmin.net&quot;,&quot;custom_domain_optional&quot;:false,&quot;hero_text&quot;:&quot;arg min: a blog of minimum value. on the history, foundations, and validity of \&quot;optimally\&quot; automated decision making.&quot;,&quot;logo_url&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/5ecc065f-b4b4-488f-9ff9-d842d175475d_256x256.png&quot;,&quot;author_id&quot;:42335610,&quot;primary_user_id&quot;:42335610,&quot;theme_var_background_pop&quot;:&quot;#25BD65&quot;,&quot;created_at&quot;:&quot;2022-12-21T02:28:39.839Z&quot;,&quot;email_from_name&quot;:null,&quot;copyright&quot;:&quot;Ben Recht&quot;,&quot;founding_plan_name&quot;:&quot;Founding Member&quot;,&quot;community_enabled&quot;:true,&quot;invite_only&quot;:false,&quot;payments_state&quot;:&quot;paused&quot;,&quot;language&quot;:null,&quot;explicit&quot;:false,&quot;homepage_type&quot;:&quot;newspaper&quot;,&quot;is_personal_mode&quot;:false}}],&quot;twitter_screen_name&quot;:&quot;beenwrekt&quot;,&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:null}],&quot;utm_campaign&quot;:null,&quot;belowTheFold&quot;:true,&quot;type&quot;:&quot;newsletter&quot;,&quot;language&quot;:&quot;en&quot;}&#x27; data-component-name=&quot;EmbeddedPostToDOM&quot;&gt;
   &lt;a href=&quot;https://www.argmin.net/p/an-open-mindset?utm_source=substack&amp;utm_campaign=post_embed&amp;utm_medium=web&quot; native=&quot;true&quot; rel=&quot;&quot;&gt;
    &lt;div&gt;
     &lt;img loading=&quot;lazy&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!MpqK!,w_56,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5ecc065f-b4b4-488f-9ff9-d842d175475d_256x256.png&quot;/&gt;
     &lt;span&gt;
      arg min
     &lt;/span&gt;
    &lt;/div&gt;
    &lt;div&gt;
     &lt;div&gt;
      An open mindset
     &lt;/div&gt;
    &lt;/div&gt;
    &lt;div&gt;
     Over the 4th of July weekend, Nathan Lambert wrote a thoughtful post on “an American Deepseek Project,” posing the challenge of building a fully open, fully performant “frontier model” in the next two years. Deepseek, in case you’ve already forgotten, is a Chinese company that released a highly performing, open-source large language model chatbot in Jan…
    &lt;/div&gt;
    &lt;div&gt;
     &lt;span&gt;
      Read more
     &lt;/span&gt;
    &lt;/div&gt;
    &lt;div&gt;
     a month ago · 39 likes · 7 comments · Ben Recht
    &lt;/div&gt;
   &lt;/a&gt;
  &lt;/div&gt;
  &lt;p&gt;
   Enjoy! Let me know if I missed any hidden gems.
  &lt;/p&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/what-im-reading-2-more-on-kimi-k2#footnote-anchor-1-170563070&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     Very related to this ongoing series on the failings of the Alan Turning Institute:
    &lt;/p&gt;
    &lt;div data-attrs=&#x27;{&quot;id&quot;:168213230,&quot;url&quot;:&quot;https://www.chalmermagne.com/p/how-not-to-fix-an-ai-institute&quot;,&quot;publication_id&quot;:3159216,&quot;publication_name&quot;:&quot;Chalmermagne &quot;,&quot;publication_logo_url&quot;:&quot;https://substackcdn.com/image/fetch/$s_!NqGX!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ac346e-8eea-4f52-9fff-2260791fb73b_1024x1024.png&quot;,&quot;title&quot;:&quot;How not to fix an AI institute&quot;,&quot;truncated_body_text&quot;:&quot;Introduction&quot;,&quot;date&quot;:&quot;2025-07-14T08:32:29.760Z&quot;,&quot;like_count&quot;:24,&quot;comment_count&quot;:3,&quot;bylines&quot;:[{&quot;id&quot;:17787335,&quot;name&quot;:&quot;Alex Chalmers&quot;,&quot;handle&quot;:&quot;chalmermagne&quot;,&quot;previous_name&quot;:&quot;AJC&quot;,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37cc7494-5020-443d-97de-7da8516c0bf7_800x800.jpeg&quot;,&quot;bio&quot;:&quot;Technology, finance, policy. \&quot;teenager with a blog\&quot;.&quot;,&quot;profile_set_up_at&quot;:&quot;2022-03-18T21:12:19.519Z&quot;,&quot;reader_installed_at&quot;:&quot;2022-03-18T21:11:25.868Z&quot;,&quot;publicationUsers&quot;:[{&quot;id&quot;:3216497,&quot;user_id&quot;:17787335,&quot;publication_id&quot;:3159216,&quot;role&quot;:&quot;admin&quot;,&quot;public&quot;:true,&quot;is_primary&quot;:true,&quot;publication&quot;:{&quot;id&quot;:3159216,&quot;name&quot;:&quot;Chalmermagne &quot;,&quot;subdomain&quot;:&quot;chalmermagne&quot;,&quot;custom_domain&quot;:&quot;www.chalmermagne.com&quot;,&quot;custom_domain_optional&quot;:false,&quot;hero_text&quot;:&quot;Systems, markets, technology &quot;,&quot;logo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a8ac346e-8eea-4f52-9fff-2260791fb73b_1024x1024.png&quot;,&quot;author_id&quot;:17787335,&quot;primary_user_id&quot;:17787335,&quot;theme_var_background_pop&quot;:&quot;#FF6719&quot;,&quot;created_at&quot;:&quot;2024-10-12T17:42:06.224Z&quot;,&quot;email_from_name&quot;:&quot;Chalmermagne &quot;,&quot;copyright&quot;:&quot;Alex Chalmers&quot;,&quot;founding_plan_name&quot;:null,&quot;community_enabled&quot;:true,&quot;invite_only&quot;:false,&quot;payments_state&quot;:&quot;disabled&quot;,&quot;language&quot;:null,&quot;explicit&quot;:false,&quot;homepage_type&quot;:&quot;newspaper&quot;,&quot;is_personal_mode&quot;:false}},{&quot;id&quot;:4581714,&quot;user_id&quot;:17787335,&quot;publication_id&quot;:90387,&quot;role&quot;:&quot;admin&quot;,&quot;public&quot;:true,&quot;is_primary&quot;:false,&quot;publication&quot;:{&quot;id&quot;:90387,&quot;name&quot;:&quot;The Works in Progress Newsletter&quot;,&quot;subdomain&quot;:&quot;worksinprogress&quot;,&quot;custom_domain&quot;:&quot;www.worksinprogress.news&quot;,&quot;custom_domain_optional&quot;:false,&quot;hero_text&quot;:&quot;New and underrated ideas to improve the world. Visit our website: worksinprogress.co&quot;,&quot;logo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6f5bf141-f845-48a4-a1d6-fb74f26daec9_1280x1280.png&quot;,&quot;author_id&quot;:15759190,&quot;primary_user_id&quot;:15759190,&quot;theme_var_background_pop&quot;:&quot;#00C2FF&quot;,&quot;created_at&quot;:&quot;2020-09-02T03:51:44.742Z&quot;,&quot;email_from_name&quot;:&quot;Works in Progress&quot;,&quot;copyright&quot;:&quot;Works in Progress&quot;,&quot;founding_plan_name&quot;:null,&quot;community_enabled&quot;:true,&quot;invite_only&quot;:false,&quot;payments_state&quot;:&quot;disabled&quot;,&quot;language&quot;:null,&quot;explicit&quot;:false,&quot;homepage_type&quot;:&quot;magaziney&quot;,&quot;is_personal_mode&quot;:false}}],&quot;is_guest&quot;:false,&quot;bestseller_tier&quot;:null}],&quot;utm_campaign&quot;:null,&quot;belowTheFold&quot;:true,&quot;type&quot;:&quot;newsletter&quot;,&quot;language&quot;:&quot;en&quot;}&#x27; data-component-name=&quot;EmbeddedPostToDOM&quot;&gt;
     &lt;a href=&quot;https://www.chalmermagne.com/p/how-not-to-fix-an-ai-institute?utm_source=substack&amp;utm_campaign=post_embed&amp;utm_medium=web&quot; native=&quot;true&quot; rel=&quot;&quot;&gt;
      &lt;div&gt;
       &lt;img loading=&quot;lazy&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!NqGX!,w_56,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ac346e-8eea-4f52-9fff-2260791fb73b_1024x1024.png&quot;/&gt;
       &lt;span&gt;
        Chalmermagne
       &lt;/span&gt;
      &lt;/div&gt;
      &lt;div&gt;
       &lt;div&gt;
        How not to fix an AI institute
       &lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;
       Introduction…
      &lt;/div&gt;
      &lt;div&gt;
       &lt;span&gt;
        Read more
       &lt;/span&gt;
      &lt;/div&gt;
      &lt;div&gt;
       a month ago · 24 likes · 3 comments · Alex Chalmers
      &lt;/div&gt;
     &lt;/a&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> GPT-5 and the arc of progress </title>
<link>https://www.interconnects.ai/p/gpt-5-and-bending-the-arc-of-progress</link>
<pubDate>Thu, 07 Aug 2025 22:20:16 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;h5&gt;
   &lt;span&gt;
    If you want a video version of this, check out the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.youtube.com/watch?v=oOtHtK7YK2g&quot; rel=&quot;&quot;&gt;
    last 20 minutes of the livestream reaction
   &lt;/a&gt;
   &lt;span&gt;
    (edit, fixed link) I did with Will Brown of Prime Intellect and Swyx of Smol AI &amp; Latent Space.
   &lt;/span&gt;
  &lt;/h5&gt;
  &lt;div&gt;
   &lt;hr/&gt;
  &lt;/div&gt;
  &lt;p&gt;
   GPT-5 was set up to fail on some of the narratives it was expected to satisfy. The two central themes it had to decide between were the AGI (or superintelligence) narrative that Sam Altman &amp; co. have been using to fundraise and the fact that ChatGPT is one of the fastest-growing consumer technologies of all time.
  &lt;/p&gt;
  &lt;p&gt;
   To fulfill both, GPT-5 needed to be AGI while also being cheap enough to serve as the most-used AI system in the world. Business and technological realities made it inevitable that GPT-5’s primary impact would be to solidify OpenAI’s market position, even if it raises a lot of eyebrows for the long-term trajectory of AI.
  &lt;/p&gt;
  &lt;p&gt;
   The reactions online capture this as well. The OpenAI live streams have historically catered to AI insiders, but the product speaks entirely to a different audience. The people discussing this release on Twitter will be disappointed in a first reaction, but 99% of people using ChatGPT are going to be so happy about the upgrade. Confusingly enough, this includes many of the critics. GPT-5 is a good AI system. It’s right in line with best-in-class across pretty much every evaluation, while being cheap enough to serve the whole world.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    OpenAI is largely fixing its product offering with an announcement that was hyped to be one of the biggest AI news cycles of the year. AI news being loud is defined by
   &lt;/span&gt;
   &lt;em&gt;
    narratives
   &lt;/em&gt;
   &lt;span&gt;
    being different more-so than technology being better. OpenAI releasing an open model again will likely be pinpointed as just as important a day for the arc of AI as the GPT-5 release. In many ways GPT-5 was set up to fail and that is very off-putting for those expecting maximum AI progress in the near term.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    I’m not going to dwell on it, but oh boy, that was a messy release. GPT-5 being announced and rolled out like this is very odd. Countless
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/connerdelights/status/1953503460768592236&quot; rel=&quot;&quot;&gt;
    plots were mislabeled
   &lt;/a&gt;
   &lt;span&gt;
    , live demos had bugs, and the
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/captainbullshi/status/1953540488549863753?s=46&quot; rel=&quot;&quot;&gt;
    early rollout is doing some weird stuff
   &lt;/a&gt;
   &lt;span&gt;
    . This reinforces how OpenAI was torn about the release and backed into a corner with their messaging. They knew they needed to improve the experience with strong competition in the industry, but releasing GPT-5 needed to make a splash after how long they’ve waited (and already parked the GPT 4.5 name).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The core question we track in this post is: What does it mean for the next 6-18 months of AI progress if GPT-5 is just as good as all the best models out there, e.g., Claude Sonnet for coding or o3 for search, funneled into one, super cheap package?
  &lt;/p&gt;
  &lt;p&gt;
   If AGI was a real goal, the main factor on progress would be raw performance. GPT-5 shows that AI is on a somewhat more traditional technological path, where there isn’t one key factor, it is a mix of performance, price, product, and everything in between.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   GPT-5’s performance
  &lt;/h2&gt;
  &lt;p&gt;
   &lt;span&gt;
    There are a few places that we can see that GPT-5 represents a solid step on the performance trend line, but nothing like a step change. First, on
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/lmarena_ai/status/1953504958378356941&quot; rel=&quot;&quot;&gt;
    LMArena
   &lt;/a&gt;
   &lt;span&gt;
    , GPT-5 is fantastic, sweeping the board to #1 on all categories. The last model to claim #1 in pretty much every category was
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/gemini-25-pro-googles-second-ai-chance&quot; rel=&quot;&quot;&gt;
    Gemini 2.5 Pro
   &lt;/a&gt;
   &lt;span&gt;
    — and that was the biggest step change in Elo since GPT-4 Turbo skyrocketed past the first Claude.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!b9ki!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dfeaad2-55f5-48f6-95cf-d80ae84f9885_2000x1600.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!b9ki!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dfeaad2-55f5-48f6-95cf-d80ae84f9885_2000x1600.jpeg 424w, https://substackcdn.com/image/fetch/$s_!b9ki!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dfeaad2-55f5-48f6-95cf-d80ae84f9885_2000x1600.jpeg 848w, https://substackcdn.com/image/fetch/$s_!b9ki!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dfeaad2-55f5-48f6-95cf-d80ae84f9885_2000x1600.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!b9ki!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dfeaad2-55f5-48f6-95cf-d80ae84f9885_2000x1600.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;Image&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8dfeaad2-55f5-48f6-95cf-d80ae84f9885_2000x1600.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1165,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:&quot;Image&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;1165&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!b9ki!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dfeaad2-55f5-48f6-95cf-d80ae84f9885_2000x1600.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!b9ki!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dfeaad2-55f5-48f6-95cf-d80ae84f9885_2000x1600.jpeg 424w, https://substackcdn.com/image/fetch/$s_!b9ki!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dfeaad2-55f5-48f6-95cf-d80ae84f9885_2000x1600.jpeg 848w, https://substackcdn.com/image/fetch/$s_!b9ki!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dfeaad2-55f5-48f6-95cf-d80ae84f9885_2000x1600.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!b9ki!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dfeaad2-55f5-48f6-95cf-d80ae84f9885_2000x1600.jpeg 1456w&quot; title=&quot;Image&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    Second, GPT-5 is the top model on the
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/ArtificialAnlys/status/1953507703105757293&quot; rel=&quot;&quot;&gt;
    ArtificialAnalysis
   &lt;/a&gt;
   &lt;span&gt;
    composite benchmark.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!8aA0!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe07d63e4-20d0-467f-93e2-59a4e0aa03b6_3916x1700.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!8aA0!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe07d63e4-20d0-467f-93e2-59a4e0aa03b6_3916x1700.jpeg 424w, https://substackcdn.com/image/fetch/$s_!8aA0!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe07d63e4-20d0-467f-93e2-59a4e0aa03b6_3916x1700.jpeg 848w, https://substackcdn.com/image/fetch/$s_!8aA0!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe07d63e4-20d0-467f-93e2-59a4e0aa03b6_3916x1700.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!8aA0!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe07d63e4-20d0-467f-93e2-59a4e0aa03b6_3916x1700.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;Image&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e07d63e4-20d0-467f-93e2-59a4e0aa03b6_3916x1700.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:632,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;632&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!8aA0!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe07d63e4-20d0-467f-93e2-59a4e0aa03b6_3916x1700.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!8aA0!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe07d63e4-20d0-467f-93e2-59a4e0aa03b6_3916x1700.jpeg 424w, https://substackcdn.com/image/fetch/$s_!8aA0!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe07d63e4-20d0-467f-93e2-59a4e0aa03b6_3916x1700.jpeg 848w, https://substackcdn.com/image/fetch/$s_!8aA0!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe07d63e4-20d0-467f-93e2-59a4e0aa03b6_3916x1700.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!8aA0!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe07d63e4-20d0-467f-93e2-59a4e0aa03b6_3916x1700.jpeg 1456w&quot; title=&quot;Image&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    These two, LMArena &amp; ArtificialAnalysis, represent two coarse evaluations — community vibes and raw benchmarks. Both of these can be gamed, but are still correlated with real-world use. You can also see in OpenAI’s shared results how much the
   &lt;/span&gt;
   &lt;em&gt;
    &lt;strong&gt;
     smaller versions
    &lt;/strong&gt;
   &lt;/em&gt;
   &lt;span&gt;
    improve on the likes of GPT-4.1 mini and o4-mini.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!Sm8y!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07eac613-bdfc-44b8-be99-4e48d26b2876_1418x666.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Sm8y!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07eac613-bdfc-44b8-be99-4e48d26b2876_1418x666.png 424w, https://substackcdn.com/image/fetch/$s_!Sm8y!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07eac613-bdfc-44b8-be99-4e48d26b2876_1418x666.png 848w, https://substackcdn.com/image/fetch/$s_!Sm8y!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07eac613-bdfc-44b8-be99-4e48d26b2876_1418x666.png 1272w, https://substackcdn.com/image/fetch/$s_!Sm8y!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07eac613-bdfc-44b8-be99-4e48d26b2876_1418x666.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/07eac613-bdfc-44b8-be99-4e48d26b2876_1418x666.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:666,&quot;width&quot;:1418,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:332847,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/170388404?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07eac613-bdfc-44b8-be99-4e48d26b2876_1418x666.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;666&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!Sm8y!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07eac613-bdfc-44b8-be99-4e48d26b2876_1418x666.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Sm8y!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07eac613-bdfc-44b8-be99-4e48d26b2876_1418x666.png 424w, https://substackcdn.com/image/fetch/$s_!Sm8y!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07eac613-bdfc-44b8-be99-4e48d26b2876_1418x666.png 848w, https://substackcdn.com/image/fetch/$s_!Sm8y!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07eac613-bdfc-44b8-be99-4e48d26b2876_1418x666.png 1272w, https://substackcdn.com/image/fetch/$s_!Sm8y!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07eac613-bdfc-44b8-be99-4e48d26b2876_1418x666.png 1456w&quot; width=&quot;1418&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   In many ways, the march of progress on evals has felt slowed for a while because model releases are so frequent and each individual step is smaller. Lots of small steps make for big change. The overall trend line is still very positive, and multiple companies are filling in the shape of it.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    My post on “
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/summertime-outlook-o3s-novelty-coming&quot; rel=&quot;&quot;&gt;
    what comes next
   &lt;/a&gt;
   &lt;span&gt;
    ” from earlier this summer all but called this type of release, where the numbers aren’t shocking but the real world use cases are great, becoming more common.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    &lt;span&gt;
     This is a different path for the industry and will take a different form of messaging than we’re used to. More releases are going to look like
    &lt;/span&gt;
    &lt;a href=&quot;https://www.interconnects.ai/p/claude-4-and-anthropics-bet-on-code&quot; rel=&quot;&quot;&gt;
     Anthropic’s Claude 4
    &lt;/a&gt;
    &lt;span&gt;
     , where the benchmark gains are minor and the real world gains are a big step. There are plenty of more implications for policy, evaluation, and transparency that come with this. It is going to take much more nuance to understand if the pace of progress is continuing, especially as critics of AI are going to seize the opportunity of evaluations flatlining to say that AI is no longer working.
    &lt;/span&gt;
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   To say it succinctly: Abilities will develop more slowly than products.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The product overhang is being
   &lt;/span&gt;
   &lt;em&gt;
    extended
   &lt;/em&gt;
   &lt;span&gt;
    with each release. We’re still building untapped value with AI models and systems faster than we’re capturing it.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Another way to see this incremental push out in models or systems is through OpenAI’s update to the famous
   &lt;/span&gt;
   &lt;a href=&quot;https://metr.org/&quot; rel=&quot;&quot;&gt;
    METR
   &lt;/a&gt;
   &lt;span&gt;
    plot of time to completion for humans of various tasks AI systems can solve 50% of the time. GPT-5 is leading, but also just in line with trends.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!SKh4!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F219a2d6e-0890-402b-af8e-08d33fcdc8f5_2788x1506.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!SKh4!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F219a2d6e-0890-402b-af8e-08d33fcdc8f5_2788x1506.png 424w, https://substackcdn.com/image/fetch/$s_!SKh4!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F219a2d6e-0890-402b-af8e-08d33fcdc8f5_2788x1506.png 848w, https://substackcdn.com/image/fetch/$s_!SKh4!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F219a2d6e-0890-402b-af8e-08d33fcdc8f5_2788x1506.png 1272w, https://substackcdn.com/image/fetch/$s_!SKh4!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F219a2d6e-0890-402b-af8e-08d33fcdc8f5_2788x1506.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/219a2d6e-0890-402b-af8e-08d33fcdc8f5_2788x1506.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:786,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1271046,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/170388404?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F219a2d6e-0890-402b-af8e-08d33fcdc8f5_2788x1506.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;786&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!SKh4!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F219a2d6e-0890-402b-af8e-08d33fcdc8f5_2788x1506.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!SKh4!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F219a2d6e-0890-402b-af8e-08d33fcdc8f5_2788x1506.png 424w, https://substackcdn.com/image/fetch/$s_!SKh4!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F219a2d6e-0890-402b-af8e-08d33fcdc8f5_2788x1506.png 848w, https://substackcdn.com/image/fetch/$s_!SKh4!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F219a2d6e-0890-402b-af8e-08d33fcdc8f5_2788x1506.png 1272w, https://substackcdn.com/image/fetch/$s_!SKh4!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F219a2d6e-0890-402b-af8e-08d33fcdc8f5_2788x1506.png 1456w&quot; title=&quot;&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   All of this is to say comprehensively that AI progress is very alive and well, as long as you don’t subscribe to the exponential takeoff in ability. Those arguments are very strained by this GPT-5 release.
  &lt;/p&gt;
  &lt;p&gt;
   Yes, AI progress on intelligence and “raw ability” is certainly going to continue at a solid pace for a long time, but how will this translate into recursive self-improvement?
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/gpt-5-and-bending-the-arc-of-progress?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/gpt-5-and-bending-the-arc-of-progress?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;h2&gt;
   GPT-5’s details
  &lt;/h2&gt;
  &lt;p&gt;
   &lt;span&gt;
    If you’re reading closely, you may have noticed that this post uses the word
   &lt;/span&gt;
   &lt;em&gt;
    system
   &lt;/em&gt;
   &lt;span&gt;
    instead of model. All of the leading chat systems have been adding more components onto them like safety checkers and so on, but this is the first one to use different architectures and weights for the primary generation of content across similar queries. GPT-5 is the first in what is to come, mostly to better balance cost and give better user experiences. From the system card:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    &lt;span&gt;
     GPT‑5 is a
    &lt;/span&gt;
    &lt;strong&gt;
     unified system
    &lt;/strong&gt;
    &lt;span&gt;
     with a smart and fast model that answers most questions, a deeper reasoning model for harder problems, and a real-time router that quickly decides which model to use based on conversation type, complexity, tool needs, and explicit intent (for example, if you say “think hard about this” in the prompt). The router is continuously trained on real signals, including when users switch models, preference rates for responses, and measured correctness, improving over time.
    &lt;/span&gt;
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   &lt;span&gt;
    Along with this, they shipped many product improvements, such as how the model has a 400K context window in the API with
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/jxmnop/status/1953511687190982919&quot; rel=&quot;&quot;&gt;
    great performance
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/polynoamial/status/1953517966978322545&quot; rel=&quot;&quot;&gt;
    reduced hallucinations
   &lt;/a&gt;
   &lt;span&gt;
    , and
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/OpenAI/status/1953534071772262511&quot; rel=&quot;&quot;&gt;
    new personalities
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Primarily, I worry as a power user about the router. I sense that for now I’ll default to GPT-5 Thinking, and sometimes upgrade to Pro mode, while downgrading to standard GPT-5 only for benign queries (depending on its search behavior — if it is search-heavy like o3 without thinking, then it should still work well).
  &lt;/p&gt;
  &lt;p&gt;
   Thankfully, the thinking mode has a “get an early answer” button, so I don’t see any reason to start elsewhere. If I need an answer fast, I’ll get one. If not, I want the best responses possible.
  &lt;/p&gt;
  &lt;p&gt;
   As for prices, here’s a comparison. GPT-5’s top-level model is cheaper than Claude Sonnet and far better than any OpenAI model has been before at coding — one of the core details of this release. Matching Gemini Pro’s pricing when considering Google’s infrastructure advantage is a substantial accomplishment.
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      OpenAI — GPT-5 (API sizes)
     &lt;/strong&gt;
    &lt;/p&gt;
    &lt;ul&gt;
     &lt;li&gt;
      &lt;p&gt;
       &lt;strong&gt;
        GPT-5:
       &lt;/strong&gt;
       &lt;span&gt;
        input
       &lt;/span&gt;
       &lt;strong&gt;
        $1.25
       &lt;/strong&gt;
       &lt;span&gt;
        , output
       &lt;/span&gt;
       &lt;strong&gt;
        $10.00
       &lt;/strong&gt;
       &lt;span&gt;
        . (
       &lt;/span&gt;
       &lt;a href=&quot;https://openai.com/gpt-5/&quot; rel=&quot;&quot;&gt;
        OpenAI
       &lt;/a&gt;
       &lt;span&gt;
        )
       &lt;/span&gt;
      &lt;/p&gt;
     &lt;/li&gt;
     &lt;li&gt;
      &lt;p&gt;
       &lt;strong&gt;
        GPT-5 mini:
       &lt;/strong&gt;
       &lt;span&gt;
        input
       &lt;/span&gt;
       &lt;strong&gt;
        $0.25
       &lt;/strong&gt;
       &lt;span&gt;
        , output
       &lt;/span&gt;
       &lt;strong&gt;
        $2.00
       &lt;/strong&gt;
       &lt;span&gt;
        . (
       &lt;/span&gt;
       &lt;a href=&quot;https://openai.com/gpt-5/&quot; rel=&quot;&quot;&gt;
        OpenAI
       &lt;/a&gt;
       &lt;span&gt;
        )
       &lt;/span&gt;
      &lt;/p&gt;
     &lt;/li&gt;
     &lt;li&gt;
      &lt;p&gt;
       &lt;strong&gt;
        GPT-5 nano:
       &lt;/strong&gt;
       &lt;span&gt;
        input
       &lt;/span&gt;
       &lt;strong&gt;
        $0.05
       &lt;/strong&gt;
       &lt;span&gt;
        , output
       &lt;/span&gt;
       &lt;strong&gt;
        $0.40
       &lt;/strong&gt;
       &lt;span&gt;
        . (
       &lt;/span&gt;
       &lt;a href=&quot;https://openai.com/gpt-5/&quot; rel=&quot;&quot;&gt;
        OpenAI
       &lt;/a&gt;
       &lt;span&gt;
        )
       &lt;/span&gt;
      &lt;/p&gt;
     &lt;/li&gt;
    &lt;/ul&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      OpenAI — o3 (reasoning)
     &lt;/strong&gt;
    &lt;/p&gt;
    &lt;ul&gt;
     &lt;li&gt;
      &lt;p&gt;
       &lt;strong&gt;
        o3:
       &lt;/strong&gt;
       &lt;span&gt;
        input
       &lt;/span&gt;
       &lt;strong&gt;
        $2.00
       &lt;/strong&gt;
       &lt;span&gt;
        , output
       &lt;/span&gt;
       &lt;strong&gt;
        $8.00
       &lt;/strong&gt;
       &lt;span&gt;
        . (
       &lt;/span&gt;
       &lt;a href=&quot;https://platform.openai.com/docs/models/o3?utm_source=chatgpt.com&quot; rel=&quot;&quot;&gt;
        OpenAI Platform
       &lt;/a&gt;
       &lt;span&gt;
        )
       &lt;/span&gt;
      &lt;/p&gt;
     &lt;/li&gt;
     &lt;li&gt;
      &lt;p&gt;
       &lt;strong&gt;
        o3-mini:
       &lt;/strong&gt;
       &lt;span&gt;
        input
       &lt;/span&gt;
       &lt;strong&gt;
        $1.10
       &lt;/strong&gt;
       &lt;span&gt;
        , output
       &lt;/span&gt;
       &lt;strong&gt;
        $4.40
       &lt;/strong&gt;
       &lt;span&gt;
        . (cached input
       &lt;/span&gt;
       &lt;strong&gt;
        $0.55
       &lt;/strong&gt;
       &lt;span&gt;
        ) (
       &lt;/span&gt;
       &lt;a href=&quot;https://platform.openai.com/docs/pricing?utm_source=chatgpt.com&quot; rel=&quot;&quot;&gt;
        OpenAI Platform
       &lt;/a&gt;
       &lt;span&gt;
        )
       &lt;/span&gt;
      &lt;/p&gt;
     &lt;/li&gt;
    &lt;/ul&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Anthropic — Claude 4 family
     &lt;/strong&gt;
    &lt;/p&gt;
    &lt;ul&gt;
     &lt;li&gt;
      &lt;p&gt;
       &lt;strong&gt;
        Claude Sonnet 4:
       &lt;/strong&gt;
       &lt;span&gt;
        input
       &lt;/span&gt;
       &lt;strong&gt;
        $3.00
       &lt;/strong&gt;
       &lt;span&gt;
        , output
       &lt;/span&gt;
       &lt;strong&gt;
        $15.00
       &lt;/strong&gt;
       &lt;span&gt;
        . (
       &lt;/span&gt;
       &lt;a href=&quot;https://www.anthropic.com/pricing&quot; rel=&quot;&quot;&gt;
        Anthropic
       &lt;/a&gt;
       &lt;span&gt;
        )
       &lt;/span&gt;
      &lt;/p&gt;
     &lt;/li&gt;
     &lt;li&gt;
      &lt;p&gt;
       &lt;strong&gt;
        Claude Opus 4.1:
       &lt;/strong&gt;
       &lt;span&gt;
        input
       &lt;/span&gt;
       &lt;strong&gt;
        $15.00
       &lt;/strong&gt;
       &lt;span&gt;
        , output
       &lt;/span&gt;
       &lt;strong&gt;
        $75.00
       &lt;/strong&gt;
       &lt;span&gt;
        . (
       &lt;/span&gt;
       &lt;a href=&quot;https://www.anthropic.com/pricing&quot; rel=&quot;&quot;&gt;
        Anthropic
       &lt;/a&gt;
       &lt;span&gt;
        )
       &lt;/span&gt;
      &lt;/p&gt;
     &lt;/li&gt;
    &lt;/ul&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Google — Gemini 2.5
     &lt;/strong&gt;
    &lt;/p&gt;
    &lt;ul&gt;
     &lt;li&gt;
      &lt;p&gt;
       &lt;strong&gt;
        Gemini 2.5 Pro:
       &lt;/strong&gt;
       &lt;span&gt;
        input
       &lt;/span&gt;
       &lt;strong&gt;
        $1.25
       &lt;/strong&gt;
       &lt;span&gt;
        (≤200k prompt) /
       &lt;/span&gt;
       &lt;strong&gt;
        $2.50
       &lt;/strong&gt;
       &lt;span&gt;
        (&amp;gt;200k); output
       &lt;/span&gt;
       &lt;strong&gt;
        $10.00
       &lt;/strong&gt;
       &lt;span&gt;
        (≤200k) /
       &lt;/span&gt;
       &lt;strong&gt;
        $15.00
       &lt;/strong&gt;
       &lt;span&gt;
        (&amp;gt;200k). (
       &lt;/span&gt;
       &lt;a href=&quot;https://ai.google.dev/gemini-api/docs/pricing&quot; rel=&quot;&quot;&gt;
        Google AI for Developers
       &lt;/a&gt;
       &lt;span&gt;
        )
       &lt;/span&gt;
      &lt;/p&gt;
     &lt;/li&gt;
     &lt;li&gt;
      &lt;p&gt;
       &lt;strong&gt;
        Gemini 2.5 Flash:
       &lt;/strong&gt;
       &lt;span&gt;
        input
       &lt;/span&gt;
       &lt;strong&gt;
        $0.30
       &lt;/strong&gt;
       &lt;span&gt;
        (text/image/video) or
       &lt;/span&gt;
       &lt;strong&gt;
        $1.00
       &lt;/strong&gt;
       &lt;span&gt;
        (audio); output
       &lt;/span&gt;
       &lt;strong&gt;
        $2.50
       &lt;/strong&gt;
       &lt;span&gt;
        (includes thinking tokens). (
       &lt;/span&gt;
       &lt;a href=&quot;https://ai.google.dev/gemini-api/docs/pricing&quot; rel=&quot;&quot;&gt;
        Google AI for Developers
       &lt;/a&gt;
       &lt;span&gt;
        )
       &lt;/span&gt;
      &lt;/p&gt;
     &lt;/li&gt;
     &lt;li&gt;
      &lt;p&gt;
       &lt;strong&gt;
        Gemini 2.5 Flash-Lite:
       &lt;/strong&gt;
       &lt;span&gt;
        input
       &lt;/span&gt;
       &lt;strong&gt;
        $0.10
       &lt;/strong&gt;
       &lt;span&gt;
        (text/image/video) or
       &lt;/span&gt;
       &lt;strong&gt;
        $0.30
       &lt;/strong&gt;
       &lt;span&gt;
        (audio); output
       &lt;/span&gt;
       &lt;strong&gt;
        $0.40
       &lt;/strong&gt;
       &lt;span&gt;
        . (
       &lt;/span&gt;
       &lt;a href=&quot;https://ai.google.dev/gemini-api/docs/pricing&quot; rel=&quot;&quot;&gt;
        Google AI for Developers
       &lt;/a&gt;
       &lt;span&gt;
        )
       &lt;/span&gt;
      &lt;/p&gt;
     &lt;/li&gt;
    &lt;/ul&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;blockquote&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   &lt;span&gt;
    Cheaper, thinking models that work well in applications are far more useful than scaling (as
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/gpt-45-not-a-frontier-model&quot; rel=&quot;&quot;&gt;
    GPT-4.5 has shown us
   &lt;/a&gt;
   &lt;span&gt;
    ).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h2&gt;
   GPT-5’s impact
  &lt;/h2&gt;
  &lt;p&gt;
   It seems like most people in all walks of life are going to love this model — from AI researchers all the way to people who are learning of ChatGPT for the first time today. This is very in line with my expectations for how AI will proceed, as a long, steady march of progress.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The fact that the models are getting way cheaper rather than way more expensive definitely signals that we cannot just brute-force scale our way to much stronger systems. Scaling helps, but it is now one of many considerations, and all the laboratories are showing us that much bigger models have diminishing returns in value to customers. At the same time, models being cheaper could be just what we need for
   &lt;/span&gt;
   &lt;a href=&quot;https://en.wikipedia.org/wiki/Jevons_paradox&quot; rel=&quot;&quot;&gt;
    Jevons paradox
   &lt;/a&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/gpt-5-and-bending-the-arc-of-progress#footnote-1-170388404&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     1
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    to kick in and provide another boost in AI adoption.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Many people will claim that the GPT-5 release was a flop and the bubble will pop for AI. This is downstream of the industry generally making totally unrealistic promises. As someone whose core through-line when covering frontier models is tracking the pace of progress, I translate this as “AI capabilities on benchmarks will proceed a bit more slowly, but we aren’t reaching any clear walls in performance.” The AI performance hills we’re climbing up as an industry do put up some more resistance as the obvious low hanging fruit is gone, but we have the tools to overcome it consistently for the next 6 to 18 months.
  &lt;/p&gt;
  &lt;p&gt;
   For companies that have been fundraising on promises of AGI, such as Anthropic and OpenAI, closing the next rounds could be harder. Of course, this depends on whether the messaging of the rounds was a key part of the fundraising.
  &lt;/p&gt;
  &lt;p&gt;
   This fundraising inspires capital expenditures across the industry, e.g. TSMC developing the next node for NVIDIA to build new chips, and so on. The AGI narrative and the fundraising it has enabled have been good for the U.S. in terms of building out valuable, raw infrastructure.
  &lt;/p&gt;
  &lt;p&gt;
   This could be the beginning of the money train slowing down, but that’s very different from a derailment and a stock market crash. As raw infrastructure spend slows, there will be even more pressure to deliver valuable products to users. A key trend for 2025 has been many of those appearing — Deep Research and Claude Code being the paradigms that everyone has copied.
  &lt;/p&gt;
  &lt;p&gt;
   GPT-5 makes these applications better and makes it easier and cheaper for the next viral AI products to hit the market. I’m still excited for what is to come.
  &lt;/p&gt;
  &lt;p&gt;
   But first, I’m going to sign off and go play with GPT-5. It’s a good day to build something for the fun of it. As I use it more, I’ll have more to say.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/gpt-5-and-bending-the-arc-of-progress?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/gpt-5-and-bending-the-arc-of-progress?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;hr/&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   Extra GPT-5 links
  &lt;/h2&gt;
  &lt;p&gt;
   &lt;span&gt;
    For more specifics on the model from people who got early access, I recommend
   &lt;/span&gt;
   &lt;a href=&quot;https://marginalrevolution.com/marginalrevolution/2025/08/gpt-5-short-and-enthusiastic-review.html&quot; rel=&quot;&quot;&gt;
    Tyler Cowen
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://every.to/vibe-check/gpt-5&quot; rel=&quot;&quot;&gt;
    Every.to
   &lt;/a&gt;
   &lt;span&gt;
    , or
   &lt;/span&gt;
   &lt;a href=&quot;https://simonwillison.net/2025/Aug/7/gpt-5/&quot; rel=&quot;&quot;&gt;
    Simon Willison
   &lt;/a&gt;
   &lt;span&gt;
    (or Swyx soon, on
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;a data-attrs=&#x27;{&quot;name&quot;:&quot;Latent.Space&quot;,&quot;id&quot;:89230629,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/703cf3dd-3bab-4f7b-86fa-f4443f15f8a4_152x152.jpeg&quot;,&quot;uuid&quot;:&quot;5502657f-cefd-4fe4-a17b-d9dea388bf03&quot;}&#x27; data-component-name=&quot;MentionUser&quot; href=&quot;https://open.substack.com/users/89230629-latentspace?utm_source=mentions&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;
    Latent.Space
   &lt;/a&gt;
  &lt;/div&gt;
  &lt;span&gt;
   ).
  &lt;/span&gt;
  &lt;p&gt;
   &lt;span&gt;
    Livestream link:
   &lt;/span&gt;
   &lt;a href=&quot;https://openai.com/gpt-5/&quot; rel=&quot;&quot;&gt;
    https://openai.com/gpt-5/
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    Research blog post:
   &lt;/span&gt;
   &lt;a href=&quot;https://openai.com/index/introducing-gpt-5/&quot; rel=&quot;&quot;&gt;
    https://openai.com/index/introducing-gpt-5/
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    Developer blog post:
   &lt;/span&gt;
   &lt;a href=&quot;https://openai.com/index/introducing-gpt-5-for-developers&quot; rel=&quot;&quot;&gt;
    https://openai.com/index/introducing-gpt-5-for-developers
   &lt;/a&gt;
   &lt;span&gt;
    Enterprise blog post:
   &lt;/span&gt;
   &lt;a href=&quot;https://openai.com/index/gpt-5-new-era-of-work&quot; rel=&quot;&quot;&gt;
    https://openai.com/index/gpt-5-new-era-of-work
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    GPT-5 landing page:
   &lt;/span&gt;
   &lt;a href=&quot;https://openai.com/gpt-5/&quot; rel=&quot;&quot;&gt;
    https://openai.com/gpt-5/
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    System Card:
   &lt;/span&gt;
   &lt;a href=&quot;https://openai.com/index/gpt-5-system-card/&quot; rel=&quot;&quot;&gt;
    https://openai.com/index/gpt-5-system-card/
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;span&gt;
    Coding examples:
   &lt;/span&gt;
   &lt;a href=&quot;https://openai.github.io/gpt-5-coding-examples/&quot; rel=&quot;&quot;&gt;
    https://openai.github.io/gpt-5-coding-examples/
   &lt;/a&gt;
   &lt;br/&gt;
   &lt;span&gt;
    What would you say if you could talk to a future OpenAI model
   &lt;/span&gt;
   &lt;a href=&quot;https://progress.openai.com/&quot; rel=&quot;&quot;&gt;
    https://progress.openai.com/
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Finally, I’ll plug again the video I did with Will Brown and Swyx:
  &lt;/p&gt;
  &lt;div data-attrs=&#x27;{&quot;videoId&quot;:&quot;oOtHtK7YK2g&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}&#x27; data-component-name=&quot;Youtube2ToDOM&quot;&gt;
   &lt;div&gt;
    &lt;iframe allow=&quot;autoplay; fullscreen&quot; allowautoplay=&quot;true&quot; allowfullscreen=&quot;true&quot; frameborder=&quot;0&quot; gesture=&quot;media&quot; height=&quot;409&quot; loading=&quot;lazy&quot; src=&quot;https://www.youtube-nocookie.com/embed/oOtHtK7YK2g?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0&quot; width=&quot;728&quot;&gt;
    &lt;/iframe&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
   Send me the most interesting things you find on GPT-5!
  &lt;/p&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/gpt-5-and-bending-the-arc-of-progress#footnote-anchor-1-170388404&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     The idea that people will buy more of a cheaper thing, resulting in more total usage.
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> gpt-oss: OpenAI validates the open ecosystem (finally) </title>
<link>https://www.interconnects.ai/p/gpt-oss-openai-validates-the-open</link>
<pubDate>Tue, 05 Aug 2025 17:24:09 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   OpenAI released two open-weight, text-only reasoning models today, both mixture of experts (MoE) sized to run efficiently on a range of hardware from consumer GPUs to the cloud. These models have the Apache 2.0 license, so they’re available for distillation into other reasoning models, deployment into commercial products, and are free of downstream restrictions. These two models, the smaller gpt-oss-20B with 3.6B active parameters and 21B total and the larger gpt-oss-120B with 5.1B active parameters,  follow the trends we’ve seen with the other leading open models in architecture choices.
  &lt;/p&gt;
  &lt;p&gt;
   Where this release shines is in the dramatic change in open model performance and strategy that comes with the leading name in AI releasing an open model that undercuts some of their own API products.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    We’ll get to the technical details on the model later, but the main point of this post is how much OpenAI has changed by releasing their first open language model since GPT-2. The larger 120B model “achieves near-parity with OpenAI o4 mini on core reasoning benchmarks‬” and is a major moment for the ecosystem:
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/gpt-oss-openai-validates-the-open#footnote-1-170127813&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     1
    &lt;/a&gt;
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      OpenAI has released an open model at the frontier of current open model performance — highlighting how
     &lt;/span&gt;
     &lt;strong&gt;
      major concerns over open models that OpenAI leadership mentioned in 2023 were overblown
     &lt;/strong&gt;
     &lt;span&gt;
      . The marginal risks of open models have been shown to not be as extreme as many people thought (at least for text only — multimodal is far riskier). Once other organizations, particularly Meta and China showed OpenAI that there was no risk here, the path was opened to release a model.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      OpenAI has revealed far more of their technical stack than any release to date.
     &lt;/strong&gt;
     &lt;span&gt;
      This blog post has light details on many things in the model, but community tinkering will begin to better understand what is going on here. This includes basic things like our first time seeing a raw chain of thought (CoT) for an OpenAI reasoning model, but also more interesting things like how this model is trained to use tools in the CoT like their o3 model. Other details include researchers being able to play with OpenAI’s
     &lt;/span&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2404.13208&quot; rel=&quot;&quot;&gt;
      instruction hierarchy
     &lt;/a&gt;
     &lt;span&gt;
      in raw weights (where pieces of it are untouchable in the API), a new “harmony” prompt format, the same “reasoning efforts” of low, medium &amp; high from the API,  a huge proof of concept on how far basic, community standard architectures with MoEs can be pushed, and other small details for the AI community to unpack.
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      OpenAI has initiated a scorched earth policy on the API market
     &lt;/strong&gt;
     &lt;span&gt;
      , undercutting their own offerings and unleashing an extremely strong, trusted model brand with a permissive license. While adoption of any open model is much slower than an API due to testing, additional configuration, etc., this is set up to go about as fast as it can. Any API model that competes with current models like OpenAI o4 mini, Claude Haiku, Gemini Flash, DeepSeek R1 etc. are all going to have to compete with this model.
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      OpenAI’s o4 mini model is currently served at $1.1 per million input tokens and $4.4 per million output. Serving this open model will likely cost at least 10x less. There are many potential strategic reasons for this, all of which paint OpenAI as having a clearer vision of what makes it valuable.
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      What OpenAI hasn’t touched with this model is interesting too — “For those seeking multimodal support, built-in tools, and‬ seamless integration with our platform, models available through our API platform remain the‬ best option.” These are dropped for reasons above, and “headaches” discussed later in the post.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   Together, these paint a much clearer vision by OpenAI on how they’ll control the AI ecosystem. The top potential reasons on my mind are:
  &lt;/p&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     OpenAI could be trying to make all API models potentially obsolete on cost ahead of the GPT-5 release, which they hope to capture the top end of the market on. Or,
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     OpenAI could be realizing that models are no longer their differentiation, as ChatGPT users continue to steadily climb — and they’ll soon pass 1 billion weekly actives.
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;p&gt;
   There are plenty of other reasons, such as the politics alluded to at the end of the blog post, but OpenAI tends to only act when it serves them directly — they’ve always been a focused company on their goals.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/gpt-oss-openai-validates-the-open?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:&quot;button-wrapper&quot;}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/gpt-oss-openai-validates-the-open?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   There’s also a long list of head scratchers or in-between the lines points that illuminate OpenAI’s strategy a bit more. OpenAI of course didn’t release training data, code, or a technical report, as expected. OpenAI is trying to make a big splash with the name that captures more of the enterprise market, but in doing so takes some collateral damage in the research and true “open source” AI communities. These future questions include:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      The naming is bad
     &lt;/strong&gt;
     &lt;span&gt;
      — a mixture of cringe, confusion-inducing, and still useful for their marketing goals. For anyone following
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/t/open-source&quot; rel=&quot;&quot;&gt;
      open-source AI
     &lt;/a&gt;
     &lt;span&gt;
      for a long time it won’t be new that a major company is blurring the association of the term open-source with the community accepted
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/defining-open-source-ai&quot; rel=&quot;&quot;&gt;
      definitions
     &lt;/a&gt;
     &lt;span&gt;
      . I understand why OpenAI did this, but the naming conflict further enforces that the true open source AI community isn’t the target of this release — it’s people that want to try an “open source AI model” for their business, and OpenAI has made the target too big to miss for enterprises.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      OpenAI did not release the base models
     &lt;/strong&gt;
     &lt;span&gt;
      . Anyone following the space would’ve expected this, but it matters substantially for researchers. These two sparse, low numerical precision MoE models won’t be easy for researchers to use. The best model for researchers and tinkerers are dense, base models from 1 to 7 billion parameters. These are much “longer term” artifacts in the open community that will still be using almost only Qwen.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   &lt;span&gt;
    I need to take a second before the “unknowns” section and comment on the architecture. These models are reinforcing trends we’re seeing in modeling across the industry. Recent frontier open models are
   &lt;/span&gt;
   &lt;em&gt;
    all
   &lt;/em&gt;
   &lt;span&gt;
    very sparse MoEs inspired by the
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2412.19437v1&quot; rel=&quot;&quot;&gt;
    DeepSeek architecture
   &lt;/a&gt;
   &lt;span&gt;
    . DeepSeek V3 had 37B active and 671B total parameters.
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/kimi-k2-and-when-deepseek-moments&quot; rel=&quot;&quot;&gt;
    Kimi K2
   &lt;/a&gt;
   &lt;span&gt;
    had 32B active and 1T total parameters. With 5B active and 121B total, the sparsity factor fits right in with normal. Sparsity in MoEs is totally king right now. The smaller gpt-oss is a bit less sparse than
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/qwen-3-the-new-open-standard&quot; rel=&quot;&quot;&gt;
    Qwen’s
   &lt;/a&gt;
   &lt;span&gt;
    3B active, 30B total smaller MoE, but expect the sparsity of these models to continue to increase.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Some things we need more testing to know the impact of include:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      The model has been quantized for release
     &lt;/strong&gt;
     &lt;span&gt;
      to MXFP4 (4 bit floating point). It’s not clear exactly who will be impacted here, but this could make it benefit people most with the newest hardware, cause minor issues across Torch/Cuda versions, or even make some of the behaviors weird relative to the trained version internal to OpenAI.
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      This could also be a plus, depending on performance, as the bigger model is quantized to 4 bit precision to enable it to be run on GPUs with 80GB of memory, such as the A/H100 line from NVIDIA.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Safety measures have been taken to change how finetunable the model is
     &lt;/strong&gt;
     &lt;span&gt;
      . With, or soon after, this release OpenAI is releasing a research paper on new methods to make it so you can’t “
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/undoing-rlhf&quot; rel=&quot;&quot;&gt;
      finetune the safety away
     &lt;/a&gt;
     &lt;span&gt;
      ” from a released instruct model. This is a very long-standing issue that people have concerns with over releasing open models. The main question here is if the models OpenAI releases are still able to be finetuned or not for productive use-cases. OpenAI claims they can be in their blog post, but this will be left up to the community to decide. Is finetuning the safety away actually a feature of an easy to use model?
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      For example, Gemma has been tougher for people to finetune historically because it uses a different attention implementation and has a different parameter space from being
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/i/145870222/are-gemini-flash-and-claude-haiku-distilled&quot; rel=&quot;&quot;&gt;
      distilled
     &lt;/a&gt;
     &lt;span&gt;
      . Open finetuning stacks are still tuned for Llama and Qwen — this takes a long time to change.
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      Many people will take the “we made it impossible to un-censor this model” as a challenge, which will be interesting to follow in the jailbreaking research community. There is a substantial market for modifiable models.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      The model was trained to expect tools, but open model tool use is a mess
     &lt;/strong&gt;
     &lt;span&gt;
      . One of the biggest problems I worry about in designing an OLMo model with native o3-style tool use is that I need to make it seamless for users to use the same tools from training time at inference time. An early tester in my network mentioned that the model would hallucinate tool calls from training (sort of like what was mentioned around
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/openais-o3-over-optimization-is-back&quot; rel=&quot;&quot;&gt;
      o3’s full release
     &lt;/a&gt;
     &lt;span&gt;
      ). I don’t expect this to be an unsolvable issue, but it could slow adoption. It could also allow people to reverse engineer the tools that OpenAI uses during training, we’ll see!
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      We need to re-benchmark the model on open infrastructure
     &lt;/strong&gt;
     &lt;span&gt;
      . OpenAI did a good job for this release integrating it everywhere, but we need to confirm that the community can
     &lt;/span&gt;
     &lt;em&gt;
      easily
     &lt;/em&gt;
     &lt;span&gt;
      replicate their evaluation scores.
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/building-on-evaluation-quicksand&quot; rel=&quot;&quot;&gt;
      Evaluation at closed labs
     &lt;/a&gt;
     &lt;span&gt;
      has increasingly become bespoke to suit their internal needs, which is a logical decision, but this comes at a cost of friction when an open model is released.
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      This is me saying loud and clear that this isn’t a model performance review in a nuanced sense, but a summary of the importance of OpenAI’s approach (and where the opportunity is for the rest of us). Not all good models are easy to use. Some models benchmark well and are useful — e.g. Qwen. Some models benchmark well and are forgotten. Regardless of scores, I expect this to be a useful model.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   &lt;span&gt;
    Overall, I would give OpenAI a very strong grade on their first open release in a while — they definitely listened to the
   &lt;/span&gt;
   &lt;a href=&quot;https://natolambert.substack.com/p/some-thoughts-on-openai-returning&quot; rel=&quot;&quot;&gt;
    feedback
   &lt;/a&gt;
   &lt;span&gt;
    given by the community. The path to earning goodwill with the open community, especially with researchers, is to embrace more risk in making models that are easier to modify (and potentially even more revealing), such as the base models for these checkpoints.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Open models from the U.S. labs were in such a dire spot that we need any step back in the right direction. As the rollout of the model begins and we have more understanding of it, we’ll include more updates on Interconnects, such as in the next
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/t/artifacts-log&quot; rel=&quot;&quot;&gt;
    Artifacts Log
   &lt;/a&gt;
   &lt;span&gt;
    issue.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So, OpenAI is the new open champion, right? There’s no more risk vis-a-vis China? We don’t need Llama anymore? Not quite, let me explain.
  &lt;/p&gt;
  &lt;h2&gt;
   OpenAI, ATOM, and national champions
  &lt;/h2&gt;
  &lt;p&gt;
   It’s a phenomenal step for the open ecosystem, especially for the West and its allies, that the most known brand in the AI space has returned to openly releasing models. This is momentum and could be the start of the turning point of adoption and impact of open models relative to China.
  &lt;/p&gt;
  &lt;p&gt;
   The open ecosystem moves fast in some ways and slow in others. Many workflows and expertise is now built on Qwen models due to their frequent, accessible releases. Some of these will try OpenAI the next time they want to make a change, but it’s far from the fact that everyone will immediately switch to OpenAI’s model now that it’s out.
  &lt;/p&gt;
  &lt;p&gt;
   To me, OpenAI dropping a strong model has switched the second derivative on the open model scales. The U.S. and its allies will no longer be falling further and further behind, which was the main story of 2025, but we need to build on this momentum if we want to have competitive open models for all use cases in the order of months rather than years.
  &lt;/p&gt;
  &lt;p&gt;
   There’s a lot of uncertainty in the incentives for open models. Some of the best China analysts I know share how China is sensing that releasing open models is a successful strategy for them and are doubling down. This is a very reasonable take. The retort is that if we use it as a weakness of the American ecosystem that it is so reliant on Meta’s Llamas, or now GPT OSS, the same could happen for Qwen. So then, what happens if Alibaba decides Qwen’s stellar releases no longer serve them?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    In this case, there would be a large opportunity in the series of small models from 1 to 70B parameters, but there’s so much competition from China at the larger scales. These are currently the big mixture of experts (MoE) models like DeepSeek V3/R1,
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/zai-org/GLM-4.5&quot; rel=&quot;&quot;&gt;
    Z.ai’s / Zhipu’s GLM 4.5
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/kimi-k2-and-when-deepseek-moments&quot; rel=&quot;&quot;&gt;
    Kimi K2
   &lt;/a&gt;
   &lt;span&gt;
    , and so on. China has more models that are close to this performance level, such as
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/collections/MiniMaxAI/minimax-m1-68502ad9634ec0eeac8cf094&quot; rel=&quot;&quot;&gt;
    MiniMax
   &lt;/a&gt;
   &lt;span&gt;
    or
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/tencent/Tencent-Hunyuan-Large&quot; rel=&quot;&quot;&gt;
    Tencent
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   All of these companies have uncertainty, but there’s a strength in numbers that reinforces standard practice and sets standards. Releasing strong, large, open models is now the standard in China. We’re back in the precarious period of establishing standards for American companies, who are exposed to the legal risk of not being able to un-release models with many open lawsuits, such as in areas like copyright.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    These two sides of the open ecosystem are at very different stages and need very different actions. In many ways, we shared
   &lt;/span&gt;
   &lt;a href=&quot;https://www.atomproject.ai/&quot; rel=&quot;&quot;&gt;
    The ATOM Project
   &lt;/a&gt;
   &lt;span&gt;
    when we did because we could tell this was a local (and hopefully global) minimum in terms of the distance between Western contributions to the open science of AI compared to any point in the recent past and near future.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    OpenAI’s release is a step in the right direction, but it is still a precarious position. Many people make noise about creating open models, from the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/the-white-houses-plan-for-open-models&quot; rel=&quot;&quot;&gt;
    AI Action Plan
   &lt;/a&gt;
   &lt;span&gt;
    to
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/martin_casado/status/1952442509600366708&quot; rel=&quot;&quot;&gt;
    venture capitalists
   &lt;/a&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;a href=&quot;https://www.deeplearning.ai/the-batch/issue-312/&quot; rel=&quot;&quot;&gt;
    academics
   &lt;/a&gt;
   &lt;span&gt;
    . What all of these parties have in common is that its not their number one goal. The goal of The ATOM Project is to give an outlet for people like myself that want to make this project their number one priority.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   This is why we need to keep nurturing entrants into the open model space that are releasing their best models there. It is what made the early versions of Llama great, and is what will be the defining factor of the outputs of ATOM. Models that are designed from first principles to be modifiable, interpretable, and extendable is what will enable a new decade of AI research to be born. This needs base models, training details, convenient sizes, and other little details that are missing from many recent open model releases, including OpenAI’s.
  &lt;/p&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/gpt-oss-openai-validates-the-open#footnote-anchor-1-170127813&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     &lt;span&gt;
      OpenAI has made other exceptional model releases including
     &lt;/span&gt;
     &lt;a href=&quot;https://openai.com/index/whisper/&quot; rel=&quot;&quot;&gt;
      Whisper
     &lt;/a&gt;
     &lt;span&gt;
      for speech recognition or
     &lt;/span&gt;
     &lt;a href=&quot;https://openai.com/index/clip/&quot; rel=&quot;&quot;&gt;
      CLIP
     &lt;/a&gt;
     &lt;span&gt;
      for image-to-text embeddings.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Towards American Truly Open Models: The ATOM Project </title>
<link>https://www.interconnects.ai/p/atom-project</link>
<pubDate>Mon, 04 Aug 2025 14:09:16 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    I’m very excited to share a substantial project on invigorating investment in open language models and AI research in the U.S.
   &lt;/span&gt;
   &lt;a href=&quot;https://www.atomproject.ai/&quot; rel=&quot;&quot;&gt;
    The ATOM (American Truly Open Models) Project
   &lt;/a&gt;
   &lt;span&gt;
    is the mature evolution of my original “
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/the-american-deepseek-project&quot; rel=&quot;&quot;&gt;
    American DeepSeek Project
   &lt;/a&gt;
   &lt;span&gt;
    ” and I hope it can help be a turning point in the current trajectory of losing open model relevance vis-a-vis China, and even the rest of the world.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I’ve included the full text below, but I encourage you to visit the website for the full version with added visuals, data, and a place to sign your support. This is a community movement, rather than me fundraising, starting an organization, or anything like that
  &lt;/p&gt;
  &lt;p&gt;
   If you can help get the word out and or sign your support, I’d greatly appreciate it.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.atomproject.ai/&quot;,&quot;text&quot;:&quot;Read More on ATOM&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.atomproject.ai/&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Read More on ATOM
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    (Or watch a
   &lt;/span&gt;
   &lt;a href=&quot;https://youtu.be/fC521st5JLY&quot; rel=&quot;&quot;&gt;
    5 minute overview on YouTube
   &lt;/a&gt;
   &lt;span&gt;
    )
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;hr/&gt;
  &lt;/div&gt;
  &lt;h1&gt;
   The ATOM Project: Towards fully open models for US research &amp; industry
  &lt;/h1&gt;
  &lt;h2&gt;
   Reinvigorating AI research in the U.S. by building leading, open models at home
  &lt;/h2&gt;
  &lt;p&gt;
   America&#x27;s AI leadership was built by being the global hub and leading producer of open AI research, research which led directly to innovations like the Transformer architecture, ChatGPT, and the latest innovations in reasoning models and agents. America is poised to lose this leadership to China, in a period of geopolitical uncertainty and rising tensions between these two nations. America&#x27;s best AI models have become more closed and restricted, while Chinese models have become more open, capturing substantial market share from businesses and researchers in the U.S. and abroad.
  &lt;/p&gt;
  &lt;p&gt;
   Open language models are becoming the foundation of AI research and the most important tool in securing this leadership. America has lost its lead in open models – both in performance and adoption – and is on pace to fall further behind. The United States must lead AI research globally, and we must invest in making the tools our researchers need to do their job here in America: a suite of leading, open foundation models that can re-establish the strength of the research ecosystem.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Recommendation: To regain global leadership in open source AI, America needs to maintain at least one lab focused on training open models with 10,000+ leading-edge GPUs.
   &lt;/strong&gt;
   &lt;span&gt;
    The PRC currently has at least five labs producing and releasing open models at or beyond the capabilities of the best U.S. open model. Regaining open source leadership is necessary to drive research into fundamental AI advances, to maximize U.S. AI market share, and to secure the U.S. AI stack.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h2&gt;
   Overview
  &lt;/h2&gt;
  &lt;p&gt;
   Open language model weights and data are the core currency of recent AI research – these are the artifacts that people use to come up with new architectures, training paradigms, or tools that will lead to the next paradigms in AI to rival The Transformer or Inference-time Scaling. These research advances provide continued progress on existing products or form the basis for new technology companies. At the same time, open language models create potential for a broader suite of AI offerings by allowing anyone to build and modify AI how they see fit, without their data being sent through the cloud to a few, closed model providers.
  &lt;/p&gt;
  &lt;p&gt;
   Open language models are crucial for long-term competition within American industry. Today, substantial innovation is happening inside of large, closed AI laboratories, but these groups can only cover so many of the potential ideas. These companies spend the vast majority of their resources focusing on the next model they need to train, where the broader, open research community focuses on innovations that’ll be transformative in 2, 5, 10, or more years. The most progress in building useful, intelligent AI systems will come when the most people can participate in improving today&#x27;s state-of-the-art, rather than the select few at certain companies.
  &lt;/p&gt;
  &lt;p&gt;
   The open AI ecosystem (regarding the models, not to be confused with the company OpenAI) has historically been defined by many parties participating. The United States emerged as a hub of the deep learning revolution via close collaboration between leading technology companies and academic institutions. Following ChatGPT, there have been countless contributions from around the globe. This distribution of impact on research has been collapsing towards clear Chinese leadership due to their commitment to open innovation, while a large proportion of leading scientists working in the United States have joined closed research organizations.
  &lt;/p&gt;
  &lt;p&gt;
   The playbook that led Google to invent and share the Transformer – the defining language model architecture of which all leading models such as ChatGPT, Gemini, or Claude are derived from – is now the standard mode of operation for Chinese companies, but it is increasingly neglected by American companies.
  &lt;/p&gt;
  &lt;p&gt;
   The impact of China’s models and research are growing because the institutions focused on open models have access to substantial compute resources for training – e.g. some have formed a close relationship between leading AI training laboratories and academic institutions. Until the United States and its partners directly invest in training more, higher performance open models and sharing the processes to do so, its pace of progress in AI research will lag behind.
  &lt;/p&gt;
  &lt;p&gt;
   To train open models at the frontier of performance, a developer currently needs a high concentration of capital and talent. We estimate that to lead in open model development, the United States needs to invest in multiple clusters of 10,000+ H100 level GPUs to create an ecosystem of fully open language models that are designed to enable a resurgence in Western AI research. Stacking large investments such as this into a few focused efforts will help them to learn from each other and make progress across a range of challenges quickly and robustly. Splitting such an investment in AI training into smaller, widespread projects will not be sufficient to build leading models due to a lack of compute concentration. Along the way we need to build models of various sizes that can enable applications of AI at every scale from local or edge devices all the way to high performance cloud computing.
  &lt;/p&gt;
  &lt;h2&gt;
   Open models as the engine for AI research and development
  &lt;/h2&gt;
  &lt;p&gt;
   America&#x27;s AI leadership was built by tens of thousands of our best and brightest students, academics and researchers. This process occurred over decades, but it is faltering at a crucial transition point to the new, language modeling era of AI research. Since the release of ChatGPT, open language models and computational resources are the most important table stakes for doing relevant and impactful research. High-quality open models and their subsequent technical reports quickly accrue thousands of citations and accolades such as best paper awards and the focus of large swaths of students. These act as foundational currencies of AI research and are crucial, achievable artifacts for the long-term American AI ecosystem.
  &lt;/p&gt;
  &lt;p&gt;
   While many direct consumers of open models are academics, this community is far from the only group that will benefit immensely from a new wave of American open models. The low cost, flexibility, and customizability of open models makes them ideal for many use cases, including many of the ways that AI stands to advance and transform businesses large and small.
  &lt;/p&gt;
  &lt;p&gt;
   If the United States does not create its own leading open models, the focus of American researchers and businesses will continue to shift abroad. The benefits of openly sharing a technology accrue to the builder in mindshare and other subtle soft power dynamics seen throughout the history of open source software. Today, these benefits are accruing elsewhere due to the intentional support of open models by many Chinese organizations. The gap in performance and adoption will only grow as the American ecosystem sees strong open models as something that is nice to have, or an afterthought, rather than a key long-term priority.
  &lt;/p&gt;
  &lt;p&gt;
   China is adopting the playbook for open innovation of language models that the United States used to create its current AI leadership, yielding rapid innovation, international adoption, and research interest. The collapse of American dominance in AI research is driven not only by the remarkable quality of the Chinese ecosystem, but also by the commitment of China to these very same Open Model Principles - the principles that American scientists used to start this AI revolution. This is reflected further in a consistent trend of Chinese open models being released with more permissive terms of use than their American counterparts.
  &lt;/p&gt;
  &lt;p&gt;
   The many leading closed research institutions in the United States are still creating world-class models – and the work they do is extraordinary. This collapse is not their fault, but closed labs make closed research, and the acceleration of AI was built on open collaboration with world-class American models as the key tool.
  &lt;/p&gt;
  &lt;p&gt;
   As researchers, our focus is on leading the research and development for the core technology defining the future, but there is also a growing list of other urgent security and policy concerns facing our nation around the lack of strong open models. To start, adoption of open models from the PRC in the US and our allies has been slow in some sectors due to worries about backdoors or poor security in generated code. Similarly, there is concern over the outputs of these Chinese models being censored or inconsistent with everyday American values of freedom, equality, and independence. There are even parallels between how the PRC’s national AI champions are increasingly racing to release cheap and open AI models and the PRC’s historical practice of dumping state-subsidized, below-cost exports from China to undermine American competitors. With the dynamic and rapid evolution of this technology, we need to get ahead of these issues before stronger habits, cost disadvantages, or other incentives reduce the practicality of adopting American open models.
  &lt;/p&gt;
  &lt;h2&gt;
   America&#x27;s lost lead in open model performance
  &lt;/h2&gt;
  &lt;p&gt;
   On countless benchmarks, the leading American models have fallen behind counterparts from Chinese companies. In July 2024, American models in the form of Llama 3 had leading performance over any openly available Chinese models. Since then, a growing number of Chinese open model providers have surpassed and widened the performance gap with the leading American open models.
  &lt;/p&gt;
  &lt;p&gt;
   The leading American open models are Meta&#x27;s Llama and Google&#x27;s Gemma models. The Chinese open models from DeepSeek and Alibaba&#x27;s Qwen have traded off positions at the frontier of capabilities ahead of their American counterparts. However, the Chinese ecosystem is expanding rapidly, with new players such as Moonshot AI (Kimi), Zhipu AI, or Tencent close behind.
  &lt;/p&gt;
  &lt;p&gt;
   We consider two popular public, aggregate benchmarks to demonstrate the state of China’s current open model dominance. These represent crowdsourced rankings, LMArena, and comprehensive intelligence rankings by blending a variety of capability benchmarks, from ArtificialAnalysis. The pace of progress on these Pareto frontiers is only part of the equation. In addition to leading, the top 10 open models on LMArena are all created by Chinese organizations. For ArtificialAnalysis rankings, the top 3 open models are of Chinese origin as of publishing on August 4th, 2025.
  &lt;/p&gt;
  &lt;h3&gt;
   The isolation of Meta&#x27;s Llama
  &lt;/h3&gt;
  &lt;p&gt;
   Meta CEO Mark Zuckerberg has been one of the few clear advocates for the long-term imperative of America building open models. Since the release of ChatGPT, this has been manifested by Meta&#x27;s Llama series of models – these had long been the definitional open models that served as the basis for research and product development in 2023 and 2024. This basis for research is established by releasing a suite of strong models across a variety of sizes. The original LLaMA family came with models of 7, 13, 32, and 65B parameters, which quickly became defaults of the research community based on convenient factors of them fitting on certain popular GPUs for finetuning or inference.
  &lt;/p&gt;
  &lt;p&gt;
   For a first instance showcasing the gap in adoption, the Qwen 1.5 family of 8 models was released shortly after the Llama 2 family of four comparably sized models in the summer of 2023. An analysis of cumulative model downloads shows the Llama 2 models being downloaded about 500% of that of early Qwen models (a difference of 10M versus 60M total downloads with half of the models), highlighting the original state of play in the open ecosystem – a large lead for American models.
  &lt;/p&gt;
  &lt;p&gt;
   Llama 3 continued this trend with a series of models across 2024. Pieces of the Llama 3 family (and its various versions in Llama 3.1 and 3.2) are some of the most popular models ever in HuggingFace’s history as the leading distributor of open models. At the same time, the newer Qwen models from Alibaba, this time the Qwen 2.5 suite of 2024, showed substantially closer adoption numbers to Meta’s Llamas – a lead of only 20 million cumulative downloads for Llama 3 over the Qwen 2.5 suite with both of them crossing over 120M total downloads.
  &lt;/p&gt;
  &lt;p&gt;
   Llama’s lead was built on a combination of strong performance and existing distribution channels. This success came in spite of a restrictive license – the contract between the open artifact’s creator and the downstream user – that can require nuanced legal consideration about if a particular use-case is compliant. Meanwhile, Qwen and other Chinese models have adopted simpler licenses drawing on historical practices in open-source software (OSS), removing another barrier to uptake on their models.
  &lt;/p&gt;
  &lt;p&gt;
   Meta has effectively been a singular horse in this race. As language models were established as a core technology, competition has arrived. Between the last releases of Llama 3 and the arrival of Llama 4, the landscape of open models changed substantially with the arrival of DeepSeek’s permissively licensed, frontier models in DeepSeek V3 and DeepSeek R1. Now, Meta was effectively alone in releasing its best models regularly and expected to compete with Qwen making large families of models great at any size scale and DeepSeek releasing open frontier models. Both types of models are crucial to the health of the ecosystem, but they can take slightly different foci to get right.
  &lt;/p&gt;
  &lt;p&gt;
   China today has 5 amazing open labs, a number which is growing, and America has Meta as its open models champion. We are running Meta in a race against 5 other Chinese runners, and then complain when it doesn&#x27;t win every race every time. Our problem is not Llama 4 being not state-of-the-art; our problem is running a solo athlete against a team built with an ecosystem to support its growth.
  &lt;/p&gt;
  &lt;h3&gt;
   Chinese open models are taking the all-time lead in adoption
  &lt;/h3&gt;
  &lt;p&gt;
   The available data showcasing adoption of open language models – how much models are downloaded and how much base models are modified for new uses – shows that China has taken the lead in recent adoption and will soon take the lead in all-time adoption.
  &lt;/p&gt;
  &lt;p&gt;
   We collected historical, daily download data from 6 of the leading open model providers across the world – Meta, Google, Mistral AI, Microsoft, Alibaba Qwen, and DeepSeek AI. Grouping by locality we can see America’s early lead with Llama, Europe’s surge with Mistral’s early viral releases almost surpassing the U.S. in April of 2024, and a consistent acceleration from the Chinese providers until they’re surpassing the U.S. this summer. As of August 2025, the leading U.S. and Chinese models both have around 300M total downloads on HuggingFace with the Chinese rate of growth being notably higher. The growth rate for European models has remained lower, with their cumulative downloads reaching around 100M today.
  &lt;/p&gt;
  &lt;p&gt;
   An important benefit of open models is the ability to finetune them, a process to adapt a given model to a specific purpose. This process is at the heart of academic research and important for businesses to shape a given model to their individual needs. While there are more cumulative derivatives of American models at the moment, Chinese models are gaining momentum, especially this year.
  &lt;/p&gt;
  &lt;p&gt;
   Early in 2024, Chinese models accounted for 10-30% of the new finetuned models appearing on HuggingFace. Today, derivatives of Alibaba’s Qwen models account for more than 40% of the language models appearing on HuggingFace month over month (the overall picture is quite similar to the downloads data) – and that is just one of China’s leading open model laboratories. Meta’s share of derivatives with the Llama models has dropped from a peak of nearly 50% in the fall of 2024 down to only 15% today. With far fewer open model options appearing from the U.S. or Europe, the proportion of Chinese models in the AI ecosystem is expected to continue to rise.
  &lt;/p&gt;
  &lt;h2&gt;
   What the ecosystem needs
  &lt;/h2&gt;
  &lt;p&gt;
   We can fix this. America has the talent, compute, and capital to lead open model development – we just need to get them to the right place.
  &lt;/p&gt;
  &lt;p&gt;
   The tone for change is well represented by the White House&#x27;s recent AI Action Plan, which paints a much clearer vision for the benefits of innovation and adoption globally to far outweigh the current measured risks. This represents an inflection point in the perception of open models, especially in the United States, but we still have a long way to go to support this vision with artifacts and actions.
  &lt;/p&gt;
  &lt;p&gt;
   The United States has a thriving AI research community, but it is missing the models that it itself has created and has complete knowledge of in order to create clear, and rapid progress. For example, the area of research with the most excitement following recent reasoning models is reinforcement learning with verifiable rewards (RLVR). This research has largely been performed on Alibaba&#x27;s Qwen models from China due to their strong performance across math, code, and STEM benchmarks.
  &lt;/p&gt;
  &lt;p&gt;
   There are two categories of truly open models that we need in order to lead on all metrics of open models defined by how AI is studied and used. Both are essential and complement each other and the rest of a leading AI ecosystem. The best outcome is when these are accompanied by training data, intermediate checkpoints, base models, training code, and permissive licenses accepted as standards for free use by the AI community. These models with everything released, currently less common across the industry, are known as “open source models” to clearly note the benefits that come with more knowledge of how it was built.
  &lt;/p&gt;
  &lt;p&gt;
   First, we need leading open models at the frontier of performance. These should be the best models in the world and can be complementary to offerings from the leading closed AI models built in America, offering cheaper costs and more modifiability. The fundamental insight driving the recent rapid buildout of AI training infrastructure is the idea of scaling laws – this applies to open and closed models alike. The ballpark of scale needed to reach the leading edge of performance today is 200 to 600+ billion parameters with a mixture of experts (MoE) architecture – a size range used for all the leading open models from the U.S. and China in 2025 that challenge the best closed models on intelligence benchmarks.
  &lt;/p&gt;
  &lt;p&gt;
   With these leading models, we need a family of related models across a variety of sizes to allow every application and direction of study to be addressed. This is a standard adapted by leading open model suites from the U.S. and China alike. Only the most challenging tasks need the largest models, and for the rest of the tasks facing AI there needs to be tools to understand the minimum model size to solve certain simple tasks. A distribution of model sizes from those that can run on your iPhone to those that are assisting with the hardest intellectual work and everything in between creates maximum opportunity to advance and integrate AI broadly.
  &lt;/p&gt;
  &lt;p&gt;
   The entry point to train models of this size distribution is a cluster of compute on the order of 10,000+ leading GPUs. It is standard for top models to be trained with small teams of fifty to a few hundred people. A famous number on the cost of training frontier AI models from earlier this year was the often quoted $5 million figure for DeepSeek V3 – this is misleading on what it actually takes to develop these models, and the authors of the DeepSeek technical report acknowledged so much. 10,000 GPUs provide an entry point for rapid iteration concurrent to large-scale training.
  &lt;/p&gt;
  &lt;p&gt;
   America should target having multiple centers producing excellent open models. This serves to de-risk progress on training these models, given the urgency of the mission, but will also allow for a more diverse set of artifacts and for the research groups to learn from each other without first making the training organizations so large that progress is slowed.
  &lt;/p&gt;
  &lt;p&gt;
   There are many avenues to obtain and allocate these resources across multiple stakeholders. We need to engage across private companies, philanthropic institutions, and government agencies. Programs such as the National AI Research Resource (NAIRR) are important for broadening access to resources related to AI research including compute, data, software, and models, but these ecosystem-wide solutions are not enough to create breakthrough models as China is with concentrated bets. We need immediate, targeted interventions that can deliver frontier open models within 6-12 months, not years.
  &lt;/p&gt;
  &lt;p&gt;
   As many organizations around the world create strong AI models, it is becoming clearer that with the right compute and talent, strong models can follow. The formula we must follow is delivering these resources with the directive to release the models openly, then we can solidify American AI leadership. Every stakeholder – from tech giants to philanthropies to federal agencies to researchers and engineers – must ask themselves: Are we funding or participating in the future of AI research, or are we ceding it to competitors who understand that open models are the foundation of AI supremacy?
  &lt;/p&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Interviewing Ross Taylor on the state of AI: Chinese open models, scaling reasoning, useful tools, and what comes next </title>
<link>https://www.interconnects.ai/p/interviewing-ross-taylor-on-the-state</link>
<pubDate>Tue, 29 Jul 2025 13:35:43 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    I’m excited to welcome Ross Taylor back on the podcast (and sorry for the lack of episodes in general – I have a lot going on!). The
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/interviewing-ross-taylor-on-llm-reasoning&quot; rel=&quot;&quot;&gt;
    first time
   &lt;/a&gt;
   &lt;span&gt;
    Ross came on we focused on reasoning – before inference-time scaling and that sort of RL was popular, agents, Galactica, and more from his Llama days. Since then, and especially after DeepSeek R1, Ross and I have talked asynchronously about the happenings of AI, so it’s exciting to do it face to face.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   In this episode we cover some of everything:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     Recent AI news (Chinese models and OpenAI’s coming releases)
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     “Do and don’t” of LLM training organizations
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Reasoning research and academic blind spots
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Research people aren’t paying enough attention to
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Non language modeling news &amp; other topics
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/interviewing-ross-taylor-on-the-state?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/interviewing-ross-taylor-on-the-state?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Listen on
   &lt;/span&gt;
   &lt;a href=&quot;https://podcasts.apple.com/us/podcast/interconnects-audio/id1719552353&quot; rel=&quot;&quot;&gt;
    Apple Podcasts
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://open.spotify.com/show/2UE6s7wZC4kiXYOnWRuxGv&quot; rel=&quot;&quot;&gt;
    Spotify
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.youtube.com/@interconnects&quot; rel=&quot;&quot;&gt;
    YouTube
   &lt;/a&gt;
   &lt;span&gt;
    , and
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/podcast&quot; rel=&quot;&quot;&gt;
    where ever you get your podcasts
   &lt;/a&gt;
   &lt;span&gt;
    . For other Interconnects interviews,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/t/interviews&quot; rel=&quot;&quot;&gt;
    go here
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div data-attrs=&#x27;{&quot;videoId&quot;:&quot;Kn0xgijnmz8&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}&#x27; data-component-name=&quot;Youtube2ToDOM&quot;&gt;
   &lt;div&gt;
    &lt;iframe allow=&quot;autoplay; fullscreen&quot; allowautoplay=&quot;true&quot; allowfullscreen=&quot;true&quot; frameborder=&quot;0&quot; gesture=&quot;media&quot; height=&quot;409&quot; loading=&quot;lazy&quot; src=&quot;https://www.youtube-nocookie.com/embed/Kn0xgijnmz8?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0&quot; width=&quot;728&quot;&gt;
    &lt;/iframe&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;p&gt;
   Show outline as a mix of questions and edited assertions that Ross sent me as potential topics.
  &lt;/p&gt;
  &lt;h3&gt;
   00:00 Recent AI news
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;em&gt;
    &lt;span&gt;
     Related reading is on
    &lt;/span&gt;
    &lt;a href=&quot;https://www.interconnects.ai/p/kimi-k2-and-when-deepseek-moments&quot; rel=&quot;&quot;&gt;
     Kimi’s K2 model
    &lt;/a&gt;
    &lt;span&gt;
     , thoughts on
    &lt;/span&gt;
    &lt;a href=&quot;https://natolambert.substack.com/p/some-thoughts-on-openai-returning&quot; rel=&quot;&quot;&gt;
     OpenAI’s forthcoming open release
    &lt;/a&gt;
    &lt;span&gt;
     .
    &lt;/span&gt;
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      What did you think of
     &lt;/span&gt;
     &lt;a href=&quot;http://z.ai&quot; rel=&quot;&quot;&gt;
      Z.ai
     &lt;/a&gt;
     &lt;span&gt;
      ’s GLM 4.5 model (including MIT licensed base model) with very strong scores? And Kimi?
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     What will OpenAI’s open model actually be?
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     What do you make of the state of the ecosystem?
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h3&gt;
   12:10 “Do and don’t” of LLM training organizations
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;em&gt;
    &lt;span&gt;
     Related reading is on
    &lt;/span&gt;
    &lt;a href=&quot;https://www.interconnects.ai/p/how-to-manage-ai-training-organizations&quot; rel=&quot;&quot;&gt;
     managing training organizations
    &lt;/a&gt;
    &lt;span&gt;
     or the
    &lt;/span&gt;
    &lt;a href=&quot;https://www.interconnects.ai/p/llama-4&quot; rel=&quot;&quot;&gt;
     Llama 4 release
    &lt;/a&gt;
    &lt;span&gt;
     .
    &lt;/span&gt;
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;p&gt;
   This is one of my favorite topics – I think a lot of great stuff will be written on it in the future. For now, Ross asserts…
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     Most major LLM efforts are not talent-bound, but politics-bound. Recent failures like Llama 4 are org failures not talent failures.
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Most labs are chaotic, changing direction every week. Very different picture from the narrative presented online.
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Most labs represent investment banks or accountancy firms in that they hire smart young people as “soldiers” and deliberately burn them out with extremely long hours.
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h3&gt;
   36:40 Reasoning research and academic blind spots
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;em&gt;
    &lt;span&gt;
     Related reading is
    &lt;/span&gt;
    &lt;a href=&quot;https://arxiv.org/abs/2506.10947&quot; rel=&quot;&quot;&gt;
     two
    &lt;/a&gt;
    &lt;span&gt;
    &lt;/span&gt;
    &lt;a href=&quot;https://arxiv.org/abs/2507.10532v1&quot; rel=&quot;&quot;&gt;
     papers
    &lt;/a&gt;
    &lt;span&gt;
     point questions at the Qwen base models for RL (or a summary
    &lt;/span&gt;
    &lt;a href=&quot;https://www.interconnects.ai/p/reinforcement-learning-with-random&quot; rel=&quot;&quot;&gt;
     blog post
    &lt;/a&gt;
    &lt;span&gt;
     I wrote).
    &lt;/span&gt;
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I start with: What do you think of o3, and search as something to train with RL?
  &lt;/p&gt;
  &lt;p&gt;
   And Ross asserts…
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     Most open reasoning research since R1 has been unhelpful - because not enough compute to see what matters (underlying model and iterations).
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Best stuff has been simple tweaks to GRPO like overlong filtering and removing KL divergence.
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Far too much focus on MATH and code - AIME has tens of samples too so is very noisy.
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     People are generally building the wrong kind of environments - like puzzles, games etc - instead of thinking about what kind of new capabilities they’d like to incentivise emerging.
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h3&gt;
   50:20 Research people aren’t paying enough attention to
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;span&gt;
    The research area I hear the most about right now is “rubrics” – a per-prompt specialized LLM-as-a-judge to replace reward models. SemiAnalysis
   &lt;/span&gt;
   &lt;a href=&quot;https://semianalysis.com/2025/06/08/scaling-reinforcement-learning-environments-reward-hacking-agents-scaling-data/&quot; rel=&quot;&quot;&gt;
    reported
   &lt;/a&gt;
   &lt;span&gt;
    OpenAI scaling this approach and
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2507.17746&quot; rel=&quot;&quot;&gt;
    lots
   &lt;/a&gt;
   &lt;span&gt;
    of
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2507.18624v1&quot; rel=&quot;&quot;&gt;
    great
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2505.13388&quot; rel=&quot;&quot;&gt;
    research
   &lt;/a&gt;
   &lt;span&gt;
    is coming out around it.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I start with: What do you think of the state of RL scaling and generalization? What of models losing
  &lt;/p&gt;
  &lt;p&gt;
   Ross asserts…
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     Rubrics are underhyped on social media - they were driving force behind projects like DeepResearch - and GenRMs are interesting but perhaps slightly overhyped.
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     There is an evals crisis - there are not enough high quality evals, particularly for frontier tasks like automating research and real life work. Impediment to anyone building agents or ASI.
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h3&gt;
   01:02:46 Extra stuff!
  &lt;/h3&gt;
  &lt;p&gt;
   I ask Ross: What AI are you using today? Why?
  &lt;/p&gt;
  &lt;p&gt;
   To conclude, Ross wanted to discuss how AlphaEvolve has been underhyped on social media, and means the future isn’t just RL. Shows there are other effective ways to use inference compute.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   Transcript
  &lt;/h2&gt;
  &lt;p&gt;
   &lt;em&gt;
    Created with AI, pardon the minor typos, not quite enough time this week but I’m hiring someone to help with this soon!
   &lt;/em&gt;
   &lt;span&gt;
    Nathan Lambert: Hey, Ross. How&#x27;s it going? Welcome back to Interconnects. I took a many month break off podcasting. I&#x27;ve been too busy to do all this stuff myself.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yeah, I was trying to think of all the things that happened since the last time we did a podcast a year ago. In AI time, that&#x27;s like two hundred years.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: Yeah, so I was looking at it. We talked about reasoning and o1 hadn’t happened yet.
  &lt;/p&gt;
  &lt;p&gt;
   For a brief intro, Ross was a co-founder of Papers with Code, and that brought him to Meta. And then at Meta, he was a lead on Galactica, which was a kind of language model ahead of its time relative to ChatGPT. So if people don&#x27;t know about Galactica, there&#x27;s a great paper worth reading. And then he was doing a bunch of stuff on reasoning with Llama related to a lot of the techniques that we&#x27;ll talk about in this episode.
  &lt;/p&gt;
  &lt;p&gt;
   And now he&#x27;s doing a startup. I don&#x27;t know if he wants to talk about this, but generally, we talk a lot about various things. This got started through o1 and trying to figure out scaling RL. We started talking a lot but then we also just resonate on a lot of topics on training language models and other fun stuff - and also trying to be one of the few people not in these big labs that tries to talk about this and think about what the heck&#x27;s going on. So we&#x27;re gonna kind of roll through a long list of a lot of things that Ross sent me that he wanted to talk about, but this will be a compilation of the things that we&#x27;ve talked about and fleshing them out outside of the Signal chat.
  &lt;/p&gt;
  &lt;p&gt;
   So, Ross, if you want to introduce yourself more, you can, or we&#x27;ll just start talking about news because I think a lot of people already know you.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yeah, let&#x27;s get into the news. There’s lots of fun things to talk about.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: So, the last two weeks of Chinese models. I think we had Z.ai&#x27;s GLM 4.5 today. Kimi-K2 last week. I think Qwen is on a roll. I thought summer was supposed to be chill but this is crazy.
  &lt;/p&gt;
  &lt;p&gt;
   I haven&#x27;t even used all of these. The pace is just incredible. And all the open models have actually good licenses now. But is this going to hurt anyone in the US? Where do you see this going in six months?
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yeah, so yesterday was the one day I actually tried to turn off Twitter. And so when you told me in the morning about the new GLM model, I had to read up on that. So that shows if you take your eye off Twitter for one second, then you’re behind on open source...
  &lt;/p&gt;
  &lt;p&gt;
   But yes, I think the general theme is that it’s been absolutely relentless. So thinking about the last time I spoke to you on the podcast a year ago, Llama 3 was a fairly established standard.
  &lt;/p&gt;
  &lt;p&gt;
   There were still things happening in the background, if you paid attention to things, but now it&#x27;s absolutely relentless. In the case of China, I think their business culture is that - as soon as they find something is successful - they’re very good at concentrating resources and going after it. So it’s created a very competitive space.
  &lt;/p&gt;
  &lt;p&gt;
   I think the context is very interesting in several different dimensions. There&#x27;s the geopolitical dimension, which you&#x27;ve hinted at in some of your blogs. For example, what does it mean if the open source standard is Chinese? What does that mean if we think about these models not just as things which power products, but as (critical) infrastructure? Then it seems like China has a great advantage if they want to be the standard for the whole Global South.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: Yeah. There are a few things that we&#x27;re going to come back to in this conversation that are so interesting. We&#x27;re gonna roll into what it takes to train these models. And we&#x27;re going to talk about how crazy, political and hard it is in the US. But we have all these orgs popping up in China - so is this partially just a US problem?
  &lt;/p&gt;
  &lt;p&gt;
   But then we also have OpenAI that&#x27;s supposedly going to release a model. There are multiple things. But my question is: why is China doing so well? Are they well suited to training these language models?
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: I’ll caveat what I’m about to say by saying that I want to be careful about making generalisations. Because, for example, we’ve seen some of these new Chinese organisations be good at innovation - for example, this week we had GSPO which was nice. But for Chinese orgs, my general sense is that, once something has already been validated, the specification for what to build has been set, and the task can be reduced to an engineering problem, then Chinese culture is very well set up to succeed in those situations.
  &lt;/p&gt;
  &lt;p&gt;
   The other dimension which has become relevant - especially after DeepSeek - is that the Chinese Government has traditionally been very good at recognising what’s successful, pouring resources in, and facilitating public-private collaborations. I think that surprises people still in the West. For example, people are surprised that a group can come out of Tsinghua can and fairly quickly have their own state-of-the-art LLM. Why isn’t there a similar story for groups coming out of MIT?
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: I’m not sure about this.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: I think the US will eventually wake up to this, but…
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Nathan Lambert: My understanding is that
   &lt;/span&gt;
   &lt;a href=&quot;http://z.ai&quot; rel=&quot;&quot;&gt;
    Z.ai
   &lt;/a&gt;
   &lt;span&gt;
    is a startup that spun out of Tsinghua, so I don’t know if it’s the best comparison. Also Alibaba is the clear winner here because they have Qwen, but they’ve also invested in Moonshot, which is Kimi, and then I think also
   &lt;/span&gt;
   &lt;a href=&quot;http://z.ai&quot; rel=&quot;&quot;&gt;
    Z.ai
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So I’m more interested in the question as to why they are all open. That seems more important relative to talent because there are lots of universities that might have model orgs spinning out of them - even in the US - and it’s not solely a Chinese thing.
  &lt;/p&gt;
  &lt;p&gt;
   I think it could happen with a group out of MIT. That being said, I agree that the US should have more compute deployed for academics and a lot of universities are just spinning them up now. It just takes a long time.
  &lt;/p&gt;
  &lt;p&gt;
   So I think there’s a lot of things that Twitter is mixing up here. There&#x27;s a good tweet in it, but I don&#x27;t think it&#x27;ll be 100% true, which makes for a very viral tweet when it feels true.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yeah, I think there is definitely naivety about how things are actually working (in China). And there’s asymmetric information, in that you don’t truly know what’s going on in the inside of these organisations.
  &lt;/p&gt;
  &lt;p&gt;
   The other thing worth mentioning - which is maybe a separate topic - is that there’s a tendency to see open models as a homogenous category. But there are very different use cases. So if I want to do a new reasoning paper, I’m going to use a Qwen model. But then if I’m doing distillation, I’m going to use DeepSeek or Kimi.
  &lt;/p&gt;
  &lt;p&gt;
   This discussion also relates to OpenAI’s rumored open model: because in my mind I still don’t quite see how it will fit into the ecosystem. Because is it going to be something that people build research on? If it’s a post-trained model, then probably not, right?
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: Yeah. But their tweet was about safety, so I doubt it is a base model if they’re delaying it for safety. I do think they actually delayed it for this reason. It’s very much in OpenAI’s culture. But I don’t think it’s going to change the ecosystem. It will be an interesting one off.
  &lt;/p&gt;
  &lt;p&gt;
   I also don&#x27;t expect them to release a model that&#x27;s based on their GPT architecture. My bet is they take an off-the-shelf architecture like Qwen or Llama. A lot of the recent OLMo models are very Qwen-y. And they will also be deciding sizes based on what fits on what cluster - e.g. Qwen is very deep rather than wide, and OLMo 2 is very similar to that. So I think the OpenAI model is going to fit that mold.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: I think so. I guess one way to think about it is they&#x27;re just trying to “distill” their RL infrastructure into weight space, right? As opposed to publicising their (internal) architectural choices.
  &lt;/p&gt;
  &lt;p&gt;
   But back to the discussion, and maybe this is a question for you Nathan, but do you think their model is going to be more comparable in use case to a Kimi or DeepSeek? Or is it more similar to Qwen? Or is it actually something completely different, like an on-device model? A smaller model?
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: I expect it to be smaller. They joked about on-device, which I don&#x27;t know is the right framing.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yeah.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: I&#x27;m also just now realizing how - if RL is their great strength - then part of the challenge of shipping an RL model in open source is that you need your training infrastructure to match the inference infrastructure. So unless they train this on an exact VLM that people have access to - and some open source environments - then they can’t just dump the model and expect people to be able to do search and code execution in the open model stack.
  &lt;/p&gt;
  &lt;p&gt;
   I don&#x27;t know exactly how Qwen and DeepSeek have gone about this. My impression is that they&#x27;re actually not as useful in terms of tool use because it&#x27;s so hard. I think that tool use is naturally a closed model reinforcing thing because it benefits to have these tools match up.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: So the Qwen models are pretty good at things like function calling. Kimi - at least in the benchmarks - was also pretty good at agentic tool use benchmarks. And then - this is a separate discussion - but they had this nice training innovation where they use lots of MCP servers in a synthetic data strategy. But then again, you’re mostly seeing indications of capability in headline evals, which you shouldn’t really trust anyway.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: I think of Claude 4 as the release that ended eval chasing. On paper the release was so lame, but it delivered for everybody - which is very bold because there is a lot of money on the line. They are constantly fundraising and if one fundraiser gets spooked because the release numbers are bad, then that’s a lot of CEO calls that they have got to make.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: On evals, I was thinking about this a few months ago. It might have changed now given the pace of AI development, but I was thinking about how you might split up the impact timeline for a release.
  &lt;/p&gt;
  &lt;p&gt;
   So day one is headline benchmark numbers - which are mostly bullshit. Like I’ve got this amount for my model on MMLU Pro. But then the next tier of impact is the day after the release where people have all these weird bespoke evals on Twitter.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: The pelicans and the rotating hexagons and balls…
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yes, and by this stage you’re getting more confident. Because unless the model developers are very smart (which some of them are), then they probably haven’t optimised for day two benchmarks. So at that stage you’re beginning to believe that the model actually generalises beyond the headline numbers.
  &lt;/p&gt;
  &lt;p&gt;
   And then finally you have a week or two weeks after the release where you can say that you’ve tried the model quite a lot now, and you then have real confidence that the model is good.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: Yeah. Refute my claim: Chinese providers are still optimizing for benchmarks more than OpenAI, Google, and
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yep, I mean it’s probably true.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: It feels so obvious to me. I think that China has closed the gap to a remarkable degree, but I don&#x27;t think they&#x27;ve caught up fully. I think that&#x27;s hard. It’s very hard to get all the data and pipelines in place. A lot of it is actually user data, knowing your user, and hill climbing that. So for example, all these APIs not working is a huge issue for them.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yeah. I think (Chinese models) have also been helped by the fact that a lot of the academic work that builds on them has been doing reasoning work in publicly available data domains like math and code.
  &lt;/p&gt;
  &lt;p&gt;
   The models have been heavily optimised for these domains anyway, so the model developers are not quite as exposed - since people aren’t really testing the true generalisation capabilities of the model. We already know that the Qwen models are heavily mid-trained on math and code, so they will hold up performance-wise there.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: Yeah. Okay, this is a good preview for the episode. I think that the main things are going to be how to build good organisations, and then academic reasoning research and how to bridge the gap. I think we can talk starting about org charts.
  &lt;/p&gt;
  &lt;p&gt;
   So how do you make a good org? Or maybe there are two things. One: how do you make a good org chart for training language models? And two, how do you make an effective culture?
  &lt;/p&gt;
  &lt;p&gt;
   I think this is quickly becoming one of my favorite little niche interests because there&#x27;s just so much intrigue in it. There&#x27;s just so much money on the line to break everything. So you sent me some hot takes if you want to read them, but the floor is yours for what doesn&#x27;t work.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Sure. So if anyone’s been on social media recently, the general trend nowadays is to check your phone and see these NFL draft style tweets about researchers moving between orgs.
  &lt;/p&gt;
  &lt;p&gt;
   First of all, researchers have always moved between orgs. This is not a new thing. And a lot of the org moves that were talked about - at least outside of Meta - were just regular moves.
  &lt;/p&gt;
  &lt;p&gt;
   But I think the bigger mistake on Twitter is just the tendency to see the bottleneck in LLM projects as skill issues. And at least from my n=1 experience, that has never been the main bottleneck for success.
  &lt;/p&gt;
  &lt;p&gt;
   There are a number of ways to make this case, but I think I&#x27;d start by saying that machine learning is a heavily empirical science. So what does genius mean in that context? What does talent actually mean?
  &lt;/p&gt;
  &lt;p&gt;
   There are certainly some skills which are useful - like how do you form the right minimal viable experiment? And how do you iterate fast to explore a research direction where you’re going to hit a lot of dead ends. But a lot of it comes down hard work, good infrastructure, and ultimately resources.
  &lt;/p&gt;
  &lt;p&gt;
   So in that context, most of these orgs - even before public failings - had very good people. And I don’t think the difference in talent between orgs is that large. Smart people will eventually figure things out. So therefore, more often than not, the difference between a good versus a bad model is reflecting an inefficiency in the ability to channel resources to your talent. And that is the fundamental point.
  &lt;/p&gt;
  &lt;p&gt;
   Now you could say, on the flip side, okay, Ross, well, if that&#x27;s true, why is Zuck paying people these massive amounts of money? And I think that&#x27;s a separate question. But yeah, more often…
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: Well what do you think?
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: I am torn on this because, on the one hand, I think the new group will probably make very good models. They’re very smart people. And I think having a new org as well is the right way to do it.
  &lt;/p&gt;
  &lt;p&gt;
   I think in leadership&#x27;s mind, it&#x27;s a case of “Look, we tried this multiple times, we’re very serious about this, we have resources, so let’s do the maximum conviction play”. And I think that&#x27;s broadly what you should do because it’s a big expense, but it’s not massive, massive spend (for these large companies).
  &lt;/p&gt;
  &lt;p&gt;
   But on the other hand, I feel sorry for - this isn’t a Meta point by the way, but a general point - but I feel it’s a shame these organisations don’t have good mechanisms to identify the talent they already have in their orgs and have to recruit externally.
  &lt;/p&gt;
  &lt;p&gt;
   The talent that has already done the hard work, that is. It’s a shame they have to hire externally and start afresh. That’s the tragedy.
  &lt;/p&gt;
  &lt;p&gt;
   So that’s the conflict in my mind. I think they’ll make great models. I think it’s the right approach to do things afresh. But at the same time, it’s a shame that all the people that came before them, and made the previous generation of models, are treated like an asset. In the sense that you’ve used these people - grinded them really hard - and now you’ve moved on to a new group of people.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: You put this in your provocations. You said LLM labs are like investment banks where people are slotted in to burn out and burn through. I know that a lot of the work that needs to be done is somewhat mundane data work and it can be parallelised - e.g. if your users are asking this type of question, let’s create new prompts and manage human works and create synthetic data pipelines. And that works a lot of the time.
  &lt;/p&gt;
  &lt;p&gt;
   But then, I remember the Dwarkesh podcast with Sholto and Trenton - and it’s the one where they’ve both moved jobs (which reinforces your point), but they were saying you just need to convince someone at a frontier lab that a particular problem is important. I.e. people talk about things, but they just have to do it.
  &lt;/p&gt;
  &lt;p&gt;
   So is it the case that people are just dispatched to solve specific problems, or do individuals have free rein, and it’s fun on the ground because you choose the things you want to add to your beautiful final model?
  &lt;/p&gt;
  &lt;p&gt;
   So you can present a positive and a negative. It might vary across labs, but I guess your provocation is that there&#x27;s a bunch of places where it is a meat grinder and you just put people in and chew through them.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: I think so. Unfortunately the model for a lot of successful tech companies is to get very young, motivated, people - with a base level of intelligence - and make them work very long hours on a project with a big mission. This was the classic Elon way to run a company.
  &lt;/p&gt;
  &lt;p&gt;
   But this is also the model for a lot of frontier labs. You have your soldiers who - on the surface - look similar to quants at hedge funds from like 10 years ago in terms of their working hours. And in the culture too, you have friendly competition between people who all want to be the best.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: I will say: I know a bunch of people at OpenAI, and they do work crazy hours. I also work a lot, but I do a lot of things that aren&#x27;t grinding data to go into the model.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yeah, so on the question of decision-making, I think major decisions are generally made by people who are a little more experienced and already have some successes to their name. But you do need to have soldiers in this kind of environment. The space is just highly competitive (and requires people to work long hours).
  &lt;/p&gt;
  &lt;p&gt;
   And I think that&#x27;s a shame. Even for myself right now, where I’m trying to build a startup, I’m thinking that - yes, we all need to work hard - but is there an alternative model where you invest in your employees instead of using them? - i.e. burning them out and then moving on to a new group. That’s what I’m trying to work out for my new company.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: I feel like a lot of people are just more cynical now in tech, myself included. I got a great cold e-mail from someone fresh out of undergrad, and I was pretty sure in two to three years this person would be legit. And I was talking to a coworker on how we could potentially capture this and invest in them. And they were just saying we might get them, but then they’d just go to OpenAI in 2 years. So we don’t get any of the upside.
  &lt;/p&gt;
  &lt;p&gt;
   I think some of that is just cynicism. Investing in people is still the right thing to do because you’ll end up keeping the ones that are a bit more grounded even if it is really hard. For example, I&#x27;ve lost people that are extremely talented that I wouldn&#x27;t want to keep. So I don&#x27;t know how to balance that cynicism versus reality of building teams in the long term.
  &lt;/p&gt;
  &lt;p&gt;
   I guess smaller teams might be a bit easier to maintain, whereas if you’re at a tech company, the churn is hard to avoid because there’s so many levels in moving up.
  &lt;/p&gt;
  &lt;p&gt;
   I think some of the rumors around Meta and Llama 4 - at least from the Dylan Patel SemiAnalysis article - were about them doing these cowboy crazy model training runs, including changing pre-training mixes half way through, and that maybe points to dynamics with middle management wanting their data to be used so they can get promotions. But most labs I don&#x27;t think are doing that type of shit for their leading models. And I don&#x27;t think Meta is normally doing that. I think that was a pressure cooker side effect.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: I would push back on that a bit by stating that all of these labs are deeply chaotic places (not just particular orgs). They change direction every week, right? That’s just the nature of the field we’re in.
  &lt;/p&gt;
  &lt;p&gt;
   But then, it is definitely true that certain labs are good at projecting, at least externally, that they have their shit together. They have AGI internally, all this kind of bullshit.
  &lt;/p&gt;
  &lt;p&gt;
   The truth is that it is a shitshow everywhere. It&#x27;s just that if you&#x27;re going to be a shit show, you at least want to be a functional shit show, and you want to make good models. Right?
  &lt;/p&gt;
  &lt;p&gt;
   As I mentioned before, I think there are new plays to be made around taking the view that you want to invest in your talent as opposed to just grinding them out. But I would also say that, in lab culture, people tend to overvalue raw talent again - especially in empirical science. If you take the view that an empirical science is mostly about experimental velocity, then you don’t just value infrastructure in that world, but you also want to hire folks who are very collaborative and who want to help each other.
  &lt;/p&gt;
  &lt;p&gt;
   It sounds like a bullshit point in a field that lionises individual intelligence, but I just feel that if you&#x27;re making a marginal hiring choice, then you have to think about how someone adds to an existing group? So I think there are new plays to be made on talent.
  &lt;/p&gt;
  &lt;p&gt;
   But there is nuance. Because there are certainly people who are especially productive. I’ve seen that in person. So it’s not like everyone is equal - that is definitely not the case - but I just feel that individual talent is overemphasised when problems in these orgs are mostly structural.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: The differentiation right now is people who are willing to put more highly focused hours turning the crank. Every organisation has the baseline time costs of needing to do meetings, commute time to work, commitments etc. But in terms of AI, where people are doing more and more, this really favors young people who don’t have a lot of responsibilities.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: This is maybe a transition onto another topic, but I’d make a more controversial point which is that - even the things in ML which seem more like novel research are more the result of persistence rather than inspiration.
  &lt;/p&gt;
  &lt;p&gt;
   For example, this time last year we were both speculating about what o1/Strawberry was. And speculation makes you think it was some amazing new thing. But actually it was basically what we were both doing two years ago right? Essentially RL from verifiable reward, but with very good base models, because they were in a good position to exploit that, and then enough ablations to find a recipe that worked.
  &lt;/p&gt;
  &lt;p&gt;
   So this is oversimplifying things a little, but we should take the view that they just had to do the work to make the recipe good. And that comes down to experimental velocity, and also having the right infrastructure and a good enough base model. So in that world, what is talent?
  &lt;/p&gt;
  &lt;p&gt;
   Is talent the person who says “we should make the models think more”, or is talent the person who is actually on the ground doing the ablations to find out which recipe works? Right? Because I can also make models think more by best-of-N, but, then there may be better ways to do it?
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: I mean, I think I analogize a lot myself with my athletics career - like rowing in college. I think so much of it is the same. I wasn&#x27;t the most gifted athlete, but if you put in the hours and you understand where you&#x27;re spending your effort, it works out for people.
  &lt;/p&gt;
  &lt;p&gt;
   The question I wanted to ask you on this topic is, given that that these orgs are so chaotic, then what does this mean for the ceiling on progress? One of the most coveted questions is about the trend line. There are obviously going to be new paradigms - inference time scaling was an obvious one if you thought from first principles about what compute and intelligence is - but even if we don’t have a new paradigm, then what is the ceiling?
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: I would say that, even in climates where most organisations are chaotic, you’re still going to have macro factors that lift all boats. So a good example recently was these gold medal results on IMO. Three or so different labs all had different approaches and all found they crossed the threshold for a gold medal.
  &lt;/p&gt;
  &lt;p&gt;
   If you were to zoom out - and one way to do this is to imagine you&#x27;re looking twenty years into the future back at this time - then would you look at the individual methods that researchers used, or would you just say compute reached a critical threshold where things began to work?
  &lt;/p&gt;
  &lt;p&gt;
   So compute is the big exponential that&#x27;s underlying all of this. And then if you zoom into a shorter time horizon, then you&#x27;re seeing more of the local challenges, like what’s the particular bottleneck at a point in time? So maybe the bottleneck to agentic models is scaling RL environments. Or maybe the bottleneck to better reasoning is longer context windows.
  &lt;/p&gt;
  &lt;p&gt;
   But look: fundamentally as long as compute keeps coming online, I think the trends look good and all of the organisational chaos is short-term noise. It slows down progress a bit but is not meaningful in the long-term. But, unfortunately, it&#x27;s still meaningful for people in their careers because one to two years of organizational chaos could matter personally. But on longer timelines, it doesn&#x27;t really matter.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: Yeah, I agree. It seems like the question is what happens when the fundraising starts to slow down. We&#x27;re on a trend line of compute rollout. But if Sam Altman can&#x27;t raise again, that is a very big sign. That&#x27;s like the end of the “bubble”. OpenAI is not going to go away because of that, but if they can’t get the next cluster… then that would be a bad sign.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: I&#x27;m quite optimistic because I think you only have a bust if AI ceases to be increasingly useful or doesn&#x27;t live up to certain promises. But even if there&#x27;s no algorithmic progress, I still think AI will continue to continue to be increasingly useful. I don&#x27;t think there are fundamental barriers. It&#x27;s just a question of how quickly you get things right.
  &lt;/p&gt;
  &lt;p&gt;
   I think the argument would have been slightly different two years ago. If the reasoning paradigm didn&#x27;t come through, then I think it would have been trickier to justify the expense because then you&#x27;d be looking at reasoning benchmarks and thinking: shit, to push this forward I need this amount of data annotation or need to generate this amount of data.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: You look at GPT 4.5 as the example.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yeah, exactly. That&#x27;s a really good example. So you can treat that model like a counterfactual universe where reasoning didn&#x27;t happen. There we would all be looking at the model thinking “it&#x27;s good at creative writing, but maybe not so good at some more things we really care about (like reasoning)”.
  &lt;/p&gt;
  &lt;p&gt;
   By the way, I&#x27;m sure it’s a really good model. I didn’t play with it enough to form a good judgement.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: I&#x27;ve been using it a lot. I used it for a long time - especially until Claude 4 - as it’s just nicer, especially when GPT 4.1 was so sycophantic. But GPT 4.5 was nice.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: So I&#x27;m gonna flip things around and ask you a question Nathan. Let&#x27;s say we are here in a year&#x27;s time. What does the key benchmark look like for LLMs that everyone is focused on?
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: Oh, it&#x27;s fully gonna be some agentic thing. I don&#x27;t know if it&#x27;ll be as stupid as making money on the stock market… I wrote a post on what I thought was coming next. One of the most poignant things I was looking at is the fact that scaling models is no longer the direction anymore. All the marketing is shifting to agents. And I think some of that is because it&#x27;s not easy to scale parameters anymore.
  &lt;/p&gt;
  &lt;p&gt;
   Every RL curve is this log plot, and it becomes hard. But agents are already beginning to work well. For example, this year Claude Code showed up. There&#x27;s gonna be versions of that in all sorts of domains and more people working to evaluate them. That will create an interesting marketing problem where labs need to figure out how to communicate that their model is good.
  &lt;/p&gt;
  &lt;p&gt;
   But the future looks like it’s all on the agentic side, and will lead to a big shift in what the language modelling companies need to think about. The prioritization of the company is also different, whereas modelling was always central before. I’m still modelling-pilled and think that is the central thing for the company…
  &lt;/p&gt;
  &lt;p&gt;
   But it’s true that now that teams building products are going to hold more weight than they used to. And there will be interesting changes in how these companies manage this transition, and how communications change.
  &lt;/p&gt;
  &lt;p&gt;
   So, I think Claude Code is great. But I think that it&#x27;s hard to integrate in some things. For example, how do I get that running on my cluster at AI2 where we have all of our data and models, launch evals from our file system on the GPU machines. I don’t think that quite works yet, but maybe I’m doing something wrong.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yeah, I agree with your answer. So I spent several years working on Papers with Code, where we were trying to focus heavily on evals before they were a big thing - trying to index all these various leaderboards. And I think now is an interesting situation because I feel like if you make good evals now, you possibly have more leverage than you&#x27;ve ever had in the field of ML..
  &lt;/p&gt;
  &lt;p&gt;
   This is a weird thing because traditionally evals were quite an unsexy thing to do. It was a thing that researchers didn&#x27;t want to do because they&#x27;d rather be training models. But now the ability to define a metric for a capability that you&#x27;d like to see - e.g. trading stocks, or doing scientific research - is just incredible leverage that you can wield. A small group of people in places like universities can say “this is the new north star that we should achieve for agents” and shape how AI progress evolves.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: It can happen. We recently released IFBench, a benchmark for following instructions which is just more constraints and a different prompt sourcing. And I was saying to folks that we need to have the goal of making at least two frontier labs adopt it. And I messaged various people, including someone at OpenAI, and they said they already integrated it last week.
  &lt;/p&gt;
  &lt;p&gt;
   So yes, someone doing research (on evals) has a shot at getting into the OpenAI internal evaluation platform.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Exactly, so it&#x27;s incredible leverage. And then the other interesting thing is that the friction for making and using good evals is going to increase quite a lot.
  &lt;/p&gt;
  &lt;p&gt;
   For example, in some of the recent benchmarks, you need the RL agent to have access to a GPU and then you need to spin up lots of these servers to do rollouts. This is expensive. Long gone are the old days where you had two CSVs with a train and a test split.
  &lt;/p&gt;
  &lt;p&gt;
   And then on the eval creator side, there’s a big difference between good and bad evals as models become more capable.
  &lt;/p&gt;
  &lt;p&gt;
   A bad eval just means that you&#x27;re going to get incredibly egregious reward hacking, and you&#x27;re not going to learn anything useful, whereas a good eval is a pathway towards a brand new capability.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: I have a related question on this. So I see three eras in evals based on what people are doing with models.
  &lt;/p&gt;
  &lt;p&gt;
   For pre-training, the best evals are testing knowledge and these very broad things and are hard to game. It&#x27;s just kind of like FLOPs.
  &lt;/p&gt;
  &lt;p&gt;
   At post training, a lot of evals are formatting and extraction. I think formatting became even clearer to people when these RL environments became the hot new thing. And I actually think that post training might be like the ugly duckling in the middle, where then if you go into agents, all the agentic tasks are gonna be evals of actually doing things and you can&#x27;t like format-lie your way through that. So it might be that post training evals are the hardest one to get right.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yeah, and I think you&#x27;re going to see more cases of people claiming good results, but when you look beneath the surface, you’ll see insane reward hacking. So the meme right is KernelBench evals. Have you seen these?
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: Oh.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: You see all these amazing speed ups which aren’t even possible based on the hardware. And this is not a problem with KernelBench, I would say it’s more a problem with people publishing papers for agentic evals and not looking at their results carefully.
  &lt;/p&gt;
  &lt;p&gt;
   So this shows that to get an eval in the right place takes a lot of work. And even with progress in models, I don’t think you’re going to be able to fully automate the construction of a good eval in the next year at least. I might be wrong. Models will certainly help us in creating evals. So I think that, for now, it’s a place where a researcher can have a lot of leverage.
  &lt;/p&gt;
  &lt;p&gt;
   I think if you were to ask what is the central eval is right now, it&#x27;d probably be something like SWE-Bench (verified). But even that is now quite saturated. So there&#x27;s a big blue sky now where someone can define what the next big task is for ML. And you don’t need a big cluster in order to be the one who defines it; so I think that’s quite exciting.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: Yeah. And when you think about the amount of money that&#x27;ll be steered by these things, it&#x27;s so crazy to have the uncertainty there and like who will come up with that as well. I think that it&#x27;s part of what makes it fun, I think.
  &lt;/p&gt;
  &lt;p&gt;
   We should talk about reasoning things.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Reasoning. Yeah.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: Where do we start? I don&#x27;t think I&#x27;ve ever done that much of a rant about the academic community chasing these things. I understand why academics are claiming to do new algorithms that get remarkable scores, but a lot of these papers are just extracting things that are hard to document from a model or something else or formatting
  &lt;/p&gt;
  &lt;p&gt;
   I was on one of these papers, which was hilarious. We figured out that if you train Qwen on random rewards, the evaluation scores go up. And we had to go through the logic on why this can happen.
  &lt;/p&gt;
  &lt;p&gt;
   Because if there&#x27;s no reward, the advantage is zero and the gradients are all literally zero. And then it turns out that the algorithm manipulates the most common sequences. It&#x27;s actually something that if you read a lot of the reasoning literature, people talk about how we want to make sure our algorithm doesn&#x27;t squash uncommon sequences. And then the real hammer is that, if you do random rewards, then you see that the model has modal collapse onto the things that it was trained on. And that can make scores go up.
  &lt;/p&gt;
  &lt;p&gt;
   So if you have a model that two thirds of the time has a certain behavior in its reasoning and that behavior is good on the benchmark, then just by fiddling the weights a bit then it does that behaviour more. This points to a structural failure.
  &lt;/p&gt;
  &lt;p&gt;
   I would also say it is a good example for why people should be using truly open models for research purposes and why they&#x27;re so good for innovation. For example, if we knew what goes in Qwen data and if someone just filtered it and it was like, oh, look, I found the found the GPQA prompts in it…then we know data contamination has happened.
  &lt;/p&gt;
  &lt;p&gt;
   The Qwen case is borderline - I don&#x27;t know how exactly to characterize it because the Qwen models are fantastic - but there&#x27;s so much research that is showing that they are very likely to be doing some dubious things in terms of benchmarks. It&#x27;s hard for people that aren&#x27;t super in the weeds to hold both of these possibilities in their brains.
  &lt;/p&gt;
  &lt;p&gt;
   So I don&#x27;t know. What do you think of the last six months? Have we actually made any progress? Has the academic community made any progress?
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: I think there&#x27;s been little progress. I mean that in the literal sense: there’s been some progress, but it has been little. I think I can answer this question in several ways.
  &lt;/p&gt;
  &lt;p&gt;
   So after DeepSeek-R1 came out, there were two approaches in open source more generally, which was either you go down the distillation route or the RL route to make interesting small models.
  &lt;/p&gt;
  &lt;p&gt;
   The initial thing that was undervalued - at least from an engineering perspective - was that for smaller model sizes, it is far more efficient to do distillation than RL.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: And not just in compute but also in performance? It&#x27;s hard to do RL on the small models.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: I think this point has been made twice now. So there was the original DeepSeek-R1 paper, and then more recently, there was a new Qwen paper as well. The Qwen paper showed that RL needed 17x times more compute than distillation.
  &lt;/p&gt;
  &lt;p&gt;
   So one way to think about this is that RL is a brute force lever to do data generation. But assuming that RL is still good, and you still want to do research on it in academia, then you run into a classic problem. And that problem is: if you don’t have enough compute, then you don&#x27;t know if the structure you are imposing is gonna generalize (to high compute settings).
  &lt;/p&gt;
  &lt;p&gt;
   And my worry is that a lot of the results are on relatively low compute budgets, both in terms of the underlying base model, which determines how well the RL approach learns, but also the total number of RL steps. So it&#x27;s just quite hard to see - unless there’s a massive gain - what’s truly important.
  &lt;/p&gt;
  &lt;p&gt;
   So the most useful things are - in my opinion - quite boring things. Like, there was the DAPO paper which showed that you should have filtering for overly long sequences, and you shouldn’t overly penalise them if your context window gets cutoff.
  &lt;/p&gt;
  &lt;p&gt;
   There has also been interesting work showing that even simpler approaches (than GRPO) might work, where you remove clipping. So Reka was doing lots of good work using REINFORCE leave-one-out (RLOO). But even there, it’s difficult because you don’t know if simpler algorithms are going to work with long agentic traces.
  &lt;/p&gt;
  &lt;p&gt;
   So it’s not clear. I think the recent work this week was actually quite good. The GSPO work was good, and if you saw their graphs…
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: Explain it to people. I think a lot of people have heard of the other ones by now. But GSPO is group sequence policy optimization with Qwen Coder. Why are you positive about it relative to the other ideas? I think GSPO is well motivated but why is it getting hyped more?
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: So I hope I don&#x27;t botch this because it&#x27;s the morning. But, essentially, with GRPO, you assign a reward to the whole sequence (via the advantage). But you also have an importance weight, which is your policy likelihood relative to your old one. Because when you do RL, you typically sample lots of rollouts but do several mini batches for your gradient update. So that means you go a little bit off policy.
  &lt;/p&gt;
  &lt;p&gt;
   So to fix that you have an importance weight term. But in GRPO, while the advantage is uniform across all tokens, the importance weight is particular for each individual token. And the importance weight is calculated for a single sequence. So one way of looking at this is that, if you had more sequences to calculate the importance weight, it would be a lot less variance - but by calculating it on a single sequence, you introduce a lot of variance through that term.
  &lt;/p&gt;
  &lt;p&gt;
   So the short answer of what GSPO does is that, instead of looking at a token likelihood, they look at the likelihood of the whole sequence. So now the clipping is not on an individual token basis, but, it looks at one of the sequences in your group and says okay, this one is less likely, so we’ll clip out that sequence. And the TLDR is, at least from the results they show, it seems to be a lot more sample efficient.
  &lt;/p&gt;
  &lt;p&gt;
   I mean, it&#x27;s not just 0.5 percentage points or something like that. But I think the reason I trust it more is that it’s very simple. And it’s quite directionally well motivated from just a basic understanding of importance sampling. If it were more complex, I&#x27;d be a lot more skeptical, but it&#x27;s fairly simple and it seems to work well.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: Yeah, I&#x27;m still fairly skeptical.
  &lt;/p&gt;
  &lt;p&gt;
   I think academic research is relatively wide in what people are trying out but labs are relatively narrow. And once you’re further along in your modelling journey, you’re dealing with different parts of state space and then all these algorithmic tweaks just like help your model on whatever blocker it was or your implementation.
  &lt;/p&gt;
  &lt;p&gt;
   I thought for GSPO the sequence thing was funny because when you read the GRPO paper, you were like oh, the reward is just per sequence. But all the tokens in the sequence get the same loss function. But the standard implementation is to break it down per token. And then GSPO is essentially to take that standard implementation and you change the weight on every token back to this. And I was doubting whether this was really going to be a major thing.
  &lt;/p&gt;
  &lt;p&gt;
   I think for junior researchers, one of the good things about this era is that you can really learn the math by studying all these algorithms and thinking about how they are implemented. I hadn’t done that for a few years until writing this RLHF book on policy gradients and I was getting into the weeds like per-token loss, length bias for GRPO, and so on. For students to be able to do this in their brain, it is really good for thinking about the interface between algorithms and systems.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: It’s interesting, because as AI became more hyped after ChatGPT, you have more people reading papers. This is a great thing, but also you have lots of new people reading papers in the wrong way.
  &lt;/p&gt;
  &lt;p&gt;
   For me the basic logic (for reading papers) is as follows: what’s the reported gain of the paper and how much complexity does it introduce?
  &lt;/p&gt;
  &lt;p&gt;
   So if you get a gain but the paper introduces shitloads of complexity, it&#x27;s probably not going to stand the test of time. Whereas if it&#x27;s something relatively simple, but it seems to get a good gain, then that’s the thing that is going to last.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: The o1 lesson. The simple thing. In RL research, I&#x27;ve heard it described as: if you see something that only beats the baseline by a few percent, it&#x27;s not gonna work. But if it’s 2x then that’s a real innovation, because whether they finetune their baselines or not, they’re still going to be crushing it.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Exactly.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: So I think that&#x27;s a good heuristic for people right now.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: And I think researchers are their worst enemy because they want to see their own methods work. But the weird thing in ML is that neural networks “want to learn”. So if you push something enough, it will work. It&#x27;s just a question of whether that is a good use of your time?
  &lt;/p&gt;
  &lt;p&gt;
   So the question is: what&#x27;s the right thing to scale and push on? So that’s why - when you read papers - at least what I say to young researchers is that you should always judge how much complexity the paper introduces, and whether you trust the gain.
  &lt;/p&gt;
  &lt;p&gt;
   And then based on those three factors, you can judge whether it’s worth caring about the paper. But I can see why - if you’re new to reading papers - why you might be attracted to complicated, new techniques in papers that seem methodologically interesting.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: And researchers often manipulate the results of their peer methods in the way to tell a convincing story. And I think these algorithms are a perfect example of trying to tell a story.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yeah.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: So when you think of cognitive behavior of paper authors, you have to take that into account too.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: The other point I’d make is that - in the reasoning trace - I understand that everyone has to focus on math and code, because that’s where the data availability is. However, if a paper comes out and it’s just flexing on AIME and GPQA then that is just very uninteresting to me - and much more so than it would have been in February.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: I think code can be much better but it&#x27;s hard to benchmark it. Describing what a good coding model is would take me an extremely long document.
  &lt;/p&gt;
  &lt;p&gt;
   That&#x27;s not what the academic papers are doing. It would be great to have more benchmarks on that.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yeah, and even the established ones have issues. For example SWE Bench has a very large proportion of issues from Django (so it’s not exactly representative of all software engineering). That’s not a burn towards SWE Bench - which is a great benchmark - but…
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: They already won. They can take it - they won!
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: But, yes, it shows that there is a lot of detail to get right in making a good coding benchmark.
  &lt;/p&gt;
  &lt;p&gt;
   Anyway, it’s difficult because I am in this position where I can say - on the one hand - papers are just hill-climbing particular math and code benchmarks, and that is fundamentally uninteresting to me. But at the same time, I sympathise. Because there are not a lot of good open reasoning datasets in the open. And those that are open, I don’t think that they’re even going to be good for testing RL necessarily. They might test something more knowledge based, like medicine or something like that, which is less inference-time scaling bound.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: This could be a good time to transition. What is the status of RL scaling and generalizing? What is the status of RL outside of math and code? I think my prompt is: what do you think about o3-like models with this crazy search behavior and multi hop execution?
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yes. So first of all, I think it was greatly overstated that these models don’t generalize beyond math and code. I think what happened in practice is that, at least from what I know, OpenAI originally was very focused on math, logic and puzzles. And then eventually they had to broaden out because it was kind of too nerdy and biased towards these kinds of tasks.
  &lt;/p&gt;
  &lt;p&gt;
   But I don&#x27;t think there was ever a question about their generalisation to other benchmarks. You could see that very early on. The way I think about this is: we started with math and code because it was easy to verify. And then through applying RL to those domains, models learnt certain strategies like “I shouldn’t answer early”, “I should check my work”, or “I should consider alternatives”. And at a very high level, if you just have a model that thinks for longer and checks its work more and considers more things, then that&#x27;s gonna be useful for things beyond math. And that&#x27;s reflected in the benchmarks.
  &lt;/p&gt;
  &lt;p&gt;
   That being said, if you want to get superintelligence outside of math and code, then yes, you probably need more specific benchmarks and datasets for that. So there the question is less about whether it generalises beyond math and code, but how far can performance go? And that’s when you get into interesting questions about, e.g, if you don’t have a numerical answer or whatever, then how do you verify things.
  &lt;/p&gt;
  &lt;p&gt;
   So rubrics are all the rage right now, but then there&#x27;s also other directions like…
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: Rubrics are so funny. It’s funny how they needed to be reinvented. Rubric is a funny name because it just seems like question-specific LLM as a judge. It&#x27;s the most basic unit of evaluation or feedback.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: So I think this was something that wasn&#x27;t very covered in the open. So the reason why it became popular was that DeepResearch was the trigger. The rumor at least was - at least for OpenAI - they didn’t need many examples to do well in these kinds of research task.
  &lt;/p&gt;
  &lt;p&gt;
   It wasn’t tens of thousands of rubrics - it was probably in the 1,000-2,000 range of well-crafted rubrics for questions. But it clearly worked very well to teach a model how to browse the internet and synthesize knowledge. There&#x27;s obviously infrastructural detail as well.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: What would a rubric look like for deep research in this case? For an essay it might be that the rubric says that an answer should be free of typos, have a clear argument and a good conclusion. It would have different checklists. But the DeepResearch example is more complicated and you might need to draw an example.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yeah, so there are different themes you could have. It could be the general style of the answer. It could be - let’s say we want a review of the latest and greatest RL algorithms for reasoning - then there you might have a high level rubric saying that the answer should compare different methods, cover underlying algorithms, mention policy gradient, PPO vs REINFORCE and so on.
  &lt;/p&gt;
  &lt;p&gt;
   But then you might have, like, more detailed things where you just have a strong conviction on what a good answer looks like. For example, a review of RL for LLMs right now might include GSPO as of this week.
  &lt;/p&gt;
  &lt;p&gt;
   So rubric-based grading comes down to a list of checks, but the goal of that form of evaluation is that you’re trying to get a nice, continuous rewrad for the model to learn from - as opposed to something more binary and sharp. Because while 0/1 rewards might work okay for mathematics or unit tests, it would work less well for a task like making a good literature review on RL. The reward structure isn’t binary there.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: So how do you think of grader functions? I’ve thought about this for code, like the percentage of unit tests that pass. But then the model might just get the easy unit tests. So will reward shaping be here to stay or will it be washed away in the ever growing sea of compute?
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: I think it&#x27;ll be washed away, but I think in the meantime, there&#x27;s a lot of value in making very good handcrafted evals. And I hate the word taste, but there is still taste to begin with.
  &lt;/p&gt;
  &lt;p&gt;
   And I think a lot of these things are quite codependent, because to make a good rubric for a deep research task, then you need something that needs the ability to do deep research. If we were to say what makes a good literature review on RL right now, then that knowledge wouldn’t be in the weights of a language model - the model would have to go out and search for things.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: You can tell it that you need to use search in this question.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yeah, if you haven’t done a search, then you&#x27;re probably doing it wrong. So yeah, in the long term, it gets washed out because there&#x27;s nothing a neural network can&#x27;t do compared to a human. But in the short term, there&#x27;s still a lot of nooks and crannies that a model wouldn&#x27;t quite cover / struggle on.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: Can you create a generative reward model by training off a bunch of rubric data? Probably?
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yeah, so verification benefits from thinking time. And I think most people are aware of this now, but it&#x27;s more of a question of how you actually execute that. So a generative reward model for something like math and code - where it&#x27;s like a 0 or 1 reward that you’re trying to figure out by thinking - is less interesting to me then questions where you really need to think from first principles on how to assign reward.
  &lt;/p&gt;
  &lt;p&gt;
   In general, the simplest way I think about it is: if you&#x27;re moving to a world where you have long agentic traces, then your “reward model” just needs to answer a simple question, which is: “is the agent making progress towards its goal?” Right? But that&#x27;s a very deep question.
  &lt;/p&gt;
  &lt;p&gt;
   So if it&#x27;s a Pokemon eval, then maybe a model needs to use its knowledge of Pokemon to figure out if the agent in a trajectory has been caught in a loop, and whether it should be going towards Lavender town instead of this other way.
  &lt;/p&gt;
  &lt;p&gt;
   So these sorts of verification tasks benefit from thinking time, but the devil is in the detail. Because if you’re not careful, you’re just going to spend an inordinate amount of compute trying to get a reward.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: It feels like there will be a lot more we will learn there. It feels obviously salient. I’d describe it as verification changing the slope of inference time scaling. And that&#x27;s really, really valuable if you&#x27;re spending a lot on inference, but we don&#x27;t really know how to do this. Like parallel compute is another factor that changes the shape of that curve.
  &lt;/p&gt;
  &lt;p&gt;
   I guess it&#x27;s really all a slope of a scaling law or like an offset or something, but it&#x27;s hard to say which things are true in terms of what we&#x27;re hearing. That&#x27;s probably what they&#x27;re doing other than this rubric stuff. It&#x27;s just a way to get RL pointed at more problems, which is not surprising.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yeah, I think RubricMania is in full force right now. I mean, I think the longer term question, which has been posed in several places, is what happens when verification becomes fundamentally harder?
  &lt;/p&gt;
  &lt;p&gt;
   So I&#x27;m quite interested in the scientific discovery question. But in a field like biology, you need to do a physical experiment in order to verify. So it’s not just a question of running things on a cluster. And if you want to simulate the underlying thing, well then you’re bottlenecked by the quality of the simulation - and it turns out to be quite hard to simulate some physical processes!
  &lt;/p&gt;
  &lt;p&gt;
   Actually - in most of the sciences - I think this is the other point I’d make” which is that in ML, people overvalue the value of individual “thinking” in something like science. They think of Einstein and they think a lot less about the data generating mechanism, and what&#x27;s the instrument.
  &lt;/p&gt;
  &lt;p&gt;
   There is no Kepler without the telescope. There is no progress in biology without X-ray crystallography. There&#x27;s maybe new theories on dark matter in space without even better, newer telescopes.
  &lt;/p&gt;
  &lt;p&gt;
   I know this sounds like a weird say in the context of RL, but if you’re thinking about very hard things to solve in the real world, then you’re just going to be bottlenecked by the need to build a better instrument to get data. So it sounds like a digression, but I’m saying that - in the long-term - you’re going to hit these bottlenecks for verification. But in the short-term, we can still solve very interesting things like Millenium Prize problems, but that will probably take quite a while too!
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: Yeah, I don&#x27;t have anything particularly eloquent to say on the scientific discovery point. I guess what will happen is that RL is going to be in training and then you just sort of punt it off to the rest of post-training. So models need to be able to get really weird, but not weird in a way that they are numerically lost.
  &lt;/p&gt;
  &lt;p&gt;
   I&#x27;ve been reading a lot of reasoning traces these days, and the Qwen and DeepSeek reasoning traces really just seem numerically lost for a while, and then they eventually get the answer right. They say “Wait” a lot and then go into half English/half Chinese, and end up getting the answer right.
  &lt;/p&gt;
  &lt;p&gt;
   My point is that I don’t think in their current form, that these things are vehicles towards (scientific) discovery. There’s some kind of fundamental research needed to make the reasoning process more real.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: My other bear case against reasoning models is the following argument - and this is mainly a devil’s advocate point, because I still fundamentally believe. Since World War 2, there are a lot more scientists in the world. But has progress kept up at the same rate? If anything, I would say that scientific progress has slowed.
  &lt;/p&gt;
  &lt;p&gt;
   Was there more progress in fundamental physics now or in the last century? And I know that is mainly because the low-hanging fruit is gone in many of these fields, but it could also be a bear case for AI because it hints that the bottleneck in science is the amount of intelligence on a problem, but maybe the speed of physical processes, or the ability to build better instruments for measuring, or the ability to get funding from governments to build bigger particle colliders…
  &lt;/p&gt;
  &lt;p&gt;
   I&#x27;m exaggerating the bear case because I think AGI mostly means autoating regular activities - law, finance and these kind of industries - and I think that’s a lot easier to do. But I’m attacking this mindset that says - now that we’ve solved reasoning - the takeoff is going to arrive in the next few years. From what I can see, that is very unrealistic.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: I&#x27;m very I&#x27;m bullish on AI being used and bearish on whatever superintelligence takes. I think we’re too compute constrained for a takeoff. I think AI is going to be very good for financialization and digitalization and seamlessly globalizing the Internet and making all information transfer and acquisition effectively free.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yeah.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: Which is really good. And I think historically, the US is very well-positioned to capture this by making products that run on top of cheap AI models.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yep.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: I wanted to ask you what AI you actually use. I don&#x27;t know if I&#x27;ve ever asked you it&#x27;s normally revealing.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Okay, so the base models we’re doing experiments on are mainly Qwen - Qwen 3, but also Qwen 2 because we know the kind of quirks of that model a bit more. A lot of people do that. Then we also do some distillation jobs, where we’re mainly using DeepSeek-R1. We did use Kimi recently, but we didn’t see massive benefits for the benchmarks we were looking at.
  &lt;/p&gt;
  &lt;p&gt;
   Then from a personal productivity perspective, Claude Code is very, very good. My main worry with Claude Code is that - I think there&#x27;s a paper on this - but people confuse agents making you more productive versus preventing you from exerting mental effort. So sometimes I&#x27;ll have a day with Claude code where I feel like I use very little mental effort - and it feels amazing - but I&#x27;m pretty sure I&#x27;ve done less work.
  &lt;/p&gt;
  &lt;p&gt;
   That will change because the models get better, but I&#x27;m trying to teach myself to be a bit careful because sometimes I need to stay in control.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: It does seem like an equilibrium. I&#x27;m happy with it. I don&#x27;t want to have to grind out some plotting code. I&#x27;m just gonna watch some sports highlights and let it do it for me. That&#x27;s fine…
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yeah. But in general, there is a lot of positive feedback from the community on Claude Code. It’s a very impressive product for me.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: What is the niche of your use case, or is it a bunch of things? Is there something you could endorse? Do you use it in math or code tasks? Do you use it in your startup’s codebase?
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: It tends to be better with brand new codebases. But I mostly use it for tasks which are quite horizontally scalable. So I&#x27;ll have some basic specification where I&#x27;ll provide it with some example code of mine, and then say “here&#x27;s what a good implementation looks like”, but I need this modification or twist done. Sorry, I&#x27;m being very vague because I don&#x27;t want to talk about specifics, but…
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: Yeah.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: It tends to be better for that. And, yeah, where it becomes really bad is when the file size becomes too long. Then the agent tends to struggle and get into these weird line search doom loops. So, yeah, there&#x27;s a bit of work to do where you have to structure the codebase a bit for it to be efficient. But in general, it’s quite helpful.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: It&#x27;s such a success that pretty much everybody that tries it is doing at least small code projects with it. I think maybe since ChatGPT, there hasn’t been this strong of a reaction.
  &lt;/p&gt;
  &lt;p&gt;
   Is this like the GPT 3.5 level? Like, Claude 4 is like GPT 3.5, the original ChatGPT, and then a couple iterations it’s gonna be incredible...
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yeah, I guess the people who really appreciate Claude Code are developers. Right? But it doesn&#x27;t have the mass appeal of ChatGPT, which could generate poetry or whatever at the time, which was the killer mainstream use case at the time…it sounds crazy now.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: But I guess pay for Claude Code. People won&#x27;t pay for ChatGPT (laughs)...
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Exactly. So maybe it&#x27;s a better business model…
  &lt;/p&gt;
  &lt;p&gt;
   But, yeah, I think that&#x27;s a good question. I wouldn&#x27;t say it&#x27;s a ChatGPT moment, but I would say it&#x27;s probably one of the most impactful products since ChatGPT. It’s not a ChatGPT moment because it hasn’t got mainstream appeal yet. And the question is: what does that agent look like? I&#x27;m still shocked that Apple hasn&#x27;t done anything yet because, for me, that would be the killer thing. We&#x27;ll see if they get that shit together.
  &lt;/p&gt;
  &lt;p&gt;
   But, yeah, I&#x27;d imagine it would be some sort of on-device model. That would be my guess. We’ll see
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: Yeah, that’s fun. Did you also wanna mention AlphaEvolve? I&#x27;ve been so burnt by Google&#x27;s hypey projects - like their chip design and stuff.
  &lt;/p&gt;
  &lt;p&gt;
   Is this like the AlphaGo story, where if you have a really high performance simulator, that’s well matched to a task and you can scale RL - like many actors in parallel - then you can get high performance? I talked to Eugene Vinitsky recently, one of my friends from Berkeley. And they were at Apple and they did this really parallel RL for self driving simulator, which was really awesome.
  &lt;/p&gt;
  &lt;p&gt;
   Is AlphaEvolve somewhat away from that, but is in the same vein of extracting simulators?
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: I think AlphaEvolve is very cool. In my mind, it&#x27;s very interesting because it feels like we are going full circle. In the 90s, the cool things which didn’t quite work were genetic algorithms and neural networks. And it feels we often see a new lease of life for several algorithms once the right context develops and other components get in place
  &lt;/p&gt;
  &lt;p&gt;
   So in the case of AlphaEvolve, you&#x27;re exploiting the strong latent knowledge of a neural network, but then you also have a neurosymbolic element….don’t read too much into that, Gary Marcus… where you have a database where you store past programs. And having that prior in the form of past programs is a very good way to exploit the internal creativity of a language model as opposed to creating from scratch each time.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: How does AlphaEvolve actually do this? I think a lot of people are not going to know what it is doing. I don&#x27;t think I have a good knowledge of it.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Say you have a kernel optimization task. For example, you’re making good kernels for common ML architectures. So you start with a reference implementation, and then in essence, it&#x27;s a bit like in- context learning where you’re taking that implementation and saying “propose a change”, and then you benchmark it and get a score. And then you have a database where you store that program and its score.
  &lt;/p&gt;
  &lt;p&gt;
   And then when you sample a new round, you have an algorithm - it tends to be based on island based algorithms - where you sample in proportion to the score but you also wanna explore a bit. And that&#x27;s your new prior. So you&#x27;re iterating and evolving a program.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: And this is just handed off to the language model? What is the language model actually inferencing? Is it inferencing new programs?
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yes. So imagine you&#x27;re constructing your prompt. You fetch a past implementation from your database and it goes in. It probably has the score as well saying “this implementation above got this result”. Then you ask the model to propose a new change.
  &lt;/p&gt;
  &lt;p&gt;
   I am oversimplifying, but this is the essence of the approach. You propose a new change, you write a program, get the score, store it in a database, and then go again.
  &lt;/p&gt;
  &lt;p&gt;
   So, basically: anything where you can pose a neat optimization task, this algorithm tends to work very well.
  &lt;/p&gt;
  &lt;p&gt;
   This is a broader debate now about how AlphaEvolve compares to RL approaches. First of all, I think they can be complementary, but…
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: Maybe the language model is trained with RL, I bet?
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yes, that too. The interesting thing by the way is that the bulk of the AlphaEvolve approach was not using the strongest Gemini model - they used a weaker model with faster inference. So that’s an interesting tidbit which is sort of anti model-scaling pilled. There is a nice balance to be found there…
  &lt;/p&gt;
  &lt;p&gt;
   But yes: back to RL vs AlphaEvolve. I think this is part of a broader trend on how you use compute and whether the approach is parallel or sequential. The AlphaEvolve approach benefits from parallelisation, but they’re not going into deep long reasoning traces (sequential) just yet. But you could use both approaches.
  &lt;/p&gt;
  &lt;p&gt;
   Similarly, with RL you usually solve problems from scratch. But you could also think of ways you might want to exploit good priors in the context window. Benchmarks like KernelBench sort of do that anyway, but they don’t evolve the reference implementation like AlphaEvolve does.
  &lt;/p&gt;
  &lt;p&gt;
   So I think it&#x27;s definitely something to watch. I think AlphaEvolve is underhyped, but we’ll see many more papers on this direction soon.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: It seems like a sign of things to come - figuring out parallel compute in the right way. It might be that the biggest model doesn’t necessarily benefit the most from a parallel compute setting.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yeah.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: I mean, there&#x27;s a lot of ways you could think about this. Like, the guess is a 100 times cheaper and half as good…
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yeah. So maybe this is a bullshitty philosophical point, but think about it this way. In the past 5,000 years, humans have made a lot of progress, but their brains fundamentally haven’t changed. What makes us smarter is that we’ve followed an invention curriculum, where the next invention builds on previous inventions.
  &lt;/p&gt;
  &lt;p&gt;
   So in the RL context, that raises the question: would you rather start from scratch each time, or would you use the best thing you have and successfully iterate that by standing on someone else’s shoulders?
  &lt;/p&gt;
  &lt;p&gt;
   So this is definitely something to watch in RL space. Instead of AlphaZero-ing things from scratch, how do we maintain existing implementations and iterate upon those?
  &lt;/p&gt;
  &lt;p&gt;
   This is also related to how we develop language models, and the discussion we had about Claude Code. You can imagine having an agentic model that is very good for starting from scratch, but you could also have a model that&#x27;s very good at dealing with an existing code base. And the question is which is more valuable? And the answer is both. But then depending on how you actually use those models, you might end up preferring a different model.
  &lt;/p&gt;
  &lt;p&gt;
   So I am trying to put AlphaEvolve into a much bigger context here: and see it as a bigger trend about how we use compute, but also how a model might learn to improve on a problem.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: Yeah, that&#x27;s fun. There&#x27;s going to be a lot more things like AlphaEvolve - where people with particular domain expertise do the muddling and figure things out and more things will fall out. It is very remarkable that a zero order optimizer like a genetic algorithm, just using prompts for language models, can get anything useful out. That is a major win for language models being a fundamental unit of compute.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yeah, absolutely. And a major win for LLMs and creativity, right? Because the meme is like “Oh, LLMs can&#x27;t be creative”, and I’m always thinking, at a fundamental level, the softmax is quite an expressive operation…You’ll get creativity eventually. It&#x27;s just a question of how quickly you can pick it out from what you sample.
  &lt;/p&gt;
  &lt;p&gt;
   So, I think AlphaEvolve is also proof of creativity. You found many new state-of-the-art implementations in AlphaEvolve - and will see more to come in upcoming papers.
  &lt;/p&gt;
  &lt;p&gt;
   Nathan Lambert: I would also guess there&#x27;s people doing stuff like that that don&#x27;t publish it. Or they&#x27;ve taken different models and hill climbed in their domain by setting up these weird loops.
  &lt;/p&gt;
  &lt;p&gt;
   I think this is a good place to end things. I’m kind of fading. Thanks for coming back. I’m doing a trip to London at some point. I don’t think we’ve ever met in person, but that’ll happen at some point!
  &lt;/p&gt;
  &lt;p&gt;
   I think we&#x27;re I mean, I&#x27;m kind of fading, so I think it&#x27;s good. Thanks for coming back. I&#x27;m doing trip to London at some point. I don&#x27;t think we&#x27;ve never met in person, but that&#x27;ll happen at some point.
  &lt;/p&gt;
  &lt;p&gt;
   Good to see you.
  &lt;/p&gt;
  &lt;p&gt;
   Ross Taylor: Yeah, good to see you Nathan. I&#x27;ll see you in a bit!
  &lt;/p&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> The White House&#x27;s plan for open models &amp; AI research in the U.S. </title>
<link>https://www.interconnects.ai/p/the-white-houses-plan-for-open-models</link>
<pubDate>Wed, 23 Jul 2025 16:09:27 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    Today, the White House released its
   &lt;/span&gt;
   &lt;a href=&quot;https://www.ai.gov/action-plan&quot; rel=&quot;&quot;&gt;
    AI Action Plan
   &lt;/a&gt;
   &lt;span&gt;
    , the document we’ve been waiting for to understand how the new administration plans to achieve “global dominance in artificial intelligence (AI).” There’s a lot to unpack in this document, which you’ll be hearing a lot about from the entire AI ecosystem. This post covers one narrow piece of the puzzle — its limited comments on open models and AI research investment.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    For some context, I was a co-author on the
   &lt;/span&gt;
   &lt;a href=&quot;https://allenai.org/blog/ostp&quot; rel=&quot;&quot;&gt;
    Ai2 official comment
   &lt;/a&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/the-white-houses-plan-for-open-models#footnote-1-169050741&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     1
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    to the Office of Science and Technology Policy (OSTP) for the AI Action Plan and have had some private discussions with White House staff on the state of the AI ecosystem.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    A focus of mine through this document is
   &lt;/span&gt;
   &lt;strong&gt;
    how the government can enable better fully open models to exist
   &lt;/strong&gt;
   &lt;span&gt;
    , rather than just more AI research in general, as we’re in a shrinking time window where if we don’t create better fully open models then the academic community could be left with a bunch of compute to do research on models that are not reflective of the frontier of performance and behavior. This is why I give myself ~18 months to finish
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/the-american-deepseek-project&quot; rel=&quot;&quot;&gt;
    The American DeepSeek Project
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Important context for this document is to consider what the federal government can actually do to make changes here. The executive branch has limited levers it can pull to disperse funding and make rules, but it sends important signaling to the rest of the government and private sector.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Overall, the
   &lt;/span&gt;
   &lt;strong&gt;
    White House AI Action Plan comes across very clearly that we should increase investment in open models, and for the right reasons
   &lt;/strong&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    This reflects a shift from previous federal policy, where the
   &lt;/span&gt;
   &lt;a href=&quot;https://bidenwhitehouse.archives.gov/briefing-room/presidential-actions/2025/01/14/executive-order-on-advancing-united-states-leadership-in-artificial-intelligence-infrastructure/&quot; rel=&quot;&quot;&gt;
    Biden executive order
   &lt;/a&gt;
   &lt;span&gt;
    had little to say about open models other than them getting grouped into models needing pre-release testing if they were trained with more than 10^26 FLOPS (which led to substantial discussion on the general uselessness of
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2407.05694v1&quot; rel=&quot;&quot;&gt;
    compute thresholds
   &lt;/a&gt;
   &lt;span&gt;
    as a policy intervention). Later, the National Telecommunications and Information Administration (NTIA) released a
   &lt;/span&gt;
   &lt;a href=&quot;https://www.ntia.gov/press-release/2024/ntia-supports-open-models-promote-ai-innovation&quot; rel=&quot;&quot;&gt;
    report
   &lt;/a&gt;
   &lt;span&gt;
    from under the umbrella of the Biden Administration that was far more positive on open models, but much more limited in the scope of its ability for agenda setting.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/the-white-houses-plan-for-open-models?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/the-white-houses-plan-for-open-models?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    This is formatted as comments in line with the full text on open models and related topics in the action plan. Let’s dive in, any
   &lt;/span&gt;
   &lt;em&gt;
    emphasis
   &lt;/em&gt;
   &lt;span&gt;
    in italics is mine.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;h3&gt;
    Encourage Open-Source and Open-Weight AI
   &lt;/h3&gt;
   &lt;p&gt;
    &lt;span&gt;
     Open-source and open-weight AI models are made freely available by developers for anyone in the world to download and modify. Models distributed this way have unique value for innovation because startups can use them flexibly without being dependent on a closed model provider. They also benefit commercial and government adoption of AI because many businesses and governments have sensitive data that they cannot send to closed model vendors. And they are essential for academic research, which often relies on access to the weights and
    &lt;/span&gt;
    &lt;em&gt;
     &lt;strong&gt;
      training data
     &lt;/strong&gt;
    &lt;/em&gt;
    &lt;span&gt;
     of a model to perform scientifically rigorous experiments.
    &lt;/span&gt;
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   This covers three things we’re seeing play out with open models and is quite sensible as an introduction:
  &lt;/p&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     Startups use open models to a large extent because pretraining themselves is expensive and modifying the model layer of the stack can provide a lot of flexibility with low serving costs. Today, most of this happens on Qwen at startups, where larger companies are more hesitant to adopt Chinese models.
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Open model deployments are slowly building up around sensitive data domains such as health care.
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Researchers need strong and transparent models to perform valuable research. This is the one I’m most interested in, as it is the one with the highest long-term impact by determining the fundamental pace of progress in the research community.
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    &lt;span&gt;
     We need to ensure America has leading open models founded on American values.
    &lt;/span&gt;
    &lt;em&gt;
     Open-source and open-weight models could become global standards in some areas of business and in academic research worldwide. For that reason, they also have geostrategic value.
    &lt;/em&gt;
    &lt;span&gt;
     While the decision of whether and how to release an open or closed model is fundamentally up to the developer, the Federal government should create a supportive environment for open models.
    &lt;/span&gt;
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   &lt;span&gt;
    The emphasized section is entirely the motivation behind ongoing efforts for
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/the-american-deepseek-project&quot; rel=&quot;&quot;&gt;
    The American DeepSeek Project
   &lt;/a&gt;
   &lt;span&gt;
    . The interplay between the three groups above is inherently geopolitical, where Chinese model providers are actively trying to
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-artifacts-12-qwen3-235b-a22b-instruct-2507&quot; rel=&quot;&quot;&gt;
    develop mindshare with Western developers
   &lt;/a&gt;
   &lt;span&gt;
    and release model suites that offer great tools for research (e.g. Qwen).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The document is highlighting why fewer open models exist right now from leading Western AI companies, simply “the decision of whether and how to release an open or closed model is fundamentally up to the developer” — this means that the government itself can mostly just stay out of the way of leading labs releasing models if we think the artifacts will come from the likes of Anthropic, OpenAI, Google, etc. The other side of this is that we need to invest in building organizations around releasing strong open models for certain use cases that do not have economic conflicts or different foci.
  &lt;/p&gt;
  &lt;p&gt;
   Onto the policy steps.
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;h4&gt;
    Recommended Policy Actions
   &lt;/h4&gt;
   &lt;ul&gt;
    &lt;li&gt;
     &lt;p&gt;
      &lt;strong&gt;
       Ensure access to large-scale computing power for startups and academics by improving the financial market for compute.
      &lt;/strong&gt;
      &lt;span&gt;
       Currently, a company seeking to use large-scale compute must often sign long-term contracts with hyperscalers—far beyond the budgetary reach of most academics and many startups. America has solved this problem before with other goods through financial markets, such as spot and forward markets for commodities. Through collaboration with industry, the National Institute of Standards and Technology (NIST) at the Department of Commerce (DOC), the Office of Science and Technology Policy (OSTP), and the National Science Foundation’s (NSF) National AI Research Resource (NAIRR) pilot, the Federal government can accelerate the maturation of a healthy financial market for compute.
      &lt;/span&gt;
     &lt;/p&gt;
    &lt;/li&gt;
   &lt;/ul&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   The sort of issue the White House is alluding to here is that if you want to have 1000 GPUs as a startup or research laboratory you often need to sign a 2-3 year commitment in order to get low prices. Market prices for on-demand GPUs tend to be higher. The goal here is to make it possible for people to get the GPU chunks they need through financial incentives.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    We’ve already seen a partial step for this in the recent budget bill, where
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/tamaybes/status/1940983352087269430&quot; rel=&quot;&quot;&gt;
    AI training costs now can be classified as R&amp;D expenses
   &lt;/a&gt;
   &lt;span&gt;
    , but this largely helps big companies. Actions here that are even more beneficial for small groups releasing open weight or open-source models would be great to see.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    One of the biggest problems I see for research funding is going to be the challenge of getting
   &lt;/span&gt;
   &lt;em&gt;
    concentrated
   &lt;/em&gt;
   &lt;span&gt;
    compute into the hands of researchers, so I hope the administration follows through here for compute density in places. A big pool of compute spread across the entire academic ecosystem means too little compute for models to get trained at any one location. It reads as if the OSTP understands this and has provided suitable guidance.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;blockquote&gt;
   &lt;ul&gt;
    &lt;li&gt;
     &lt;p&gt;
      &lt;strong&gt;
       Partner with leading technology companies
      &lt;/strong&gt;
      &lt;span&gt;
       to increase the research community’s access to world-class private sector computing, models, data, and software resources as part of the NAIRR pilot.
      &lt;/span&gt;
     &lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
     &lt;p&gt;
      &lt;strong&gt;
       Build the foundations for a lean and sustainable NAIRR operations capability
      &lt;/strong&gt;
      &lt;span&gt;
       that can connect an increasing number of researchers and educators across the country to critical AI resources.
      &lt;/span&gt;
     &lt;/p&gt;
    &lt;/li&gt;
   &lt;/ul&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   &lt;span&gt;
    This is simple and to my knowledge has largely been under way. NAIRR provided a variety of resources to many academic parties, such as API credits, data, and compute access, so it should be expanded upon. I wrote an entire piece on
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/saving-the-nairr&quot; rel=&quot;&quot;&gt;
    saving the NAIRR
   &lt;/a&gt;
   &lt;span&gt;
    last November when its funding future was unclear (and needed Congressional action).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   This is the balance to what I was talking about above on model training. It provides smaller resource chunks to many players, which is crucial, but doesn’t address the problem of building great open models.
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;ul&gt;
    &lt;li&gt;
     &lt;p&gt;
      &lt;strong&gt;
       Continue to foster the next generation of AI breakthroughs
      &lt;/strong&gt;
      &lt;span&gt;
       by publishing a new National AI Research and Development (R&amp;D) Strategic Plan, led by OSTP, to guide Federal AI research investments.
      &lt;/span&gt;
     &lt;/p&gt;
    &lt;/li&gt;
   &lt;/ul&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   This seems like a nod to a logical next step.
  &lt;/p&gt;
  &lt;p&gt;
   Where the overall picture of research funding in the U.S. has been completely dire, the priority in AI research has already been expressed through AI being the only area of NSF grant areas without major cuts. There is likely to be many other direct effects of this, but it is out of scope of the article.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    More exact numbers can be found in the
   &lt;/span&gt;
   &lt;a href=&quot;https://nsf-gov-resources.nsf.gov/files/00-NSF-FY26-CJ-Entire-Rollup.pdf?VersionId=O06XnbgojADDf9uCPe_MIkjRPBScU1Lt&quot; rel=&quot;&quot;&gt;
    NSF 2026 proposed budget
   &lt;/a&gt;
   &lt;span&gt;
    , where AI is an outlier as one of the only topics with a positive net change from 2024 or 2025.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!HGoC!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fc65b49-8841-468f-a798-40cb73ba892e_646x640.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!HGoC!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fc65b49-8841-468f-a798-40cb73ba892e_646x640.png 424w, https://substackcdn.com/image/fetch/$s_!HGoC!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fc65b49-8841-468f-a798-40cb73ba892e_646x640.png 848w, https://substackcdn.com/image/fetch/$s_!HGoC!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fc65b49-8841-468f-a798-40cb73ba892e_646x640.png 1272w, https://substackcdn.com/image/fetch/$s_!HGoC!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fc65b49-8841-468f-a798-40cb73ba892e_646x640.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9fc65b49-8841-468f-a798-40cb73ba892e_646x640.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:640,&quot;width&quot;:646,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:68107,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/169050741?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fc65b49-8841-468f-a798-40cb73ba892e_646x640.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;640&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!HGoC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fc65b49-8841-468f-a798-40cb73ba892e_646x640.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!HGoC!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fc65b49-8841-468f-a798-40cb73ba892e_646x640.png 424w, https://substackcdn.com/image/fetch/$s_!HGoC!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fc65b49-8841-468f-a798-40cb73ba892e_646x640.png 848w, https://substackcdn.com/image/fetch/$s_!HGoC!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fc65b49-8841-468f-a798-40cb73ba892e_646x640.png 1272w, https://substackcdn.com/image/fetch/$s_!HGoC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fc65b49-8841-468f-a798-40cb73ba892e_646x640.png 1456w&quot; width=&quot;646&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;blockquote&gt;
   &lt;ul&gt;
    &lt;li&gt;
     &lt;p&gt;
      &lt;strong&gt;
       Led by DOC through the National Telecommunications and Information Administration (NTIA),
      &lt;/strong&gt;
      &lt;span&gt;
       convene stakeholders to help drive adoption of open-source and open-weight models by small and medium-sized businesses.
      &lt;/span&gt;
     &lt;/p&gt;
    &lt;/li&gt;
   &lt;/ul&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   &lt;span&gt;
    This is a more unexpected line item, but a welcome one. It’ll be harder to implement, but if it works it’ll do a lot of good for building momentum around open model investment. A large part of why few open models exist in the U.S. is just because there’s not a lot of business value from releasing them. A big story of 2025 has been how
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/gemma-3-olmo-2-32b-and-the-growing&quot; rel=&quot;&quot;&gt;
    open models are closing the gap in capabilities
   &lt;/a&gt;
   &lt;span&gt;
    , or at least crossing important ability thresholds, which could start to change this equilibrium.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   That’s it for the core section on open models! It’s right to the point.
  &lt;/p&gt;
  &lt;p&gt;
   There are a couple related sections I wanted to point you to, which largely complement the above or show how it is hard for a document like this to acknowledge things like “our R&amp;D ecosystem is being outcompeted by Chinese models.”
  &lt;/p&gt;
  &lt;p&gt;
   First, more on AI research itself.
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;h3&gt;
    Advance the Science of AI
   &lt;/h3&gt;
   &lt;p&gt;
    Just as LLMs and generative AI systems represented a paradigm shift in the science of AI, future breakthroughs may similarly transform what is possible with AI. It is imperative that the United States remain the leading pioneer of such breakthroughs, and this begins with strategic, targeted investment in the most promising paths at the frontier.
   &lt;/p&gt;
   &lt;h4&gt;
    Recommended Policy Actions
   &lt;/h4&gt;
   &lt;ul&gt;
    &lt;li&gt;
     &lt;p&gt;
      Prioritize investment in theoretical, computational, and experimental research to preserve America’s leadership in discovering new and transformative paradigms that advance the capabilities of AI, reflecting this priority in the forthcoming National AI R&amp;D Strategic Plan.
     &lt;/p&gt;
    &lt;/li&gt;
   &lt;/ul&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   &lt;span&gt;
    Something in my mind that is very missing from this document is a comment on immigration. If we want the U.S. to be a leader in AI research we need to prioritize fixing the immigration ecosystem as soon as possible. Leading AI conferences
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/natolambert/status/1945632827032121491&quot; rel=&quot;&quot;&gt;
    can no longer be located solely in the U.S.
   &lt;/a&gt;
   &lt;span&gt;
    because too many authors cannot get a travel visa in time to attend the conference, let alone the other issues on hiring or funding at academic institutions.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   This section on the Science of AI reads very similar to the section on open models.
  &lt;/p&gt;
  &lt;p&gt;
   And the only mentions of China, which is related as the party pushing open models the furthest today:
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;h3&gt;
    Counter Chinese Influence in International Governance Bodies
   &lt;/h3&gt;
   &lt;p&gt;
    A large number of international bodies, including the United Nations, the Organisation for Economic Co-operation and Development, G7, G20, International Telecommunication Union, Internet Corporation for Assigned Names and Numbers, and others have proposed AI governance frameworks and AI development strategies. The United States supports likeminded nations working together to encourage the development of AI in line with our shared values. But too many of these efforts have advocated for burdensome regulations, vague “codes of conduct” that promote cultural agendas that do not align with American values, or have been influenced by Chinese companies attempting to shape standards for facial recognition and surveillance.
   &lt;/p&gt;
   &lt;h4&gt;
    Recommended Policy Actions
   &lt;/h4&gt;
   &lt;ul&gt;
    &lt;li&gt;
     &lt;p&gt;
      Led by DOS and DOC, leverage the U.S. position in international diplomatic and standard-setting bodies to vigorously advocate for international AI governance approaches that promote innovation, reflect American values, and counter authoritarian influence.
     &lt;/p&gt;
    &lt;/li&gt;
   &lt;/ul&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   and a quick comment on Chinese talking points in the section “Ensure that Frontier AI Protects Free Speech and American Values”:
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;ul&gt;
    &lt;li&gt;
     &lt;p&gt;
      Led by DOC through NIST’s Center for AI Standards and Innovation (CAISI), conduct research and, as appropriate, publish evaluations of frontier models from the People’s Republic of China for alignment with Chinese Communist Party talking points and censorship.
     &lt;/p&gt;
    &lt;/li&gt;
   &lt;/ul&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   &lt;span&gt;
    This reads as there being a low probability that we see any immediate executive action trying to ban the likes of Qwen or DeepSeek, which is good for the time being. The evaluation of Chinese and American values is a slippery slope in some ways, as it quickly will become enmeshed in the idea of “woke AI,” but in the meantime it is likely to be a major talking point with respect to the open models we’re seeing from Chinese companies, which do often parrot very simple talking points reflective of “
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/natolambert/status/1945959796382859372&quot; rel=&quot;&quot;&gt;
    Chinese socialist values
   &lt;/a&gt;
   &lt;span&gt;
    .”
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    We need our ecosystem to compete on merits of the technology being better at useful tasks if we want to lead in the long-term technological arc, rather than political games. That’s
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/the-american-deepseek-project&quot; rel=&quot;&quot;&gt;
    my number one focus
   &lt;/a&gt;
   &lt;span&gt;
    over the next couple of years and why I reiterate the need for open models for fundamental AI research and innovation. The biggest beneficiaries of this sort of innovation have historically been the biggest American technology companies, who now should do their part to support them existing — with some government encouragement.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Let me know if I missed anything, as this was a quick pass to make sure I read the details and connected the recent dots.
  &lt;/p&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/the-white-houses-plan-for-open-models#footnote-anchor-1-169050741&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     The call for comments was here: https://www.whitehouse.gov/briefings-statements/2025/02/public-comment-invited-on-artificial-intelligence-action-plan/
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Latest open artifacts (#12): Chinese models continue to dominate throughout the summer 🦦 </title>
<link>https://www.interconnects.ai/p/latest-open-artifacts-12-qwen3-235b-a22b-instruct-2507</link>
<pubDate>Tue, 22 Jul 2025 00:02:51 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;h5&gt;
   Edit 07/21: Added a note on how bad the license for the Hunyuan-A13B-Instruct model by Tencent is.
  &lt;/h5&gt;
  &lt;p&gt;
   &lt;span&gt;
    Back in February, we
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/artifacts-7&quot; rel=&quot;&quot;&gt;
    observed
   &lt;/a&gt;
   &lt;span&gt;
    the growing presence of Chinese companies on X to spread awareness of their models as part of a concerted effort to grow their market share in the U.S. For example, in the last couple months, Nathan has gotten DMs from 3 of the leading Chinese frontier model laboratories on Twitter asking to collaborate or promote their work (and zero from Western companies).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    This has only continued — even small subdivisions of Alibaba like
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/Ali_TongyiLab&quot; rel=&quot;&quot;&gt;
    Tongyi
   &lt;/a&gt;
   &lt;span&gt;
    are growing their presence. Another direction is how Qwen has launched a new page for tinkering with their models on
   &lt;/span&gt;
   &lt;a href=&quot;https://qwen.ai/apiplatform&quot; rel=&quot;&quot;&gt;
    Qwen.ai
   &lt;/a&gt;
   &lt;span&gt;
    , which feels similar in functionality to
   &lt;/span&gt;
   &lt;a href=&quot;https://ai.dev/&quot; rel=&quot;&quot;&gt;
    Google&#x27;s AI Studio
   &lt;/a&gt;
   &lt;span&gt;
    , as a landing page for those building with Qwen.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The recent Kimi K2 launch is a case study of this — days before the launch, the Kimi account messaged several people in the AI space, even smaller accounts, and offered them pre-release access to the model. This isn’t new for Western companies, but is noteworthy as it becomes standard practice internationally. The way Kimi cleverly captured Western interest is by being the only provider (to our knowledge) to offer an
   &lt;/span&gt;
   &lt;a href=&quot;https://platform.moonshot.cn/docs/guide/agent-support#%E9%85%8D%E7%BD%AE-anthropic-api&quot; rel=&quot;&quot;&gt;
    Anthropic-compatible API
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
   &lt;a href=&quot;https://github.com/LLM-Red-Team/kimi-cc&quot; rel=&quot;&quot;&gt;
    Scripts
   &lt;/a&gt;
   &lt;span&gt;
    to use K2 in Claude Code quickly emerged. With the capabilities of the model, this yielded immediate
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/sdrzn/status/1945627207914893568&quot; rel=&quot;&quot;&gt;
    adoption
   &lt;/a&gt;
   &lt;span&gt;
    and praise on
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/iannuttall/status/1944705474059718789&quot; rel=&quot;&quot;&gt;
    social media
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Zooming out, this is part of a larger trend where the
   &lt;/span&gt;
   &lt;strong&gt;
    quality of the open artifacts we are covering are maturing rapidly
   &lt;/strong&gt;
   &lt;span&gt;
    . In terms of overall quality, this issue of
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/t/artifacts-log&quot; rel=&quot;&quot;&gt;
    Artifacts Log
   &lt;/a&gt;
   &lt;span&gt;
    is the most impressive yet, and this extends far beyond text-only models. A year ago, it felt like a mix of half-baked research artifacts and interesting ideas. Today, there are viable open models for many real-world tasks.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    In the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-artifacts-11-visualizing&quot; rel=&quot;&quot;&gt;
    last issue
   &lt;/a&gt;
   &lt;span&gt;
    , we introduced more metadata for this series, highlighting the base models used to create the artifacts we highlight. We extended our database to include the rest of our issues, where you can see the original dominance of Meta’s Llama in Artifacts Log, where now Qwen has been the default for many months.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!HP3C!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2d72df0-506f-4b74-98f4-a7809680f39a_5370x2371.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!HP3C!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2d72df0-506f-4b74-98f4-a7809680f39a_5370x2371.png 424w, https://substackcdn.com/image/fetch/$s_!HP3C!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2d72df0-506f-4b74-98f4-a7809680f39a_5370x2371.png 848w, https://substackcdn.com/image/fetch/$s_!HP3C!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2d72df0-506f-4b74-98f4-a7809680f39a_5370x2371.png 1272w, https://substackcdn.com/image/fetch/$s_!HP3C!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2d72df0-506f-4b74-98f4-a7809680f39a_5370x2371.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f2d72df0-506f-4b74-98f4-a7809680f39a_5370x2371.png&quot;,&quot;srcNoWatermark&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9b1abe59-d986-4a51-a7d8-1cc1d687bcab_5370x2371.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:643,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:260578,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/168882114?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b1abe59-d986-4a51-a7d8-1cc1d687bcab_5370x2371.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;643&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!HP3C!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2d72df0-506f-4b74-98f4-a7809680f39a_5370x2371.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!HP3C!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2d72df0-506f-4b74-98f4-a7809680f39a_5370x2371.png 424w, https://substackcdn.com/image/fetch/$s_!HP3C!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2d72df0-506f-4b74-98f4-a7809680f39a_5370x2371.png 848w, https://substackcdn.com/image/fetch/$s_!HP3C!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2d72df0-506f-4b74-98f4-a7809680f39a_5370x2371.png 1272w, https://substackcdn.com/image/fetch/$s_!HP3C!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2d72df0-506f-4b74-98f4-a7809680f39a_5370x2371.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   More analysis like this soon, but onto the post!
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/latest-open-artifacts-12-qwen3-235b-a22b-instruct-2507?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-artifacts-12-qwen3-235b-a22b-instruct-2507?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   &lt;strong&gt;
    Our Picks
   &lt;/strong&gt;
  &lt;/h3&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507&quot; rel=&quot;&quot;&gt;
       Qwen3-235B-A22B-Instruct-2507
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/Qwen&quot; rel=&quot;&quot;&gt;
      Qwen
     &lt;/a&gt;
     &lt;span&gt;
      (released earlier today): While the dual-thinking mode wasn&#x27;t introduced by Qwen, they helped popularize it with a simple mode switch by including either
     &lt;/span&gt;
     &lt;code&gt;
      /no_think
     &lt;/code&gt;
     &lt;span&gt;
      or
     &lt;/span&gt;
     &lt;code&gt;
      /think
     &lt;/code&gt;
     &lt;span&gt;
      in the prompt. To the surprise of some, Qwen is abandoning the concept after
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/Alibaba_Qwen/status/1947344511988076547&quot; rel=&quot;&quot;&gt;
      talking to the community
     &lt;/a&gt;
     &lt;span&gt;
      and
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/Alibaba_Qwen/status/1947344511988076547&quot; rel=&quot;&quot;&gt;
      released
     &lt;/a&gt;
     &lt;span&gt;
      an update to the big (now non-reasoning) MoE model. The scores are impressive (
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/AiBattle_/status/1947356300309860559&quot; rel=&quot;&quot;&gt;
      beating the Kimi K2 model
     &lt;/a&gt;
     &lt;span&gt;
      we recently hyped as a major release), including
     &lt;/span&gt;
     &lt;strong&gt;
      41.8
     &lt;/strong&gt;
     &lt;span&gt;
      on ARC-AGI.
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      It turns out training a hybrid reasoning model is more challenging technically than it is worth relative to the upside of downstream serving (where training two separate models, one thinker one not, is much easier).
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      The best part of this release is that it has come with multiple reports of
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/willccbb/status/1947375372523233484&quot; rel=&quot;&quot;&gt;
      strong vibe tests
     &lt;/a&gt;
     &lt;span&gt;
      . Historically, Qwen has been known to be among the benchmark-maximizing labs — there
     &lt;/span&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2507.10532v1&quot; rel=&quot;&quot;&gt;
      are a few
     &lt;/a&gt;
     &lt;span&gt;
     &lt;/span&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2506.10947&quot; rel=&quot;&quot;&gt;
      papers
     &lt;/a&gt;
     &lt;span&gt;
      that have come out recently highlighting signs of data contamination in Qwen base models — but the Qwen models are improving in the robustness of normal testing. We’ve written multiple times on Interconnects about how labs will first shoot for strong benchmarks to get on the map, and then move to models that are more precisely those that people want to use. Quoting from our
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/qwen-3-the-new-open-standard&quot; rel=&quot;&quot;&gt;
      Qwen 3 post
     &lt;/a&gt;
     &lt;span&gt;
      :
     &lt;/span&gt;
     &lt;br/&gt;
    &lt;/p&gt;
    &lt;p&gt;
     &lt;em&gt;
      &lt;span&gt;
       ”We&#x27;ll start to see if Qwen has taste/vibes. They have the benchmarks complete, and now we&#x27;ll see how they compare to the likes of R1, o3, and Gemini 2.5 Pro for staying power at the frontier.”
      &lt;/span&gt;
      &lt;br/&gt;
      &lt;br/&gt;
     &lt;/em&gt;
     &lt;span&gt;
      Qwen team members mentioned a new flagship thinking model is
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/JustinLin610/status/1947351064820519121&quot; rel=&quot;&quot;&gt;
      on the way
     &lt;/a&gt;
     &lt;span&gt;
      and
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/JustinLin610/status/1947349155296264271&quot; rel=&quot;&quot;&gt;
      joked
     &lt;/a&gt;
     &lt;span&gt;
      about coding models coming soon. The evaluation scores are below relative to other models without a &amp;lt;think&amp;gt; section. Again, as we mentioned in our
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/kimi-k2-and-when-deepseek-moments&quot; rel=&quot;&quot;&gt;
      Kimi K2 post
     &lt;/a&gt;
     &lt;span&gt;
      , these models are trained extensively with reinforcement learning still, but the goals of the model are more constrained. These instruct, non-thinking, models are best for when the user wants a fast time-to-first token or other automation tasks.
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      The evaluation summary is here:
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!sJV5!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14b06602-42fa-4bef-bd3f-590061938d54_1920x1080.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!sJV5!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14b06602-42fa-4bef-bd3f-590061938d54_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/$s_!sJV5!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14b06602-42fa-4bef-bd3f-590061938d54_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/$s_!sJV5!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14b06602-42fa-4bef-bd3f-590061938d54_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!sJV5!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14b06602-42fa-4bef-bd3f-590061938d54_1920x1080.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;image/jpeg&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/14b06602-42fa-4bef-bd3f-590061938d54_1920x1080.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:695,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;image/jpeg&quot;,&quot;title&quot;:&quot;image/jpeg&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;390.9375&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!sJV5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14b06602-42fa-4bef-bd3f-590061938d54_1920x1080.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!sJV5!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14b06602-42fa-4bef-bd3f-590061938d54_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/$s_!sJV5!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14b06602-42fa-4bef-bd3f-590061938d54_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/$s_!sJV5!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14b06602-42fa-4bef-bd3f-590061938d54_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!sJV5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F14b06602-42fa-4bef-bd3f-590061938d54_1920x1080.jpeg 1456w&quot; title=&quot;image/jpeg&quot; width=&quot;695&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/HuggingFaceTB/SmolLM3-3B&quot; rel=&quot;&quot;&gt;
       SmolLM3-3B
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/HuggingFaceTB&quot; rel=&quot;&quot;&gt;
      HuggingFaceTB
     &lt;/a&gt;
     &lt;span&gt;
      : HuggingFace has released a new version of their SmolLM series alongside a very detailed
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/blog/smollm3&quot; rel=&quot;&quot;&gt;
      writeup
     &lt;/a&gt;
     &lt;span&gt;
      of all the decisions made, including details about all the used datasets. Similar to other models, it supports a thinking and non-thinking mode. We played around with it and were impressed by the quality, it really is a model on the level of the small Qwen3 models and comes with all artifacts released — one of the few “open-source” models today.
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!uzrb!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c3e3ad2-0d9b-4633-9e5e-864b0591f1b9_2194x954.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!uzrb!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c3e3ad2-0d9b-4633-9e5e-864b0591f1b9_2194x954.png 424w, https://substackcdn.com/image/fetch/$s_!uzrb!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c3e3ad2-0d9b-4633-9e5e-864b0591f1b9_2194x954.png 848w, https://substackcdn.com/image/fetch/$s_!uzrb!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c3e3ad2-0d9b-4633-9e5e-864b0591f1b9_2194x954.png 1272w, https://substackcdn.com/image/fetch/$s_!uzrb!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c3e3ad2-0d9b-4633-9e5e-864b0591f1b9_2194x954.png 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2c3e3ad2-0d9b-4633-9e5e-864b0591f1b9_2194x954.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:633,&quot;width&quot;:1456,&quot;resizeWidth&quot;:682,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;296.5013736263736&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!uzrb!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c3e3ad2-0d9b-4633-9e5e-864b0591f1b9_2194x954.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!uzrb!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c3e3ad2-0d9b-4633-9e5e-864b0591f1b9_2194x954.png 424w, https://substackcdn.com/image/fetch/$s_!uzrb!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c3e3ad2-0d9b-4633-9e5e-864b0591f1b9_2194x954.png 848w, https://substackcdn.com/image/fetch/$s_!uzrb!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c3e3ad2-0d9b-4633-9e5e-864b0591f1b9_2194x954.png 1272w, https://substackcdn.com/image/fetch/$s_!uzrb!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c3e3ad2-0d9b-4633-9e5e-864b0591f1b9_2194x954.png 1456w&quot; title=&quot;&quot; width=&quot;682&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/moonshotai/Kimi-K2-Instruct&quot; rel=&quot;&quot;&gt;
       Kimi-K2-Instruct
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/moonshotai&quot; rel=&quot;&quot;&gt;
      moonshotai
     &lt;/a&gt;
     &lt;span&gt;
      : It is hard to understate the impact of the model, which we&#x27;ve
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/kimi-k2-and-when-deepseek-moments&quot; rel=&quot;&quot;&gt;
      covered
     &lt;/a&gt;
     &lt;span&gt;
      already.
     &lt;/span&gt;
     &lt;strong&gt;
      &lt;span&gt;
       The new update is that they released a
      &lt;/span&gt;
      &lt;a href=&quot;https://github.com/MoonshotAI/Kimi-K2/blob/main/tech_report.pdf&quot; rel=&quot;&quot;&gt;
       technical report
      &lt;/a&gt;
      &lt;span&gt;
       today,
      &lt;/span&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      with a bunch of nice methods, but nothing incredibly surprising. K2 has proven itself to be a capable model on various,
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/htihle/status/1944304092928446894&quot; rel=&quot;&quot;&gt;
      unusual
     &lt;/a&gt;
     &lt;span&gt;
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/lechmazur/status/1944848213556838713&quot; rel=&quot;&quot;&gt;
      benchmarks
     &lt;/a&gt;
     &lt;span&gt;
      , matching Opus on
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/lmarena_ai/status/1945866381880373490&quot; rel=&quot;&quot;&gt;
      LMArena
     &lt;/a&gt;
     &lt;span&gt;
      while becoming one of the most used models on
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/OpenRouterAI/status/1944466834167919043&quot; rel=&quot;&quot;&gt;
      OpenRouter
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/black-forest-labs/FLUX.1-Kontext-dev&quot; rel=&quot;&quot;&gt;
       FLUX.1-Kontext-dev
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/black-forest-labs&quot; rel=&quot;&quot;&gt;
      black-forest-labs
     &lt;/a&gt;
     &lt;span&gt;
      : After the GPT-4o image release, a lot of people (especially on social media) claimed that omni models are the future and that specialized image models will be unable to catch up. Avid readers of the Artifacts series know that this is not the case, see
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/stepfun-ai/Step1X-Edit&quot; rel=&quot;&quot;&gt;
      Step1X Edit
     &lt;/a&gt;
     &lt;span&gt;
      as an example. BFL has now released their editing model based on
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/black-forest-labs/FLUX.1-Kontext-dev&quot; rel=&quot;&quot;&gt;
      FLUX.1-Kontext-dev
     &lt;/a&gt;
     &lt;span&gt;
      . Fun fact: FLUX.1-Kontext-dev is the model with the most fine-tunes / adapters on HuggingFace, despite its non-commercial license.
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!FFf9!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5c10e668-30e3-444e-be74-a13cdde81dd3_2939x2100.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!FFf9!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5c10e668-30e3-444e-be74-a13cdde81dd3_2939x2100.png 424w, https://substackcdn.com/image/fetch/$s_!FFf9!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5c10e668-30e3-444e-be74-a13cdde81dd3_2939x2100.png 848w, https://substackcdn.com/image/fetch/$s_!FFf9!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5c10e668-30e3-444e-be74-a13cdde81dd3_2939x2100.png 1272w, https://substackcdn.com/image/fetch/$s_!FFf9!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5c10e668-30e3-444e-be74-a13cdde81dd3_2939x2100.png 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;FLUX.1 [dev] Grid&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5c10e668-30e3-444e-be74-a13cdde81dd3_2939x2100.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1040,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;FLUX.1 [dev] Grid&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;1040&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!FFf9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5c10e668-30e3-444e-be74-a13cdde81dd3_2939x2100.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!FFf9!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5c10e668-30e3-444e-be74-a13cdde81dd3_2939x2100.png 424w, https://substackcdn.com/image/fetch/$s_!FFf9!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5c10e668-30e3-444e-be74-a13cdde81dd3_2939x2100.png 848w, https://substackcdn.com/image/fetch/$s_!FFf9!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5c10e668-30e3-444e-be74-a13cdde81dd3_2939x2100.png 1272w, https://substackcdn.com/image/fetch/$s_!FFf9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5c10e668-30e3-444e-be74-a13cdde81dd3_2939x2100.png 1456w&quot; title=&quot;FLUX.1 [dev] Grid&quot; width=&quot;1456&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/tencent/Hunyuan-A13B-Instruct&quot; rel=&quot;&quot;&gt;
       Hunyuan-A13B-Instruct
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/tencent&quot; rel=&quot;&quot;&gt;
      tencent
     &lt;/a&gt;
     &lt;span&gt;
      : Tencent releases both a 7B dense and a 80B total / 13B active MoE model. It also features 256K context, has very solid benchmark scores (including function calling). Aside from that, people actually use it and are impressed by it! We sound like a broken record, but Chinese labs and companies continue to outbid each other in the open model space with very solid models.
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;strong&gt;
      Edit:
     &lt;/strong&gt;
     &lt;span&gt;
      Unfortunately this model is up there in terms of
     &lt;/span&gt;
     &lt;a href=&quot;https://github.com/Tencent-Hunyuan/Hunyuan-A13B/blob/main/LICENSE&quot; rel=&quot;&quot;&gt;
      bad licenses
     &lt;/a&gt;
     &lt;span&gt;
      . A portion of it states: “You must not use, reproduce, modify, distribute, or display the Tencent Hunyuan Works, Output or results of the Tencent Hunyuan Works outside the Territory. Any such use outside the Territory is unlicensed and unauthorized under this Agreement.” Here, the
     &lt;/span&gt;
     &lt;em&gt;
      territory
     &lt;/em&gt;
     &lt;span&gt;
      is everywhere but the EU, UK, and SK.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h3&gt;
   &lt;strong&gt;
    Models
   &lt;/strong&gt;
  &lt;/h3&gt;
  &lt;h4&gt;
   &lt;strong&gt;
    Flagship
   &lt;/strong&gt;
  &lt;/h4&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/baidu/ERNIE-4.5-21B-A3B-PT&quot; rel=&quot;&quot;&gt;
       ERNIE-4.5-21B-A3B-PT
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/baidu&quot; rel=&quot;&quot;&gt;
      baidu
     &lt;/a&gt;
     &lt;span&gt;
      : Baidu followed up on their promise to release their flagship model, ERNIE, in various sizes, both dense and MoE. The models are licensed under Apache 2.0. However, the model got mixed reactions on social media, with some people being surprised with the quality, while others are disappointed with its performance on tasks outside of usual benchmarks.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/IntervitensInc/pangu-pro-moe-model&quot; rel=&quot;&quot;&gt;
       pangu-pro-moe-model
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/IntervitensInc&quot; rel=&quot;&quot;&gt;
      IntervitensInc
     &lt;/a&gt;
     &lt;span&gt;
      : A MoE trained by the Huawei Pangu team on Ascend NPUs. However, the model release is overshadowed by
     &lt;/span&gt;
     &lt;a href=&quot;https://github.com/HW-whistleblower/True-Story-of-Pangu?&quot; rel=&quot;&quot;&gt;
      allegations
     &lt;/a&gt;
     &lt;span&gt;
      of them being upcycled DeepSeek / Qwen models.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/LGAI-EXAONE/EXAONE-4.0-32B&quot; rel=&quot;&quot;&gt;
       EXAONE-4.0-32B
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/LGAI-EXAONE&quot; rel=&quot;&quot;&gt;
      LGAI-EXAONE
     &lt;/a&gt;
     &lt;span&gt;
      : LG also continues to release new models. This iteration adds a dual-thinking mode, a 3:1 local:global attention and a focus on tool calling. However, it is released under a noncommercial license.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h4&gt;
   &lt;strong&gt;
    General Purpose
   &lt;/strong&gt;
  &lt;/h4&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/ServiceNow-AI/Apriel-Nemotron-15b-Thinker&quot; rel=&quot;&quot;&gt;
       Apriel-Nemotron-15b-Thinker
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/ServiceNow-AI&quot; rel=&quot;&quot;&gt;
      ServiceNow-AI
     &lt;/a&gt;
     &lt;span&gt;
      : ServiceNow is also joining the ever-growing list of companies training their own reasoning models.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/ibm-ai-platform/micro-g3.3-8b-instruct-1b&quot; rel=&quot;&quot;&gt;
       micro-g3.3-8b-instruct-1b
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/ibm-ai-platform&quot; rel=&quot;&quot;&gt;
      ibm-ai-platform
     &lt;/a&gt;
     &lt;span&gt;
      : A 1B model building upon the 8B Granite model, featuring only 3 hidden layers.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/tngtech/DeepSeek-TNG-R1T2-Chimera&quot; rel=&quot;&quot;&gt;
       DeepSeek-TNG-R1T2-Chimera
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/tngtech&quot; rel=&quot;&quot;&gt;
      tngtech
     &lt;/a&gt;
     &lt;span&gt;
      : The German TNG has thrown the new R1 into the model soup (because DeepSeek released an updated R1 model on
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-artifacts-10-new-deepseek&quot; rel=&quot;&quot;&gt;
      May 28th
     &lt;/a&gt;
     &lt;span&gt;
      ), improving performance over the original Chimera model even further.
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!yYuw!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bd902d5-e194-4128-8bf6-f62ae98b9bb5_1337x999.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!yYuw!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bd902d5-e194-4128-8bf6-f62ae98b9bb5_1337x999.png 424w, https://substackcdn.com/image/fetch/$s_!yYuw!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bd902d5-e194-4128-8bf6-f62ae98b9bb5_1337x999.png 848w, https://substackcdn.com/image/fetch/$s_!yYuw!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bd902d5-e194-4128-8bf6-f62ae98b9bb5_1337x999.png 1272w, https://substackcdn.com/image/fetch/$s_!yYuw!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bd902d5-e194-4128-8bf6-f62ae98b9bb5_1337x999.png 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;Intelligence Score&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2bd902d5-e194-4128-8bf6-f62ae98b9bb5_1337x999.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:999,&quot;width&quot;:1337,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Intelligence Score&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;999&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!yYuw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bd902d5-e194-4128-8bf6-f62ae98b9bb5_1337x999.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!yYuw!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bd902d5-e194-4128-8bf6-f62ae98b9bb5_1337x999.png 424w, https://substackcdn.com/image/fetch/$s_!yYuw!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bd902d5-e194-4128-8bf6-f62ae98b9bb5_1337x999.png 848w, https://substackcdn.com/image/fetch/$s_!yYuw!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bd902d5-e194-4128-8bf6-f62ae98b9bb5_1337x999.png 1272w, https://substackcdn.com/image/fetch/$s_!yYuw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bd902d5-e194-4128-8bf6-f62ae98b9bb5_1337x999.png 1456w&quot; title=&quot;Intelligence Score&quot; width=&quot;1337&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/ai21labs/AI21-Jamba-Large-1.7&quot; rel=&quot;&quot;&gt;
       AI21-Jamba-Large-1.7
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/ai21labs&quot; rel=&quot;&quot;&gt;
      ai21labs
     &lt;/a&gt;
     &lt;span&gt;
      : An update to the hybrid SSM-Transformer model series from AI21.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/allenai/FlexOlmo-7x7B-1T&quot; rel=&quot;&quot;&gt;
       FlexOlmo-7x7B-1T
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/allenai&quot; rel=&quot;&quot;&gt;
      allenai
     &lt;/a&gt;
     &lt;span&gt;
      : A new model by Ai2, where
     &lt;/span&gt;
     &lt;strong&gt;
      different organizations can train experts on their data to improve a shared model
     &lt;/strong&gt;
     &lt;span&gt;
      . The
     &lt;/span&gt;
     &lt;a href=&quot;https://www.allenai.org/blog/flexolmo&quot; rel=&quot;&quot;&gt;
      blog
     &lt;/a&gt;
     &lt;span&gt;
      provides more details about the model and its training process.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/microsoft/Phi-4-mini-flash-reasoning&quot; rel=&quot;&quot;&gt;
       Phi-4-mini-flash-reasoning
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/microsoft&quot; rel=&quot;&quot;&gt;
      microsoft
     &lt;/a&gt;
     &lt;span&gt;
      : A hybrid model to speed up inference.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/OctoThinker/OctoThinker-3B-Hybrid-Zero&quot; rel=&quot;&quot;&gt;
       OctoThinker-3B-Hybrid-Zero
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/OctoThinker&quot; rel=&quot;&quot;&gt;
      OctoThinker
     &lt;/a&gt;
     &lt;span&gt;
      : The OctoThinker team has released a comprehensive
     &lt;/span&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2506.20512&quot; rel=&quot;&quot;&gt;
      paper
     &lt;/a&gt;
     &lt;span&gt;
      about their mid-training process.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/nvidia/OpenReasoning-Nemotron-32B&quot; rel=&quot;&quot;&gt;
       OpenReasoning-Nemotron-32B
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/nvidia&quot; rel=&quot;&quot;&gt;
      nvidia
     &lt;/a&gt;
     &lt;span&gt;
      : A new version of NVIDIA&#x27;s reasoning model, using the same prompts as the
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/nvidia/OpenMath-Nemotron-32B&quot; rel=&quot;&quot;&gt;
      previous version
     &lt;/a&gt;
     &lt;span&gt;
      , but with traces generated by R1 0528.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h4&gt;
   &lt;strong&gt;
    Multimodal
   &lt;/strong&gt;
  &lt;/h4&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/AIDC-AI/Ovis-U1-3B&quot; rel=&quot;&quot;&gt;
       Ovis-U1-3B
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/AIDC-AI&quot; rel=&quot;&quot;&gt;
      AIDC-AI
     &lt;/a&gt;
     &lt;span&gt;
      : Another omni model by another subdivision of Alibaba.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/THUDM/GLM-4.1V-9B-Thinking&quot; rel=&quot;&quot;&gt;
       GLM-4.1V-9B-Thinking
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/THUDM&quot; rel=&quot;&quot;&gt;
      THUDM
     &lt;/a&gt;
     &lt;span&gt;
      : An extension of zAI&#x27;s GLM-9B-0414 to also support images as inputs. This is one of the longer-tail of very strong open weight model laboratories from China.
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!6qjQ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc33e22e2-e1e7-4cc8-8129-23bccbbcf32e_1880x817.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!6qjQ!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc33e22e2-e1e7-4cc8-8129-23bccbbcf32e_1880x817.jpeg 424w, https://substackcdn.com/image/fetch/$s_!6qjQ!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc33e22e2-e1e7-4cc8-8129-23bccbbcf32e_1880x817.jpeg 848w, https://substackcdn.com/image/fetch/$s_!6qjQ!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc33e22e2-e1e7-4cc8-8129-23bccbbcf32e_1880x817.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!6qjQ!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc33e22e2-e1e7-4cc8-8129-23bccbbcf32e_1880x817.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;rl&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c33e22e2-e1e7-4cc8-8129-23bccbbcf32e_1880x817.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:633,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;rl&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;633&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!6qjQ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc33e22e2-e1e7-4cc8-8129-23bccbbcf32e_1880x817.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!6qjQ!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc33e22e2-e1e7-4cc8-8129-23bccbbcf32e_1880x817.jpeg 424w, https://substackcdn.com/image/fetch/$s_!6qjQ!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc33e22e2-e1e7-4cc8-8129-23bccbbcf32e_1880x817.jpeg 848w, https://substackcdn.com/image/fetch/$s_!6qjQ!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc33e22e2-e1e7-4cc8-8129-23bccbbcf32e_1880x817.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!6qjQ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc33e22e2-e1e7-4cc8-8129-23bccbbcf32e_1880x817.jpeg 1456w&quot; title=&quot;rl&quot; width=&quot;1456&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Kimi K2 and when &quot;DeepSeek Moments&quot; become normal </title>
<link>https://www.interconnects.ai/p/kimi-k2-and-when-deepseek-moments</link>
<pubDate>Mon, 14 Jul 2025 15:15:10 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    The DeepSeek R1 release earlier this year was more of a prequel than a one-off fluke in the trajectory of AI. Last week, a Chinese startup named Moonshot AI dropped
   &lt;/span&gt;
   &lt;a href=&quot;https://moonshotai.github.io/Kimi-K2/&quot; rel=&quot;&quot;&gt;
    Kimi K2
   &lt;/a&gt;
   &lt;span&gt;
    , an open model that is permissively licensed
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/kimi-k2-and-when-deepseek-moments#footnote-1-168259687&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     1
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    and competitive with leading frontier models in the U.S. If you&#x27;re interested in the geopolitics of AI and the rapid dissemination of the technology, this is going to represent another &quot;DeepSeek moment&quot; where much of the Western world — even those who consider themselves up-to-date with happenings of AI — need to change their expectations for the coming years.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   In summary, Kimi K2 shows us that:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     HighFlyer, the organization that built DeepSeek, is far from a uniquely capable AI laboratory in China,
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     China is continuing to approach (or reached) the absolute frontier of modeling performance, and
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     The West is falling even further behind on open models.
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/kimi-k2-and-when-deepseek-moments?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/kimi-k2-and-when-deepseek-moments?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Kimi K2, described as an &quot;Open-Source Agentic Model&quot; is a sparse mixture of experts (MoE) model
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/kimi-k2-and-when-deepseek-moments#footnote-2-168259687&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     2
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    with 1T total parameters (~1.5x DeepSeek V3/R1&#x27;s 671B) and 32B active parameters (similar to DeepSeek V3/R1&#x27;s 37B). It is a &quot;non-thinking&quot; model with leading performance numbers in coding and related agentic tasks (earning it many comparisons to Claude 3.5 Sonnet), which means it doesn&#x27;t generate a long reasoning chain before answering, but it was still trained extensively with reinforcement learning. It clearly outperforms DeepSeek V3 on a variety of benchmarks, including SWE-Bench, LiveCodeBench, AIME, or GPQA, and comes with a base model released as well. It is the new best-available open model by a clear margin.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!ZKa8!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b6bb3ef-ce00-4253-81c5-0c6c30f1f0a4_1920x1080.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!ZKa8!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b6bb3ef-ce00-4253-81c5-0c6c30f1f0a4_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/$s_!ZKa8!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b6bb3ef-ce00-4253-81c5-0c6c30f1f0a4_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/$s_!ZKa8!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b6bb3ef-ce00-4253-81c5-0c6c30f1f0a4_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!ZKa8!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b6bb3ef-ce00-4253-81c5-0c6c30f1f0a4_1920x1080.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7b6bb3ef-ce00-4253-81c5-0c6c30f1f0a4_1920x1080.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:215783,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/168259687?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b6bb3ef-ce00-4253-81c5-0c6c30f1f0a4_1920x1080.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;819&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!ZKa8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b6bb3ef-ce00-4253-81c5-0c6c30f1f0a4_1920x1080.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!ZKa8!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b6bb3ef-ce00-4253-81c5-0c6c30f1f0a4_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/$s_!ZKa8!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b6bb3ef-ce00-4253-81c5-0c6c30f1f0a4_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/$s_!ZKa8!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b6bb3ef-ce00-4253-81c5-0c6c30f1f0a4_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!ZKa8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b6bb3ef-ce00-4253-81c5-0c6c30f1f0a4_1920x1080.jpeg 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   These facts with the points above all have useful parallels for what comes next:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Controlling who can
     &lt;/strong&gt;
     &lt;em&gt;
      &lt;strong&gt;
       train
      &lt;/strong&gt;
     &lt;/em&gt;
     &lt;strong&gt;
      cutting edge models is extremely difficult
     &lt;/strong&gt;
     &lt;span&gt;
      . More organizations will join this list of OpenAI, Anthropic, Google, Meta, xAI, Qwen, DeepSeek, Moonshot AI, etc. Where there is a concentration of talent and sufficient compute, excellent models are very possible. This is easier to do somewhere such as China or Europe where there is existing talent, but is not restricted to these localities.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Kimi K2 was trained on 15.5T tokens and has a very similar number of active parameters as DeepSeek V3/R1, which was trained on 14.8T tokens.
     &lt;/span&gt;
     &lt;strong&gt;
      Better models are being trained without substantial increases in compute
     &lt;/strong&gt;
     &lt;span&gt;
      — these are referred to as a mix of &quot;algorithmic gains&quot; or &quot;efficiency gains&quot; in training. Compute restrictions will certainly slow this pace of progress on Chinese companies, but they are clearly not a binary on/off bottleneck on training.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      The gap between the leading open models from the Western research labs versus their Chinese counterparts is only increasing in magnitude
     &lt;/strong&gt;
     &lt;span&gt;
      . The best open model from an American company is, maybe, Llama-4-Maverick? Three Chinese organizations have released obviously more useful models with more permissive licenses: DeepSeek, Moonshot AI, and Qwen. A few others such as
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/tencent/models?sort=likes&quot; rel=&quot;&quot;&gt;
      Tencent
     &lt;/a&gt;
     &lt;span&gt;
      ,
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/MiniMaxAI&quot; rel=&quot;&quot;&gt;
      Minimax
     &lt;/a&gt;
     &lt;span&gt;
      ,
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/THUDM&quot; rel=&quot;&quot;&gt;
      Z.ai/THUDM
     &lt;/a&gt;
     &lt;span&gt;
      may have Llama-4 beat too but are a half step behind the leading Chinese models on some combination of license and performance.
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      This comes at the same time that new inference-heavy products are coming online that&#x27;ll benefit from the potential of cheaper, lower margin hosting options on open models relative to API counterparts (which tend to have high profit margins).
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
  &lt;/div&gt;
  &lt;p&gt;
   Kimi K2 is set up for a much slower style &quot;DeepSeek Moment&quot; than the DeepSeek R1 model that came out in January of this year because it lacks two culturally salient factors:
  &lt;/p&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     DeepSeek R1 was revelatory because it was the first model to expose the reasoning trace to the users, causing massive adoption outside of the technical AI community, and
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      The broader public is already aware that training leading AI models is actually
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/deepseek-v3-and-the-actual-cost-of&quot; rel=&quot;&quot;&gt;
      very low cost
     &lt;/a&gt;
     &lt;span&gt;
      once the technical expertise is built up (recall the DeepSeek V3 $5M training cost number), i.e. the final training run is cheap, so there
     &lt;/span&gt;
     &lt;em&gt;
      should
     &lt;/em&gt;
     &lt;span&gt;
      be a smaller reaction to similar cheap training cost numbers in the Kimi K2 report coming soon.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;p&gt;
   &lt;span&gt;
    Still, as more noise is created around the K2 release (Moonshot releases a technical report soon), this could evolve very rapidly. We&#x27;ve already seen quick experiments spin up
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/jeremyphoward/status/1944326308210921652&quot; rel=&quot;&quot;&gt;
    slotting it into the Claude Code application
   &lt;/a&gt;
   &lt;span&gt;
    (because Kimi&#x27;s API is Claude-compatible) and K2 topping many nice &quot;
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/tri_dao/status/1943745133603610864?s=46&quot; rel=&quot;&quot;&gt;
    vibe
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/kalomaze/status/1943711672285139043&quot; rel=&quot;&quot;&gt;
    tests
   &lt;/a&gt;
   &lt;span&gt;
    &quot; or
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/sam_paech/status/1944276326598553853&quot; rel=&quot;&quot;&gt;
    creativity benchmarks
   &lt;/a&gt;
   &lt;span&gt;
    . There are also tons of fun technical details that I don&#x27;t have time to go into — from using a relatively unproven optimizer Muon
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/kimi-k2-and-when-deepseek-moments#footnote-3-168259687&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     3
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    and scaling up the self-rewarding LLM-as-a-judge pipeline in post-training. A fun tidbit to show how much this matters relative to the noisy Grok 4 release last week is that
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/OpenRouterAI/status/1944466834167919043&quot; rel=&quot;&quot;&gt;
    Kimi K2 has already surpassed Grok 4
   &lt;/a&gt;
   &lt;span&gt;
    in API usage on the popular OpenRouter platform.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Later in the day on the 11th, following the K2 release, OpenAI CEO Sam Altman shared the following
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/sama/status/1943837550369812814&quot; rel=&quot;&quot;&gt;
    message
   &lt;/a&gt;
   &lt;span&gt;
    regarding OpenAI&#x27;s forthcoming open model (which I previously shared more optimistic thoughts on
   &lt;/span&gt;
   &lt;a href=&quot;https://natolambert.substack.com/p/some-thoughts-on-openai-returning&quot; rel=&quot;&quot;&gt;
    here
   &lt;/a&gt;
   &lt;span&gt;
    ) :
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    we planned to launch our open-weight model next week.
   &lt;/p&gt;
   &lt;p&gt;
    we are delaying it; we need time to run additional safety tests and review high-risk areas. we are not yet sure how long it will take us.
   &lt;/p&gt;
   &lt;p&gt;
    while we trust the community will build great things with this model, once weights are out, they can’t be pulled back. this is new for us and we want to get it right.
   &lt;/p&gt;
   &lt;p&gt;
    sorry to be the bearer of bad news; we are working super hard!
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   Many attributed this as a reactive move by OpenAI to get out from the shadow of Kimi K2&#x27;s wonderful release and another DeepSeek media cycle.
  &lt;/p&gt;
  &lt;p&gt;
   Even though someone at OpenAI shared with me that the rumor that Kimi caused the delay for their open model is very likely not true, this is what being on the back foot looks like. When you&#x27;re on the back foot, narratives like this are impossible to control.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    We need leaders at the closed AI laboratories in the U.S. to rethink some of the long-term dynamics they&#x27;re battling with R&amp;D adoption. We need to mobilize funding for
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/the-american-deepseek-project&quot; rel=&quot;&quot;&gt;
    great, open science projects
   &lt;/a&gt;
   &lt;span&gt;
    in the U.S. and Europe. Until then, this is what losing looks like if you want The West to be the long-term foundation of AI research and development. Kimi K2 has shown us that one &quot;DeepSeek Moment&quot; wasn&#x27;t enough for us to make the changes we need, and hopefully we don&#x27;t need a third.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/kimi-k2-and-when-deepseek-moments#footnote-anchor-1-168259687&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     &lt;span&gt;
      The modified MIT
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/moonshotai/Kimi-K2-Instruct/blob/main/LICENSE&quot; rel=&quot;&quot;&gt;
      license
     &lt;/a&gt;
     &lt;span&gt;
      is somewhat annoying, but technically easy to comply with. These sorts of added terms on marketing make it in conflict with &quot;true open-source principles&quot;.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/kimi-k2-and-when-deepseek-moments#footnote-anchor-2-168259687&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    2
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     &lt;span&gt;
      Very similar to
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/rasbt/status/1944056316424577525&quot; rel=&quot;&quot;&gt;
      DeepSeek architecture
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/kimi-k2-and-when-deepseek-moments#footnote-anchor-3-168259687&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    3
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     Beautiful learning curve.
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!3UEt!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4e86366-eb95-456a-914e-6bca469902ef_1664x1038.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!3UEt!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4e86366-eb95-456a-914e-6bca469902ef_1664x1038.png 424w, https://substackcdn.com/image/fetch/$s_!3UEt!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4e86366-eb95-456a-914e-6bca469902ef_1664x1038.png 848w, https://substackcdn.com/image/fetch/$s_!3UEt!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4e86366-eb95-456a-914e-6bca469902ef_1664x1038.png 1272w, https://substackcdn.com/image/fetch/$s_!3UEt!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4e86366-eb95-456a-914e-6bca469902ef_1664x1038.png 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e4e86366-eb95-456a-914e-6bca469902ef_1664x1038.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:908,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:287226,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/168259687?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4e86366-eb95-456a-914e-6bca469902ef_1664x1038.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;908&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!3UEt!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4e86366-eb95-456a-914e-6bca469902ef_1664x1038.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!3UEt!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4e86366-eb95-456a-914e-6bca469902ef_1664x1038.png 424w, https://substackcdn.com/image/fetch/$s_!3UEt!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4e86366-eb95-456a-914e-6bca469902ef_1664x1038.png 848w, https://substackcdn.com/image/fetch/$s_!3UEt!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4e86366-eb95-456a-914e-6bca469902ef_1664x1038.png 1272w, https://substackcdn.com/image/fetch/$s_!3UEt!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4e86366-eb95-456a-914e-6bca469902ef_1664x1038.png 1456w&quot; width=&quot;1456&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
    &lt;p&gt;
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> xAI&#x27;s Grok 4: The tension of frontier performance with a side of Elon favoritism </title>
<link>https://www.interconnects.ai/p/grok-4-an-o3-look-alike-in-search</link>
<pubDate>Sat, 12 Jul 2025 14:41:32 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;h5&gt;
   Voiceover for this post will be late as I’m traveling and don’t know when I’ll find the time.
  &lt;/h5&gt;
  &lt;h5&gt;
   &lt;span&gt;
    I had the pleasure of being on both
   &lt;/span&gt;
   &lt;a href=&quot;https://www.youtube.com/live/p7ERvuUVnW8?si=jfQUfJBYNdgEB_ij&amp;t=9224&quot; rel=&quot;&quot;&gt;
    TBPN
   &lt;/a&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;a href=&quot;https://open.spotify.com/episode/45NrhTr99EXSEaAuQL2v3u&quot; rel=&quot;&quot;&gt;
    ChinaTalk
   &lt;/a&gt;
   &lt;span&gt;
    again to discuss the American DeepSeek project and other happenings in AI, check them out!
   &lt;/span&gt;
  &lt;/h5&gt;
  &lt;div&gt;
   &lt;hr/&gt;
  &lt;/div&gt;
  &lt;p&gt;
   Elon Musk’s xAI launched Grok 4 on Wednesday, the 9th, with the fanfare of leading benchmarks and 10X RL compute for reasoning, but even with that it is unlikely to substantively disrupt the current user bases of the frontier model market. On top of stellar scores, Grok 4 comes with severe brand risk, a lack of differentiation, and mixed vibe tests, highlighting how catching up in benchmarks is one thing, but finding a use for expensive frontier models isn’t automatic — it is the singular challenge as model performance becomes commoditized.
  &lt;/p&gt;
  &lt;p&gt;
   In this post we detail everything about Grok 4, including:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     Performance overview and a survey of early vibe checks,
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Testing Grok 4 Heavy and how xAI’s approach to parallel compute compares to o3 pro,
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     xAI’s lack of differentiated products, and
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     MechaHitler and culture risk.
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   The core of it is a very impressive model, but the frontier model plagued with the most serious behavioral risks and cultural concerns in the AI industry since ChatGPT’s release.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/grok-4-an-o3-look-alike-in-search?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/grok-4-an-o3-look-alike-in-search?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;h2&gt;
   Grok 4’s performance
  &lt;/h2&gt;
  &lt;p&gt;
   Grok 4 is the leading publicly available model on a wide variety of frontier model benchmarks. It was trained with large scale reinforcement learning on verifiable rewards with tool-integrated reasoning.
  &lt;/p&gt;
  &lt;h3&gt;
   Benchmarks
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;span&gt;
    Swyx at Smol AI and
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;a data-attrs=&#x27;{&quot;name&quot;:&quot;Latent.Space&quot;,&quot;id&quot;:89230629,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/703cf3dd-3bab-4f7b-86fa-f4443f15f8a4_152x152.jpeg&quot;,&quot;uuid&quot;:&quot;e6fe7cd6-8c06-45ac-bb48-e2bb79ad759b&quot;}&#x27; data-component-name=&quot;MentionUser&quot; href=&quot;https://open.substack.com/users/89230629-latentspace?utm_source=mentions&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;
    Latent.Space
   &lt;/a&gt;
  &lt;/div&gt;
  &lt;span&gt;
  &lt;/span&gt;
  &lt;a href=&quot;https://news.smol.ai/issues/25-07-10-grok-4&quot; rel=&quot;&quot;&gt;
   summarized the performance perfectly
  &lt;/a&gt;
  &lt;span&gt;
   :
  &lt;/span&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    &lt;span&gt;
     Rumored to be
    &lt;/span&gt;
    &lt;a href=&quot;https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fx.com%2Fkalomaze%2Fstatus%2F1942996555088134592%3Fs=46/1/01000197f6bc697d-815775ba-8cd6-4d0c-a428-be3d27a609fe-000000/RQeRmOvkrlFJTYWNJqelfwtUlq1-jD6QxvlLuWP24FA=413&quot; rel=&quot;&quot;&gt;
     2.4T params
    &lt;/a&gt;
    &lt;span&gt;
     (the second released &amp;gt;2T model after 4 Opus?), it hits new high water marks on HLE, GPQA (leading to a new
    &lt;/span&gt;
    &lt;a href=&quot;https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fx.com%2FArtificialAnlys%2Fstatus%2F1943166841150644622/1/01000197f6bc697d-815775ba-8cd6-4d0c-a428-be3d27a609fe-000000/kVvb9FieZEGC55rKAn34ti8OUNFNAK3HN0RPkxtKNPg=413&quot; rel=&quot;&quot;&gt;
     AAQI
    &lt;/a&gt;
    &lt;span&gt;
     ) HMMT,
    &lt;/span&gt;
    &lt;a href=&quot;https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fx.com%2Flechmazur%2Fstatus%2F1943245535973945428%3Fs=46/1/01000197f6bc697d-815775ba-8cd6-4d0c-a428-be3d27a609fe-000000/S0CZy6NnZV6YVrjs9VZYPWvRSOkcTGPughHTtc34_DE=413&quot; rel=&quot;&quot;&gt;
     Connections
    &lt;/a&gt;
    &lt;span&gt;
     , LCB,
    &lt;/span&gt;
    &lt;a href=&quot;https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fx.com%2Farthurmacwaters%2Fstatus%2F1943171049010688060%3Fs=46/1/01000197f6bc697d-815775ba-8cd6-4d0c-a428-be3d27a609fe-000000/U3y6PvLVUPoO2vK4HBqjIAZ0IYtKhZ-gxWfG5XENnrQ=413&quot; rel=&quot;&quot;&gt;
     Vending-Bench
    &lt;/a&gt;
    &lt;span&gt;
     ,
    &lt;/span&gt;
    &lt;a href=&quot;https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fx.com%2Fmattshumer_%2Fstatus%2F1943167369720807909%3Fs=46/1/01000197f6bc697d-815775ba-8cd6-4d0c-a428-be3d27a609fe-000000/S6wm0tinI9taVf-gYR6nngEhiBP0FDFJGozprYCZ2yY=413&quot; rel=&quot;&quot;&gt;
     AIME
    &lt;/a&gt;
    &lt;span&gt;
     ,
    &lt;/span&gt;
    &lt;a href=&quot;https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fx.com%2Fpdhsu%2Fstatus%2F1943174995020255287%3Fs=46/1/01000197f6bc697d-815775ba-8cd6-4d0c-a428-be3d27a609fe-000000/NMi7HBJSaGxPZ7SZ7c0-St50ZPZesDViXatJxUmrnsU=413&quot; rel=&quot;&quot;&gt;
     Chest Agent Bench
    &lt;/a&gt;
    &lt;span&gt;
     , and
    &lt;/span&gt;
    &lt;a href=&quot;https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fx.com%2FGregKamradt%2Fstatus%2F1943169631491100856/1/01000197f6bc697d-815775ba-8cd6-4d0c-a428-be3d27a609fe-000000/fVqqKEE1sJFF5NMDwR4bofbWWdULiT6JDHb_2JZb9ss=413&quot; rel=&quot;&quot;&gt;
     ARC-AGI
    &lt;/a&gt;
    &lt;span&gt;
     , and
    &lt;/span&gt;
    &lt;a href=&quot;https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftechcrunch.com%2F2025%2F07%2F09%2Felon-musks-xai-launches-grok-4-alongside-a-300-monthly-subscription%2F/1/01000197f6bc697d-815775ba-8cd6-4d0c-a428-be3d27a609fe-000000/2gVmxNkpXRJiNfOpPVP0CaZVjGXqOJrJODtp2TOfS8w=413&quot; rel=&quot;&quot;&gt;
     Grok 4 Heavy
    &lt;/a&gt;
    &lt;span&gt;
     , available at a new $300/month tier, is their equivalent of O3 pro (with
    &lt;/span&gt;
    &lt;a href=&quot;https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fx.com%2FRayFernando1337%2Fstatus%2F1943384191443575254/1/01000197f6bc697d-815775ba-8cd6-4d0c-a428-be3d27a609fe-000000/StHh2NiNlLAwTTBVye2fOfAOV1p3vlTcjgju1dtt0wc=413&quot; rel=&quot;&quot;&gt;
     some reliability issues
    &lt;/a&gt;
    &lt;span&gt;
     ). What else is there to say about it apart from go try it out?
    &lt;/span&gt;
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   &lt;span&gt;
    A few others include it being top overall by
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/artificialanlys/status/1943166841150644622&quot; rel=&quot;&quot;&gt;
    ArtificialAnalysis
   &lt;/a&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/ficlive/status/1943401632181440692?s=46&quot; rel=&quot;&quot;&gt;
    dethroning Gemini 2.5 Pro on long context
   &lt;/a&gt;
   &lt;span&gt;
    . It also launches with an
   &lt;/span&gt;
   &lt;a href=&quot;https://console.x.ai/&quot; rel=&quot;&quot;&gt;
    API
   &lt;/a&gt;
   &lt;span&gt;
    version (a first for xAI).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    This is an extremely impressive list, and something we don’t see regularly in AI model releases as the landscape has been more competitive. The sorts of models with this “wiping the floor” on benchmarks are only the likes of
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/reverse-engineering-openai-o1?utm_source=publication-search&quot; rel=&quot;&quot;&gt;
    o1
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/openais-o3-the-2024-finale-of-ai&quot; rel=&quot;&quot;&gt;
    o3
   &lt;/a&gt;
   &lt;span&gt;
    (which was just an announcement, not released), and
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/gemini-25-pro-googles-second-ai-chance&quot; rel=&quot;&quot;&gt;
    Gemini 2.5 Pro
   &lt;/a&gt;
   &lt;span&gt;
    . Benchmark progress is in many ways going faster than ever — the previous major step like these models was arguably
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/gpt4-review&quot; rel=&quot;&quot;&gt;
    GPT-4 itself
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   In order to achieve this, xAI put up a slide saying that they increased the RL compute from Grok 3 reasoning by 10X to create this model, shown below.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!a74S!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa288a8a9-4509-4d57-848b-354ac2f6864a_959x533.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!a74S!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa288a8a9-4509-4d57-848b-354ac2f6864a_959x533.png 424w, https://substackcdn.com/image/fetch/$s_!a74S!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa288a8a9-4509-4d57-848b-354ac2f6864a_959x533.png 848w, https://substackcdn.com/image/fetch/$s_!a74S!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa288a8a9-4509-4d57-848b-354ac2f6864a_959x533.png 1272w, https://substackcdn.com/image/fetch/$s_!a74S!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa288a8a9-4509-4d57-848b-354ac2f6864a_959x533.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a288a8a9-4509-4d57-848b-354ac2f6864a_959x533.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:533,&quot;width&quot;:959,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:88177,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/167998749?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa288a8a9-4509-4d57-848b-354ac2f6864a_959x533.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;533&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!a74S!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa288a8a9-4509-4d57-848b-354ac2f6864a_959x533.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!a74S!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa288a8a9-4509-4d57-848b-354ac2f6864a_959x533.png 424w, https://substackcdn.com/image/fetch/$s_!a74S!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa288a8a9-4509-4d57-848b-354ac2f6864a_959x533.png 848w, https://substackcdn.com/image/fetch/$s_!a74S!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa288a8a9-4509-4d57-848b-354ac2f6864a_959x533.png 1272w, https://substackcdn.com/image/fetch/$s_!a74S!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa288a8a9-4509-4d57-848b-354ac2f6864a_959x533.png 1456w&quot; width=&quot;959&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
    &lt;figcaption&gt;
     Screenshot from the livestream. Note the lack of y-axis labels.
    &lt;/figcaption&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   This plot is not something that should be taken as precise. Even if they did use the exact same pretraining compute as Grok 3 and scaled up RL to be exactly the same amount of compute, it is definitely case that it is not representative of any “RL is saturating already” or other timeline comments. The benchmarks and speed of releases speak for this — RL is enabling a new type of rapid hillclimbing and all of the leading labs are committing large personnel and compute resources to exploiting it.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    We have no indications that we are near the top of the RL curve to balance out the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/gpt-45-not-a-frontier-model?utm_source=publication-search&quot; rel=&quot;&quot;&gt;
    GPT-4.5 release
   &lt;/a&gt;
   &lt;span&gt;
    that showed “simple parameter scaling alone” (without RL), isn’t the short term path forward.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    A few more striking plots of the performance are included here from the
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/xai/status/1943158495588815072&quot; rel=&quot;&quot;&gt;
    livestream
   &lt;/a&gt;
   &lt;span&gt;
    announcing the model.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!q_jG!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff128bb57-bd7b-4130-8a06-d1c6cd573665_1048x768.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!q_jG!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff128bb57-bd7b-4130-8a06-d1c6cd573665_1048x768.jpeg 424w, https://substackcdn.com/image/fetch/$s_!q_jG!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff128bb57-bd7b-4130-8a06-d1c6cd573665_1048x768.jpeg 848w, https://substackcdn.com/image/fetch/$s_!q_jG!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff128bb57-bd7b-4130-8a06-d1c6cd573665_1048x768.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!q_jG!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff128bb57-bd7b-4130-8a06-d1c6cd573665_1048x768.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;Image&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f128bb57-bd7b-4130-8a06-d1c6cd573665_1048x768.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:768,&quot;width&quot;:1048,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;768&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!q_jG!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff128bb57-bd7b-4130-8a06-d1c6cd573665_1048x768.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!q_jG!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff128bb57-bd7b-4130-8a06-d1c6cd573665_1048x768.jpeg 424w, https://substackcdn.com/image/fetch/$s_!q_jG!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff128bb57-bd7b-4130-8a06-d1c6cd573665_1048x768.jpeg 848w, https://substackcdn.com/image/fetch/$s_!q_jG!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff128bb57-bd7b-4130-8a06-d1c6cd573665_1048x768.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!q_jG!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff128bb57-bd7b-4130-8a06-d1c6cd573665_1048x768.jpeg 1456w&quot; title=&quot;Image&quot; width=&quot;1048&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   The Humanity’s Last Exam plot, while showcasing overall peak performance, is also a beautiful example of scaling both training time (RL) and test-time (inference time scaling, CoT, parallel compute) with and without tools. This is the direction leading models are going.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!TcWM!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fb1b7dc-505d-4356-aa46-636885a3b980_1986x1119.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!TcWM!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fb1b7dc-505d-4356-aa46-636885a3b980_1986x1119.jpeg 424w, https://substackcdn.com/image/fetch/$s_!TcWM!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fb1b7dc-505d-4356-aa46-636885a3b980_1986x1119.jpeg 848w, https://substackcdn.com/image/fetch/$s_!TcWM!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fb1b7dc-505d-4356-aa46-636885a3b980_1986x1119.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!TcWM!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fb1b7dc-505d-4356-aa46-636885a3b980_1986x1119.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;Image&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2fb1b7dc-505d-4356-aa46-636885a3b980_1986x1119.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:820,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;820&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!TcWM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fb1b7dc-505d-4356-aa46-636885a3b980_1986x1119.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!TcWM!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fb1b7dc-505d-4356-aa46-636885a3b980_1986x1119.jpeg 424w, https://substackcdn.com/image/fetch/$s_!TcWM!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fb1b7dc-505d-4356-aa46-636885a3b980_1986x1119.jpeg 848w, https://substackcdn.com/image/fetch/$s_!TcWM!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fb1b7dc-505d-4356-aa46-636885a3b980_1986x1119.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!TcWM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fb1b7dc-505d-4356-aa46-636885a3b980_1986x1119.jpeg 1456w&quot; title=&quot;Image&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   The main question with this release was then — does the usefulness of the model in everyday queries match the on paper numbers of the model?
  &lt;/p&gt;
  &lt;h3&gt;
   Vibe tests
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;span&gt;
    Immediately after the release there were
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/zjasper666/status/1943567080017494313?s=46&quot; rel=&quot;&quot;&gt;
    a lot of
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/kalomaze/status/1943169371620208828&quot; rel=&quot;&quot;&gt;
    reports
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/zjasper666/status/1943567080017494313?s=46&quot; rel=&quot;&quot;&gt;
    of Grok 4
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/doomslide/status/1943206474966069439&quot; rel=&quot;&quot;&gt;
    fumbling
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/_xjdr/status/1943184326100947099&quot; rel=&quot;&quot;&gt;
    over its words
   &lt;/a&gt;
   &lt;span&gt;
    . Soon after, the
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/lintool/status/1943721853186404606&quot; rel=&quot;&quot;&gt;
    first crowdsourced leaderboards
   &lt;/a&gt;
   &lt;span&gt;
    (Yupp in this case, a new LMArena competitor), showed Grok 4 as very middle of the pack — far lower than its benchmark scores would suggest.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    My testing agrees with this. I didn’t find Grok 4 particularly nice to use like I did the original Claude 3.5 Sonnet or GPT 4.5, but its behavior with tools was immediately of interest to me. Grok 4 is a model that is very reminiscent of o3 in its search-heavy style —
   &lt;/span&gt;
   &lt;strong&gt;
    &lt;span&gt;
     this is a
    &lt;/span&gt;
    &lt;a href=&quot;https://www.interconnects.ai/i/166556899/o-as-a-technical-breakthrough-beyond-scaling&quot; rel=&quot;&quot;&gt;
     milestone
    &lt;/a&gt;
    &lt;span&gt;
     I’ve been specifically monitoring, and again confirms that major technical differentiation doesn’t last long across frontier model providers.
    &lt;/span&gt;
   &lt;/strong&gt;
   &lt;span&gt;
    Maybe making an o3 style model isn&#x27;t so hard, but making one that has style and taste is.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    It’s the sort of behavior where the model almost always searches, e.g. for the simple query below.
   &lt;/span&gt;
   &lt;a href=&quot;https://grok.com/share/bGVnYWN5_f9757490-c174-4c2a-87f9-3525cb81b0b6&quot; rel=&quot;&quot;&gt;
    Grok 4 uses search
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://chatgpt.com/share/686fe56f-6214-8005-b376-93b89bfa5e5e&quot; rel=&quot;&quot;&gt;
    so does o3
   &lt;/a&gt;
   &lt;span&gt;
    , but
   &lt;/span&gt;
   &lt;a href=&quot;https://claude.ai/share/ae9e3412-2abb-45b0-989b-e4d83b515aad&quot; rel=&quot;&quot;&gt;
    Claude 4
   &lt;/a&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;a href=&quot;https://g.co/gemini/share/2cc423a04236&quot; rel=&quot;&quot;&gt;
    Gemini 2.5 do not
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!CWGv!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50f80d3c-4470-40ac-8eef-7a4624191fca_1680x614.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!CWGv!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50f80d3c-4470-40ac-8eef-7a4624191fca_1680x614.png 424w, https://substackcdn.com/image/fetch/$s_!CWGv!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50f80d3c-4470-40ac-8eef-7a4624191fca_1680x614.png 848w, https://substackcdn.com/image/fetch/$s_!CWGv!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50f80d3c-4470-40ac-8eef-7a4624191fca_1680x614.png 1272w, https://substackcdn.com/image/fetch/$s_!CWGv!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50f80d3c-4470-40ac-8eef-7a4624191fca_1680x614.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/50f80d3c-4470-40ac-8eef-7a4624191fca_1680x614.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:532,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:102215,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/167998749?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50f80d3c-4470-40ac-8eef-7a4624191fca_1680x614.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;532&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!CWGv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50f80d3c-4470-40ac-8eef-7a4624191fca_1680x614.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!CWGv!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50f80d3c-4470-40ac-8eef-7a4624191fca_1680x614.png 424w, https://substackcdn.com/image/fetch/$s_!CWGv!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50f80d3c-4470-40ac-8eef-7a4624191fca_1680x614.png 848w, https://substackcdn.com/image/fetch/$s_!CWGv!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50f80d3c-4470-40ac-8eef-7a4624191fca_1680x614.png 1272w, https://substackcdn.com/image/fetch/$s_!CWGv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50f80d3c-4470-40ac-8eef-7a4624191fca_1680x614.png 1456w&quot; title=&quot;&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    At the same time, it doesn’t seem quite as extensive in its search as o3, but much of this could be down to UX and inference settings rather than the underlying model’s training. The reasoning is far more interpretable than OpenAI and some other providers which is nice to understand how the model is using tools (e.g. the exact search queries).
   &lt;/span&gt;
   &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/grok-4-an-o3-look-alike-in-search#footnote-1-167998749&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Overall, the vibe tests indicate that Grok 4 is a bit benchmaxxed and overcooked, but this doesn’t mean it is not a major technical achievement. It makes adoption harder.
  &lt;/p&gt;
  &lt;h3&gt;
   Grok 4 Heavy search &amp; tool use — an o3 competitor?
  &lt;/h3&gt;
  &lt;p&gt;
   Along with the new model itself, xAI announced a new “Heavy” mode which “dynamically spawns multiple agents” to help solve problems. This new offering combined with the search-heavy behavior represented an important item to test explicitly.
  &lt;/p&gt;
  &lt;p&gt;
   In summary, Grok 4 Heavy behaves like a hybrid between Deep Research products and o1/3-Pro style models on open domains. This points to a new era of technical uncertainty as users and companies race to understand how the top models behave at inference. No longer is it enough to only serve long chains of thought at inference — Grok 4 Heavy shows substantial improvements across all of the reasoning benchmarks.
  &lt;/p&gt;
  &lt;p&gt;
   We don’t have enough information on Grok Heavy, o3-Pro, or Deep Research to know exactly which of these are close to each other. The operating assumptions in industry are that two types of parallel compute exist:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Multi-agent systems with an orchestrator model
     &lt;/strong&gt;
     &lt;span&gt;
      : In this case, which I interpret being close to Claude Code with parallelism enabled or Deep Research, one central repository manages parallel search agents assigned sub tasks.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Parallel, ranked generation
     &lt;/strong&gt;
     &lt;span&gt;
      : in this case, the same prompt is provided to multiple copies of the model and the best answer is selected by a verifier or reward model.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   Both of these will be impactful for different domains, but the former is far closer to general agents that the industry is collectively striving for and anticipating.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Some examples of Grok 4 Heavy compared to Grok 4 and Deep Research as a baseline are included below.
   &lt;/span&gt;
   &lt;strong&gt;
    My testing focuses on information processing as the most interesting behavior of search-heavy models, but other tests should be done for coding, creativity, and other domains.
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;h4&gt;
   Example 1
  &lt;/h4&gt;
  &lt;p&gt;
   &lt;span&gt;
    “rank caltrain stations by proximity to McDonald’s” (
   &lt;/span&gt;
   &lt;a href=&quot;https://grok.com/share/bGVnYWN5_be1fb6d1-6937-43f6-b80c-937bd59297ba&quot; rel=&quot;&quot;&gt;
    Grok 4 Heavy
   &lt;/a&gt;
   &lt;span&gt;
    - 190 web pages,
   &lt;/span&gt;
   &lt;a href=&quot;https://grok.com/share/bGVnYWN5_08f31f94-044c-49ff-bfb5-7d6bfdc06f09&quot; rel=&quot;&quot;&gt;
    Grok 4 baseline
   &lt;/a&gt;
   &lt;span&gt;
    - 226 web pages,
   &lt;/span&gt;
   &lt;a href=&quot;https://chatgpt.com/s/dr_686fe005df088191b8046375a8146cfc&quot; rel=&quot;&quot;&gt;
    OpenAI Deep Research baseline
   &lt;/a&gt;
   &lt;span&gt;
    - 49 sources, 164 searches)
   &lt;/span&gt;
   &lt;br/&gt;
   &lt;br/&gt;
   &lt;span&gt;
    Grok 4 (not heavy) here, showed clearly that it’s using the Google search in the browser (rather than API, which could come into legal dispute as they’re taking Google infrastructure for free?), which could be a big advantage over Bing (for ChatGPT) or custom indexes in the short term.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!P6lR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ed3a5d2-53a2-4c94-96f7-50cb9b5e0270_1638x1126.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!P6lR!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ed3a5d2-53a2-4c94-96f7-50cb9b5e0270_1638x1126.jpeg 424w, https://substackcdn.com/image/fetch/$s_!P6lR!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ed3a5d2-53a2-4c94-96f7-50cb9b5e0270_1638x1126.jpeg 848w, https://substackcdn.com/image/fetch/$s_!P6lR!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ed3a5d2-53a2-4c94-96f7-50cb9b5e0270_1638x1126.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!P6lR!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ed3a5d2-53a2-4c94-96f7-50cb9b5e0270_1638x1126.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;Image&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1ed3a5d2-53a2-4c94-96f7-50cb9b5e0270_1638x1126.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1001,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;1001&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!P6lR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ed3a5d2-53a2-4c94-96f7-50cb9b5e0270_1638x1126.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!P6lR!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ed3a5d2-53a2-4c94-96f7-50cb9b5e0270_1638x1126.jpeg 424w, https://substackcdn.com/image/fetch/$s_!P6lR!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ed3a5d2-53a2-4c94-96f7-50cb9b5e0270_1638x1126.jpeg 848w, https://substackcdn.com/image/fetch/$s_!P6lR!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ed3a5d2-53a2-4c94-96f7-50cb9b5e0270_1638x1126.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!P6lR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ed3a5d2-53a2-4c94-96f7-50cb9b5e0270_1638x1126.jpeg 1456w&quot; title=&quot;Image&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    The model still has issues — Grok 4 gave up. For a counterexample,
   &lt;/span&gt;
   &lt;a href=&quot;https://chatgpt.com/share/686fe517-6dc4-8005-9927-007573eca0fe&quot; rel=&quot;&quot;&gt;
    o3 attempted something
   &lt;/a&gt;
   &lt;span&gt;
    at least plausible.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!JxaQ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faee47ccf-2c4b-4862-a118-43f4426fcad5_1692x620.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!JxaQ!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faee47ccf-2c4b-4862-a118-43f4426fcad5_1692x620.png 424w, https://substackcdn.com/image/fetch/$s_!JxaQ!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faee47ccf-2c4b-4862-a118-43f4426fcad5_1692x620.png 848w, https://substackcdn.com/image/fetch/$s_!JxaQ!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faee47ccf-2c4b-4862-a118-43f4426fcad5_1692x620.png 1272w, https://substackcdn.com/image/fetch/$s_!JxaQ!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faee47ccf-2c4b-4862-a118-43f4426fcad5_1692x620.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/aee47ccf-2c4b-4862-a118-43f4426fcad5_1692x620.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:534,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:79466,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/167998749?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faee47ccf-2c4b-4862-a118-43f4426fcad5_1692x620.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;534&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!JxaQ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faee47ccf-2c4b-4862-a118-43f4426fcad5_1692x620.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!JxaQ!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faee47ccf-2c4b-4862-a118-43f4426fcad5_1692x620.png 424w, https://substackcdn.com/image/fetch/$s_!JxaQ!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faee47ccf-2c4b-4862-a118-43f4426fcad5_1692x620.png 848w, https://substackcdn.com/image/fetch/$s_!JxaQ!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faee47ccf-2c4b-4862-a118-43f4426fcad5_1692x620.png 1272w, https://substackcdn.com/image/fetch/$s_!JxaQ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faee47ccf-2c4b-4862-a118-43f4426fcad5_1692x620.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   For this I lack the ground truth answer and the rankings are highly variable. I expect neither of the models completed it.
  &lt;/p&gt;
  &lt;h4&gt;
   Example 2
  &lt;/h4&gt;
  &lt;p&gt;
   &lt;span&gt;
    “Find me everything you can say about how Grok 4 Heavy works. My guess is its something like OpenAI&#x27;s deep research, but in a more general domain?” (
   &lt;/span&gt;
   &lt;a href=&quot;https://grok.com/share/bGVnYWN5_c1e7769a-7bfc-43ca-896c-76bb29b33d16&quot; rel=&quot;&quot;&gt;
    Grok 4 Heavy
   &lt;/a&gt;
   &lt;span&gt;
    - 29 web pages,
   &lt;/span&gt;
   &lt;a href=&quot;https://grok.com/share/bGVnYWN5_8a116620-5309-47ec-8668-782c3fe0dc86&quot; rel=&quot;&quot;&gt;
    Grok 4 baseline
   &lt;/a&gt;
   &lt;span&gt;
    - 19 web pages,
   &lt;/span&gt;
   &lt;a href=&quot;https://chatgpt.com/share/686fe1bb-f394-8005-97a3-fffdc2d3dbb1&quot; rel=&quot;&quot;&gt;
    OpenAI Deep Research baseline
   &lt;/a&gt;
   &lt;span&gt;
    - 24 sources).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Here we can see the interface for Grok 4 Heavy, which always shows 4 spawned agents. The static agent number could change in the future or be somewhat misleading UX.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!5NvR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ca0f346-a914-430d-a5ec-69ca027421c8_1694x2060.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!5NvR!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ca0f346-a914-430d-a5ec-69ca027421c8_1694x2060.png 424w, https://substackcdn.com/image/fetch/$s_!5NvR!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ca0f346-a914-430d-a5ec-69ca027421c8_1694x2060.png 848w, https://substackcdn.com/image/fetch/$s_!5NvR!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ca0f346-a914-430d-a5ec-69ca027421c8_1694x2060.png 1272w, https://substackcdn.com/image/fetch/$s_!5NvR!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ca0f346-a914-430d-a5ec-69ca027421c8_1694x2060.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8ca0f346-a914-430d-a5ec-69ca027421c8_1694x2060.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1771,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:876501,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/167998749?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ca0f346-a914-430d-a5ec-69ca027421c8_1694x2060.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;1771&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!5NvR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ca0f346-a914-430d-a5ec-69ca027421c8_1694x2060.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!5NvR!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ca0f346-a914-430d-a5ec-69ca027421c8_1694x2060.png 424w, https://substackcdn.com/image/fetch/$s_!5NvR!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ca0f346-a914-430d-a5ec-69ca027421c8_1694x2060.png 848w, https://substackcdn.com/image/fetch/$s_!5NvR!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ca0f346-a914-430d-a5ec-69ca027421c8_1694x2060.png 1272w, https://substackcdn.com/image/fetch/$s_!5NvR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ca0f346-a914-430d-a5ec-69ca027421c8_1694x2060.png 1456w&quot; title=&quot;&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   Here I like Grok 4 Heavy’s answer better than ChatGPT Deep Research. They have similar information, but Grok 4 Heavy is more concise.
  &lt;/p&gt;
  &lt;h4&gt;
   Example 3
  &lt;/h4&gt;
  &lt;p&gt;
   &lt;span&gt;
    “Make a complete map of my, Nathan Lambert&#x27;s, writing on interconnects.ai in the last 24 months, listing with links organized by topic.” (
   &lt;/span&gt;
   &lt;a href=&quot;https://grok.com/share/bGVnYWN5_d3565539-ad0e-40a3-99f2-54c5be548f99&quot; rel=&quot;&quot;&gt;
    Grok 4 Heavy
   &lt;/a&gt;
   &lt;span&gt;
    - 96 pages,
   &lt;/span&gt;
   &lt;a href=&quot;https://grok.com/share/bGVnYWN5_ba7b0b67-ad5d-48e1-9239-34950467a14f&quot; rel=&quot;&quot;&gt;
    Grok 4 baseline
   &lt;/a&gt;
   &lt;span&gt;
    - 58 pages,
   &lt;/span&gt;
   &lt;a href=&quot;https://chatgpt.com/share/686fe061-ba0c-8005-a951-d10f20398197&quot; rel=&quot;&quot;&gt;
    OpenAI Deep Research baseline
   &lt;/a&gt;
   &lt;span&gt;
    - 36 sources, 114 searches)
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!D1Nz!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fb32c04-4c16-4d6e-a480-996035eae13f_1694x1958.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!D1Nz!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fb32c04-4c16-4d6e-a480-996035eae13f_1694x1958.png 424w, https://substackcdn.com/image/fetch/$s_!D1Nz!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fb32c04-4c16-4d6e-a480-996035eae13f_1694x1958.png 848w, https://substackcdn.com/image/fetch/$s_!D1Nz!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fb32c04-4c16-4d6e-a480-996035eae13f_1694x1958.png 1272w, https://substackcdn.com/image/fetch/$s_!D1Nz!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fb32c04-4c16-4d6e-a480-996035eae13f_1694x1958.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9fb32c04-4c16-4d6e-a480-996035eae13f_1694x1958.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1683,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:519018,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/167998749?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fb32c04-4c16-4d6e-a480-996035eae13f_1694x1958.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;1683&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!D1Nz!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fb32c04-4c16-4d6e-a480-996035eae13f_1694x1958.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!D1Nz!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fb32c04-4c16-4d6e-a480-996035eae13f_1694x1958.png 424w, https://substackcdn.com/image/fetch/$s_!D1Nz!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fb32c04-4c16-4d6e-a480-996035eae13f_1694x1958.png 848w, https://substackcdn.com/image/fetch/$s_!D1Nz!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fb32c04-4c16-4d6e-a480-996035eae13f_1694x1958.png 1272w, https://substackcdn.com/image/fetch/$s_!D1Nz!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fb32c04-4c16-4d6e-a480-996035eae13f_1694x1958.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    In this case and overall,
   &lt;/span&gt;
   &lt;strong&gt;
    Grok 4 outperforms OpenAI Deep Research
   &lt;/strong&gt;
   &lt;span&gt;
    . Grok 4 simply got far more of the correct links and presented it in the requested form. Combined with the live information graph on X, there are multiple groups who would benefit from this substantially and immediately.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   This example above is one of the first times a single request to an AI model has done a “wide” search over source materials. A factor that eventually will come into play here is both user price and effective margins. We don’t know the costs to serve any of these models.
  &lt;/p&gt;
  &lt;p&gt;
   All in, the performance of Grok 4 is very spikey. It has incredible performance on benchmarks and some of the tests done are the best an AI has ever been at some information retrieval tasks, but it falls on its face in some simple ways when compared to its peers like o3 or Claude 4 Opus.
  &lt;/p&gt;
  &lt;h2&gt;
   Lack of differentiation, market share, and Kimi K2
  &lt;/h2&gt;
  &lt;p&gt;
   &lt;span&gt;
    Despite all of this success, xAI and Grok still face a major issue — making a slightly better model in performance that is comparable on price isn’t enough to unseat existing usage patterns. In order to make people switch from existing applications and workflows, the model needs to be
   &lt;/span&gt;
   &lt;em&gt;
    way
   &lt;/em&gt;
   &lt;span&gt;
    better. This sort of gap I have only experienced with the original
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/switched-to-claude-from-chatgpt&quot; rel=&quot;&quot;&gt;
    Claude 3.5 Sonnet
   &lt;/a&gt;
   &lt;span&gt;
    pulling me from ChatGPT (until better applications and ecosystem pulled me back to ChatGPT). The question is — how does xAI monetize this technical success?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    In my
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/i/164377582/will-anthropic-code-their-way-to-agi-first&quot; rel=&quot;&quot;&gt;
    Claude 4 post
   &lt;/a&gt;
   &lt;span&gt;
    , I concluded with a small roundup of where the different providers land. Despite all the performance gains, Grok is still the same:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    &lt;strong&gt;
     Grok
    &lt;/strong&gt;
    &lt;span&gt;
     is on the path to being a niche player serving use-cases that need more permissive content guidelines.
    &lt;/span&gt;
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   Grok’s differentiation is still that it doesn’t have many of the industry standard guardrails. This is great from a consumer perspective, but presents challenges at the enterprise level (even if the lack of alignment was only a minor worry).
  &lt;/p&gt;
  &lt;p&gt;
   With the current offerings, the performance of ChatGPT at $20/month is similar to Super Grok at $300/month. Where is their market?
  &lt;/p&gt;
  &lt;p&gt;
   The thing is, there are still many ways to differentiate in AI. The differentiation takes taste, product skill, or frankly a willingness to commoditize your technology and release it openly.
  &lt;/p&gt;
  &lt;p&gt;
   We have multiple timely examples.
  &lt;/p&gt;
  &lt;p&gt;
   Claude Code with higher tiers of Anthropic plans is the most differentiated offering among the paid chatbots. For many people, Claude Code is the most fun and useful way to use a language model right now. This is a minority group, but at least one that is willing to pay. For coding, I don’t think Grok 4’s search behavior is as good (same reason I don’t recommend using o3 in something like Cursor), where Claude is still king.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The xAI team did say “
   &lt;/span&gt;
   &lt;strong&gt;
    Grok 4 coding model soon
   &lt;/strong&gt;
   &lt;span&gt;
    ”
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/elonmusk/status/1938561602640605363?referrer=grok-com&quot; rel=&quot;&quot;&gt;
    before
   &lt;/a&gt;
   &lt;span&gt;
    and during the livestream (easily
   &lt;/span&gt;
   &lt;a href=&quot;https://grok.com/share/bGVnYWN5_4b053dcc-4dca-4a6e-b84f-a9fed8b353d1&quot; rel=&quot;&quot;&gt;
    found via Grok 4
   &lt;/a&gt;
   &lt;span&gt;
    ), so they understand this. Still, the timeliness of this model with product-market-fit matters far more than all the benchmarks, as seen by
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/claude-4-and-anthropics-bet-on-code&quot; rel=&quot;&quot;&gt;
    Claude 4’s lackluster benchmark release
   &lt;/a&gt;
   &lt;span&gt;
    . Claude 4 has only become more popular since its release day — I don’t see Grok 4 being the same.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Another timely example of a model that’ll have immediate and practical real-world uptake is the new open-weight
   &lt;/span&gt;
   &lt;a href=&quot;https://moonshotai.github.io/Kimi-K2/&quot; rel=&quot;&quot;&gt;
    Kimi K2
   &lt;/a&gt;
   &lt;span&gt;
    model. Moonshot AI describes their new, mostly permissively licensed 1T total, 32B active MoE model “Open Agentic Intelligence.” This model rivals Claude 4 Sonnet and Opus on coding and reasoning benchmarks.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   This makes an impact by being by far and away the best open weight model in this class. Similar to, but not in the same magnitude, there will be a rush to deploy this model and build new products off the backbone of cheap inference from an optimized stack similar to the DeepSeek MoE architecture.
  &lt;/p&gt;
  &lt;p&gt;
   AI adoption and market share downstream of modeling success comes from differentiation in AI.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!qBcg!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58374a17-9659-4504-898f-d661d07e68b9_1920x1080.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!qBcg!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58374a17-9659-4504-898f-d661d07e68b9_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/$s_!qBcg!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58374a17-9659-4504-898f-d661d07e68b9_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/$s_!qBcg!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58374a17-9659-4504-898f-d661d07e68b9_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!qBcg!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58374a17-9659-4504-898f-d661d07e68b9_1920x1080.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;Image&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/58374a17-9659-4504-898f-d661d07e68b9_1920x1080.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;819&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!qBcg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58374a17-9659-4504-898f-d661d07e68b9_1920x1080.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!qBcg!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58374a17-9659-4504-898f-d661d07e68b9_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/$s_!qBcg!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58374a17-9659-4504-898f-d661d07e68b9_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/$s_!qBcg!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58374a17-9659-4504-898f-d661d07e68b9_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!qBcg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58374a17-9659-4504-898f-d661d07e68b9_1920x1080.jpeg 1456w&quot; title=&quot;Image&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    I’ll be covering Kimi K2 in more detail shortly, so make sure to subscribe. You can also read Simon Willison’s
   &lt;/span&gt;
   &lt;a href=&quot;https://simonwillison.net/2025/Jul/11/kimi-k2/&quot; rel=&quot;&quot;&gt;
    notes
   &lt;/a&gt;
   &lt;span&gt;
    now.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    To be abundantly clear — business success through model
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/i/166556899/progress-on-agents-will-be-higher-variance-than-modeling-was-but-often-still-extremely-rapid&quot; rel=&quot;&quot;&gt;
    competition on scores alone
   &lt;/a&gt;
   &lt;span&gt;
    is a hopeless strategy right now. OpenAI’s o4 mini exists, so in all likelihood, I’d say o4 soon (or GPT-5), and there are plenty of other competitors.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h2&gt;
   Grok’s recurring failure: SOC2 compliance doesn&#x27;t matter if you&#x27;re selling MechaHitler
  &lt;/h2&gt;
  &lt;p&gt;
   Grok 4 is the culmination of an ethos that will lead to more dangerous outcomes for AI with little upside on added performance. xAI, in the livestream, announced they have gotten extended security compliance tests commonly referred to as System and Organization Controls 2 (SOC 2) in order to sell into enterprises. This is a wholly useless endeavor when the underlying technology isn’t trustworthy for cultural reasons.
  &lt;/p&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Latest open artifacts (#11): Visualizing China&#x27;s open models market share, Arcee&#x27;s models, and VLAs for robotics </title>
<link>https://www.interconnects.ai/p/latest-open-artifacts-11-visualizing</link>
<pubDate>Thu, 26 Jun 2025 14:19:26 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    In previous
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/t/artifacts-log&quot; rel=&quot;&quot;&gt;
    posts
   &lt;/a&gt;
   &lt;span&gt;
    , we&#x27;ve noted in text how Chinese models currently dominate the space of open models. We analyzed the geographic distribution of all models from past Artifacts collections to quantify it. It turns out that most of the artifacts are released by Western organizations (~60%), but most of these rely on Chinese models (i.e. Qwen). Crucially, on top of counting, Chinese models also have been qualitatively more impactful on the direction of the open ecosystem by releasing models closest to the frontier of performance with the most permissive licenses.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!plq4!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93501ee6-71ae-497e-84f8-3140c30b57f2_4167x2371.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!plq4!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93501ee6-71ae-497e-84f8-3140c30b57f2_4167x2371.png 424w, https://substackcdn.com/image/fetch/$s_!plq4!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93501ee6-71ae-497e-84f8-3140c30b57f2_4167x2371.png 848w, https://substackcdn.com/image/fetch/$s_!plq4!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93501ee6-71ae-497e-84f8-3140c30b57f2_4167x2371.png 1272w, https://substackcdn.com/image/fetch/$s_!plq4!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93501ee6-71ae-497e-84f8-3140c30b57f2_4167x2371.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/93501ee6-71ae-497e-84f8-3140c30b57f2_4167x2371.png&quot;,&quot;srcNoWatermark&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4c96f561-d533-441f-b4b7-9007214e4c48_4167x2371.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:828,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:222077,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/166716779?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c96f561-d533-441f-b4b7-9007214e4c48_4167x2371.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;828&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!plq4!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93501ee6-71ae-497e-84f8-3140c30b57f2_4167x2371.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!plq4!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93501ee6-71ae-497e-84f8-3140c30b57f2_4167x2371.png 424w, https://substackcdn.com/image/fetch/$s_!plq4!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93501ee6-71ae-497e-84f8-3140c30b57f2_4167x2371.png 848w, https://substackcdn.com/image/fetch/$s_!plq4!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93501ee6-71ae-497e-84f8-3140c30b57f2_4167x2371.png 1272w, https://substackcdn.com/image/fetch/$s_!plq4!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F93501ee6-71ae-497e-84f8-3140c30b57f2_4167x2371.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   We present only a selection of models in the Artifacts series based on a mix of our perceived immediate and long-term impact. Our analysis of is broader than just text-only language models, including image/video generation models where Chinese labs are more dominant.
  &lt;/p&gt;
  &lt;p&gt;
   For attribution, we count fine-tunes according to the team that released them, i.e., a Qwen fine-tune published by a Western company is marked as Western.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    When looking into the models heritage (as reported by HuggingFace), the picture is as expected: Qwen is the first choice for anyone who fine-tunes their model.
   &lt;/span&gt;
   &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/latest-open-artifacts-11-visualizing#footnote-1-166716779&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!SUBI!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc85868a2-2c9a-4c26-9f0d-d39f2e0a618f_4167x2371.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!SUBI!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc85868a2-2c9a-4c26-9f0d-d39f2e0a618f_4167x2371.png 424w, https://substackcdn.com/image/fetch/$s_!SUBI!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc85868a2-2c9a-4c26-9f0d-d39f2e0a618f_4167x2371.png 848w, https://substackcdn.com/image/fetch/$s_!SUBI!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc85868a2-2c9a-4c26-9f0d-d39f2e0a618f_4167x2371.png 1272w, https://substackcdn.com/image/fetch/$s_!SUBI!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc85868a2-2c9a-4c26-9f0d-d39f2e0a618f_4167x2371.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c85868a2-2c9a-4c26-9f0d-d39f2e0a618f_4167x2371.png&quot;,&quot;srcNoWatermark&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5b3426af-cff6-48ca-a0e7-ca045da6f217_4167x2371.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:828,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:117993,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/166716779?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b3426af-cff6-48ca-a0e7-ca045da6f217_4167x2371.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;828&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!SUBI!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc85868a2-2c9a-4c26-9f0d-d39f2e0a618f_4167x2371.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!SUBI!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc85868a2-2c9a-4c26-9f0d-d39f2e0a618f_4167x2371.png 424w, https://substackcdn.com/image/fetch/$s_!SUBI!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc85868a2-2c9a-4c26-9f0d-d39f2e0a618f_4167x2371.png 848w, https://substackcdn.com/image/fetch/$s_!SUBI!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc85868a2-2c9a-4c26-9f0d-d39f2e0a618f_4167x2371.png 1272w, https://substackcdn.com/image/fetch/$s_!SUBI!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc85868a2-2c9a-4c26-9f0d-d39f2e0a618f_4167x2371.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    Also, RL and reasoning is now part of a lot of the model releases as part of the training pipeline. Therefore, we stop making reasoning its own category. Together with links being broken out into its own
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/what-ive-been-reading-1&quot; rel=&quot;&quot;&gt;
    series
   &lt;/a&gt;
   &lt;span&gt;
    , these posts should have a more streamlined structure. Our picks, then models, then datasets.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/latest-open-artifacts-11-visualizing?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-artifacts-11-visualizing?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;h2&gt;
   &lt;strong&gt;
    Our Picks
   &lt;/strong&gt;
  &lt;/h2&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/datasets/common-pile/comma_v0.1_training_dataset&quot; rel=&quot;&quot;&gt;
       comma_v0.1_training_dataset
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/common-pile&quot; rel=&quot;&quot;&gt;
      common-pile
     &lt;/a&gt;
     &lt;span&gt;
      : EleutherAI (and many others), known for various open-source projects such as The Pile, have shared their first stab at an openly licensed dataset with &quot;Common Pile&quot;, spanning 8TB from various sources, such as code, legal documents or public domain books.
     &lt;/span&gt;
     &lt;strong&gt;
      This differs from other datasets for open-source models because those rely on a “fair use” like argument where publicly, unlicensed data is seen as fair to train on — 100% of this dataset has a clearly attributed, permissive license.
     &lt;/strong&gt;
     &lt;span&gt;
      Work in this direction is still rare, so every addition to those efforts is extremely valuable.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/arcee-ai/Virtuoso-Large&quot; rel=&quot;&quot;&gt;
       Virtuoso-Large
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/arcee-ai&quot; rel=&quot;&quot;&gt;
      arcee-ai
     &lt;/a&gt;
     &lt;span&gt;
      : Arcee AI, which we&#x27;ve featured in previous episodes with some of their fine-tunes, have started pre-training their own models, starting with a 4.5B parameter model (
     &lt;/span&gt;
     &lt;a href=&quot;https://www.arcee.ai/blog/announcing-the-arcee-foundation-model-family&quot; rel=&quot;&quot;&gt;
      blog
     &lt;/a&gt;
     &lt;span&gt;
      ). This has led to them opening their previously closed models to the public, released under permissive licenses. This model is their flagship model, a 72B fine-tune of Qwen2.5. The move to open older models is really commendable, we hope others will follow suit!
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/vikhyatk/moondream2&quot; rel=&quot;&quot;&gt;
       moondream2
      &lt;/a&gt;
      &lt;span&gt;
      &lt;/span&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/vikhyatk&quot; rel=&quot;&quot;&gt;
      vikhyatk
     &lt;/a&gt;
     &lt;span&gt;
      : The moondream2 team is known for their excellent execution and attention to detail. This model release marks their first reasoning release. For training, they avoided using a larger teacher model, making the release even more impressive. This update delivers the usual improvements, most notably in object detection tasks. The model uses the same repository as previous releases, so update the weights if you downloaded the model previously.
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!0eJN!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6321bb3d-ef4a-45d6-90cb-798645bab8cc_3935x2218.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!0eJN!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6321bb3d-ef4a-45d6-90cb-798645bab8cc_3935x2218.png 424w, https://substackcdn.com/image/fetch/$s_!0eJN!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6321bb3d-ef4a-45d6-90cb-798645bab8cc_3935x2218.png 848w, https://substackcdn.com/image/fetch/$s_!0eJN!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6321bb3d-ef4a-45d6-90cb-798645bab8cc_3935x2218.png 1272w, https://substackcdn.com/image/fetch/$s_!0eJN!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6321bb3d-ef4a-45d6-90cb-798645bab8cc_3935x2218.png 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;Grounding improves counting accuracy&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6321bb3d-ef4a-45d6-90cb-798645bab8cc_3935x2218.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:821,&quot;width&quot;:1456,&quot;resizeWidth&quot;:686,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Grounding improves counting accuracy&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;386.8173076923077&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!0eJN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6321bb3d-ef4a-45d6-90cb-798645bab8cc_3935x2218.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!0eJN!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6321bb3d-ef4a-45d6-90cb-798645bab8cc_3935x2218.png 424w, https://substackcdn.com/image/fetch/$s_!0eJN!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6321bb3d-ef4a-45d6-90cb-798645bab8cc_3935x2218.png 848w, https://substackcdn.com/image/fetch/$s_!0eJN!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6321bb3d-ef4a-45d6-90cb-798645bab8cc_3935x2218.png 1272w, https://substackcdn.com/image/fetch/$s_!0eJN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6321bb3d-ef4a-45d6-90cb-798645bab8cc_3935x2218.png 1456w&quot; title=&quot;Grounding improves counting accuracy&quot; width=&quot;686&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-Embedding-0.6B&quot; rel=&quot;&quot;&gt;
       Qwen3-Embedding-0.6B
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/Qwen&quot; rel=&quot;&quot;&gt;
      Qwen
     &lt;/a&gt;
     &lt;span&gt;
      : Qwen has entered the retrieval scene as well. While the community already fine-tuned Qwen2 and Qwen2.5 for various embedding tasks, the Qwen team has now started to release models on their own. As usual for the team, the models are solid in the related benchmarks and likely perform well in downstream tasks.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/MiniMaxAI/MiniMax-M1-80k&quot; rel=&quot;&quot;&gt;
       MiniMax-M1-80k
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/MiniMaxAI&quot; rel=&quot;&quot;&gt;
      MiniMaxAI
     &lt;/a&gt;
     &lt;span&gt;
      : Minimax has also released their first reasoning model, based on their own hybrid attention MoE architecture. They release two models, one with 40K and one with a whopping 80K thinking budget, which is the most of any available model, both open and closed. However, this does not necessarily mean that they are the best models for reasoning tasks; in our tests, the model really tends to overthink and spend a lot of tokens to reconsider its answers.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h2&gt;
   &lt;strong&gt;
    Models
   &lt;/strong&gt;
  &lt;/h2&gt;
  &lt;h3&gt;
   &lt;strong&gt;
    Flagship
   &lt;/strong&gt;
  &lt;/h3&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/mistralai/Magistral-Small-2506&quot; rel=&quot;&quot;&gt;
       Magistral-Small-2506
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/mistralai&quot; rel=&quot;&quot;&gt;
      mistralai
     &lt;/a&gt;
     &lt;span&gt;
      : Mistral has joined the party of reasoners with an open release building upon Mistral Small. The accompanying
     &lt;/span&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2506.10910&quot; rel=&quot;&quot;&gt;
      technical report
     &lt;/a&gt;
     &lt;span&gt;
      provides a lot of details.
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!RVJQ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63cb2a77-091d-4700-99ce-595c3deab717_1315x517.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!RVJQ!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63cb2a77-091d-4700-99ce-595c3deab717_1315x517.png 424w, https://substackcdn.com/image/fetch/$s_!RVJQ!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63cb2a77-091d-4700-99ce-595c3deab717_1315x517.png 848w, https://substackcdn.com/image/fetch/$s_!RVJQ!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63cb2a77-091d-4700-99ce-595c3deab717_1315x517.png 1272w, https://substackcdn.com/image/fetch/$s_!RVJQ!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63cb2a77-091d-4700-99ce-595c3deab717_1315x517.png 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/63cb2a77-091d-4700-99ce-595c3deab717_1315x517.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:517,&quot;width&quot;:1315,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:111198,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/166716779?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63cb2a77-091d-4700-99ce-595c3deab717_1315x517.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;517&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!RVJQ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63cb2a77-091d-4700-99ce-595c3deab717_1315x517.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!RVJQ!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63cb2a77-091d-4700-99ce-595c3deab717_1315x517.png 424w, https://substackcdn.com/image/fetch/$s_!RVJQ!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63cb2a77-091d-4700-99ce-595c3deab717_1315x517.png 848w, https://substackcdn.com/image/fetch/$s_!RVJQ!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63cb2a77-091d-4700-99ce-595c3deab717_1315x517.png 1272w, https://substackcdn.com/image/fetch/$s_!RVJQ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63cb2a77-091d-4700-99ce-595c3deab717_1315x517.png 1456w&quot; width=&quot;1315&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Latest open artifacts (#10): New DeepSeek R1 0528!, more permissive licenses, everything as a reasoner, and from artifacts to agents </title>
<link>https://www.interconnects.ai/p/latest-open-artifacts-10-new-deepseek</link>
<pubDate>Thu, 29 May 2025 13:37:23 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   A consistent trend over the last few months has been in the surge of Chinese models with permissive licenses, which has been translating into improvements in the licenses used by other open models. The major players in the Western ecosystem — Meta’s Llama and Google’s Gemma — are yet to do this, but pressure is building.
  &lt;/p&gt;
  &lt;p&gt;
   Mirroring this, we’re seeing far more Qwen finetunes than Llama. Llama, for it’s first 3 versions, was by far and away the leading model for fine-tuners. “Qwen as the default” is not only the view of other Chinese companies, but it is championed by many smaller American startups looking to break through wit hstrong models. While Qwen2.5, Qwen2.5-VL and QwQ are the leading base models, we also see first models based on Qwen3.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    These trends are on top of the transition we’ve seen wrapping up on top of the entire industry where reasoning models are the default. GRPO is still the most common algorithm in practice (see
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/papers-im-reading-base-model-rl-grpo&quot; rel=&quot;&quot;&gt;
    our research overview
   &lt;/a&gt;
   &lt;span&gt;
    for expansions of the method).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   A trend that is beginning, and one that will take longer, is that leading AI releases are much more often about tools than models alone. From Claude Code to OpenAI’s Codex (agent) and Gemini’s Jules, open replications of these systems will be much slower. The open systems will need to take on different forms in order to take the benefits of open models that can be swapped and iterated upon, all of which we hope to highlight in future issues.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/latest-open-artifacts-10-new-deepseek?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/latest-open-artifacts-10-new-deepseek?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   Our Picks
  &lt;/h3&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/deepseek-ai/DeepSeek-R1-0528&quot; rel=&quot;&quot;&gt;
       DeepSeek-R1-0528
      &lt;/a&gt;
      &lt;span&gt;
      &lt;/span&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/deepseek-ai&quot; rel=&quot;&quot;&gt;
      deepseek-ai
     &lt;/a&gt;
     &lt;span&gt;
      : DeepSeek updated their
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1&quot; rel=&quot;&quot;&gt;
      R1 reasoning model
     &lt;/a&gt;
     &lt;span&gt;
      . The model card has not a lot of details (more compute + algorithmic improvements), but the benchmarks show that the whale is yet again at the frontier, rivaling closed models.
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!WVqp!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F903dbdcb-5cbc-4b8e-9c2d-4d84d1ffc9ef_3961x2393.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!WVqp!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F903dbdcb-5cbc-4b8e-9c2d-4d84d1ffc9ef_3961x2393.jpeg 424w, https://substackcdn.com/image/fetch/$s_!WVqp!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F903dbdcb-5cbc-4b8e-9c2d-4d84d1ffc9ef_3961x2393.jpeg 848w, https://substackcdn.com/image/fetch/$s_!WVqp!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F903dbdcb-5cbc-4b8e-9c2d-4d84d1ffc9ef_3961x2393.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!WVqp!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F903dbdcb-5cbc-4b8e-9c2d-4d84d1ffc9ef_3961x2393.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/903dbdcb-5cbc-4b8e-9c2d-4d84d1ffc9ef_3961x2393.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:880,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;880&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!WVqp!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F903dbdcb-5cbc-4b8e-9c2d-4d84d1ffc9ef_3961x2393.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!WVqp!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F903dbdcb-5cbc-4b8e-9c2d-4d84d1ffc9ef_3961x2393.jpeg 424w, https://substackcdn.com/image/fetch/$s_!WVqp!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F903dbdcb-5cbc-4b8e-9c2d-4d84d1ffc9ef_3961x2393.jpeg 848w, https://substackcdn.com/image/fetch/$s_!WVqp!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F903dbdcb-5cbc-4b8e-9c2d-4d84d1ffc9ef_3961x2393.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!WVqp!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F903dbdcb-5cbc-4b8e-9c2d-4d84d1ffc9ef_3961x2393.jpeg 1456w&quot; title=&quot;&quot; width=&quot;1456&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
      &lt;figcaption&gt;
       From the model card.
      &lt;/figcaption&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
    &lt;p&gt;
     Even more exciting as we enter the agentic era is the support for tools. R1 is close to the frontier in popular function-calling benchmarks as well:
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!vB08!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccc3d83d-5eb7-4716-9ca7-431473a8d37d_1073x520.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!vB08!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccc3d83d-5eb7-4716-9ca7-431473a8d37d_1073x520.png 424w, https://substackcdn.com/image/fetch/$s_!vB08!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccc3d83d-5eb7-4716-9ca7-431473a8d37d_1073x520.png 848w, https://substackcdn.com/image/fetch/$s_!vB08!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccc3d83d-5eb7-4716-9ca7-431473a8d37d_1073x520.png 1272w, https://substackcdn.com/image/fetch/$s_!vB08!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccc3d83d-5eb7-4716-9ca7-431473a8d37d_1073x520.png 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ccc3d83d-5eb7-4716-9ca7-431473a8d37d_1073x520.png&quot;,&quot;srcNoWatermark&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/49f3522f-cd8e-4654-822f-a67246159895_1073x520.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:520,&quot;width&quot;:1073,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:50886,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/164406805?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49f3522f-cd8e-4654-822f-a67246159895_1073x520.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;520&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!vB08!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccc3d83d-5eb7-4716-9ca7-431473a8d37d_1073x520.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!vB08!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccc3d83d-5eb7-4716-9ca7-431473a8d37d_1073x520.png 424w, https://substackcdn.com/image/fetch/$s_!vB08!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccc3d83d-5eb7-4716-9ca7-431473a8d37d_1073x520.png 848w, https://substackcdn.com/image/fetch/$s_!vB08!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccc3d83d-5eb7-4716-9ca7-431473a8d37d_1073x520.png 1272w, https://substackcdn.com/image/fetch/$s_!vB08!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccc3d83d-5eb7-4716-9ca7-431473a8d37d_1073x520.png 1456w&quot; width=&quot;1073&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
      &lt;figcaption&gt;
       Figure made by Interconnects, using the lab-reported numbers for tau-bench and the leaderboard numbers for BFCL.
      &lt;/figcaption&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
    &lt;p&gt;
     In my quick tests it seems like the new R1 at least has the same distinctive character, but could be even more clever. Here’s an example:
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!uMp3!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F557c3e1e-8bcb-400c-8c10-098c7b9902cc_1768x1152.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!uMp3!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F557c3e1e-8bcb-400c-8c10-098c7b9902cc_1768x1152.jpeg 424w, https://substackcdn.com/image/fetch/$s_!uMp3!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F557c3e1e-8bcb-400c-8c10-098c7b9902cc_1768x1152.jpeg 848w, https://substackcdn.com/image/fetch/$s_!uMp3!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F557c3e1e-8bcb-400c-8c10-098c7b9902cc_1768x1152.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!uMp3!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F557c3e1e-8bcb-400c-8c10-098c7b9902cc_1768x1152.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;Image&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/557c3e1e-8bcb-400c-8c10-098c7b9902cc_1768x1152.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:949,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;949&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!uMp3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F557c3e1e-8bcb-400c-8c10-098c7b9902cc_1768x1152.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!uMp3!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F557c3e1e-8bcb-400c-8c10-098c7b9902cc_1768x1152.jpeg 424w, https://substackcdn.com/image/fetch/$s_!uMp3!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F557c3e1e-8bcb-400c-8c10-098c7b9902cc_1768x1152.jpeg 848w, https://substackcdn.com/image/fetch/$s_!uMp3!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F557c3e1e-8bcb-400c-8c10-098c7b9902cc_1768x1152.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!uMp3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F557c3e1e-8bcb-400c-8c10-098c7b9902cc_1768x1152.jpeg 1456w&quot; title=&quot;Image&quot; width=&quot;1456&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
    &lt;p&gt;
     Another example is it seeming to do better on the search APIs (at least what is built into OpenRouter), boosted by the new tool-calling capabilities.
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!eOcz!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe864b0b0-9660-4a0f-a90f-9e6bac06a03a_1654x1324.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!eOcz!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe864b0b0-9660-4a0f-a90f-9e6bac06a03a_1654x1324.png 424w, https://substackcdn.com/image/fetch/$s_!eOcz!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe864b0b0-9660-4a0f-a90f-9e6bac06a03a_1654x1324.png 848w, https://substackcdn.com/image/fetch/$s_!eOcz!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe864b0b0-9660-4a0f-a90f-9e6bac06a03a_1654x1324.png 1272w, https://substackcdn.com/image/fetch/$s_!eOcz!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe864b0b0-9660-4a0f-a90f-9e6bac06a03a_1654x1324.png 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e864b0b0-9660-4a0f-a90f-9e6bac06a03a_1654x1324.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1166,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:333588,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/164406805?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe864b0b0-9660-4a0f-a90f-9e6bac06a03a_1654x1324.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;1166&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!eOcz!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe864b0b0-9660-4a0f-a90f-9e6bac06a03a_1654x1324.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!eOcz!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe864b0b0-9660-4a0f-a90f-9e6bac06a03a_1654x1324.png 424w, https://substackcdn.com/image/fetch/$s_!eOcz!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe864b0b0-9660-4a0f-a90f-9e6bac06a03a_1654x1324.png 848w, https://substackcdn.com/image/fetch/$s_!eOcz!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe864b0b0-9660-4a0f-a90f-9e6bac06a03a_1654x1324.png 1272w, https://substackcdn.com/image/fetch/$s_!eOcz!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe864b0b0-9660-4a0f-a90f-9e6bac06a03a_1654x1324.png 1456w&quot; width=&quot;1456&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
    &lt;p&gt;
     This new version of R1 is much less likely to start every reasoning chain with “Okay,” which should be good for diversity and token efficiency.
    &lt;/p&gt;
    &lt;p&gt;
     &lt;br/&gt;
     &lt;span&gt;
      And, to top it all off: They also used the new R1 thinking traces to fine-tune
     &lt;/span&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B&quot; rel=&quot;&quot;&gt;
       DeepSeek-R1-0528-Qwen3-8B
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      , boosting scores significantly in math benchmarks.
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!MWej!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01486246-6840-4ccf-8936-099a8bb9f313_707x420.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!MWej!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01486246-6840-4ccf-8936-099a8bb9f313_707x420.png 424w, https://substackcdn.com/image/fetch/$s_!MWej!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01486246-6840-4ccf-8936-099a8bb9f313_707x420.png 848w, https://substackcdn.com/image/fetch/$s_!MWej!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01486246-6840-4ccf-8936-099a8bb9f313_707x420.png 1272w, https://substackcdn.com/image/fetch/$s_!MWej!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01486246-6840-4ccf-8936-099a8bb9f313_707x420.png 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/01486246-6840-4ccf-8936-099a8bb9f313_707x420.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:420,&quot;width&quot;:707,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:52445,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/164406805?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01486246-6840-4ccf-8936-099a8bb9f313_707x420.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;420&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!MWej!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01486246-6840-4ccf-8936-099a8bb9f313_707x420.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!MWej!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01486246-6840-4ccf-8936-099a8bb9f313_707x420.png 424w, https://substackcdn.com/image/fetch/$s_!MWej!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01486246-6840-4ccf-8936-099a8bb9f313_707x420.png 848w, https://substackcdn.com/image/fetch/$s_!MWej!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01486246-6840-4ccf-8936-099a8bb9f313_707x420.png 1272w, https://substackcdn.com/image/fetch/$s_!MWej!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01486246-6840-4ccf-8936-099a8bb9f313_707x420.png 1456w&quot; width=&quot;707&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
    &lt;p&gt;
     &lt;span&gt;
      For more, see DeepSeek’s
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/deepseek_ai/status/1928061589107900779&quot; rel=&quot;&quot;&gt;
      announcement
     &lt;/a&gt;
     &lt;span&gt;
      or
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/ArtificialAnlys/status/1928071179115581671&quot; rel=&quot;&quot;&gt;
      Artificial Analysis’s scores
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/Skywork/Skywork-R1V2-38B&quot; rel=&quot;&quot;&gt;
       Skywork-R1V2-38B
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/Skywork&quot; rel=&quot;&quot;&gt;
      Skywork
     &lt;/a&gt;
     &lt;span&gt;
      : Skywork, a Singaporean startup, has been around for some time as a solid smaller contributor to the open ecosystem, but their pace of (open) model releases picked up recently. In the last episode, we featured their
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/Skywork/Skywork-OR1-Math-7B&quot; rel=&quot;&quot;&gt;
      math reasoning model
     &lt;/a&gt;
     &lt;span&gt;
      and their
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/Skywork/SkyReels-A2&quot; rel=&quot;&quot;&gt;
      video generation model
     &lt;/a&gt;
     &lt;span&gt;
      . They also have closed models, such as
     &lt;/span&gt;
     &lt;a href=&quot;https://www.mureka.ai/&quot; rel=&quot;&quot;&gt;
      Mureka
     &lt;/a&gt;
     &lt;span&gt;
      for song generation or an
     &lt;/span&gt;
     &lt;a href=&quot;https://skywork.ai/&quot; rel=&quot;&quot;&gt;
      agent platform
     &lt;/a&gt;
     &lt;span&gt;
      to rival Manus. R1V2 is one of the few open multimodal reasoning models. They use GRPO and
     &lt;/span&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2505.07263&quot; rel=&quot;&quot;&gt;
      Mixed Preference Optimization
     &lt;/a&gt;
     &lt;span&gt;
      (MPO) to train the model, rivaling the performance of closed models such as Gemini 2.0 Flash or GPT-4o-mini.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/PleIAs/Pleias-RAG-1B&quot; rel=&quot;&quot;&gt;
       Pleias-RAG-1B
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/PleIAs&quot; rel=&quot;&quot;&gt;
      PleIAs
     &lt;/a&gt;
     &lt;span&gt;
      : A small model trained for RAG. It can reason whether the query is sufficient to be answered, reformulate queries if needed and analyze the sources, which usually needs multiple models or calls to a model; it can also provide citations within the answer, similar to the Anthropic API. It is also multilingual, trained on permissive data and released under Apache 2.0.
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!rb43!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cad93eb-52e3-4c6e-b983-57f51a57e5b1_2054x1432.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!rb43!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cad93eb-52e3-4c6e-b983-57f51a57e5b1_2054x1432.png 424w, https://substackcdn.com/image/fetch/$s_!rb43!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cad93eb-52e3-4c6e-b983-57f51a57e5b1_2054x1432.png 848w, https://substackcdn.com/image/fetch/$s_!rb43!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cad93eb-52e3-4c6e-b983-57f51a57e5b1_2054x1432.png 1272w, https://substackcdn.com/image/fetch/$s_!rb43!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cad93eb-52e3-4c6e-b983-57f51a57e5b1_2054x1432.png 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5cad93eb-52e3-4c6e-b983-57f51a57e5b1_2054x1432.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1015,&quot;width&quot;:1456,&quot;resizeWidth&quot;:653,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;455.21634615384613&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!rb43!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cad93eb-52e3-4c6e-b983-57f51a57e5b1_2054x1432.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!rb43!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cad93eb-52e3-4c6e-b983-57f51a57e5b1_2054x1432.png 424w, https://substackcdn.com/image/fetch/$s_!rb43!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cad93eb-52e3-4c6e-b983-57f51a57e5b1_2054x1432.png 848w, https://substackcdn.com/image/fetch/$s_!rb43!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cad93eb-52e3-4c6e-b983-57f51a57e5b1_2054x1432.png 1272w, https://substackcdn.com/image/fetch/$s_!rb43!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cad93eb-52e3-4c6e-b983-57f51a57e5b1_2054x1432.png 1456w&quot; width=&quot;653&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/PrimeIntellect/INTELLECT-2&quot; rel=&quot;&quot;&gt;
       INTELLECT-2
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/PrimeIntellect&quot; rel=&quot;&quot;&gt;
      PrimeIntellect
     &lt;/a&gt;
     &lt;span&gt;
      : After
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/PrimeIntellect/INTELLECT-1&quot; rel=&quot;&quot;&gt;
      INTELLECT-1
     &lt;/a&gt;
     &lt;span&gt;
      , the globally pre-trained 10B model on 1T tokens, the PI team is tackling globally decentralized post-training. This model, based on QwQ 32B, is an impressive technical achievement. Their
     &lt;/span&gt;
     &lt;a href=&quot;https://storage.googleapis.com/public-technical-paper/INTELLECT_2_Technical_Report.pdf&quot; rel=&quot;&quot;&gt;
      technical report
     &lt;/a&gt;
     &lt;span&gt;
      goes into more detail.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/datasets/ministere-culture/comparia-conversations&quot; rel=&quot;&quot;&gt;
       comparia-conversations
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/ministere-culture&quot; rel=&quot;&quot;&gt;
      ministere-culture
     &lt;/a&gt;
     &lt;span&gt;
      : The French government runs a chatbot arena, similar to
     &lt;/span&gt;
     &lt;a href=&quot;https://lmarena.ai/&quot; rel=&quot;&quot;&gt;
      LMArena
     &lt;/a&gt;
     &lt;span&gt;
      , where users can chat with two chatbots at once and then click the answer they prefer. Aside from the
     &lt;/span&gt;
     &lt;a href=&quot;https://cohere.com/research/lmarena&quot; rel=&quot;&quot;&gt;
      critique of LMArena
     &lt;/a&gt;
     &lt;span&gt;
      , the French version is predominantly used by French citizens and not used as a testing ground for pre-release models. This dataset consists of 175K conversations from thousands of users and PII-redacted, offering interesting insights into non-English preferences and model strengths.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h3&gt;
   Links
  &lt;/h3&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      A wonderful essay,
     &lt;/span&gt;
     &lt;em&gt;
      &lt;a href=&quot;https://koomen.dev/essays/horseless-carriages/&quot; rel=&quot;&quot;&gt;
       AI Horseless Carriages
      &lt;/a&gt;
      &lt;span&gt;
       ,
      &lt;/span&gt;
     &lt;/em&gt;
     &lt;span&gt;
      highlighted the bizarre way that places like Gmail are forcing AI intro products that make the tasks we want to do harder.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Lilian Weng wrote a phenomenal
     &lt;/span&gt;
     &lt;a href=&quot;https://lilianweng.github.io/posts/2025-05-01-thinking/&quot; rel=&quot;&quot;&gt;
      blog post
     &lt;/a&gt;
     &lt;span&gt;
      about reasoning models. Friend of the pod, Ross Taylor, wrote a
     &lt;/span&gt;
     &lt;a href=&quot;https://www.perplexity.ai/hub/blog/rl-training-for-math-reasoning&quot; rel=&quot;&quot;&gt;
      more focused (shorter) one too
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;a data-attrs=&#x27;{&quot;name&quot;:&quot;Latent.Space&quot;,&quot;id&quot;:1084089,&quot;type&quot;:&quot;pub&quot;,&quot;url&quot;:&quot;https://open.substack.com/pub/swyx?utm_source=mentions&quot;,&quot;uuid&quot;:&quot;05e2258d-1ded-452a-a77c-65368eea4b01&quot;}&#x27; data-component-name=&quot;MentionPub&quot; href=&quot;https://open.substack.com/pub/swyx&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;
      Latent.Space
     &lt;/a&gt;
    &lt;/div&gt;
    &lt;span&gt;
     had a
    &lt;/span&gt;
    &lt;a href=&quot;https://www.latent.space/p/clippy-v-anton?r=68gy5&amp;utm_medium=ios&amp;triedRedirect=true&quot; rel=&quot;&quot;&gt;
     good post
    &lt;/a&gt;
    &lt;span&gt;
     on how the GPT-4o sychophancy fiasco shows that OpenAI is barking up the wrong tree with their personality, at least if the goal is productivity.
    &lt;/span&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Natasha Jaques gave a nice
     &lt;/span&gt;
     &lt;a href=&quot;https://www.youtube.com/watch?v=KvTGUI4Tznw&quot; rel=&quot;&quot;&gt;
      more general audience talk
     &lt;/a&gt;
     &lt;span&gt;
      on trends in AI. It covers normal techniques like RLHF and LLMs but with new flavors added in.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Tyler Cowen wrote
     &lt;/span&gt;
     &lt;em&gt;
      &lt;a href=&quot;https://marginalrevolution.com/marginalrevolution/2025/04/in-defense-of-an-online-life.html&quot; rel=&quot;&quot;&gt;
       In defense of an online life
      &lt;/a&gt;
      &lt;span&gt;
       ,
      &lt;/span&gt;
     &lt;/em&gt;
     &lt;span&gt;
      which really resonated with us on how relationships can thrive in different ways online.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      This
     &lt;/span&gt;
     &lt;a href=&quot;https://www.youtube.com/watch?v=wLb9g_8r-mE&quot; rel=&quot;&quot;&gt;
      conversation
     &lt;/a&gt;
     &lt;span&gt;
      between Jony Ive and Patrick Collison is one of the best dives into what it means to make “good products” in the modern world.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      A
     &lt;/span&gt;
     &lt;a href=&quot;https://www.theverge.com/news/661230/trump-signs-take-it-down-act-ai-deepfakes&quot; rel=&quot;&quot;&gt;
      bill was somewhat quietly passed
     &lt;/a&gt;
     &lt;span&gt;
      that helps clamp down on nonconsensual deepfakes — one of the biggest AI risks accelerated by open models. This is a step in the right direction, but can only work to ban them as well as anything online can be banned — partially.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Will Brown gave a
     &lt;/span&gt;
     &lt;a href=&quot;https://youtube.com/watch?v=Xkwok_XXQgw&quot; rel=&quot;&quot;&gt;
      talk about open problems
     &lt;/a&gt;
     &lt;span&gt;
      in multi-turn and agentic RL.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      This
     &lt;/span&gt;
     &lt;a href=&quot;https://www.tensoreconomics.com/p/llm-inference-economics-from-first&quot; rel=&quot;&quot;&gt;
      post
     &lt;/a&gt;
     &lt;span&gt;
      dives deep into the economics of LLM inference.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Vlad Feinberg published his
     &lt;/span&gt;
     &lt;a href=&quot;https://vladfeinberg.com/2025/04/24/gemini-flash-pretraining.html&quot; rel=&quot;&quot;&gt;
      slides
     &lt;/a&gt;
     &lt;span&gt;
      discussing his work on Gemini Flash Pretraining.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h3&gt;
   Reasoning
  &lt;/h3&gt;
  &lt;h4&gt;
   Models
  &lt;/h4&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/tngtech/DeepSeek-R1T-Chimera&quot; rel=&quot;&quot;&gt;
       DeepSeek-R1T-Chimera
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/tngtech&quot; rel=&quot;&quot;&gt;
      tngtech
     &lt;/a&gt;
     &lt;span&gt;
      (friends of the pod): A model merge of DeepSeek R1 and DeepSeek V3. It works surprisingly well, resulting in a model that has shorter CoTs and thus is faster to run, while still being more capable than just using V3. Even more surprising: The merged model refuses fewer requests than both V3 and R1.
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!7sye!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafb26560-677b-44be-8a65-0b1f80e956a2_577x466.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!7sye!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafb26560-677b-44be-8a65-0b1f80e956a2_577x466.jpeg 424w, https://substackcdn.com/image/fetch/$s_!7sye!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafb26560-677b-44be-8a65-0b1f80e956a2_577x466.jpeg 848w, https://substackcdn.com/image/fetch/$s_!7sye!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafb26560-677b-44be-8a65-0b1f80e956a2_577x466.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!7sye!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafb26560-677b-44be-8a65-0b1f80e956a2_577x466.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;R1T-Chimera&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/afb26560-677b-44be-8a65-0b1f80e956a2_577x466.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:466,&quot;width&quot;:577,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;R1T-Chimera&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;466&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!7sye!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafb26560-677b-44be-8a65-0b1f80e956a2_577x466.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!7sye!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafb26560-677b-44be-8a65-0b1f80e956a2_577x466.jpeg 424w, https://substackcdn.com/image/fetch/$s_!7sye!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafb26560-677b-44be-8a65-0b1f80e956a2_577x466.jpeg 848w, https://substackcdn.com/image/fetch/$s_!7sye!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafb26560-677b-44be-8a65-0b1f80e956a2_577x466.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!7sye!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fafb26560-677b-44be-8a65-0b1f80e956a2_577x466.jpeg 1456w&quot; title=&quot;R1T-Chimera&quot; width=&quot;577&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/OpenPipe/art-e-008&quot; rel=&quot;&quot;&gt;
       art-e-008
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/OpenPipe&quot; rel=&quot;&quot;&gt;
      OpenPipe
     &lt;/a&gt;
     &lt;span&gt;
      : A LoRA adapter for Qwen2.5 14B to act as an email research agent. It was trained with GRPO on the infamous Enron email dataset, with questions and answers being generated by GPT-4.1. The
     &lt;/span&gt;
     &lt;a href=&quot;https://openpipe.ai/blog/art-e-mail-agent&quot; rel=&quot;&quot;&gt;
      writeup
     &lt;/a&gt;
     &lt;span&gt;
      goes into more detail.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/XiaomiMiMo/MiMo-7B-RL&quot; rel=&quot;&quot;&gt;
       MiMo-7B-RL
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/XiaomiMiMo&quot; rel=&quot;&quot;&gt;
      XiaomiMiMo
     &lt;/a&gt;
     &lt;span&gt;
      : Even Xiaomi has started releasing open models. Their first model series doesn&#x27;t have to hide, following the DeepSeek playbook: Multi-token prediction, an RL-only model and an SFT-&amp;gt;RL model. All models (Base, RL-only, SFT-only, SFT-&amp;gt;RL) are available under the MIT license.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/deepseek-ai/DeepSeek-Prover-V2-671B&quot; rel=&quot;&quot;&gt;
       DeepSeek-Prover-V2-671B
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/deepseek-ai&quot; rel=&quot;&quot;&gt;
      deepseek-ai
     &lt;/a&gt;
     &lt;span&gt;
      : An updated version of the Prover series by DeepSeek, building upon V3. They also used a smaller 7B Prover model (which, of course, is also
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/deepseek-ai/DeepSeek-Prover-V2-7B10&quot; rel=&quot;&quot;&gt;
      open-sourced
     &lt;/a&gt;
     &lt;span&gt;
      ) to search for subgoals in proofs. The resulting model shatters proof-related benchmarks, but this is expected from DeepSeek.
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!uiwc!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59e555ad-b146-40f7-9e06-ab0074d4b58c_3572x1542.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!uiwc!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59e555ad-b146-40f7-9e06-ab0074d4b58c_3572x1542.png 424w, https://substackcdn.com/image/fetch/$s_!uiwc!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59e555ad-b146-40f7-9e06-ab0074d4b58c_3572x1542.png 848w, https://substackcdn.com/image/fetch/$s_!uiwc!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59e555ad-b146-40f7-9e06-ab0074d4b58c_3572x1542.png 1272w, https://substackcdn.com/image/fetch/$s_!uiwc!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59e555ad-b146-40f7-9e06-ab0074d4b58c_3572x1542.png 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/59e555ad-b146-40f7-9e06-ab0074d4b58c_3572x1542.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:629,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;629&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!uiwc!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59e555ad-b146-40f7-9e06-ab0074d4b58c_3572x1542.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!uiwc!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59e555ad-b146-40f7-9e06-ab0074d4b58c_3572x1542.png 424w, https://substackcdn.com/image/fetch/$s_!uiwc!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59e555ad-b146-40f7-9e06-ab0074d4b58c_3572x1542.png 848w, https://substackcdn.com/image/fetch/$s_!uiwc!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59e555ad-b146-40f7-9e06-ab0074d4b58c_3572x1542.png 1272w, https://substackcdn.com/image/fetch/$s_!uiwc!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59e555ad-b146-40f7-9e06-ab0074d4b58c_3572x1542.png 1456w&quot; width=&quot;1456&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/microsoft/Phi-4-reasoning-plus&quot; rel=&quot;&quot;&gt;
       Phi-4-reasoning-plus
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/microsoft&quot; rel=&quot;&quot;&gt;
      microsoft
     &lt;/a&gt;
     &lt;span&gt;
      : Phi also joined the ranks of the reasoning models. The &quot;plus&quot; variant uses GRPO on top of an SFT model. We found the model surprisingly capable in our testing considering both the size and the reputation of the Phi series as benchmark-maxers.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/nvidia/AceReason-Nemotron-14B&quot; rel=&quot;&quot;&gt;
       AceReason-Nemotron-14B
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/nvidia&quot; rel=&quot;&quot;&gt;
      nvidia
     &lt;/a&gt;
     &lt;span&gt;
      : Building upon R1-Qwen 14B, AceReason uses two RL phases: One exclusively for math, followed by one for code. Like others they use GRPO.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/sarvamai/sarvam-m&quot; rel=&quot;&quot;&gt;
       Sarvam-M
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/sarvamai&quot; rel=&quot;&quot;&gt;
      sarvamai
     &lt;/a&gt;
     &lt;span&gt;
      : A hybrid reasoning model (on/off) based on Mistral-Small. It focuses on Indian languages.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/nvidia/Cosmos-Reason1-7B&quot; rel=&quot;&quot;&gt;
       Cosmos-Reason1-7B
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/nvidia&quot; rel=&quot;&quot;&gt;
      nvidia
     &lt;/a&gt;
     &lt;span&gt;
      : Multimodal model for robotic tasks.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/nvidia/OpenCodeReasoning-Nemotron-32B-IOI&quot; rel=&quot;&quot;&gt;
       OpenCodeReasoning-Nemotron-32B-IOI
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/nvidia&quot; rel=&quot;&quot;&gt;
      nvidia
     &lt;/a&gt;
     &lt;span&gt;
      : A reasoning model based on distilled R1 traces.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/nvidia/OpenMath-Nemotron-32B&quot; rel=&quot;&quot;&gt;
       OpenMath-Nemotron-32B
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/nvidia&quot; rel=&quot;&quot;&gt;
      nvidia
     &lt;/a&gt;
     &lt;span&gt;
      : A math model, based on Qwen 32B. The
     &lt;/span&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2504.16891&quot; rel=&quot;&quot;&gt;
      paper
     &lt;/a&gt;
     &lt;span&gt;
      goes into more detail for the data creation, which needed a lot of work to get another model (LIMO-Qwen 32B) to output proper tool calls. They also used a lot of different reasoning models to create the data.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/Salesforce/Elastic-Reasoning&quot; rel=&quot;&quot;&gt;
       Elastic-Reasoning
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/Salesforce&quot; rel=&quot;&quot;&gt;
      Salesforce
     &lt;/a&gt;
     &lt;span&gt;
      : A series of models that have two different thinking budgets: One for thinking, one for the solution phase. The models are trained with a budget-constrained rollout strategy using GRPO.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/BAAI/OpenSeek-Small-v1&quot; rel=&quot;&quot;&gt;
       OpenSeek-Small-v1
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/BAAI&quot; rel=&quot;&quot;&gt;
      BAAI
     &lt;/a&gt;
     &lt;span&gt;
      : The first model from the
     &lt;/span&gt;
     &lt;a href=&quot;https://github.com/FlagAI-Open/OpenSeek&quot; rel=&quot;&quot;&gt;
      OpenSeek
     &lt;/a&gt;
     &lt;span&gt;
      project, which wants to replicate R1-style models in the open.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/ByteDance-Seed/Seed-Coder-8B-Reasoning&quot; rel=&quot;&quot;&gt;
       Seed-Coder-8B-Reasoning
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/ByteDance-Seed&quot; rel=&quot;&quot;&gt;
      ByteDance-Seed
     &lt;/a&gt;
     &lt;span&gt;
      : ByteDance also started dropping a lot of open models and research. Seed-Coder is a coding model, trained on 6T tokens, which are curated by using LLMs as a quality filter. The reasoning variant is trained with GRPO. Unsurprisingly for Chinese model releases, the model is released under MIT.
     &lt;/span&gt;
    &lt;/p&gt;
    &lt;div&gt;
     &lt;figure&gt;
      &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!CoQY!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F786335ba-f46f-4057-9459-ab6bee477f27_2632x1214.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
       &lt;div&gt;
        &lt;picture&gt;
         &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!CoQY!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F786335ba-f46f-4057-9459-ab6bee477f27_2632x1214.png 424w, https://substackcdn.com/image/fetch/$s_!CoQY!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F786335ba-f46f-4057-9459-ab6bee477f27_2632x1214.png 848w, https://substackcdn.com/image/fetch/$s_!CoQY!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F786335ba-f46f-4057-9459-ab6bee477f27_2632x1214.png 1272w, https://substackcdn.com/image/fetch/$s_!CoQY!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F786335ba-f46f-4057-9459-ab6bee477f27_2632x1214.png 1456w&quot; type=&quot;image/webp&quot;&gt;
          &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/786335ba-f46f-4057-9459-ab6bee477f27_2632x1214.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:672,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;672&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!CoQY!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F786335ba-f46f-4057-9459-ab6bee477f27_2632x1214.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!CoQY!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F786335ba-f46f-4057-9459-ab6bee477f27_2632x1214.png 424w, https://substackcdn.com/image/fetch/$s_!CoQY!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F786335ba-f46f-4057-9459-ab6bee477f27_2632x1214.png 848w, https://substackcdn.com/image/fetch/$s_!CoQY!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F786335ba-f46f-4057-9459-ab6bee477f27_2632x1214.png 1272w, https://substackcdn.com/image/fetch/$s_!CoQY!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F786335ba-f46f-4057-9459-ab6bee477f27_2632x1214.png 1456w&quot; width=&quot;1456&quot;/&gt;
         &lt;/source&gt;
        &lt;/picture&gt;
       &lt;/div&gt;
      &lt;/a&gt;
     &lt;/figure&gt;
    &lt;/div&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h4&gt;
   Datasets
  &lt;/h4&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/datasets/marcodsn/academic-chains&quot; rel=&quot;&quot;&gt;
       academic-chains
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/marcodsn&quot; rel=&quot;&quot;&gt;
      marcodsn
     &lt;/a&gt;
     &lt;span&gt;
      : A dataset consisting of CoTs and answers to problems from academic papers.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      &lt;a href=&quot;https://huggingface.co/datasets/nvidia/Llama-Nemotron-Post-Training-Dataset&quot; rel=&quot;&quot;&gt;
       Llama-Nemotron-Post-Training-Dataset
      &lt;/a&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      by
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/nvidia&quot; rel=&quot;&quot;&gt;
      nvidia
     &lt;/a&gt;
     &lt;span&gt;
      : The underlying SFT and RL dataset for many of the Nemotron models.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h3&gt;
   Models
  &lt;/h3&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Interviewing Eugene Vinitsky on self-play for self-driving and what else people do with RL </title>
<link>https://www.interconnects.ai/p/interviewing-eugene-vinitsky-on-self</link>
<pubDate>Wed, 12 Mar 2025 13:03:15 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;a href=&quot;https://www.eugenevinitsky.com/&quot; rel=&quot;&quot;&gt;
    Eugene Vinitsky
   &lt;/a&gt;
   &lt;span&gt;
    is a professor a New York University department of Civil and Urban Engineering. He’s one of my original reinforcement learning friends from when we were both doing our Ph.D.’s in RL at UC Berkeley circa 2020. Eugene has extensive experience in
   &lt;/span&gt;
   &lt;a href=&quot;https://proceedings.mlr.press/v87/vinitsky18a.html&quot; rel=&quot;&quot;&gt;
    self-driving
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2012.02096&quot; rel=&quot;&quot;&gt;
    open endedness
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2103.01955&quot; rel=&quot;&quot;&gt;
    multi-agent reinforcement learning
   &lt;/a&gt;
   &lt;span&gt;
    , and
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2502.03349&quot; rel=&quot;&quot;&gt;
    self-play with RL
   &lt;/a&gt;
   &lt;span&gt;
    . In this conversation we focus on a few key topics:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     His latest results on self-play for self-driving and what they say about the future of RL,
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Why self-play is confusing and how it relates to the recent takeoff of RL for language models, and
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     The future of RL in LMs and elsewhere.
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   This is a conversation where we take the time to distill very cutting edge research directions down into the core essences. I felt like we were learning in real time what recent developments mean for RL, how RL has different scaling laws for deep learning, and what is truly salient about self-play.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/interviewing-eugene-vinitsky-on-self?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/interviewing-eugene-vinitsky-on-self?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The main breakthrough we discuss is scaling up self-play techniques for large-scale, simulated reinforcement learning. Previously, scaling RL in simulation has become economical in single-agent domains. Now, the door is open to complex, multi-agent scenarios where more diversity is needed to find solutions (in this case, that’s what self play does).
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Eugene’s
   &lt;/span&gt;
   &lt;a href=&quot;https://scholar.google.com/citations?user=6dr5fLEAAAAJ&amp;hl=en&quot; rel=&quot;&quot;&gt;
    Google Scholar
   &lt;/a&gt;
   &lt;span&gt;
    |
   &lt;/span&gt;
   &lt;a href=&quot;https://emerge-lab.github.io/&quot; rel=&quot;&quot;&gt;
    Research Lab
   &lt;/a&gt;
   &lt;span&gt;
    |
   &lt;/span&gt;
   &lt;a href=&quot;https://www.linkedin.com/in/eugenevinitsky&quot; rel=&quot;&quot;&gt;
    Linkedin
   &lt;/a&gt;
   &lt;span&gt;
    |
   &lt;/span&gt;
   &lt;a href=&quot;https://twitter.com/EugeneVinitsky&quot; rel=&quot;&quot;&gt;
    Twitter
   &lt;/a&gt;
   &lt;span&gt;
    |
   &lt;/span&gt;
   &lt;a href=&quot;https://bsky.app/profile/eugenevinitsky.bsky.social&quot; rel=&quot;&quot;&gt;
    BlueSky
   &lt;/a&gt;
   &lt;span&gt;
    |
   &lt;/span&gt;
   &lt;a href=&quot;https://www.eugenevinitsky.com/blogs/&quot; rel=&quot;&quot;&gt;
    Blog
   &lt;/a&gt;
   &lt;span&gt;
    (with some great career
   &lt;/span&gt;
   &lt;a href=&quot;https://www.eugenevinitsky.com/posts/coldemails/&quot; rel=&quot;&quot;&gt;
    advice
   &lt;/a&gt;
   &lt;span&gt;
    ).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Listen on
   &lt;/span&gt;
   &lt;a href=&quot;https://podcasts.apple.com/us/podcast/interconnects-audio/id1719552353&quot; rel=&quot;&quot;&gt;
    Apple Podcasts
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://open.spotify.com/show/2UE6s7wZC4kiXYOnWRuxGv&quot; rel=&quot;&quot;&gt;
    Spotify
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.youtube.com/@interconnects&quot; rel=&quot;&quot;&gt;
    YouTube
   &lt;/a&gt;
   &lt;span&gt;
    , and
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/podcast&quot; rel=&quot;&quot;&gt;
    where ever you get your podcasts
   &lt;/a&gt;
   &lt;span&gt;
    . For other Interconnects interviews,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/t/interviews&quot; rel=&quot;&quot;&gt;
    go here
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div data-attrs=&#x27;{&quot;videoId&quot;:&quot;2Q66uIRMEnc&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}&#x27; data-component-name=&quot;Youtube2ToDOM&quot;&gt;
   &lt;div&gt;
    &lt;iframe allow=&quot;autoplay; fullscreen&quot; allowautoplay=&quot;true&quot; allowfullscreen=&quot;true&quot; frameborder=&quot;0&quot; gesture=&quot;media&quot; height=&quot;409&quot; loading=&quot;lazy&quot; src=&quot;https://www.youtube-nocookie.com/embed/2Q66uIRMEnc?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0&quot; width=&quot;728&quot;&gt;
    &lt;/iframe&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div&gt;
   &lt;hr/&gt;
  &lt;/div&gt;
  &lt;h3&gt;
   Show outline &amp; links
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;span&gt;
    We cover many papers in this podcast. Also, as an experiment, here’s a Deep Research report on “
   &lt;/span&gt;
   &lt;a href=&quot;https://chatgpt.com/share/67d0fd58-8764-8005-8622-dbef26880a13&quot; rel=&quot;&quot;&gt;
    all the papers that appeared in this podcast transcript
   &lt;/a&gt;
   &lt;span&gt;
    .”
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   In this episode, we cover:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Self-play for self-driving, mostly around the recent paper
     &lt;/span&gt;
     &lt;em&gt;
      &lt;a href=&quot;https://arxiv.org/abs/2502.03349&quot; rel=&quot;&quot;&gt;
       Robust Autonomy Emerges from Self-Play
      &lt;/a&gt;
      &lt;span&gt;
      &lt;/span&gt;
     &lt;/em&gt;
     &lt;span&gt;
      (Cusumano-Towner et al. 2025).
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      The simulator they built powering this is
     &lt;/span&gt;
     &lt;strong&gt;
      Gigaflow
     &lt;/strong&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;span&gt;
      More
     &lt;/span&gt;
     &lt;a href=&quot;https://news.ycombinator.com/item?id=42968700&quot; rel=&quot;&quot;&gt;
      discussion on HackerNews
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;span&gt;
      (Here’s another
     &lt;/span&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2403.19648&quot; rel=&quot;&quot;&gt;
      self-play for self-driving paper
     &lt;/a&gt;
     &lt;span&gt;
      and
     &lt;/span&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2502.14706&quot; rel=&quot;&quot;&gt;
      another
     &lt;/a&gt;
     &lt;span&gt;
      from Eugene from earlier this year).
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      A few highlights:
     &lt;/span&gt;
     &lt;br/&gt;
    &lt;/p&gt;
    &lt;p&gt;
     &lt;span&gt;
      “
     &lt;/span&gt;
     &lt;strong&gt;
      All simulated agents use the
     &lt;/strong&gt;
     &lt;em&gt;
      &lt;strong&gt;
       same
      &lt;/strong&gt;
     &lt;/em&gt;
     &lt;strong&gt;
      neural net with the same weights
     &lt;/strong&gt;
     &lt;span&gt;
      , albeit with randomized rewards and conditioning vector to allow them to behave as different types of vehicles with different types of aggressiveness. This is like driving in a world where everyone is different copies of you, but some of your copies are in rush while others are patient. This allows backprop to optimize for a sort of global utility across the entire population.”
     &lt;/span&gt;
     &lt;br/&gt;
    &lt;/p&gt;
    &lt;p&gt;
     “The resulting policy simulates agents that are human-like, even though the system has never seen humans drive.”
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!Z3Yl!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d42760d-2ba6-46cd-9a8d-9eae285345d2_1022x847.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Z3Yl!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d42760d-2ba6-46cd-9a8d-9eae285345d2_1022x847.png 424w, https://substackcdn.com/image/fetch/$s_!Z3Yl!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d42760d-2ba6-46cd-9a8d-9eae285345d2_1022x847.png 848w, https://substackcdn.com/image/fetch/$s_!Z3Yl!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d42760d-2ba6-46cd-9a8d-9eae285345d2_1022x847.png 1272w, https://substackcdn.com/image/fetch/$s_!Z3Yl!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d42760d-2ba6-46cd-9a8d-9eae285345d2_1022x847.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7d42760d-2ba6-46cd-9a8d-9eae285345d2_1022x847.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:847,&quot;width&quot;:1022,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:318634,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/157775177?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d42760d-2ba6-46cd-9a8d-9eae285345d2_1022x847.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;847&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!Z3Yl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d42760d-2ba6-46cd-9a8d-9eae285345d2_1022x847.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!Z3Yl!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d42760d-2ba6-46cd-9a8d-9eae285345d2_1022x847.png 424w, https://substackcdn.com/image/fetch/$s_!Z3Yl!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d42760d-2ba6-46cd-9a8d-9eae285345d2_1022x847.png 848w, https://substackcdn.com/image/fetch/$s_!Z3Yl!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d42760d-2ba6-46cd-9a8d-9eae285345d2_1022x847.png 1272w, https://substackcdn.com/image/fetch/$s_!Z3Yl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d42760d-2ba6-46cd-9a8d-9eae285345d2_1022x847.png 1456w&quot; title=&quot;&quot; width=&quot;1022&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;em&gt;
      &lt;a href=&quot;https://arxiv.org/abs/2410.17233&quot; rel=&quot;&quot;&gt;
       Large Language Models are In-context Preference Learners
      &lt;/a&gt;
     &lt;/em&gt;
     &lt;span&gt;
      — how language models can come up with reward functions that will be applied to RL training directly.
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2502.03717v1&quot; rel=&quot;&quot;&gt;
      Related work from Stanford
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!0SnP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf31aed6-feef-41f6-b63b-ccfba3aca771_1151x717.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!0SnP!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf31aed6-feef-41f6-b63b-ccfba3aca771_1151x717.png 424w, https://substackcdn.com/image/fetch/$s_!0SnP!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf31aed6-feef-41f6-b63b-ccfba3aca771_1151x717.png 848w, https://substackcdn.com/image/fetch/$s_!0SnP!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf31aed6-feef-41f6-b63b-ccfba3aca771_1151x717.png 1272w, https://substackcdn.com/image/fetch/$s_!0SnP!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf31aed6-feef-41f6-b63b-ccfba3aca771_1151x717.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bf31aed6-feef-41f6-b63b-ccfba3aca771_1151x717.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:717,&quot;width&quot;:1151,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:235790,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.interconnects.ai/i/157775177?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf31aed6-feef-41f6-b63b-ccfba3aca771_1151x717.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;717&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!0SnP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf31aed6-feef-41f6-b63b-ccfba3aca771_1151x717.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!0SnP!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf31aed6-feef-41f6-b63b-ccfba3aca771_1151x717.png 424w, https://substackcdn.com/image/fetch/$s_!0SnP!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf31aed6-feef-41f6-b63b-ccfba3aca771_1151x717.png 848w, https://substackcdn.com/image/fetch/$s_!0SnP!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf31aed6-feef-41f6-b63b-ccfba3aca771_1151x717.png 1272w, https://substackcdn.com/image/fetch/$s_!0SnP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf31aed6-feef-41f6-b63b-ccfba3aca771_1151x717.png 1456w&quot; title=&quot;&quot; width=&quot;1151&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     Related literature from Interconnects! The first includes literature we mention on the learning locomotion for quadrupeds with deep RL (special shoutout as usual to Marco Hutter’s group).
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;div data-component-name=&quot;DigestPostEmbed&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/rl-quadrupeds&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;
   &lt;/a&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;DigestPostEmbed&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/scaling-rl-axes&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;
   &lt;/a&gt;
  &lt;/div&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Recent and relevant papers
     &lt;/span&gt;
     &lt;em&gt;
      &lt;a href=&quot;https://arxiv.org/abs/2502.04327&quot; rel=&quot;&quot;&gt;
       Value-based RL Scales Predictably
      &lt;/a&gt;
      &lt;span&gt;
       ,
      &lt;/span&gt;
      &lt;a href=&quot;https://www.nature.com/articles/s41586-021-04301-9&quot; rel=&quot;&quot;&gt;
       Magnetic control of tokamak plasmas through deep reinforcement learning
      &lt;/a&gt;
      &lt;span&gt;
       .
      &lt;/span&gt;
     &lt;/em&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Other things we mention:
    &lt;/p&gt;
    &lt;ul&gt;
     &lt;li&gt;
      &lt;p&gt;
       Cruise, Tesla, and Waymo’s autonomy stacks (speculation) and how the self-driving industry has changed since we were / were considering working in it.
      &lt;/p&gt;
     &lt;/li&gt;
     &lt;li&gt;
      &lt;p&gt;
       &lt;a href=&quot;https://arcinstitute.org/tools/evo&quot; rel=&quot;&quot;&gt;
        Evo 2 foundation model for biology.
       &lt;/a&gt;
      &lt;/p&gt;
     &lt;/li&gt;
    &lt;/ul&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Eugene is working with a new startup on some LLM and RL stuff. If you’re interested in this episode, ping eugene@aitco.dev. Not a paid promotion.
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h2&gt;
   Chapters
  &lt;/h2&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:00:00 Introduction &amp; RL Fundamentals
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:11:27 Self‑Play for Self‑Driving Cars
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:31:57 RL Scaling in Robotics and Other Domains
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:44:23 Language Models and In-Context Preference Learning
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     00:55:31 Future of RL and Grad School Advice
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   Transcript
  &lt;/h2&gt;
  &lt;p&gt;
   &lt;em&gt;
    &lt;span&gt;
     I attempted to generate with ElevenLab’s new
    &lt;/span&gt;
    &lt;a href=&quot;https://elevenlabs.io/blog/meet-scribe&quot; rel=&quot;&quot;&gt;
     Scribe
    &lt;/a&gt;
    &lt;span&gt;
     tool, but found the formatting annoying and reverted back to Alessio’s smol-podcaster. If you’re interested in working part-time as an editorial aide to Interconnects, please get in touch.
    &lt;/span&gt;
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:01:27]: Hey, Eugene. Welcome to the show.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:01:29]: Hey, Nathan. Thanks for having me. Excited to be here.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:01:32]: Yeah, so I&#x27;ll have said this in the intro as well, but we definitely go well back in all the way to Berkeley days and RL days, I think.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I will embarrass you a little bit now on the live read, which is like, you were one of the people when I was switching into RL, and they&#x27;re like, oh, it seems like you only figured out how to get into AI from a potentially different background, and that&#x27;s what I was trying to do in 2017 and 2018.
  &lt;/p&gt;
  &lt;p&gt;
   So that was kind of fun, and now we&#x27;re just friends, which is good.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:02:01]: Yeah, we were both figuring out. If I had any lead over you there, I was also frantically trying to figure it out, because I was coming from a weird background.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:02:11]: There are definitely a lot of people that do that now and over-attribute small time deltas to big strategic plans, which was probably what it was.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And we&#x27;re just going to do some of our normal conversations on RL and self-play.
  &lt;/p&gt;
  &lt;p&gt;
   I think the backstory of this is you told me that your recent paper from some of your time at Apple, I think I don&#x27;t want to time for it too specifically, was something, paraphrasing, like the most exciting RL thing you&#x27;ve ever had a part of.
  &lt;/p&gt;
  &lt;p&gt;
   And major RL projects are not that frequent.
  &lt;/p&gt;
  &lt;p&gt;
   I think if you segment out all the language model excitement in the past 10 years, there&#x27;s really a few major milestones, and it&#x27;s good to kind of talk about them.
  &lt;/p&gt;
  &lt;p&gt;
   So we can kind of start, I think, basic things, like how do you define reinforcement learning, and it will kind of build up to this self-driving project.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:03:05]: Yeah, so I think RL is kind of a big thing, but at a really basic level, you have this process of taking actions in the world.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   You&#x27;re seeing the state of the world.
  &lt;/p&gt;
  &lt;p&gt;
   If you&#x27;re taking actions in the world, you sometimes receive a reward that tells you the value of that action, and you&#x27;re trying to kind of optimize your cumulative behavior over time.
  &lt;/p&gt;
  &lt;p&gt;
   So that, you know, over long trajectories, you&#x27;re optimizing those costs.
  &lt;/p&gt;
  &lt;p&gt;
   That&#x27;s both, you know, the hard thing and the exciting thing is that if you do it well, you can really optimize really long horizon behaviors.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:03:41]: Yeah, I agree.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And it&#x27;s funny because now it&#x27;s finally, the language models are finally doing this long chain of thought, and I don&#x27;t really think that&#x27;s the same.
  &lt;/p&gt;
  &lt;p&gt;
   I think the interactive notion will come up a lot here where these long context behaviors are many, many actions interacting with the world relative to one really, really long action, which is kind of odd.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:04:04]: Yeah, I guess, yeah, it mixes things, right?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Because it has very long state, right?
  &lt;/p&gt;
  &lt;p&gt;
   It&#x27;s got very long contexts, and it&#x27;s generating its own context.
  &lt;/p&gt;
  &lt;p&gt;
   But in the end, there&#x27;s really one action at the end that, like, kind of determines how everything went, you know?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:04:23]: Yeah, yeah, yeah, we&#x27;ll get into this.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And then the next thing that we kind of need to set up is what do you define self-play as?
  &lt;/p&gt;
  &lt;p&gt;
   I think this word has been particularly broken in recent times with language models, and I&#x27;m hoping we can get a fairly specific criteria for what is self-play and what are related topics.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:04:42]: Yeah, I think even within the field, there&#x27;s quite a bit of debate as to what constitutes self-play.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So talking to, you know, experts, people will disagree about what methods are and are in self-play.
  &lt;/p&gt;
  &lt;p&gt;
   But what I will say is I generally define self-play as anything where an agent plays a copy of itself.
  &lt;/p&gt;
  &lt;p&gt;
   So up to a bunch of different agents interacting with each other, as long as they&#x27;re mostly, in some ways, copies of each other, we&#x27;re doing self-play.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:05:12]: Yeah, and then do you think anything, I mean, your background&#x27;s in multi-agent as well.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Do you think there is something fundamental to kind of a game that has a really specific hill to climb where it&#x27;s kind of this competitive nature versus something like language?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:05:29]: Yeah, this is kind of the dream of, I think, some multi-agent researchers is this type of like ratchet effect where you have a bunch of agents interacting with each other and kind of increasing complexity on the part of any agent generates increasing, like creates new challenges that need to be solved and then force you to learn new skills.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And then you kind of get this endless, endless ratchet.
  &lt;/p&gt;
  &lt;p&gt;
   Maybe that&#x27;s what you meant.
  &lt;/p&gt;
  &lt;p&gt;
   I may have misinterpreted.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:05:55]: We&#x27;re going to revisit it.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I think also it&#x27;s like, how does the multi-agent nature of a lot of these things change what people think about with RL?
  &lt;/p&gt;
  &lt;p&gt;
   This is kind of the last building block before we go into the self-driving stuff.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:06:07]: Yeah, yeah, yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So the way that the multi-agent thing changes things is it makes everything much harder and more interesting.
  &lt;/p&gt;
  &lt;p&gt;
   So you go away from this world where you have like a clear score function, right?
  &lt;/p&gt;
  &lt;p&gt;
   So you have some reward for first in single agent setting, you have some reward.
  &lt;/p&gt;
  &lt;p&gt;
   If that reward is high, you&#x27;re doing well, right?
  &lt;/p&gt;
  &lt;p&gt;
   And when you move into the multi-agent setting, it becomes reward with respect to whom, right?
  &lt;/p&gt;
  &lt;p&gt;
   It all of a sudden matters whom I&#x27;m playing, right?
  &lt;/p&gt;
  &lt;p&gt;
   So if we go to a game of like, like one setting is like two players, zero sum games, right?
  &lt;/p&gt;
  &lt;p&gt;
   So a game of two player poker, I give you, I train a poker bot, right?
  &lt;/p&gt;
  &lt;p&gt;
   How do I know it&#x27;s any good?
  &lt;/p&gt;
  &lt;p&gt;
   I have to play another poker bot to decide that it&#x27;s any good, right?
  &lt;/p&gt;
  &lt;p&gt;
   And so all of a sudden, this challenge of like, what is a good policy becomes very fundamental.
  &lt;/p&gt;
  &lt;p&gt;
   And you kind of lose even a notion of there being like one clear good policy.
  &lt;/p&gt;
  &lt;p&gt;
   And like the whole, a lot of, a lot of the field of multi-agents is coming up with different definitions of what would cost you goodness.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:07:06]: Um, so, and then back to the self-play thing with that, like, is all of the self-play that we discussed, like if you were playing yourself, does the same consideration apply?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Like, is that, is self-play necessarily a multi-agent framing?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:07:19]: Um, I think it, I think it is because oftentimes what we&#x27;re trying to do with self-play is like to converge to some notion of policy goodness.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And self-play is just a mechanism that gets us to some definition of, of high quality policies.
  &lt;/p&gt;
  &lt;p&gt;
   Um, and, and, and what turns out to be the case is there, there are actually many like non-self-play type methods for doing this.
  &lt;/p&gt;
  &lt;p&gt;
   Self-play just turns out to be an effective way to accomplish constructing effective policies.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:07:45]: Yeah, I, I, there&#x27;s many, I&#x27;ll, I&#x27;ll link later a lot of these papers on self-play for preference learning and look into them a bit more.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:07:56]: Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:07:57]: Essentially that&#x27;s been the lens.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   There&#x27;s two lenses by which this has come back and both of them, I don&#x27;t think fit into, I, I think this multi-agent lens of self-play is much richer and I don&#x27;t think any of them have fulfilled this.
  &lt;/p&gt;
  &lt;p&gt;
   I think there&#x27;s useful methods for preference tuning.
  &lt;/p&gt;
  &lt;p&gt;
   I think that&#x27;s like maybe spin it&#x27;s like self-play something preference learning is one.
  &lt;/p&gt;
  &lt;p&gt;
   And there&#x27;s papers related to this where they&#x27;re probably looking at the probability of the own model in generating a response or something like looking at the internals of the model.
  &lt;/p&gt;
  &lt;p&gt;
   And it&#x27;s not really set up in this game nature of some sort.
  &lt;/p&gt;
  &lt;p&gt;
   And then also with Q stars, when the self-play stuff came back where I really think I&#x27;ve, I&#x27;ve talked to some people that did original reporting on this and it was that the model looked like it was talking to itself.
  &lt;/p&gt;
  &lt;p&gt;
   And I think that very understandably for less, a little bit less technical audiences that haven&#x27;t engaged with self-play, that coverage of talking to itself got transformed into a self-play commentary and hype cycle, which took people down the wrong path for like an entire year, which is so brutal, but also very understandable and funny.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:09:11]: Yeah, I think there&#x27;s something interesting and different happening in these like multi-agent like LLM self-play setups.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I&#x27;m not super familiar, but I think what&#x27;s happening is something quite different than what we mean in other multi-agent settings when we&#x27;re talking about self-play.
  &lt;/p&gt;
  &lt;p&gt;
   Like I feel like it&#x27;s, it&#x27;s more about like refining like the distribution of actions that it takes in some, some kind of odd way.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:09:39]: I think this sounds ridiculous at first pass, but it&#x27;s almost that the language models are simulating a softer version of self-play within themselves to kind of check their own work and engage in their own discourse, which the level of intelligence they have is not going to like unlock the true like incremental progress that we think of with self-play.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Which probably, I think for context of things for self-play, just to put them on the record of this are, have been very impactful or things like AlphaGo and New Zero.
  &lt;/p&gt;
  &lt;p&gt;
   I think that&#x27;s, those are the prime examples of generating some superhuman policy in a closer way.
  &lt;/p&gt;
  &lt;p&gt;
   I think it&#x27;s, it&#x27;s important to kind of gate the conversation on like, these are the aspirational goals, um, in terms of outcomes and then figuring out how to apply them to new domains and new tools is kind of unknown.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:10:31]: So, so maybe I should have said this earlier, but like self-play is the thing that gives a, is like maybe the one way that we know to build superhuman agents right now.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So, right.
  &lt;/p&gt;
  &lt;p&gt;
   So, um, superhuman go, um, human level Dota, human level, uh, Starcraft.
  &lt;/p&gt;
  &lt;p&gt;
   Um, technically poker is in a, in a slightly weirder, um, weirder space where I don&#x27;t, I don&#x27;t exactly know that I would call the method on that underlie that self-play.
  &lt;/p&gt;
  &lt;p&gt;
   Um, sorry.
  &lt;/p&gt;
  &lt;p&gt;
   Um, and, uh, but yeah, it&#x27;s the one way we really know how to build superhuman agents.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:11:06]: And I think this is a kind of a natural transition because the, to make people excited in the work that you did, it seems like you&#x27;ve discovered superhuman driving through self-play without inductive biases.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And I&#x27;m like, um, how do you view the potential impact of this?
  &lt;/p&gt;
  &lt;p&gt;
   And then we can kind of go into the method.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:11:27]: Right.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So the, the challenge with self-play is, and this requires a bit of technical detail to get there, but you know, in, in like two players, here are some games, games where you and an adversary are playing with each other and somebody wins and somebody loses, there&#x27;s a very well defined notion of what being good is.
  &lt;/p&gt;
  &lt;p&gt;
   Um, you know, that they&#x27;re, they&#x27;re well, you know, their criteria that we would like our policies to converge to.
  &lt;/p&gt;
  &lt;p&gt;
   And, and the challenge has always been about moving beyond that to a domain where it&#x27;s much harder to define what, what doing well means, right?
  &lt;/p&gt;
  &lt;p&gt;
   There isn&#x27;t like an abstract notion of what good driving is there out in the world where I could just write down the reward function and simulate it and optimize with respect to that.
  &lt;/p&gt;
  &lt;p&gt;
   And all of a sudden I&#x27;d have a good driving policy.
  &lt;/p&gt;
  &lt;p&gt;
   So the, the gap has always been between these methods that work really, really well in, in well-defined games like, like Starcraft or go, uh, and chess, um, and settings where it&#x27;s much harder to define that.
  &lt;/p&gt;
  &lt;p&gt;
   And so we haven&#x27;t been able to, to move to self-play in settings where, for example, humans might be in the loop, right.
  &lt;/p&gt;
  &lt;p&gt;
   And, and particularly driving is an instance of that somewhere where at the end, we&#x27;re going to take our policy and it&#x27;s going to drive with humans and we have no way to simulate humans and play against them.
  &lt;/p&gt;
  &lt;p&gt;
   Um, and so figuring out how to close that gap has been kind of an open, open challenge.
  &lt;/p&gt;
  &lt;p&gt;
   And I think maybe this is the first instance of, uh, finding a way to do that.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:12:51]: Okay.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So that&#x27;s a much better motivation than I gave.
  &lt;/p&gt;
  &lt;p&gt;
   And I understand the excitement now, because if this works in one domain, um, and you&#x27;ll tell us about how grand of an effort it actually was.
  &lt;/p&gt;
  &lt;p&gt;
   I know big tech companies can put a lot of force and long-term investment behind things to get them off the ground.
  &lt;/p&gt;
  &lt;p&gt;
   Then a lot of the other things that people are saying about language models or other complicated domains are at least there&#x27;s an existence proof of something similar happening.
  &lt;/p&gt;
  &lt;p&gt;
   So why don&#x27;t you just continue to explain, uh, this problem set up of learning driving without having a human teacher.
  &lt;/p&gt;
  &lt;p&gt;
   It will probably take detours to analogize different self-driving stacks just because we know about them and it&#x27;s good to compare.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:13:36]: So one way of framing this is, and I&#x27;m going to put cautions in the end, I&#x27;m going to give you the, the, the extreme version of it.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And I&#x27;m going to walk it back a little bit is like human level driving without any human level data.
  &lt;/p&gt;
  &lt;p&gt;
   And the caution needs to be that this is in simulation and our ability to measure human level driving in simulation is limited in a lot of ways.
  &lt;/p&gt;
  &lt;p&gt;
   So I can tell you about the ways that we measured it and then I&#x27;ll, I&#x27;ll have to tell you what the limitations of those things are.
  &lt;/p&gt;
  &lt;p&gt;
   Um, so this was a large scale effort, um, uh, and Lovlin Colton&#x27;s team and at Apple, um, it was about like eight researchers, research engineers working together for about a year and a half, uh, build, building the stack out.
  &lt;/p&gt;
  &lt;p&gt;
   Um, it was, I think a lot of us came at it from different places.
  &lt;/p&gt;
  &lt;p&gt;
   I know some folks were very inspired by this idea of like alpha star for driving, you know, building a diverse, rich world and then driving it in a way that such you would, you would transfer to policies that you hadn&#x27;t seen before.
  &lt;/p&gt;
  &lt;p&gt;
   So like human actors.
  &lt;/p&gt;
  &lt;p&gt;
   Um, so, um, yeah, the, the, if, if, if it&#x27;s helpful that the idea here is that, or the goal here was to build a human level simulated driver.
  &lt;/p&gt;
  &lt;p&gt;
   Um, and here, what that means in our case is not a fully end-to-end method, right?
  &lt;/p&gt;
  &lt;p&gt;
   So we&#x27;re not simulating perception.
  &lt;/p&gt;
  &lt;p&gt;
   So driving stacks consist of like generally perception, prediction, planning controls.
  &lt;/p&gt;
  &lt;p&gt;
   So you have a perception stack that, you know, takes your LIDAR, your camera, your radar, and converts it into, you know, where are the cars, where are the road is, what&#x27;s impassable.
  &lt;/p&gt;
  &lt;p&gt;
   Um, and then a prediction stack will take the like positions of all the cars, the cyclists, pedestrians, and it&#x27;ll predict, predict where they&#x27;re going to go next.
  &lt;/p&gt;
  &lt;p&gt;
   And then a planning stack will say, okay, given those predictions, you know, what&#x27;s a good trajectory for me to take.
  &lt;/p&gt;
  &lt;p&gt;
   And then the control stack will say how to actually follow that trajectory safely and robust.
  &lt;/p&gt;
  &lt;p&gt;
   Right.
  &lt;/p&gt;
  &lt;p&gt;
   And we&#x27;re talking about subsuming the prediction, planning, control portion of the stack, not the perception part of the stack.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:15:28]: Okay.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So I was, I was thinking that you might not even do control.
  &lt;/p&gt;
  &lt;p&gt;
   I was thinking you might just say, uh, control is a softer album and not do that too.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:15:35]: So in the same way, we&#x27;re kind of, we&#x27;re only kind of doing control.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Uh, we&#x27;re, we&#x27;re, we&#x27;re doing this for, I think Waymo uses the
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:15:42]: the term behavior for this.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I think it&#x27;s been their behavior team for a while.
  &lt;/p&gt;
  &lt;p&gt;
   Is that right?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:15:46]: Okay.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:15:47]: Uh, you know, I very, it&#x27;s hard to know where the abstraction ends, but they definitely have a behavior team that&#x27;s done a lot of things through the years.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Well, he&#x27;s not the job apps that I&#x27;ve been applying to an interview or have interviewed for in the past.
  &lt;/p&gt;
  &lt;p&gt;
   Yeah, me too.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:16:01]: Um, I think we do know how to control cars.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   We know how to make cars follow a pre-specified trajectory, right?
  &lt;/p&gt;
  &lt;p&gt;
   This is, this is somewhat of an easier problem than like humanoid robotics or something.
  &lt;/p&gt;
  &lt;p&gt;
   You know, big thing got wheels.
  &lt;/p&gt;
  &lt;p&gt;
   We know how to make it turn.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:16:14]: Um, so how do we get these things from, I mean, they start as like, it doesn&#x27;t start at just all the simulated cars crashing all the time.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   What is the start here?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:16:24]: I&#x27;ll send you the video once it&#x27;s out, but like, you know, the, the first 10 hours of simulation is just like cars scattered all across the road, smashing into each other, driving off the road, that type of thing.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   It&#x27;s actually interestingly useful because what we do is when two cars crash, we have them come to an immediate stop.
  &lt;/p&gt;
  &lt;p&gt;
   And this actually creates a lot of blockades in the road.
  &lt;/p&gt;
  &lt;p&gt;
   So at some point during the training, the cars start to learn to drive around stopped cars, even though those cars are stopped because they&#x27;ve crashed, um, as well as to drive around like obstacles and things like that.
  &lt;/p&gt;
  &lt;p&gt;
   Um, so that, yeah, that&#x27;s what it looks like.
  &lt;/p&gt;
  &lt;p&gt;
   Um, yeah.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:16:58]: Um, as well as the reward function for these.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So you have a bunch of cars that can see their peers and there&#x27;s some reward function I&#x27;m guessing.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:17:06]: So the, the major component of the reward function is getting to your goal without colliding.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So we, we have these maps that we&#x27;ve taken from the cartless simulator.
  &lt;/p&gt;
  &lt;p&gt;
   They&#x27;re fairly large maps.
  &lt;/p&gt;
  &lt;p&gt;
   Some of them are like multiple kilometers in spatial extent.
  &lt;/p&gt;
  &lt;p&gt;
   We have eight of them and we place goals randomly over the map.
  &lt;/p&gt;
  &lt;p&gt;
   Um, and you get a sequence of goals.
  &lt;/p&gt;
  &lt;p&gt;
   So, you know, that like, okay, I want to get to this point.
  &lt;/p&gt;
  &lt;p&gt;
   And then after that, I&#x27;m going to want to get to this next point.
  &lt;/p&gt;
  &lt;p&gt;
   After that, you&#x27;re going to get a big reward for getting to that goal.
  &lt;/p&gt;
  &lt;p&gt;
   You&#x27;re going to get some amount of penalty for colliding.
  &lt;/p&gt;
  &lt;p&gt;
   And then there&#x27;s also an implicit penalty because if you collide, you&#x27;re not ever going to get to your goal.
  &lt;/p&gt;
  &lt;p&gt;
   And then there, there is some amount of hand design here in that there are small rewards for like staying in your lane and being aligned with your lane and like, you know, not driving in the opposite direction in the wrong lane.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:17:51]: This was one of the questions is if you had to do this sort of thing.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:17:54]: You have to do that.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   But one interesting thing, and maybe we could talk about that at some point is we randomize the weights of those rewards.
  &lt;/p&gt;
  &lt;p&gt;
   So there are agents that like really want to drive in the lane going in the right direction.
  &lt;/p&gt;
  &lt;p&gt;
   And there are agents that don&#x27;t care about that at all.
  &lt;/p&gt;
  &lt;p&gt;
   And they will take the wrong lane on the highway, uh, you know, going at full speed in the opposite direction.
  &lt;/p&gt;
  &lt;p&gt;
   And that&#x27;s kind of useful because you&#x27;re ready for that scenario.
  &lt;/p&gt;
  &lt;p&gt;
   You&#x27;ve seen that scenario in the world when you&#x27;re driving around.
  &lt;/p&gt;
  &lt;p&gt;
   Right.
  &lt;/p&gt;
  &lt;p&gt;
   Um, but yeah, we have to, we have to do some of that stuff because at some point there are laws and you can&#x27;t avoid encoding the laws into your system.
  &lt;/p&gt;
  &lt;p&gt;
   You know, stop signs are a human concept.
  &lt;/p&gt;
  &lt;p&gt;
   Um, they&#x27;re, they&#x27;re not, you know, it&#x27;s not going to emerge that you see a red thing and you&#x27;re like, oh yeah, that means I should stop.
  &lt;/p&gt;
  &lt;p&gt;
   And then I should like give the right of way rules to the other cars.
  &lt;/p&gt;
  &lt;p&gt;
   Um, but all of our rewards are kind of soft in the sense, like, you know, if you&#x27;re at a stop sign and folks have been preventing you from going for a very long period of time, right.
  &lt;/p&gt;
  &lt;p&gt;
   You&#x27;re going to start to nudge in and like break the rules about right away.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:18:55]: One of my questions for later on this is like, do you think our vehicles and driving dynamics and infrastructure kind of constrain the way of driving?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Like we&#x27;ve co-designed human driving in our infrastructure so that human driving is actually no longer that special because of the track is so long, so defined.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:19:11]: I think this is, this is part of why this is all going to work or like why it works is because like human, human driving is, and human behavior in many domains is like fairly constrained by the institutions and the laws and the norms that we design.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Uh, it&#x27;s not super free from, uh, so like driving amongst humans is much more of a constrained problem than you would, than you would, you would think it&#x27;s also unconstrained in some interesting ways, but, but it&#x27;s, it&#x27;s quite unconstrained, quite constrained.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:19:42]: And how hard to act was this to actually learn?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So how sensitive of a process is it now?
  &lt;/p&gt;
  &lt;p&gt;
   I think in the paper, you&#x27;re talking about gigaflow, which is like a high speed
  &lt;/p&gt;
  &lt;p&gt;
   simulation engine.
  &lt;/p&gt;
  &lt;p&gt;
   So obviously, you know, on data, the final paper says that it learns in 1.6 billion kilometers of driving.
  &lt;/p&gt;
  &lt;p&gt;
   I was wondering if you had an intuition for that.
  &lt;/p&gt;
  &lt;p&gt;
   So like how many miles are driven by all the cars in San Francisco and day or something like this?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:20:10]: That&#x27;s a, that&#x27;s a great question.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:20:12]: Um, it could be a good chat GPT query, to be honest.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:20:16]: This might be a chat GPT question.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Um, let me, let me give some, some numbers that I do know.
  &lt;/p&gt;
  &lt;p&gt;
   Uh, and this is kind of maybe helpful.
  &lt;/p&gt;
  &lt;p&gt;
   So I think cars crash every 20,000 to a hundred thousand miles and a fatal collision happens every a hundred million miles, something like that.
  &lt;/p&gt;
  &lt;p&gt;
   Um, but how many miles are driven in a day in a city?
  &lt;/p&gt;
  &lt;p&gt;
   I&#x27;m not sure.
  &lt;/p&gt;
  &lt;p&gt;
   1.6 billion kilometers, the distance between here and Saturn.
  &lt;/p&gt;
  &lt;p&gt;
   Um, it sounds like kind of far when you put it that way, but there are a lot of cars.
  &lt;/p&gt;
  &lt;p&gt;
   Yeah, there are a lot of cars, right?
  &lt;/p&gt;
  &lt;p&gt;
   There are a lot of drivers.
  &lt;/p&gt;
  &lt;p&gt;
   Um, there are surprisingly few trips in a city, fewer than you would expect, but, um, I&#x27;m struggling to put a number on it.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:21:01]: Um, I&#x27;ll tell you what chat GPT gets when it&#x27;s done.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I was thinking it&#x27;s Oh three mini high.
  &lt;/p&gt;
  &lt;p&gt;
   This is not a reliable number.
  &lt;/p&gt;
  &lt;p&gt;
   Take this time.
  &lt;/p&gt;
  &lt;p&gt;
   So your intuition that it&#x27;s lower goes a lot.
  &lt;/p&gt;
  &lt;p&gt;
   I mean, you&#x27;ve thought about a lot of these car systems for a very long time and I will link to some of your other work on this.
  &lt;/p&gt;
  &lt;p&gt;
   So you definitely have better intuitions than I would.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:21:20]: Well, the intuition comes with the fact that like a lane of the highway can take 2000 vehicles per hour, which is like just not that many vehicles.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Um, and you know, most, most of, most of traffic is between like, you know, 8am and or like 7am and like 10am and then on the way back home.
  &lt;/p&gt;
  &lt;p&gt;
   And so, you know, you can like kind of estimate based on how many lanes there are on the main highway, how many trips there are.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:21:43]: So San Francisco, the chat Oh three mini high estimated four to 5 million miles in a day in San Francisco.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   It&#x27;s a bully.
  &lt;/p&gt;
  &lt;p&gt;
   It&#x27;s a plausible number, but it&#x27;s well below what you are doing.
  &lt;/p&gt;
  &lt;p&gt;
   Like this is, I think maybe globally this billion kilometers could be hit.
  &lt;/p&gt;
  &lt;p&gt;
   So this is okay.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:22:03]: Here&#x27;s one way to think of it.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   We simulate 10,000 years of human drive.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:22:08]: Okay.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So yeah, 10,000 per one.
  &lt;/p&gt;
  &lt;p&gt;
   I guess it depends on how many cars you have in parallel.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:22:14]: Per one training run one trip to get the policy that we get.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   We simulate about 10,000 years of human drive.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:22:20]: Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:22:21]: Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:22:22]: So to have 10,000 cars, it&#x27;s all of them driving for a year.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:22:26]: Yeah, exactly.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And we have about like a million cars driving at any given time in the simulator.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:22:34]: Do you think that substantially changes the learning dynamics?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Like are they all, how many cars are any of them interacting with at any one time?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:22:40]: Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Any given simulator in any given world.
  &lt;/p&gt;
  &lt;p&gt;
   So this is this like kind of like Isaac&#x27;s gym style vectorized simulator.
  &lt;/p&gt;
  &lt;p&gt;
   So it all runs in the GPU.
  &lt;/p&gt;
  &lt;p&gt;
   So it&#x27;s a bunch of worlds happening in parallel, but any given world, there are about 150 cars in it, which means that sometimes you&#x27;re driving in sparse traffic and sometimes you&#x27;re going to interact with like 10 or 20 cars at any given time.
  &lt;/p&gt;
  &lt;p&gt;
   Um, and I, I think one thing is that one, one cool thing is that at that scale, I think RL becomes very, very stable.
  &lt;/p&gt;
  &lt;p&gt;
   Um, like for us, like every training run succeeds, the reward curves go straight up.
  &lt;/p&gt;
  &lt;p&gt;
   You know, there&#x27;s no like, um, what are you scaling?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:23:19]: Are you just like scaling batch size effectively?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Uh, what is, yeah.
  &lt;/p&gt;
  &lt;p&gt;
   What is the actual thing you&#x27;re, they&#x27;re scaling?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:23:26]: We&#x27;re scaling the amount of experience generated.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So it&#x27;s like a trillion samples of, of total experience, um, that, that the agents train on.
  &lt;/p&gt;
  &lt;p&gt;
   Um, and then, yeah, we use gigantic batch sizes, like, you know, um, but like, what is the thing
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:23:43]: that you need to dial up in order to make learning actually happen?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:23:47]: Uh, total amount of experience generated, right?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So you need to be generating, you know, million samples per second to train on type of thing.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:23:57]: Okay.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And then what is the actual, I guess I don&#x27;t know a ton about multi-gen RL, but what is the actual RL like algorithm and is it a giant replay buffer that is just building and building and building?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:24:08]: It&#x27;s PPO.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Uh, you know, one thing we&#x27;ve been seeing throughout our work pretty continually is that for, for both theoretical and empirical reasons, PPO is actually a really good multi-agent RL algorithm.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:24:20]: You had the paper, are you, you are on the paper years ago.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   That&#x27;s like on the something, something PPO multi-agent simple.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:24:29]: So we know that PPO works empirically pretty well.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   That&#x27;s basically the title of the paper.
  &lt;/p&gt;
  &lt;p&gt;
   That&#x27;s a PPO simple, good multi-agent cooperative.
  &lt;/p&gt;
  &lt;p&gt;
   Good.
  &lt;/p&gt;
  &lt;p&gt;
   Uh, it&#x27;s good in cooperative problems.
  &lt;/p&gt;
  &lt;p&gt;
   It&#x27;s, it turns out to be pretty good in two players, zero, some games.
  &lt;/p&gt;
  &lt;p&gt;
   And, and here in, um, this driving thing, it&#x27;s what&#x27;s called the general sum game.
  &lt;/p&gt;
  &lt;p&gt;
   And, and there, you know, it seems to work in the setting too.
  &lt;/p&gt;
  &lt;p&gt;
   So evidence is accumulating.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:24:51]: Something that people probably don&#x27;t know about multi-agent RL and maybe I don&#x27;t know either, but in this paper, all of the cars were using the same actual weights of the model.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Is that standard in multi-agent RL or is it kind of a variable?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:25:04]: So I&#x27;ll add one little, uh, subtlety here.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So yes, we&#x27;re using every policy is the copy of the same agent, right?
  &lt;/p&gt;
  &lt;p&gt;
   They&#x27;re all looking at their local observations.
  &lt;/p&gt;
  &lt;p&gt;
   So it&#x27;s decentralized, but it&#x27;s all one copy, but every agent gets its own like conditioning vector.
  &lt;/p&gt;
  &lt;p&gt;
   That&#x27;s like, what are my like reward weights?
  &lt;/p&gt;
  &lt;p&gt;
   How big of a, you know, what&#x27;s my width and my length?
  &lt;/p&gt;
  &lt;p&gt;
   Am I a cyclist?
  &lt;/p&gt;
  &lt;p&gt;
   Am I a pedestrian?
  &lt;/p&gt;
  &lt;p&gt;
   Am I a driver?
  &lt;/p&gt;
  &lt;p&gt;
   And they flexibly adjust their behavior based on that condition.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:25:29]: Do you think that&#x27;s actually like, if you were to squint at the system, is that actually changing the policy or is it changing the environment in kind of an indirect way?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:25:38]: It&#x27;s, it&#x27;s changing the policy.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Like you&#x27;ll see that like a car is like, oh, I&#x27;m a, I&#x27;m a, like a pedestrian.
  &lt;/p&gt;
  &lt;p&gt;
   I&#x27;m a, I&#x27;m a big truck.
  &lt;/p&gt;
  &lt;p&gt;
   I&#x27;m going to do like a K point turn to turn around.
  &lt;/p&gt;
  &lt;p&gt;
   Uh, I&#x27;m a pedestrian.
  &lt;/p&gt;
  &lt;p&gt;
   I&#x27;m, you know, going to like smoothly wiggle through these small boxes of areas that I couldn&#x27;t get through.
  &lt;/p&gt;
  &lt;p&gt;
   Otherwise it, it, it really, uh, appreciably changes the policy, which is cool because it&#x27;s this like tiny 3 million parameter neural network or like 6 million parameter.
  &lt;/p&gt;
  &lt;p&gt;
   Um, and, and so like, there are all these like little sub policies inside of it that you can activate by, by conditioning.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:26:11]: Can you do it, um, post hoc to change the behavior in an interpretable way?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:26:16]: Um, I don&#x27;t know about interpretable.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I guess it, it sometimes depends what we mean when we say interpretable, but yeah.
  &lt;/p&gt;
  &lt;p&gt;
   So you can be like, look, okay, you, you, you don&#x27;t care about staying in your lane and you&#x27;ll see it start going into the other lane and driving.
  &lt;/p&gt;
  &lt;p&gt;
   You know, you change the size of the policy or like the, the car and it will change the trajectories that it takes in response.
  &lt;/p&gt;
  &lt;p&gt;
   Um, it&#x27;s, it&#x27;s very responsive to this condition.
  &lt;/p&gt;
  &lt;p&gt;
   Um, we have some cool graphs in the paper pointing, pointing out all the different things you can make it do by changing these, these values.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:26:46]: Um, I&#x27;m trying to think of how this reflects on the nature of driving and what the downstream use of this tool is.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So you showed that this is doable and what does this, like, what does this mean for self-driving specifically?
  &lt;/p&gt;
  &lt;p&gt;
   Like, what would you do if you had the same big team and you know that this exists and you&#x27;re interested in self-driving as a field?
  &lt;/p&gt;
  &lt;p&gt;
   I mean, there are obviously a lot of people that a lot of companies that have big teams and lots of money to try to think about self-driving.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:27:14]: So as I said earlier, like there&#x27;s this like, um, perception, prediction, planning, control stack.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And I think this is a really is providing a lot of evidence that you could maybe subsume the prediction and the planning stack, um, and, and put it into this type of like end-to-end policy that you could then like train in sim and then maybe not zero shot deploy onto the roadway.
  &lt;/p&gt;
  &lt;p&gt;
   Just like take a straight from sim, put it onto the roadway though.
  &lt;/p&gt;
  &lt;p&gt;
   I think like maybe possible, uh, but like really give you this like base policy that you could then start to put on the roadway and start to build this flywheel, um, that you can then use to collect, you know, more and more experience, validate the safety.
  &lt;/p&gt;
  &lt;p&gt;
   You know, like if you&#x27;re, you know, if you&#x27;re a, um, uh, automotive manufacturer that doesn&#x27;t have like a full spun up self-driving team, but you have a pretty good perception stack, like this is something that you can use to just like get something out in the world pretty fast.
  &lt;/p&gt;
  &lt;p&gt;
   Cause like three, I think like two, two, three days of training later, you have something that I think, and we&#x27;d like to start testing it, uh, can be like straight up put onto the roadway with humans driven around and things will be like pretty okay.
  &lt;/p&gt;
  &lt;p&gt;
   Um, you know, don&#x27;t take the safety driver out, but like, yeah, and you have some cred
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:28:24]: saying this given that you&#x27;ve done RL experiments with real cars, this is not something that&#x27;s, um, ripping off the bandaid for the first time.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   You&#x27;ve done different types of self-driving experiments with RL policies in the real world.
  &lt;/p&gt;
  &lt;p&gt;
   I don&#x27;t, it might not be at the same level of the stack, but I can add links to that.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:28:42]: That was a lot more constrained, right?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   We were putting these cars on the highway to like smooth traffic.
  &lt;/p&gt;
  &lt;p&gt;
   So they would drive in a way such that like stop and go waves and traffic would like get smoothed out and disappear.
  &lt;/p&gt;
  &lt;p&gt;
   Um, but there it was just like, you know, stay in your lane, follow the car behind you here.
  &lt;/p&gt;
  &lt;p&gt;
   We&#x27;re talking about like, you know, complicated interactions at intersections and that type of thing.
  &lt;/p&gt;
  &lt;p&gt;
   So a lot, a lot more like safe, everything there is safety critical, but like significantly less constrained than anything we&#x27;ve done in the past.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:29:08]: And then to kind of keep leading this on, uh, I will say a bunch of things because you&#x27;re more of an industry insider.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So it makes it less revealing if I say things, cause I don&#x27;t really know anything.
  &lt;/p&gt;
  &lt;p&gt;
   Um, back when I was interviewing for a job and around 2021, at least a lot of RL people were interviewing with self-driving companies who were doing extensive research in RL for different parts of this behavior stack.
  &lt;/p&gt;
  &lt;p&gt;
   Um, even at that time, four years ago, prediction seemed largely or like sensing and prediction was perception was largely solved.
  &lt;/p&gt;
  &lt;p&gt;
   At least CV stacks are really mature and figuring out the actual driving component and decision making was really hard.
  &lt;/p&gt;
  &lt;p&gt;
   There was, I mean, I did a Tesla self home self like take home and for their self-driving team and they were hiring other RL people that take home was ridiculous.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:29:54]: I was like, yeah, I remember that.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:29:56]: Freaking intersection of polygons.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   It&#x27;s four years ago.
  &lt;/p&gt;
  &lt;p&gt;
   They&#x27;ve got to be using a different question, but it was so hard.
  &lt;/p&gt;
  &lt;p&gt;
   Um, I did end up solving the test cases.
  &lt;/p&gt;
  &lt;p&gt;
   Um, it was, I solved the test cases.
  &lt;/p&gt;
  &lt;p&gt;
   God, that was rough.
  &lt;/p&gt;
  &lt;p&gt;
   But essentially the rumor was they&#x27;re doing something like mu zero for self-driving and or a mix of imitation learning, which is there&#x27;s a duality of learning a world model from real data relative to building a simulator.
  &lt;/p&gt;
  &lt;p&gt;
   But the motivation of the work is very similar, which is in mu zero, you want to unroll trajectories and be able to learn from that and distill an RL policy versus if you have a big simulator, you then can learn everything from scratch and figure out how to transfer that to real.
  &lt;/p&gt;
  &lt;p&gt;
   And I think there&#x27;s different assumptions on what would work.
  &lt;/p&gt;
  &lt;p&gt;
   And the history of RL, it is now that the simulator to real is generally a more promising path.
  &lt;/p&gt;
  &lt;p&gt;
   If you can build the right simulator then and going from real to enhancing real with, with RL alone, um, cruise was building a research team.
  &lt;/p&gt;
  &lt;p&gt;
   And one of the best engineers I talked to was trying to build a world model or like a simulator and do this like alpha go for self-driving.
  &lt;/p&gt;
  &lt;p&gt;
   I think that was a phrase from the interviews four years ago.
  &lt;/p&gt;
  &lt;p&gt;
   So a lot of this, and Waymo is now obviously winning.
  &lt;/p&gt;
  &lt;p&gt;
   I think Waymo, I don&#x27;t know exactly what they&#x27;re doing.
  &lt;/p&gt;
  &lt;p&gt;
   I think their stack is actually probably the most complicated, um, where they probably were looking at behavior, like all sorts of RL inspired things for very specific parts of the stack to, to improve behavior.
  &lt;/p&gt;
  &lt;p&gt;
   But it&#x27;s funny that looking back four years ago, this was something that the spectrum of ideas that industry was looking at was actually very related to this.
  &lt;/p&gt;
  &lt;p&gt;
   And in the same time, the self-driving industry has changed a lot.
  &lt;/p&gt;
  &lt;p&gt;
   Uh, so what do you think of this whole industry of self-driving relative to, you have a lot of experience here.
  &lt;/p&gt;
  &lt;p&gt;
   I mean, I&#x27;m, I&#x27;m a big Waymo fan now, but there&#x27;s just like, it&#x27;s so funny how these things evolve.
  &lt;/p&gt;
  &lt;p&gt;
   And I think after this, later on, we&#x27;ll talk about the, like, this is the RL specific trajectory with simulation, simulated results and stuff too.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:31:57]: I mean, we were interviewing at the same time.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So I was also interviewing with all of these self-driving companies when you were, uh, and, and it, it did seem like it was the place that was the most friendly to doing RL type research at the time.
  &lt;/p&gt;
  &lt;p&gt;
   Um, I think now almost everyone has gone all in on this like imitation learning type approach, um, that are like, this is a huge fraction of what people are doing.
  &lt;/p&gt;
  &lt;p&gt;
   I think a lot of the RL teams have been spun down, uh, which I think is unfortunate a little bit because I think what this work shows is that, uh, it may be wrong to do so that there is a lot of, a lot of value still in RL for this last piece of, of the, of the puzzle.
  &lt;/p&gt;
  &lt;p&gt;
   Um, you know, um, you know, one thing we have here is, uh, an insanely robust policy, right?
  &lt;/p&gt;
  &lt;p&gt;
   So like just an end to end neural network in SIM, it crashes once in a million miles,
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:32:46]: um, crashes at all.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:32:49]: Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:32:50]: And you, but what was the number you said before for miles per crash?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:32:53]: Uh, humans are between 20 and a hundred K, um, somewhere, somewhere like that.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   It&#x27;s a little hard to get estimates because it varies from place to place a lot.
  &lt;/p&gt;
  &lt;p&gt;
   So, I mean, a lot of industries are pretty excited about this, like alpha zero for self driving type thing.
  &lt;/p&gt;
  &lt;p&gt;
   And the question, you know, becomes, as you said, like, what is the simulator that we do this in?
  &lt;/p&gt;
  &lt;p&gt;
   And so one perspective that&#x27;s very prominent is like, let&#x27;s collect a lot of data.
  &lt;/p&gt;
  &lt;p&gt;
   Let&#x27;s sell the world model and then let&#x27;s unroll in that simulator.
  &lt;/p&gt;
  &lt;p&gt;
   And then the challenge becomes like, who do you unroll in that simulator?
  &lt;/p&gt;
  &lt;p&gt;
   Now your world model has a build into itself, a model of the other agents, right?
  &lt;/p&gt;
  &lt;p&gt;
   If you kind of take the single agent perspective, I&#x27;m going to unroll world model.
  &lt;/p&gt;
  &lt;p&gt;
   I&#x27;m going to place a car inside of it.
  &lt;/p&gt;
  &lt;p&gt;
   And that&#x27;s the car I&#x27;m going to train with RL.
  &lt;/p&gt;
  &lt;p&gt;
   And now what happens.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:33:40]: This was a big problem for self-driving because you have like a dynamic number of, um, objects in the scene that you&#x27;re supposed to reason about with your world model.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   How does the policy that you train handle this kind of agents coming in and out?
  &lt;/p&gt;
  &lt;p&gt;
   Now, is it all just that you have some, like, are you identifying entities as nearby as other cars are nearby or is there some abstraction or is that the perception stack handles that?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:34:04]: Yeah, exactly.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   We roughly simulate a sensor in the sense that you only see cars in some radius of yourself.
  &lt;/p&gt;
  &lt;p&gt;
   Um, but, but we don&#x27;t, we don&#x27;t, yeah.
  &lt;/p&gt;
  &lt;p&gt;
   I mean, all the cars are there persistently in the simulator driving around and we, we answered this riddle of like, what should the other cars do by like their self-play, right?
  &lt;/p&gt;
  &lt;p&gt;
   They&#x27;re a copy of your policy.
  &lt;/p&gt;
  &lt;p&gt;
   They&#x27;re driving around.
  &lt;/p&gt;
  &lt;p&gt;
   Um, whereas I don&#x27;t know what happens in the world model, right?
  &lt;/p&gt;
  &lt;p&gt;
   Like kind of in this like world model approach, you&#x27;re limited by how capable the world model is at simulating the behavior of other actors.
  &lt;/p&gt;
  &lt;p&gt;
   And if your world model has actually learned a robust model of human driving for all the other agents in the simulator, then like, you don&#x27;t even need, you don&#x27;t really need, you need to do RL because like the world model already has a model of how humans should behave in a simulator at human level, but they don&#x27;t.
  &lt;/p&gt;
  &lt;p&gt;
   Um, so yeah.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:34:53]: And it&#x27;s just like, it&#x27;s just, it&#x27;s, it&#x27;s so funny that it just feels like they haven&#x27;t.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And the only way that Waymo et cetera has gotten it, it seems like Waymo has adapted a autonomous stack with like some human inspiration to make the driver more smooth is what it seems like when you&#x27;re in it, which is like extremely, really strong perception and world understanding with some really clever policy that is tuned to feel human, but probably not human or RL at the bottom of the day.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:35:27]: I wonder, I don&#x27;t know what Waymo&#x27;s planning stack actually looks like in the end, right?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Like Waymo&#x27;s pretty secretive and, uh, I&#x27;ve never worked there.
  &lt;/p&gt;
  &lt;p&gt;
   Um, and if I had worked there, I wouldn&#x27;t be able to say.
  &lt;/p&gt;
  &lt;p&gt;
   Um, but you know, I think, I think, you know, if I had to make a bet, it&#x27;s some, some kind of like hand designed cost, um, like mixing a bunch of terms together about like what a good trajectory looks like, maybe mixing with a little bit of human data to like, to make that trajectory feel like a little smooth in human life.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:35:59]: And yeah, to prompt you, um, what does your, yeah, I agree with this.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   What does your history of being a nerd on urban plan and planning make you think of what is coming for self-driving cars?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:36:12]: So, so I guess the thing to mention is I&#x27;m a professor of transportation engineering, uh, among other things.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So I have, I have, um, required to have some thoughts on this.
  &lt;/p&gt;
  &lt;p&gt;
   Um, I think that, you know, self-driving cars are, are coming.
  &lt;/p&gt;
  &lt;p&gt;
   Um, I don&#x27;t know if they&#x27;re, they&#x27;re coming a year from now to who knows when the cost curve gets driven down.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:36:32]: Where we live, they&#x27;re more likely to come sooner given tech hubs and, um, people are willing to pay very high premiums.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:36:39]: That&#x27;s true.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So like, like a lot of goods, they may come for, for wealthy folks first.
  &lt;/p&gt;
  &lt;p&gt;
   And then that allows the cost scaling to come down over time.
  &lt;/p&gt;
  &lt;p&gt;
   Um, and it really is a magical experience to take away Mo, right?
  &lt;/p&gt;
  &lt;p&gt;
   Like I remember the first day I saw like the cars driving around and nobody in it.
  &lt;/p&gt;
  &lt;p&gt;
   And I actually just started chasing one of the cars cause I was so like, it was such a magical moment.
  &lt;/p&gt;
  &lt;p&gt;
   I needed to, I needed to experience it for as long as possible.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:37:04]: Um, yeah, my first time was in Scottsdale, Arizona for one of my best friend&#x27;s bachelor parties.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   He&#x27;s also an engineer.
  &lt;/p&gt;
  &lt;p&gt;
   And we saw one driving with no person.
  &lt;/p&gt;
  &lt;p&gt;
   And I was like, I wonder if we could take one.
  &lt;/p&gt;
  &lt;p&gt;
   And I immediately download the app.
  &lt;/p&gt;
  &lt;p&gt;
   And because it&#x27;s in the middle of nowhere, they&#x27;re testing zone.
  &lt;/p&gt;
  &lt;p&gt;
   They have tons of supply and no demand.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:37:20]: So we were just immediately able to drive one around.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I actually sat in an airport for three hours in, in Phoenix while my phone upgraded to the newest OS so that I could like download the app and take away Mo for the first time there.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:37:36]: Uh, yeah, it&#x27;s, this is totally reasonable behavior for anybody listening and you should update your prior.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   If you don&#x27;t think it&#x27;s reasonable, it&#x27;s totally reasonable.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:37:44]: It&#x27;s a totally normal thing to do.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Um, but I think, so I think in cities, like.
  &lt;/p&gt;
  &lt;p&gt;
   Um, so I think that it&#x27;s, it&#x27;s still going to be a long time before these things are rolled out at scale.
  &lt;/p&gt;
  &lt;p&gt;
   Um, so just because costs, safety, how long does it take you to verify that it&#x27;s safe to drive in a new city?
  &lt;/p&gt;
  &lt;p&gt;
   I mean, okay, let&#x27;s put Tesla aside.
  &lt;/p&gt;
  &lt;p&gt;
   I don&#x27;t, I don&#x27;t talk about it.
  &lt;/p&gt;
  &lt;p&gt;
   I don&#x27;t really know how to think about that.
  &lt;/p&gt;
  &lt;p&gt;
   Um, but that&#x27;s how I feel too.
  &lt;/p&gt;
  &lt;p&gt;
   Um, there&#x27;s, you know, there, there&#x27;s parts of the United States that are due to state dependence, like very spread out, right?
  &lt;/p&gt;
  &lt;p&gt;
   Like because of like suburbization, like, I don&#x27;t know if that&#x27;s a word, it&#x27;s the word I use.
  &lt;/p&gt;
  &lt;p&gt;
   Um, like they&#x27;re, they&#x27;re very spatially spread out.
  &lt;/p&gt;
  &lt;p&gt;
   Like in my, my grandpa&#x27;s hometown or where my grandpa lives, uh, there&#x27;s no public transit.
  &lt;/p&gt;
  &lt;p&gt;
   There&#x27;s no way to get by without a car.
  &lt;/p&gt;
  &lt;p&gt;
   Public transit isn&#x27;t viable because of the way people are distributed.
  &lt;/p&gt;
  &lt;p&gt;
   So if those systems like those continue to exist, like, you know, people will continue to drive there.
  &lt;/p&gt;
  &lt;p&gt;
   And over time, those things will be replaced by, by, by a few self-driving cars.
  &lt;/p&gt;
  &lt;p&gt;
   Um, you know, uh, as a public transit advocate, I would still say that I think within cities, it is significantly more efficient to like fund buses and subways and things like that.
  &lt;/p&gt;
  &lt;p&gt;
   Um, but you know, there&#x27;s, there&#x27;s parts of the U S that are just like, so set up and I expect self-driving cars to be part of that.
  &lt;/p&gt;
  &lt;p&gt;
   Uh, yeah.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:39:15]: I mean, this isn&#x27;t, this isn&#x27;t a hot take.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I think you&#x27;re just kind of like a realistic and you don&#x27;t have a crazy worldview about it.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:39:22]: Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I mean, I have, I have my, you know, real deep love for public transit and like a desire for more people to experience it than just the people who live in New York city, where I think New York sees like 50% of all public transit areas in the U S.
  &lt;/p&gt;
  &lt;p&gt;
   Um, uh, but you know, the system is what the system is right now.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:39:41]: Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Okay.
  &lt;/p&gt;
  &lt;p&gt;
   Um, let&#x27;s pivot from self-driving land where we&#x27;ve had this self-play RL and try to draw some analogies to the other RL breakthroughs that aren&#x27;t language models that have been happening.
  &lt;/p&gt;
  &lt;p&gt;
   I think the one that everybody should know about or in many people do is this, um, locomotion and or sim to real with robotics with humanoids, quadrupeds.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:40:07]: Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:40:07]: If you look at it, it is definitely directionally similar to what is this self-play thing is.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I think that it&#x27;s hard for people who haven&#x27;t been in RL to understand the grandness of this transition from one agent locomotion to many agents doing something in a cooperative or competitive game with these same mechanisms.
  &lt;/p&gt;
  &lt;p&gt;
   I feel like even talking to you, I don&#x27;t think we&#x27;ve done a good job grasping just that enormity.
  &lt;/p&gt;
  &lt;p&gt;
   Like multi-agent is just historically so much more complex.
  &lt;/p&gt;
  &lt;p&gt;
   I don&#x27;t know if there&#x27;s anything about something like Dota five and how that, I wish I knew more lore of how that happened and it didn&#x27;t continue because I feel like it could be a good example of why this is actually so much harder than even something like AlphaGo, which is just one policy and these robotics things we&#x27;re going to talk about, which are one, like it is all still one policy, but just like one thing in the world.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:41:07]: So let me, let me give it another try because I think I also haven&#x27;t done the greatest job describing it.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So like in something like Dota or Go, there is in fact a notion of like a best way to play.
  &lt;/p&gt;
  &lt;p&gt;
   It&#x27;s, you know, it&#x27;s, it&#x27;s, well, it&#x27;s, it&#x27;s, it&#x27;s like an ash equilibrium.
  &lt;/p&gt;
  &lt;p&gt;
   It&#x27;s like, you can&#x27;t do better than that.
  &lt;/p&gt;
  &lt;p&gt;
   If you play it, nobody can beat you.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:41:27]: Have we arrived at that at Go?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I don&#x27;t think like, have we actually arrived at these at chess and Go because the ELO scores are still going up.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:41:33]: No, we haven&#x27;t.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:41:34]: But like conceivably there is a max.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:41:37]: There is a max.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   You&#x27;re, you&#x27;re never going to get it.
  &lt;/p&gt;
  &lt;p&gt;
   It&#x27;s like the game&#x27;s too big, but there is a best way to play.
  &lt;/p&gt;
  &lt;p&gt;
   And then in every domain where there&#x27;s a human in the loop, there&#x27;s not an obvious best way to play it.
  &lt;/p&gt;
  &lt;p&gt;
   And so the challenge has always been like, you know, if I run self-play, it&#x27;s going to converge to some behavior.
  &lt;/p&gt;
  &lt;p&gt;
   And that behavior is not necessarily something that can drive with, with humans in the loop.
  &lt;/p&gt;
  &lt;p&gt;
   Like, you know, it&#x27;ll learn something like you could imagine, for example, like you do a bunch of self-play and the cars learn that they can tell their partner where they want to go by hitting the blinkers left, left, right, right, left, left.
  &lt;/p&gt;
  &lt;p&gt;
   That means like, I&#x27;m taking a left turn and I&#x27;m going to go at 25 miles per hour.
  &lt;/p&gt;
  &lt;p&gt;
   And so there&#x27;s this idea that like, there&#x27;s all these policies that you wouldn&#x27;t want to play and don&#x27;t make any sense.
  &lt;/p&gt;
  &lt;p&gt;
   And kind of what we show in this paper is that if you do a little bit of reward design and you really scale up RL, then like the simple fact of like having, being uncertain about where everybody wants to go and having to be very robust to collisions constrains your behavior in such a way that you like broadly learn how to drive well.
  &lt;/p&gt;
  &lt;p&gt;
   Um, and, and I think this is transferable to other domains where, you know, you want some kind of base policy that roughly knows how to do the task well over some unknown distribution of partners.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:43:02]: How easy do you think it would be to learn in the same simulator?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   If all the other cars were controlled by this policy, if you only had to learn for one policy, how much easier is it to learn just one policy that kind of works in the world rather than this multi-agent and everybody is learning at one setup?
  &lt;/p&gt;
  &lt;p&gt;
   Because this is essentially what people have done is like, we&#x27;ve learned how to control one robot in the world and do that super well versus learning everything from scratch with multiple is well harder.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:43:30]: And I, I think if imagine, if you imagine that, okay, we have N cars and N minus one of them are controlled by a perfect model of human driving, right?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Like, I think that you could learn that super fast and really robustly.
  &lt;/p&gt;
  &lt;p&gt;
   Um, and of course the problem is we don&#x27;t have that one perfect model of human driving that we can plug into our simulator.
  &lt;/p&gt;
  &lt;p&gt;
   I don&#x27;t think you would, it would take, you know, the trillion samples that it took us.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:43:54]: So, so I think this, yeah, so that&#x27;s the difference.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And that&#x27;s what these other things and that&#x27;s like quadruped for robotics to have, let me just let you talk about it.
  &lt;/p&gt;
  &lt;p&gt;
   Where do you think this sim to real robots and single agent is at and heading?
  &lt;/p&gt;
  &lt;p&gt;
   So like, what do you see in the, and being more, slightly more plugged into the academic RL side of things?
  &lt;/p&gt;
  &lt;p&gt;
   So, so it&#x27;s like 2021 and 2022 is when these Marco Hutter group papers started.
  &lt;/p&gt;
  &lt;p&gt;
   And I&#x27;m sure the trend is still content, continuing.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:44:23]: It&#x27;s still continuing, right?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Like for quadrupeds, we, we, there, people are regularly making them do these insane behaviors that we, we haven&#x27;t been able to design in other ways.
  &lt;/p&gt;
  &lt;p&gt;
   And I think the real, the lesson there is like at scale RL works.
  &lt;/p&gt;
  &lt;p&gt;
   Like a lot of the lessons of like self-supervised learning are transferable to the RL side.
  &lt;/p&gt;
  &lt;p&gt;
   Um, and while it would be great to get the sample complexity down and stop doing this with like a trillion samples, you know, if you&#x27;re willing to bite that bullet and just scale, um, and you, you have, you know, kind of a, a fairly good simulator, um, you know, you can, you can, you can really do incredible things.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:45:00]: Um, do you think these RL results scale more with model size or sample complexity?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Do you think that they&#x27;re kind of brute forcing it through many more inter scaling the interactions with the world?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:45:10]: Yeah, uh, I think that they scale, um, scaling with model size is like a little iffy in, in, in, in RL.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Um, there, there are tricks that people have been coming up with to let you use bigger and bigger models.
  &lt;/p&gt;
  &lt;p&gt;
   But right now I think a lot of the, the impetus is towards smaller models that like have low inference costs, um, that let you like force a trillion samples into the policy, right?
  &lt;/p&gt;
  &lt;p&gt;
   Whereas if you make the model bigger, inference cost becomes more of a thing.
  &lt;/p&gt;
  &lt;p&gt;
   I think it&#x27;s harder to acquire the samples.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:45:38]: Um, so I think, I think this relates to, I think the other area that I&#x27;m excited about in RL is this like procedural generation and open-endedness.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Do you think this kind of, I see needing to see a ton of samples as being in spirit related to this where open-endedness is, I think a field of study designed to make agents that are good at collecting the right samples and in using the word explore, which we haven&#x27;t really used.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:46:07]: Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So I think a lot of, a lot of what we&#x27;re doing here is actually kind of dodging the exploration problem in a lot of ways.
  &lt;/p&gt;
  &lt;p&gt;
   Um, and in general, this is something that like the RL that works is a lot about dodging the exploration problem, right?
  &lt;/p&gt;
  &lt;p&gt;
   Why do we need a trillion samples?
  &lt;/p&gt;
  &lt;p&gt;
   Because we explore very inefficiently.
  &lt;/p&gt;
  &lt;p&gt;
   Um, if we, you know, the, the kind of, this is, I think what we have, if we talk about the quadrupeds and things like that, right?
  &lt;/p&gt;
  &lt;p&gt;
   Like these are well-defined tasks with a well-understood reward function.
  &lt;/p&gt;
  &lt;p&gt;
   Um, and this, you know, at some point as we started to scale up RL, this, this, this task design will become the bottom, right?
  &lt;/p&gt;
  &lt;p&gt;
   It&#x27;s like, uh, what tasks should the agent do?
  &lt;/p&gt;
  &lt;p&gt;
   There&#x27;s a human in the loop sitting down writing the reward function saying, okay, that&#x27;s a good task.
  &lt;/p&gt;
  &lt;p&gt;
   This is a good task.
  &lt;/p&gt;
  &lt;p&gt;
   The kind of the dream of open-endedness is that we&#x27;ll move away from this and towards kind of just taking the human, this task designer out of the loop.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:47:00]: Let&#x27;s start taking a step back.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Are there tasks that you think are heavily simulated in control domains that are actually well-suited to this RL approach that may have not been done yet?
  &lt;/p&gt;
  &lt;p&gt;
   I mean, simulation is like a core tool in robotics and autonomy.
  &lt;/p&gt;
  &lt;p&gt;
   So what other things are doing heavy simulation and not leveraging this?
  &lt;/p&gt;
  &lt;p&gt;
   Maybe even like hard sciences are doing this.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:47:19]: I think this is going to eat almost everything that can be simulated.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Uh, well, so like the fundamental thing is like, can you simulate it with a relatively small sim to real gap and can you simulate it efficiently?
  &lt;/p&gt;
  &lt;p&gt;
   Um, and if you have both of those things, like I think RL is going to eat all of those things.
  &lt;/p&gt;
  &lt;p&gt;
   Um, so, and, and, or you can also scale this up by like, you know, uh, paying the price.
  &lt;/p&gt;
  &lt;p&gt;
   So if you can, uh, for example, like I expect like formal verification, like agents that like, uh, write lean proofs to do really well.
  &lt;/p&gt;
  &lt;p&gt;
   Um, you know, any there it&#x27;s expensive because the simulator is slow, but there&#x27;s no sim to real gap.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:47:57]: Um, I&#x27;m thinking in the, like this scientific in control domain.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I think one of them is, I mean, a timely example is humanoids, which I&#x27;m very, um, I&#x27;ve been consistently bearish on them.
  &lt;/p&gt;
  &lt;p&gt;
   I think if you have the simulator, the control policy will be solved, but I think most of it is an environment problem where the robotic actuators are too strong.
  &lt;/p&gt;
  &lt;p&gt;
   So therefore they&#x27;re limited to manufacturing.
  &lt;/p&gt;
  &lt;p&gt;
   And I don&#x27;t necessarily know how much a humanoid, um, is better than the static arm in manufacturing and logistics.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:48:29]: So I might be bearish on humanoids for similar reasons, but like, you&#x27;re, I guess you&#x27;re right on the point.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I think like, will we think, will we be able to make a humanoid follow whatever trajectory we would like it to follow through scaling up RL?
  &lt;/p&gt;
  &lt;p&gt;
   Yeah, I think so.
  &lt;/p&gt;
  &lt;p&gt;
   Like, but then the question becomes like, what trajectory should it follow?
  &lt;/p&gt;
  &lt;p&gt;
   And then that&#x27;s where things get iffy again, right?
  &lt;/p&gt;
  &lt;p&gt;
   Like exactly, you know, how, how softly should it behave?
  &lt;/p&gt;
  &lt;p&gt;
   You know, how, stuff like that, like task planning, things like that.
  &lt;/p&gt;
  &lt;p&gt;
   But, but from the, like the controls perspective of like, here&#x27;s a system, I want it to follow this trajectory.
  &lt;/p&gt;
  &lt;p&gt;
   Um, most of these things have like good fast simulators.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:49:10]: Um, do you think RL should be used more in AI for science than scaling deep learning?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So I&#x27;m guessing there are a lot of scientific domains that are very simulation intensive.
  &lt;/p&gt;
  &lt;p&gt;
   And a lot of the approaches and excitement right now is to train a deep learning model to predict data.
  &lt;/p&gt;
  &lt;p&gt;
   I think there&#x27;s Evo2, which is a recent DNA sequence predictor.
  &lt;/p&gt;
  &lt;p&gt;
   And I was reading a lot about this.
  &lt;/p&gt;
  &lt;p&gt;
   And a lot of the criticism is like, we don&#x27;t really know how to use it.
  &lt;/p&gt;
  &lt;p&gt;
   And the mechanism is if, if the model is like, oh, I don&#x27;t know about this DNA string, and then like, maybe it&#x27;s a mutation.
  &lt;/p&gt;
  &lt;p&gt;
   And there&#x27;s a lot of weirdness like that.
  &lt;/p&gt;
  &lt;p&gt;
   Yeah.
  &lt;/p&gt;
  &lt;p&gt;
   But maybe it&#x27;s still that just this slow burn of scaling RL systems has a, at least like a more direct way that can potentially improve some domains.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:49:54]: Great question.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Um, super interesting question.
  &lt;/p&gt;
  &lt;p&gt;
   Um, so I think that the story I&#x27;ve been telling you about like sample inefficient RL scaling really well, I think we, we understand that pretty well.
  &lt;/p&gt;
  &lt;p&gt;
   And less, less clear on the sample in RL in like limited sample domains.
  &lt;/p&gt;
  &lt;p&gt;
   And I think a lot of the thing in deep learning for science that the simulators themselves are quite slow.
  &lt;/p&gt;
  &lt;p&gt;
   Um, so like if you want to simulate, say like a fusion, like loop, um, honest, like, like a tokamak of some kind, um, it can take actually months to run a single simulation.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:50:28]: Um, then what do you think of the deep, you brought this up?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   What do you think of the deep line nuclear fusion control paper then?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:50:34]: Uh, they might&#x27;ve been doing a slightly different simulator.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   It&#x27;s a different simulator.
  &lt;/p&gt;
  &lt;p&gt;
   It&#x27;s not as it doesn&#x27;t, it&#x27;s, I don&#x27;t think it requires quite as much, much precision.
  &lt;/p&gt;
  &lt;p&gt;
   Um, I&#x27;m thinking of other, other, other simulators, um, to be clear, I haven&#x27;t read that paper super closely, but if you think about something like AI for materials or AI for bio, like a lot of these are fairly slow simulation platforms.
  &lt;/p&gt;
  &lt;p&gt;
   What I do think is pretty exciting is I think at some point somebody is going to, and there are a lot of bottlenecks to this, like someone&#x27;s going to build like a, an autonomous lab and just like keep letting it loop forwards and characterizing some material and then like running it through the loop again.
  &lt;/p&gt;
  &lt;p&gt;
   The problem there is actually this like characterization step doing it correctly is really hard.
  &lt;/p&gt;
  &lt;p&gt;
   Um, like, you know, what are the properties of the material that I&#x27;ve just synthesized?
  &lt;/p&gt;
  &lt;p&gt;
   Um, but, but, you know, so, so I think that in terms of RL for science, I think that trajectory is a little trickier because of this like kind of low ability to acquire samples.
  &lt;/p&gt;
  &lt;p&gt;
   Whereas in the humanoid and the quadruped domain, we can generate just, you know, people they&#x27;ll simulate like 2000 humanoids at once on one GPU or something silly like that.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:51:41]: Um, do you think these things scale nicely with action space?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I feel like if we want to do this open-ended learning in a lot of environments, I don&#x27;t know how to constrain the action space in a nice way.
  &lt;/p&gt;
  &lt;p&gt;
   So that somewhat worries me.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:51:55]: So I think there&#x27;s a couple of pieces of that.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So I think LLM sometimes give you pretty good priors over actions, right?
  &lt;/p&gt;
  &lt;p&gt;
   That&#x27;s the thing we&#x27;ve been pretty consistently seeing is that they constrain the action space on their own in a, in a really helpful way.
  &lt;/p&gt;
  &lt;p&gt;
   Um, it is also the case that with like much larger action spaces, you just eat a sample complexity penalty and like things take longer, but we&#x27;re seeing it be fine.
  &lt;/p&gt;
  &lt;p&gt;
   You know, kind of in the domain of like 500 actions, this kind of thing.
  &lt;/p&gt;
  &lt;p&gt;
   Now, if we all of a sudden go out to like 5 million actions, I think all bets are off.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:52:26]: Um, it does kind of seem like they might have the same thing that happened with language models is that open-endedness.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Now all the agents are going like pointing out a language model or some general interface, like a computer interface that ends up concerning action space to keyboard mouse inputs, which order of magnitude wise is actually the same in action space.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:52:49]: I think, I think there are a lot going to be a lot of helpful constraints on the action space to let you, you know, deal, deal with this problem, right?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   You know, you&#x27;re not operating in totally open-ended language or open-ended use of a computer.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:53:04]: To recap some of this, just because it&#x27;s interesting is this self, it&#x27;s like the self-play question is, is the hardest, is the hardest one to grok, which is really just that, uh, honestly, I still don&#x27;t even fully understand it.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And I will listen to some of these things, but it&#x27;s just like the scaling in sample time is the biggest, is the thing that makes RL actually work is that we can scale in samples.
  &lt;/p&gt;
  &lt;p&gt;
   And that is the thing that&#x27;s needed for most of these domains.
  &lt;/p&gt;
  &lt;p&gt;
   And it&#x27;s very different than what&#x27;s happening in language models, but it&#x27;s at least a consistent theme across what is now over like five years of like resurgent RL for control results.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:53:41]: Scaling works in RL, right?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   There&#x27;s, there&#x27;s like no, no real wall here.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:53:46]: It&#x27;s a different type of scaling than people expect.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I think a lot of the historical scaling papers were trying to scale parameters and looking at something like deep, um, what is dreamer V3 or whatever, and scaling the parameters of the policy with the number of environment interactions.
  &lt;/p&gt;
  &lt;p&gt;
   But it seems like that is just like, it&#x27;s actually just different axes to what is thought of in traditional deep learning scaling.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:54:07]: It&#x27;s, it&#x27;s kind of the number of samples that you&#x27;re getting.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:54:10]: Which is very good to say clearly.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And then the, um, the self-play thing is changing the domain to be one that is much more complicated.
  &lt;/p&gt;
  &lt;p&gt;
   And the fact that it can still work there opens up a lot of interesting questions.
  &lt;/p&gt;
  &lt;p&gt;
   So like the scaling thing is an independent axis that actually works.
  &lt;/p&gt;
  &lt;p&gt;
   And then the self-play thing is dramatically increasing the complexity of your problem from this single agent world.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:54:34]: It&#x27;s adding a lot of like diversity through, you know, there being other agents in the system that behaving in unexpected ways.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Um, so yeah, there&#x27;s like scaling up the sample complexity.
  &lt;/p&gt;
  &lt;p&gt;
   There&#x27;s scaling up in diversity of your simulator and in the single agent domains, you don&#x27;t need to scale up the diversity of your simulator.
  &lt;/p&gt;
  &lt;p&gt;
   You have one task you want to do it.
  &lt;/p&gt;
  &lt;p&gt;
   Um, but yeah, yeah, that makes sense.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:54:55]: Okay.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I&#x27;m pretty, that&#x27;s, these are interesting takeaways to kind of reflect on what they mean, um, to kind of go towards wrapping this up or go into language model corner and then grad school advice corner.
  &lt;/p&gt;
  &lt;p&gt;
   You had a paper that you, um, you were on a paper as an advisor of large language models are in context, preference learners.
  &lt;/p&gt;
  &lt;p&gt;
   What, what is this story here?
  &lt;/p&gt;
  &lt;p&gt;
   I think I&#x27;ve been preference learning is openly out of vogue, but I think that&#x27;s because people are short-sighted and AI is so easy dominated where it&#x27;s like, everyone is still actually doing preference tuning, but everyone&#x27;s just talking about like RL and verifiable domains
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:55:31]: or whatever, whatever the hype is that I, yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:55:34]: But like, what is your take on this preference learning thing?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And I know you have big self-play and RL background here.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:55:42]: YSo I&#x27;ll tell you, I&#x27;ll tell you how we got here real quick and it&#x27;ll, it&#x27;ll make clear and I should say that there&#x27;s coincident work by Jaden Clark, Joey, I&#x27;m going to mispronounce his name, Hedgna and Dorsa at Stanford.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Um, that kind of got the same idea across at the same time.
  &lt;/p&gt;
  &lt;p&gt;
   And the idea is that if you want to do preference learning, right.
  &lt;/p&gt;
  &lt;p&gt;
   And you&#x27;re doing preference learning, you&#x27;re doing like RLHF from scratch or something.
  &lt;/p&gt;
  &lt;p&gt;
   You have to learn this reward function.
  &lt;/p&gt;
  &lt;p&gt;
   And you have to acquire a lot of samples to do it, to do so.
  &lt;/p&gt;
  &lt;p&gt;
   Um, and you know, the tabula rasa version of this is really inefficient.
  &lt;/p&gt;
  &lt;p&gt;
   And it turns out that what you can do is if you have a particular like description of a task you&#x27;d like to do, you can ask a language model, like write me a set of reward functions that I think correspond to this task, right?
  &lt;/p&gt;
  &lt;p&gt;
   You&#x27;ll take those reward functions.
  &lt;/p&gt;
  &lt;p&gt;
   You&#x27;ll train an agent corresponding to those reward functions.
  &lt;/p&gt;
  &lt;p&gt;
   You&#x27;ll have a human rank, um, their preferences over those reward functions.
  &lt;/p&gt;
  &lt;p&gt;
   Like this was a good one.
  &lt;/p&gt;
  &lt;p&gt;
   That was a bad one.
  &lt;/p&gt;
  &lt;p&gt;
   And you&#x27;ll feed all of that to a language model again, and do another loop of asking it to write some reward functions, given these preferences.
  &lt;/p&gt;
  &lt;p&gt;
   And it turns out that language models can take that information and use it to decide what a good next reward function to try out is.
  &lt;/p&gt;
  &lt;p&gt;
   And over time, you&#x27;re going to get a reward function that is much more aligned with your preferences just by having the language models actually write the rewards.
  &lt;/p&gt;
  &lt;p&gt;
   And so this is like, you know, kind of letting you do like personalization or reward tuning in like 50 human queries kind of scale.
  &lt;/p&gt;
  &lt;p&gt;
   So like this kind of came about because we want, we were asking like, if I wanted to build an agent that like acts scared or is deceptive, right?
  &lt;/p&gt;
  &lt;p&gt;
   Like I kind of have to do some amount of preference learning, right?
  &lt;/p&gt;
  &lt;p&gt;
   Like is deceptive is the thing that&#x27;s defined with respect to humans.
  &lt;/p&gt;
  &lt;p&gt;
   Um, and so, you know, we&#x27;re trying to figure out how to do something like that sample efficiently.
  &lt;/p&gt;
  &lt;p&gt;
   It turns out you can just ask an LLM, write a reward function that corresponds to being deceptive and then like run that loop a bunch of times.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:57:35]: So I would say that this means that like language model personalization doesn&#x27;t need to be done within the parameter space or something like this.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Or like, imagine having the domain here is, yeah, the domain here is partially at least control looking at, looking at this figure, but it&#x27;s goes to show that they actually probably have the representation and it&#x27;s just a problem of setup and how do you get people to actually do this and stuff.
  &lt;/p&gt;
  &lt;p&gt;
   I&#x27;ve, I&#x27;ve said the same 20 questions saying, which is what if a language model and ask 20 questions about the user and get the information out of there.
  &lt;/p&gt;
  &lt;p&gt;
   So it&#x27;s nice to see that this might not be like, it&#x27;s not an actual technical limitation.
  &lt;/p&gt;
  &lt;p&gt;
   It&#x27;s just like, we don&#x27;t like, how the hell do you do that and chat or whatever.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:58:17]: We haven&#x27;t tested that particular case.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And I want to, I think it&#x27;s like a thing that might work.
  &lt;/p&gt;
  &lt;p&gt;
   Like our case, it was like, make a robot jump like a human, right?
  &lt;/p&gt;
  &lt;p&gt;
   Like write a reward function that corresponds to jumping like a human.
  &lt;/p&gt;
  &lt;p&gt;
   And it turns out like a couple of rounds of iteration, you can get a language model to write down a reward function.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:58:32]: Did the reward function make sense?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Like what the, what is the reward function for jumping like a human?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:58:37]: You know, it&#x27;s like, you know, make sure that you jump off both legs instead of hopping on one leg, you know, don&#x27;t flail your arms around too wildly, you know, that type of thing.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I think, I think the whole reward function is in the paper.
  &lt;/p&gt;
  &lt;p&gt;
   But yeah, you know, it&#x27;s got some interpretable terms, like the, the, the, the base reward function that comes out in the first iteration always involves hopping on one leg.
  &lt;/p&gt;
  &lt;p&gt;
   And then by the end, it&#x27;s, you know, two legs, not too much flailing.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:59:04]: There&#x27;s like a deeper RL control thing there, which is that all of the agents when they start are just wildly flailing when you learn control from scratch.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So that&#x27;s in many ways, not super surprising.
  &lt;/p&gt;
  &lt;p&gt;
   Um, do you have any comments on the general like language modeling RL stuff?
  &lt;/p&gt;
  &lt;p&gt;
   I think it&#x27;s so focused on, and part of the point of this is just like broaden the, broaden the lens by which people consider RL to be a thing.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [00:59:33]: I mean, the biggest thing I should say there is I think it&#x27;s going to work.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Like, I don&#x27;t think like for domains where you have verifiable rewards, like I just, I think this is going to work.
  &lt;/p&gt;
  &lt;p&gt;
   Just going to have to bite the bullet and, and, uh, generate a lot of samples.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:59:46]: Um, so, uh, it&#x27;s interesting that you say that because one of the biggest things we find is you just have to keep training, right?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So I mean, it&#x27;s a classic RL curve.
  &lt;/p&gt;
  &lt;p&gt;
   So you start out, it&#x27;s a log, it&#x27;s like a really, it&#x27;s like, you start out really fast and then you&#x27;re just on this plateau of just, you&#x27;re getting a little bit more for a really long time.
  &lt;/p&gt;
  &lt;p&gt;
   And it&#x27;s much far fewer samples and pre-training and everything, but it is, the learning curves look so similar to anything you would get in RL and you can have crashes and stuff, which is such a throwback.
  &lt;/p&gt;
  &lt;p&gt;
   And it&#x27;s very different than preference tuning, which you have this whole over-optimization thing and stuff like this, where it&#x27;s just so much less artful.
  &lt;/p&gt;
  &lt;p&gt;
   It&#x27;s like, just so obvious.
  &lt;/p&gt;
  &lt;p&gt;
   It&#x27;s like, if the number&#x27;s going up, it&#x27;s probably fine.
  &lt;/p&gt;
  &lt;p&gt;
   And you don&#x27;t really have to do that much.
  &lt;/p&gt;
  &lt;p&gt;
   It&#x27;s nice, right?
  &lt;/p&gt;
  &lt;p&gt;
   There&#x27;s a number.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [01:00:32]: There&#x27;s a, there&#x27;s a number.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   You just have to push that number up.
  &lt;/p&gt;
  &lt;p&gt;
   Life is great.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [01:00:36]: Last, last section is career corner.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   What do you think people are interested in working on an RL right now?
  &lt;/p&gt;
  &lt;p&gt;
   What do you say to them?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [01:00:46]: I mean, I think, I think RL is just starting to eat different domains.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So like, I think this is a really good time to get started on it.
  &lt;/p&gt;
  &lt;p&gt;
   You know, there, there are not enough strong RL researchers, surprisingly.
  &lt;/p&gt;
  &lt;p&gt;
   So like, I don&#x27;t think we&#x27;re like an, even an oversaturated domain.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [01:01:07]: Do you think it&#x27;s feasible for grad students to do this language model stuff and core like RL agent stuff?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Because the agent stuff feels like more of a long-term moat because you&#x27;re doing something that fewer people know about.
  &lt;/p&gt;
  &lt;p&gt;
   But should people like fully ignore the language model stuff if they&#x27;re trying to get established as a grad student?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [01:01:24]: I think that you should like, this is an important academic thing is like, you need to focus on demonstrating the idea with as minimal, as few barriers as possible to it, right?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So you want to pull out the minimum version of the demonstration.
  &lt;/p&gt;
  &lt;p&gt;
   And a lot of the time putting a language model in there is adding a huge bottleneck, right?
  &lt;/p&gt;
  &lt;p&gt;
   All of a sudden you need a bunch to use, training takes forever.
  &lt;/p&gt;
  &lt;p&gt;
   So, I mean, you should probably do some language modeling things at some point because like, it&#x27;s a good skill to have demonstrated when you go on the job market.
  &lt;/p&gt;
  &lt;p&gt;
   So I think a lot of students will do is they&#x27;ll do that in their last year or two of grad school, just to show that they kind of know, can&#x27;t, can do this.
  &lt;/p&gt;
  &lt;p&gt;
   But like for demonstrating the core ideas, I don&#x27;t think, I don&#x27;t think you always have to use the language model there unless your ideas are deeply tied to that domain.
  &lt;/p&gt;
  &lt;p&gt;
   Yeah.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [01:02:14]: The way that by which things scale and results are communicated is just really different in the RL for domain or the core RL algorithm or the language model plus RL thing, which I think is sequencing probably can be the best bet, which is like starting with something less competitive and focusing on skill development, which is generally my biggest, should I do a PhD answer is if you&#x27;re invested in developing new skills or you are a person that&#x27;s like actually extremely academic and scientific in nature, which there are a subset of people
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   that are just truly like scientists in the nature of the word and they will probably thrive emotionally in that situation.
  &lt;/p&gt;
  &lt;p&gt;
   But most people want to do an AI PhD because they think of it as a credential for a future job, which is generally a hilarious and ill-formed side effect of wherever the field is right now.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [01:03:03]: It&#x27;s just such a bad idea.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   There&#x27;s one brief moment in history where a PhD was like a definitive route to a, like a high paying job, right?
  &lt;/p&gt;
  &lt;p&gt;
   Generally what a PhD is supposed to do is it&#x27;s like, Hey, it should be fun.
  &lt;/p&gt;
  &lt;p&gt;
   It should be fascinating.
  &lt;/p&gt;
  &lt;p&gt;
   It should be like five years where you&#x27;re like, I could not imagine doing something cooler than what I&#x27;m doing right now.
  &lt;/p&gt;
  &lt;p&gt;
   And then it&#x27;s supposed to unlock some jobs that aren&#x27;t accessible to you otherwise.
  &lt;/p&gt;
  &lt;p&gt;
   Running a research team in industry, doing particular skills that, you know, using particular skills that are hard to develop unless someone gives you a year or two to focus on, right?
  &lt;/p&gt;
  &lt;p&gt;
   Like hard optimization problems, a lot of specialties.
  &lt;/p&gt;
  &lt;p&gt;
   But, you know, the like, I&#x27;m going to do a PhD.
  &lt;/p&gt;
  &lt;p&gt;
   That&#x27;s going to give me like a 500K total compensation job straight out of grad school.
  &lt;/p&gt;
  &lt;p&gt;
   It&#x27;s just like such a weird quirk of history that like optimizing for it is never a good idea.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [01:03:56]: Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And I think that kind of says if people are trying to be, or people are grad students or like junior faculty or junior grad students right now, I think if anything you&#x27;re optimizing for is trying to extract value from that quirk of history, you&#x27;re putting yourself in a precarious position.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [01:04:15]: Yeah, optimize for being able to do cool things, you know, that&#x27;s, that&#x27;s a consistent thing you can always optimize for.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   It doesn&#x27;t go away when the job market changes.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [01:04:29]: Yeah, I agree.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I mean, that could be a good place to end it.
  &lt;/p&gt;
  &lt;p&gt;
   You can do, you can actually surprisingly still just do things.
  &lt;/p&gt;
  &lt;p&gt;
   And yeah, I think it&#x27;s easy to lose track of that in the language modeling chaos.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [01:04:43]: Yeah, I mean, but look, also, I&#x27;m coming from a position of privilege, right?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Like I have a faculty position.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [01:04:48]: We&#x27;re early enough where it is fine.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [01:04:51]: Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Okay.
  &lt;/p&gt;
  &lt;p&gt;
   Well, you know, this has been a pleasure, you know, thank you for taking the time to chat with me and give me a chance to talk about this paper, which is, I think, still had some trouble conveying exactly why I think it&#x27;s so exciting.
  &lt;/p&gt;
  &lt;p&gt;
   But hopefully some of it got across.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [01:05:06]: I think we got to some clear things and the self-play being weird thing definitely gives me more sympathy to how bad the discussion around self-play for language models is, because there is very nuanced on why this, like what we&#x27;re doing with RL with verifiable rewards is very different than language models talking to themselves and both updating their policy.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And it&#x27;s not to say we shouldn&#x27;t be trying that, but we should be very wary in saying that is that until we are trying to do really, really hard things.
  &lt;/p&gt;
  &lt;p&gt;
   The grandioseness of language model self-play is probably like trying to let language models discover their own language to be more effective at tasks.
  &lt;/p&gt;
  &lt;p&gt;
   And they do this with interacting with each other.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [01:05:50]: And so, yeah, language model self-play for tasks they haven&#x27;t been trained on, like learning to do new tasks collaboratively together.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Super exciting.
  &lt;/p&gt;
  &lt;p&gt;
   It makes sense.
  &lt;/p&gt;
  &lt;p&gt;
   I&#x27;m doing some work on it.
  &lt;/p&gt;
  &lt;p&gt;
   I&#x27;m excited about that.
  &lt;/p&gt;
  &lt;p&gt;
   This thing where you, the amount of knowledge that they have is bounded and you do self-play to kind of refine the distribution that they&#x27;re playing over, as opposed to like doing a new task together, a little weirder, weirder stuff going on there.
  &lt;/p&gt;
  &lt;p&gt;
   Yeah.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [01:06:16]: Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   So I think it&#x27;s good.
  &lt;/p&gt;
  &lt;p&gt;
   I think people now know that this, the single agent RL stuff working is not surprising.
  &lt;/p&gt;
  &lt;p&gt;
   And the self-play area could be one of these like multi-year out before takeoff thing.
  &lt;/p&gt;
  &lt;p&gt;
   And there are early signs that it could actually work.
  &lt;/p&gt;
  &lt;p&gt;
   And that&#x27;s something that people are often looking for, which is what are the problems that there are a bit more risk on, but not complete risk and not the obvious thing that everybody is working on.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [01:06:41]: Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And I think if you&#x27;re thinking that category, collaborative agents, agents that know how to effectively collaborate with humans, with other AI agents, very underrated area, going to be big in a bit, I think.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [01:06:54]: I think the ones who are playing these models is what does it mean for multiple language models to be interacting on the web that have separate goals, but are going to interact with each other and it&#x27;s not necessarily the same self-play setup, but you could understand it with, through some of these lenses.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And it&#x27;s easy to see how this is going to come about with you when listening to the marketing from all these labs.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [01:07:17]: Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Well, it&#x27;s, yeah, it&#x27;s going to be fun.
  &lt;/p&gt;
  &lt;p&gt;
   It&#x27;s going to be weird.
  &lt;/p&gt;
  &lt;p&gt;
   It&#x27;s going to be great.
  &lt;/p&gt;
  &lt;p&gt;
   I also, I do have to inject a quick little pitch before I, before I disappear.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [01:07:28]: Sounds good.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [01:07:28]: Um, so, uh, I&#x27;ve joined, uh, like a new, like AI, uh, stealth AI company.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Um, we&#x27;re like working on, um, making better decisions in critical industries like healthcare, supply chain, defense.
  &lt;/p&gt;
  &lt;p&gt;
   So like in industries that are like not very tech forward, not very AI native, um, but like are where almost all productivity lies.
  &lt;/p&gt;
  &lt;p&gt;
   Um, and so, uh, we&#x27;re, uh, looking for strong folks with experience with either RL or LLMs.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [01:07:55]: Do you have a company name?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [01:07:56]: We do not.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [01:07:57]: Okay.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Well, we&#x27;ll have a link.
  &lt;/p&gt;
  &lt;p&gt;
   We&#x27;ll have a contact link below.
  &lt;/p&gt;
  &lt;p&gt;
   I think, yeah, Eugene is a fun person.
  &lt;/p&gt;
  &lt;p&gt;
   Um, so, and at least knows enough to make it through this conversation, which is, there are a lot of startups out there that are riding on less.
  &lt;/p&gt;
  &lt;p&gt;
   So that&#x27;s good.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [01:08:13]: Um, that&#x27;ll be fun.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   It&#x27;s, it&#x27;s, there aren&#x27;t, I don&#x27;t think there are that many applied RL teams out there in the world.
  &lt;/p&gt;
  &lt;p&gt;
   So maybe there are, and I just don&#x27;t know them, but I think like Mark Belmer&#x27;s startup is
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [01:08:24]: actually potentially related, which is seems like it&#x27;s kind of trying to scale.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   RL with the mix of language models to solve problems, but I haven&#x27;t asked him directly.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [01:08:33]: I mean, that&#x27;s somewhat of what we&#x27;re, what we&#x27;re doing, doing too.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Um, but, uh, that&#x27;s all I can say.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [01:08:42]: Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Sounds good.
  &lt;/p&gt;
  &lt;p&gt;
   It&#x27;s, it&#x27;s early days for, for that and self-play and many other things, but, um, I&#x27;m sure we&#x27;ll cross paths soon.
  &lt;/p&gt;
  &lt;p&gt;
   Either if I go back to New York or if you, for some reason, come all the way to Seattle, which I don&#x27;t know.
  &lt;/p&gt;
  &lt;p&gt;
   I love Seattle.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Eugene Vinitsky
   &lt;/strong&gt;
   &lt;span&gt;
    [01:08:58]: So yeah, I&#x27;ll love in the fall.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Um, anyways, yeah, uh, it was, it was a pleasure talking to you and hopefully, uh, you know, get a chance to talk again soon.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [01:09:08]: Yeah, we&#x27;ll do.
   &lt;/span&gt;
  &lt;/p&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Interviewing OLMo 2 leads: Open secrets of training language models </title>
<link>https://www.interconnects.ai/p/olmo-2-pod</link>
<pubDate>Wed, 22 Jan 2025 15:39:56 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   We&#x27;re here to share the story of building our Open Language Models (OLMos) and what we improved to build the OLMo 2 7B/13B model that is competitive with the Llama 3.1 8B model. This is all about building an effective, small language modeling team that can share all it learns with the scientific community. Dirk, Luca, and Kyle are some of the people I learn the most from and have more knowledge (and entertainment) to share than we have time.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;em&gt;
    &lt;span&gt;
     Some questions were
    &lt;/span&gt;
    &lt;a href=&quot;https://x.com/natolambert/status/1876309495472693741&quot; rel=&quot;&quot;&gt;
     pulled from Twitter
    &lt;/a&gt;
    &lt;span&gt;
     , but please comment or get in touch if you want us to cover anything in the future episode(s)!
    &lt;/span&gt;
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Main topics:
  &lt;/p&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     Pretraining efficiency and our quest for stability after a not-so-secret failed 70B run early in 2024,
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     What the role of OLMo is in the broader AI landscape and how that is, or is not, changing,
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Many little decisions that going into building language models and their teams (with a focus on NOT post-training, given I already talk about that a ton).
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;p&gt;
   &lt;span&gt;
    Play with the models we build here:
   &lt;/span&gt;
   &lt;a href=&quot;http://playground.allenai.org/&quot; rel=&quot;&quot;&gt;
    playground.allenai.org/
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    For more history of open language models (OLMos) on Interconnects, see my
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/olmo?utm_source=publication-search&quot; rel=&quot;&quot;&gt;
    first post on OLMo
   &lt;/a&gt;
   &lt;span&gt;
    , my coverage of
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/olmoe-and-building-better-llms?utm_source=publication-search&quot; rel=&quot;&quot;&gt;
    OLMoE
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/olmo-2-and-building-language-model-training?utm_source=publication-search&quot; rel=&quot;&quot;&gt;
    OLMo 2
   &lt;/a&gt;
   &lt;span&gt;
    , and
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/why-i-build-open-language-models?utm_source=publication-search&quot; rel=&quot;&quot;&gt;
    why I build open language models
   &lt;/a&gt;
   &lt;span&gt;
    . If you have more questions or requests, please let us know (especially the researchers out there) and this can be one of N, rather than a one off celebration.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Listen on
   &lt;/span&gt;
   &lt;a href=&quot;https://podcasts.apple.com/us/podcast/interconnects-audio/id1719552353&quot; rel=&quot;&quot;&gt;
    Apple Podcasts
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://open.spotify.com/show/2UE6s7wZC4kiXYOnWRuxGv&quot; rel=&quot;&quot;&gt;
    Spotify
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.youtube.com/@interconnects&quot; rel=&quot;&quot;&gt;
    YouTube
   &lt;/a&gt;
   &lt;span&gt;
    , and
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/podcast&quot; rel=&quot;&quot;&gt;
    where ever you get your podcasts
   &lt;/a&gt;
   &lt;span&gt;
    . For other Interconnects interviews,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/t/interviews&quot; rel=&quot;&quot;&gt;
    go here
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div data-attrs=&#x27;{&quot;videoId&quot;:&quot;dS7QI99uJVc&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}&#x27; data-component-name=&quot;Youtube2ToDOM&quot;&gt;
   &lt;div&gt;
    &lt;iframe allow=&quot;autoplay; fullscreen&quot; allowautoplay=&quot;true&quot; allowfullscreen=&quot;true&quot; frameborder=&quot;0&quot; gesture=&quot;media&quot; height=&quot;409&quot; loading=&quot;lazy&quot; src=&quot;https://www.youtube-nocookie.com/embed/dS7QI99uJVc?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0&quot; width=&quot;728&quot;&gt;
    &lt;/iframe&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;h3&gt;
   Contacts
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;span&gt;
    Dirk Groeneveld —
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/mechanicaldirk&quot; rel=&quot;&quot;&gt;
    https://x.com/mechanicaldirk
   &lt;/a&gt;
   &lt;span&gt;
    //
   &lt;/span&gt;
   &lt;a href=&quot;https://bsky.app/profile/mechanicaldirk.bsky.social&quot; rel=&quot;&quot;&gt;
    https://bsky.app/profile/mechanicaldirk.bsky.social
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Kyle Lo —
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/kylelostat&quot; rel=&quot;&quot;&gt;
    https://x.com/kylelostat
   &lt;/a&gt;
   &lt;span&gt;
    //
   &lt;/span&gt;
   &lt;a href=&quot;https://bsky.app/profile/kylelo.bsky.social&quot; rel=&quot;&quot;&gt;
    https://bsky.app/profile/kylelo.bsky.social
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Luca Soldaini —
   &lt;/span&gt;
   &lt;a href=&quot;https://twitter.com/soldni&quot; rel=&quot;&quot;&gt;
    https://twitter.com/soldni
   &lt;/a&gt;
   &lt;span&gt;
    //
   &lt;/span&gt;
   &lt;a href=&quot;https://bsky.app/profile/soldaini.net&quot; rel=&quot;&quot;&gt;
    https://bsky.app/profile/soldaini.net
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    General OLMo contact —
   &lt;/span&gt;
   &lt;a href=&quot;mailto:olmo@allenai.org&quot; rel=&quot;&quot;&gt;
    olmo@allenai.org
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   Papers / models / codebases discussed
  &lt;/h3&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2501.00656&quot; rel=&quot;&quot;&gt;
      OLMo 2 paper
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2402.00838&quot; rel=&quot;&quot;&gt;
      OLMo 1 paper
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2205.01068&quot; rel=&quot;&quot;&gt;
      OPT
     &lt;/a&gt;
     &lt;span&gt;
      models and
     &lt;/span&gt;
     &lt;a href=&quot;https://www.youtube.com/watch?v=p9IxoSkvZ-M&quot; rel=&quot;&quot;&gt;
      talk
     &lt;/a&gt;
     &lt;span&gt;
      from Susan Zhang
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2211.05100&quot; rel=&quot;&quot;&gt;
      BLOOM
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2411.12372&quot; rel=&quot;&quot;&gt;
      Red Pajama V1 Dataset
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2311.16867&quot; rel=&quot;&quot;&gt;
      Falcon LLM
     &lt;/a&gt;
     &lt;span&gt;
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2406.04594v1&quot; rel=&quot;&quot;&gt;
      C4
     &lt;/a&gt;
     &lt;span&gt;
      :
     &lt;/span&gt;
     &lt;em&gt;
      Boosting Large-scale Parallel Training Efficiency with C4: A Communication-Driven Approach
     &lt;/em&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2203.03466&quot; rel=&quot;&quot;&gt;
      Maximal Update Parametrization
     &lt;/a&gt;
     &lt;span&gt;
      (muP) is from
     &lt;/span&gt;
     &lt;em&gt;
      Tensor Programs V: Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer
     &lt;/em&gt;
     &lt;span&gt;
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2312.16903&quot; rel=&quot;&quot;&gt;
      Spike No More
     &lt;/a&gt;
     &lt;span&gt;
      : Stabilizing the Pre-training of Large Language Models
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2312.06550&quot; rel=&quot;&quot;&gt;
      LLM360: Towards Fully Transparent Open-Source LLMs
     &lt;/a&gt;
     &lt;span&gt;
      —
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/LLM360/Amber&quot; rel=&quot;&quot;&gt;
      Amber model
     &lt;/a&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://arxiv.org/abs/1905.11946&quot; rel=&quot;&quot;&gt;
      EfficientNet
     &lt;/a&gt;
     &lt;span&gt;
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://github.com/databricks/megablocks&quot; rel=&quot;&quot;&gt;
      MegaBlocks
     &lt;/a&gt;
     &lt;span&gt;
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2305.13169&quot; rel=&quot;&quot;&gt;
      A Pretrainer&#x27;s Guide to Training Data
     &lt;/a&gt;
     &lt;span&gt;
      : Measuring the Effects of Data Age, Domain Coverage, Quality, &amp; Toxicity  (Kyle said
     &lt;/span&gt;
     &lt;em&gt;
      Hitchhikers
     &lt;/em&gt;
     &lt;span&gt;
      )
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2405.05417&quot; rel=&quot;&quot;&gt;
      Fishing for Magikarp
     &lt;/a&gt;
     &lt;span&gt;
      : Automatically Detecting Under-trained Tokens in Large Language Models
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h3&gt;
   Chapters
  &lt;/h3&gt;
  &lt;p&gt;
   Chapters: Here is a list of major topics covered in the podcast, with timestamps for when the discussion starts:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     [00:00:00] Introduction
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     [00:02:45] Early history of the OLMo project
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     [00:15:27] The journey to stability
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     [00:25:00] The evolving role of OLMo and pretraining research
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     [00:29:00] Pretraining Q&amp;A (µP, scaling laws, MoE, etc.)
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     [00:40:40] How to think about pretraining data work
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     [00:54:30] Role of pre-training vs mid training vs post-training
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     [01:02:19] Release strategy and wrapping up
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;h3&gt;
   Transcript
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;em&gt;
    This is generated by AI and lightly edited for clarity. Particularly, the attribution per-speaker was poor on this time around.
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:00:07]: Hey, welcome back to Interconnects. In this interview, we&#x27;re bringing one that I&#x27;ve hinted at for a while, which is interviewing some of the other leads on the OLMo team at AI2. So essentially, this covers the story of OLMo from its early days where we got our compute, kind of our path to stability and some failed runs along the way, the role of OLMo and the broader AI ecosystem, and really just a very long tale of technical details and decision making and considerations that you have when actually training language models that you&#x27;re trying to have at the frontier of performance relative to peers like Llama, etc. This is a fun one. There&#x27;s less post-training than normal because this is me interviewing some other co-leads at the Allen Institute for AI. So there&#x27;s three people in addition to me, which is Dirk Groeneveld, who is the lead of training, handles most of engineering, Kyle Lo, and Luca Soldaini, who are the data leads. So we have a pre-training engineering lead and two data leads with me who has done a lot of the post-training. This is just a part of the team. And I hope you enjoy this one. We can do more of these and bear with the fact that I&#x27;m still expanding my podcasting tech equipment. But I think the audio is definitely good enough and enjoy this episode with me, Kyle, Dirk, and Luca.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Hey, everyone. Welcome to the AI2 office. We&#x27;re finally talking more about some of our OLMo things. Too much work to do to actually get all the... the information we want to share out into the world. So I&#x27;m here with Dirk, Kyle, and Luca. We can also talk so people identify your voices so people are not all on video. Hi, I&#x27;m Dirk.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:02:01]: I am the lead of the pre-training part of OLMo.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    : Hi, I&#x27;m Kyle. I work on data.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:02:08]: Hello, Luca. Also work on data with Kyle.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:02:13]: Okay, so we&#x27;re kind of going to maybe go through some of the story of OLMo to start. And then just get into as many nerdy details until we get tired of OLMo 2. Which, in my state, this will probably be mostly about pre-training. You can ask me post-training questions as well. But I&#x27;m not going to sit here and be like, ask myself questions that I&#x27;m not going to answer. Because that is an absolutely ridiculous thing. You can ask me one question. Okay. One question. It&#x27;s like, why shouldn&#x27;t you post-training with all the compute?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:02:45]: But I wasn&#x27;t here for when OLMo actually started. So I think it&#x27;d be good to tell people, I mean, like, broadly what AI2 was like at the time, what language modeling was like at the time, what it may or may not have been risky.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [00:03:01]: Yeah, you should probably get this.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:03:03]: Yeah, I think it all started in the fall of 2022.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:03:10]: We were talking to AMD at the time about some sort of collaboration. We&#x27;re scoping out some stuff. And at the time, we wanted to take the Bloom model. And put 300 billion extra tokens in. And we wrote up a proposal and we sent it to AMD and it disappeared into a black hole. And we never heard from them again. And then ChatGPT came out a couple months after that. And suddenly everybody was very excited. And two, maybe one month after that, AMD came back to us and said, now let&#x27;s do it. And that kicked off a very busy period for us. At least the three of us were involved at the time. Plus some of us. Some more people trying to scope out exactly what the project would be. Putting 300 billion tokens into Bloom wasn&#x27;t that cool anymore. The field had moved on. So we needed to find something else that would work both for us and for AMD.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:04:07]: And that&#x27;s exactly what we did. We figured it out. We figured out who would be on the team, how exactly to do it. We had to get the data from all of that stuff and then started working on it.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:04:16]: I think it was, let&#x27;s look it up. And the official birthday of all of us. Almost is February 2nd, 2023. That&#x27;s when we had like a big sort of half day. Summit workshop and a bunch of researchers self-organized a long discussion. I&#x27;m foreseeing maybe like 40, 50 of us try to scope down a potential language model project at AI2.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [00:04:48]: Yeah, it was also extremely bottom. Up because we were all like, nobody, it was not on anyone&#x27;s radar. We were working on, everyone&#x27;s working on different projects that we had promised for the end of the year. This was very much just like a side gig for us. We had no compute other than this mysterious AMD GPUs that just came. It was like, oh, it&#x27;s possible. And everyone was just like, yeah, I&#x27;ll work on this on the side. Let&#x27;s just start hacking together some stuff.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:05:14]: How far along the line until you decided on 7B? Like, were these things obvious at the time?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:05:20]: I think the size of it. This is where Llama&#x27;s size was. Yeah, we started with seven because seven was the smallest Llama size. This was Llama one. Yeah, Llama one was like first couple months of 2023. Yeah, we started, we started scoping before Llama one. And then when Llama one came out, it made sense to have a configuration that was just sort of close to what they were doing. So it&#x27;s not too much reinventing. I think seven was.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:05:52]: Yeah, I mean, I think the original scope was recreate Llama one, which would be a 7B at 1.4 million tokens. What were we staring at? OPT.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [00:06:03]: We were staring at OPT also, right? During around that time.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:06:07]: For inspiration. Yeah. And for what not to do in many cases. Was OPT even like in the many tokens regime or was that still like when people did the booms and booms?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:06:18]: I think OPT and booms were.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:06:22]: They were not, they were not over trained at the end were both a scope to Chinchilla that they both had extensive logs and so they were very useful because both of them have hundreds of pages of like, whatever can go wrong during pre-training. Yeah. I mean, OPT was amazing as a resource for figuring out, you know, we knew nothing, so we needed to know what&#x27;s important. And yeah, I remember there&#x27;s also avoidance and so on. There&#x27;s that. It&#x27;s like Susan has this talk.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    : I&#x27;ll come load parallels of training OPT and yeah, I think the original ones, I always feel it&#x27;s kind of a shame because the OPT models are not very good, but, but they were first, like they figured all that stuff out for the first time. I have huge amounts of respect for that.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:07:11]: And what&#x27;s the like open source angle thing at the time, or like, had you already identified that there was no open pre-trained data sets for these models?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    There definitely wasn&#x27;t any open pre-trained data sets. I think we were basically looking at. The gopher paper that had most documentation and then Llama one had enough documentation about what data sources were using, where we were like, okay, let&#x27;s try to reconstruct what it was. And I think roughly around the same time, Red Pajama V1 and then shortly after it was like Falcon, Falcon, the first Falcon, we were all kind of concurrent works at the time, but basically starting from, I don&#x27;t know, Grab, Common Crawl, grab a bunch of sources to try our best.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:07:50]: The funny thing, like we had conversation of like. Like, uh, there was like, boy, it would be good if we didn&#x27;t have to do the data. This would be one fewer thing to do, but at the time, like even when, uh, Falcon dropped, they released like a small preview that wouldn&#x27;t match like the token budget that we wanted for a training run. So it was not even like, you know, it was good work and like, oh, maybe we just switched to this one. And then we quickly arise, not, not big enough for the two trillion. So I think it was like, maybe. Yeah. Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:08:22]: I mean, we did the C4 data set way before any of this. Um, and so my first idea for how to do data was to just run C4, but on all the Common Crawl, um, instead of just whatever the most recent one was at the time. And I actually started writing a repo for that, but then ended up not doing it. This is the C5 repo. Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    This was C4&#x27;s side of data cleaning practices.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    Yes. That&#x27;s exactly a re-implementation of C4. And, um, for it to touch it, we&#x27;d run on slightly different hardware, um, with more dApps and that was, that was going to be the entire story until we found we could do better.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. And, um, for general timelining, I joined pretty much like almost 7B was, I think mostly done training or wrapping up pre-training and the like instruction tuning at the time was like basic SFT with a sprinkle of DPO. Yeah. So I think a lot of that story gets cut. Compressed. Like I&#x27;m guessing the actual pre-training happened in like the second half of the year, mostly. So it&#x27;s a lot of prep to get a language modeling system to exist. Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:09:32]: I think we handed off the one of Dolma. So the data set that we used for pre-training is like end of June, I think, 2023. Grab Common Crawl, end of March. Yeah. So all the source acquisition was March, April. Let&#x27;s see March and then yeah, a few months. There.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:09:52]: Um, if someone wants to do the same thing today, which is like, we should train a language model, how much faster would it be to like, is OLMo actually making that much of like, would it be a week with OLMo stuff now, or would it still take a lot of time to set this up?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:10:07]: I think if, if you want to, um, if you want to train exactly on OLMo data, you know, data, it&#x27;s much faster, um, training, I think it requires a little bit more finesse and dirt. Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:10:23]: If someone gives you a cluster to, to run on, just figuring out the mechanics of getting your thing to run, just so setting all the environment variables and having the drivers loaded and so on, it might take you a week or so if you&#x27;re, if you&#x27;ve done that kind of thing before. Um, so that&#x27;s very different, but you can take a trainer that already works and just, just use it.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:10:45]: Um, it really depends like where, where you start. It&#x27;s like, if, if you&#x27;re spinning up your cluster from. Scratch, then you acquired a hardware, then that hardware has burning periods. So the first three months stuff will fail and that has nothing to do with the model itself. It&#x27;s just, your hardware is also brand new.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:11:06]: Yeah. I mean, I am eternally grateful for AMD for giving us the compute to get started, but it was kind of difficult to run on.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    What was the exact amount of compute? Like, I think when I arrived, that wasn&#x27;t even what we&#x27;re using where it&#x27;s like Lumi discussions and the original amount.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    Of compute was, uh, 2 million hours on Lumi.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    So, so 2 million GPU hours.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:11:29]: Um, that&#x27;s we&#x27;re training way bigger now than that. Yeah. So I think I did the math recently. It&#x27;s like the order of a million hours is if you do a thousand GPUs concurrently, like 20 days. Uh, I don&#x27;t have that math in the top of my head, but, um, the first, the first end to end run for the 7B that we did took, uh, 35 days. We can now train that same. Model again in three days. So things have changed a lot since then. Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:11:58]: Well, some rough, rough stats for almost two anyways, seven and 13, just the final ones, um, was a little bit over 5 million GPU hours combined. And then we have roughly 5 million hours worth of experiments.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:12:15]: Um, these are, uh, A100, H100. Might be surprised. Oh, it&#x27;s the case too high or too bad to do some, it&#x27;s way too high.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:12:33]: Um, it&#x27;s like, how do you encamber overhead then?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    Oh, combined.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:12:36]: It&#x27;s some of them plus the ultimate training. They&#x27;re also not using the new one core quickly.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:12:42]: So, yeah, but I&#x27;m just thinking if it&#x27;s, let&#x27;s say conservatively 7,000 tokens per second, four months on a thousand. Do you think it&#x27;s less than that?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    Like, okay, let&#x27;s just go and track those number down. I think it&#x27;s interesting. It&#x27;s like, what percentage, what is the percentage of improvements still? Like how much of all the two being better is just by the compute being more stable just by doing more experiments. And that lets you test things like stability and just get the ducks in a row rather than like the data being so much better. It&#x27;s an impossible question.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:13:20]: It&#x27;s that it was like. And, you know, the trigger part with using that AMD hardware at the time, specifically that cluster, was that cluster was being brought up online at the same time as we were experimenting with it. So we were helping that cluster being set up. So it&#x27;s because of that, there&#x27;s a lot of things where we had to second guess ourselves, whether that was an issue on our side, the hardware side.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:13:58]: Isn&#x27;t this always going to be an issue with new GPUs coming into the world? Does Microsoft plug in opening eyes GPUs and they just work?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:14:06]: I think it was, yeah, it&#x27;s always tricky. It&#x27;s a combination of like getting both new GPUs. At the time, AMD was a relatively new vendor, plus the cluster itself being new. So it&#x27;s like stacking, you know, risky, risky things on top of each other in a way that it&#x27;s like, oh, if you can, if your cluster is solid, that, you know, the GPUs are brand new. Well, the network is not going to cause issues, but if the cluster is new and the GPUs are new, who knows where the problem sits. Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:14:44]: We&#x27;ll go down the... Yeah. We&#x27;ll go down the whole stability round the hole. Dirk, how close are you to a number?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    Five trillion tokens at 7,000 tokens per second, which is what we get for the 7 billion, more or less, over the long run, is only about 200,000 hours on each one. So our first estimate was way off.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:15:05]: It was... Check the top. I think maybe my memory was wrong. Maybe my thing was... This is why I have this laptop here.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:15:18]: Oh, no, I was misremembering. Okay. My name is 500K. I remember flying... 500K. Yeah, yeah, yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:15:27]: So it&#x27;s like from the first AMD grant of a few million GPU hours on AMD to what we have today. It&#x27;s like it&#x27;s gone from multiple million AMD hours to training a model over five times the tokens in half the GPU hours. That&#x27;s right. Yeah. Like, where do we...
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    I mean, the biggest one is that the MI250 that Lumi has on, like, the MI250 is the AMD GPU that Lumi has, is of the A100 era. It&#x27;s comparable to an A100 in price and capacity. But now we train on H100s, and they&#x27;re just...
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    What percentage of tokens... It&#x27;s just a newer GPU. Yeah, what percentage of tokens in OLMo 1 code versus OLMo 2 code are lost at, like, a 7B, so a scale that we&#x27;re reliable on? What percentage of tokens in OLMo 1 code versus OLMo 2 code are lost to spikes?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    I think it was OLMo 1 losing a considerable amount against the spikes game. That&#x27;s impossible to estimate, because there&#x27;s so many other differences at the same time between OLMo 1 and OLMo 2.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    Can you summarize the architecture differences? There&#x27;s a list in the paper. We don&#x27;t have to be exhaustive.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    That&#x27;s going to be a lot of stuff. The biggest difference is the init. So I guess now we&#x27;re getting into what did we actually discover?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    These are some audience questions. OLMo 1 and OLMo 2. Finbar, who you might know specifically, asked, like, how do you write an init N(0,0.02) to an init? I&#x27;m like, I don&#x27;t know.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    That particular init is the default in Megatron. And the init that we had in all one was just trying to be too clever. We stole that init from OpenOLM, and they took it from somewhere else, actually. And I don&#x27;t remember what the original source is.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    What is the actual decision-making on an init that&#x27;s too clever? You, like, think that you can get a better learning region by bundling with something?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    We tried it. We ran it for, you know, 100 billion, 200 billion tokens, and we looked at which one is better. And scaled init is absolutely better for a long time. So scaled init is the original. It&#x27;s the OLMo 1 init. Works better for a long time. You have to train for a really long time before you see it come apart. You have 2 trillion tokens for a 7Bmodel. And then things get a little bit dicey. So this is why, you know, this is why we used it for OLMo 1, because it looks quite good for a long time.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    Which of our OLMo models did we figure out that the init was a change?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    Because we did a few through the year. We tried that same init with a 7D model, and that did not work. That model stalled out around 1.3 trillion, 1.4 trillion, something like that,
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:18:12]: which gets at the heart of the stability. So we started to think about the stability investigation. So I think that was one of the audience questions, right? And how do we even go about the stability investigation? starting from the point of we&#x27;re training the 7DB and it&#x27;s not working anymore, what did we do? The first step was to identify the issues that we see in the metrics and see them in a smaller model. And the two issues we saw were lots of spikes that we call them fast spikes. So the model recover. They recover quickly, but they just happen more and more the longer you keep training. And at some point, even the fast spikes kill you.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   And the other thing was a growth in GradNorm. It seemed very much that the 7DB would always start blowing up once the GradNorm got to 0.4, regardless of what intervention we did, it would get a little bit further. And then as soon as we hit 0.4 GradNorm, it would blow up again.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    So you lowered the learning rate and it was up again.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    So fortunately, yeah. Yeah. So we would do things like that, increase the batch size, change the late decay, blah, blah, blah, but quickly it gets back to 0.4 and then blows up again. So fortunately, both of those phenomena also appear at the 7DB, even though the 7DB trains fine, it has both of those traits. So we decided to focus on those two because it&#x27;s too expensive to try all these experiments at 7DB. But these are two things we could fix at 7DB and then see how it goes. So that was, that was the first step. But now. Now we have a metric where we can pretty quickly, within 12 hours or so, do a run, find out if our numbers are better and then change something and do it again. And the second component was we took another model that successfully trained that didn&#x27;t show these issues, that didn&#x27;t show the slow GradNorm growth and it didn&#x27;t show the spikes either. And we ablated against that. So that was the LLM-360 Amber model. They&#x27;re like all very open. So we could take their data. We could take their setup and look at it in great detail.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:20:22]: And we basically tried things one by one, sometimes two by two or so to not run too many operations. But we tried things until we got to a stable setup. There are some other insights at the time. I was really into the Spike No More paper, which is all about the magnitude of this. So we tried embeddings. So we tried some stuff there.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:20:48]: Pete Walsh on our team tried some other stuff involving Adam W settings that made things even better. And then we took a lot of inspiration from the Chameleon models because we were talking to that team on a semi-regular basis and they had a lot of stability issues. They found some solutions that we also tried and some of them worked for us and some of them didn&#x27;t. And we took the ones that worked for us. So it&#x27;s always ablating at the 70 scale until our numbers look super smooth and super nice.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    How specific do you think these are to our setup? Are these all OLMo specific insights or is it just kind of a process you have to walk down? We&#x27;ve heard some of these things before. It&#x27;s like all these developments are you have to do the previous type of thing before you can go bigger, do a more complicated model. Do you think that&#x27;s actually true or is there just best configurations at the time?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    I really don&#x27;t know the answer to that. It&#x27;s hard. But something I want to know, something I want to do for OLMo three is walk back a few of these things and see in retrospect which ones are actually necessary. And in particular, I&#x27;m hoping that some of those are not necessary and they&#x27;re costing a bit of performance, you know, just to boost our own efficiency a little bit.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:21:54]: In general, I don&#x27;t know, you can tell me if there&#x27;s a useful summary, but it seems like the space of intervention you can take is so big. And other model, they&#x27;re not going to translate perfectly, but the hit rate to like find a good solution is higher if you start from that model and you explore around it versus like try to explore like the full space of possible solutions. Yeah. And then some things will not pan out once you try to rerun them on your setup. And I don&#x27;t think that&#x27;s an indication of like necessary . Yeah. You know, we can mistakenly reimplement their thing, not in the way they&#x27;re supposed to be. It&#x27;s more like some things translate, some things don&#x27;t. But it&#x27;s a good starting point.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:22:55]: Yeah. I mean, we are a fairly conservative bunch with this, right? Because even the 7B runs are actually kind of expensive. So make small changes from a known baseline by and large. Yeah. I mean, everyone has.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. And risk is pretty obvious when you look at the cost numbers and like who you are trying to beat or not. And it&#x27;s like we are trying to try to plot or people can build on it. And it&#x27;s much better to keep making small progress than it is to go for glory runs and just hope that works. I think both works. The more compute you have, you can have a bigger distribution of investments, but it&#x27;s not that surprising.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    I mean, I hope that we can be a lab that is a little bit more risk tolerant than others. For one thing, we don&#x27;t have Meta&#x27;s resources. So we should be a little bit more aggressive. You know, it would make me much more nervous if I had to bet a billion dollars on our next run than the amounts that we can bet. So we can try a little bit more. I also feel and I hope that our management agrees with this. I feel that if we always, if we&#x27;re always safe, if every one of our runs works. That means we&#x27;re not trying hard enough, right? We have to occasionally crash and burn.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    I think there&#x27;s a few every year that you should crash and burn. I think these crash and burns at the big scale get a lot of attention from media and stuff. But it&#x27;s like, what do you expect them to do? If they haven&#x27;t, you&#x27;re walking up a line and might as well try to take three steps at once every so often. Exactly. But I do agree. I think that&#x27;s a cultural thing that we&#x27;re trying to navigate. It&#x27;s like, how do we do more interesting stuff and not just fall into the trap of being the best? Open model. No one else is doing this. Like, okay, you could do that for a while, but it&#x27;s not as motivating.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    And it&#x27;s not just because it&#x27;s more interesting to do that, but also just the fastest way to make a better model. The fastest way to calibrate your risk tolerance properly. You have to sometimes be over. Yeah. It&#x27;s inevitable.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:25:05]: Any follow ups on risk?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. I&#x27;m thinking now it&#x27;s like, because the 70B crash was so sad. Yeah. And I&#x27;m wondering if you look back on it now, it&#x27;s like, that was the greatest thing for us. We learned so much from that.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:25:19]: It was very important to love too. I do a little bit. So, I mean, we felt terrible, right? Like this was an awful time for us. I was like, I&#x27;m done. Let&#x27;s get good questions. No, we were the training team that couldn&#x27;t train at all. I felt so bad. But the work we did following up is some of the proudest I&#x27;ve been about the stuff I&#x27;ve done in my time at AI2. Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:25:47]: In general, my thing about the role of OLMo sort of keeps evolving, right? It was very natural to have OLMo as these models designed to help others do research and language models. That&#x27;s how we initially, it was a big part of OLMo 1. You just release all the components because it&#x27;s important to have these tools available to everyone. To study language models. And I think we serve that community well. One thing that it&#x27;s, I hope we can do with OLMo more is that there are like some interesting aspects of language models. Interesting capability, interesting architectural decisions that for a myriad of reasons, they sort of get overlooked in like say a company or like in a framework where, you know, you have certain constraints in your model. But it&#x27;s still there. They are important. And there are questions around like what a model should be able to do, how it should operate, and things like that. But I think we can take a role where like we have in general this recipe that both enables research and language model and for like subset of model capabilities that we think are fundamental. No one is touching. It&#x27;s our space to do work there. I think the prime example that I keep repeating these days is what we did with MOLMo and
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:27:25]: vision team was mostly working on it. And MOLMo is very good vision language model in general. It benchmarks up there. It&#x27;s not the best, but it benchmarks up there with open models. And then it has this like this interesting point. Pointing capability that no other vision language model has. And that pointing capability is, turns out, is fundamental for a lot of language models and robotics that you want to build. It&#x27;s a core capability the same way that a text model should have long context. And it was cool to make, to sort of emphasize that of like, oh, we have the specific capabilities that would enable all these applications. And so more people should work on like the specific aspects. So I think that&#x27;s a cool way to like work on things that folks haven&#x27;t had a chance to touch on yet.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:28:24]: I think it&#x27;s like trying to parse out why this type of situation could happen is not easy. Because you generally, everybody would want to do this. Like everybody wants to come up with a new capability that expands the scope of what X type of AI model can do. And I think it&#x27;s most of like probably goes down to the culture of where people have space. To think about stuff in a more interesting way. It&#x27;s like, because obviously everyone wants to have breakthroughs and open AI and Anthropic that copy. But it&#x27;s like sitting at a boundary between doing just the same stuff and doing more researchy stuff that you need to have. I have more architecture questions. One is MUP. Multiple people are asking about it. I still don&#x27;t really intuitively know what it is. But are we going to use this?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    We have done a fair bit of work into it. And it hasn&#x27;t worked for us yet.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    Can you explain what it is?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    MUP is mainly a way of setting the learning rate, but also some other hyperparameters. By training only small models and then having a guarantee or at least a pretty good idea that it will work also for larger models.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:29:33]: We have implemented this. We&#x27;ve experimented with it. So far in our setup, it works across model sizes. So the learning rate that it predicts you should use, it doesn&#x27;t predict the learning. It just gives you one learning rate. Basically, the good learning rate for the small model is also the good learning rate for the big model. That works if we change the size of the model. It does not so far work if we change the length of the training run. And that&#x27;s why we haven&#x27;t been using it so far.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Like number of tokens.
  &lt;/p&gt;
  &lt;p&gt;
   Yeah. Or longer. If we double the length of the training run or we 10x the length of the training run, the optimal learning rate is different in our setup.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:30:21]: It seems like this might be a bug. It should work, but it doesn&#x27;t.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    And the positive gain is just that better scaling because you don&#x27;t have to fiddle with the certain. You know you&#x27;re getting the right learning rate, which is a crucial hyperparameter.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. It&#x27;s just a better way of setting learning rate. And it works for a few other hyperparameters too.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    But there are other open models that use this. Explicitly. Pretty sure. I mean, open weights model. Yeah. Those are linking. Like Llama and stuff using this. Llama does not, I think. But I don&#x27;t know for sure. We&#x27;ll always see with the next iteration. Even Llama3 felt like they were still building their org and their infrastructure so fast. It&#x27;s just like get in what you can get in and there will be more models in the future.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. I mean, MUP is a shortcut, right? Like you can for many settings where MUP wouldn&#x27;t work. Or you have to just establish scaling laws and predict what it will be. You could do the same thing for the learning rate. Just MUP lets you do this with even fewer runs. You know, you don&#x27;t even have to extrapolate anything anymore. You just use MUP and your setting will work. That&#x27;s the idea.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:31:29]: But you kind of already need a scaling law set up anyways for things that MUP doesn&#x27;t work for. You know, like architecture changes and so on. Yeah. So in that sense, it&#x27;s not that important. It&#x27;s still pretty important. And we&#x27;re going to keep trying to make it work for us. Maybe just find the bug. But it&#x27;s not absolutely critical.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    How does scaling laws actually tell you the way to change like the width? Do they actually tell you the change in width or the depth, like the proportions of the network relative to the size? Like what are the actual output variables? Or how are you controlling the architecture you&#x27;re going to use in the scaling laws? Well, like I know what it&#x27;s trying to predict, the accuracy, but are they on set architecture things?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    You would usually vary one thing.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:32:17]: Like you don&#x27;t vary anything. You establish how it scales with size. Yeah. And you set your size according to a certain formula. Like you might say, I will go 1.4x the depth and 1.4x the width. So I have roughly 2000 pixels. That&#x27;s a bigger model. And you do that a few times and you draw it on a graph. Then you change your architecture. You do it again. You draw a different graph. You lay them over each other and you hope that the lines don&#x27;t cross. And one of them is clearly better than the other.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. I definitely have known that there&#x27;s some, it&#x27;s like one of the obvious things architecture design and the not obvious things. It&#x27;s like you obviously make the model bigger, but the subtlety of like how tall versus wide. I think we&#x27;re talking about like a client that&#x27;s like much deeper than ours, our model architectures. And it&#x27;s just like, I&#x27;m around these things and I don&#x27;t have an intuition for if tall or wide is better. And I think it&#x27;s like what works.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    There are some early results from Google, I think. I think they&#x27;re called efficient net or something. That suggests that over a wide range, it doesn&#x27;t matter whether you go wide or deep. It&#x27;s not that surprising. That&#x27;s pretty old results now. We&#x27;re following up on a particular result right now. Actually, so OLMo 2 is a 7 and a 13, right? But there also was a 1 that didn&#x27;t work very well. And we&#x27;re trying to find out why. And one thing about that model was it was pretty wide and not very deep. So we&#x27;re checking whether that is the reason why it wasn&#x27;t very good. So we&#x27;re sort of in the middle of double checking this assumption that it doesn&#x27;t really matter whether you go wide or deep.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah, that makes sense. I think that is something that doesn&#x27;t matter to most people. They&#x27;re probably very interested in it. Just like how they have these blocks and how do they decide. And it&#x27;s like just one of us decides.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    And it&#x27;s like, eh, seems right. There are other concerns, right? So we train with FSDP, with 0.3 sharding. So we can try to choose these sizes such that they utilize the GPU in the optimal way.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:34:29]: Which has nothing to do with the sort of abstract training dynamics. It&#x27;s just the practicality of getting this thing into 80 gigabytes of memory. So then those concerns might take over. There&#x27;s other stuff like all your tensors, all your tensor dimensions need to be multiple of 64, 128, things like that. GPU math stuff. Yeah, exactly.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:34:53]: It&#x27;s really hard to argue against things that are practically making you run fast. Because it means that if I find something that is 20% faster, your big run trees fast. All the experimental cycles are 20% faster. So it&#x27;s not very glamorous. But everyone is really happy when we find one of these. Like, oh, this is a shortcut.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:35:16]: I find it super glamorous. I mean, when did you ever have such a clear sign of impact that you can say, I wrote this thing and it is not 20% faster? No, the impact is very good. Yes.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    The numbers you&#x27;re changing are not necessarily glamorous. It&#x27;s just detailed stuff.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [00:35:34]: I also think the experimental cycle thing is probably the biggest thing for me. What we&#x27;re seeing consistently is the more experiments you run for a particular idea, the more likely it is to just work out. It&#x27;s just a function of trying more things.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:35:47]: It seems like in the pre-training, there&#x27;s very few, like, you just get the idea. I mean, well, I said post-training more. But literally, like, we had a meeting with John Schulman. He was like, everyone, lead labs, train RL and athletes do this. And we got, like, a three-month head start on one step. But pre-training, all that stuff. I think it&#x27;s evaporated.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [00:36:05]: The human intuition piece is just gone. I think once you do v0, you can kind of do everything with intuition. It&#x27;s like, oh, look at data. This kind of makes sense. This seems like . And then after you get to, like, v2 of something, it starts becoming really hard to make sense of what is good for a language model or not. So you kind of just need to just try a bunch of stuff.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:36:29]: And then there comes a game of stacking improvements that are worth 2% to 5% each.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    I think it&#x27;s very compounding, at least in all the math, works out over a year. I think I want to ask about MOEs as well, if you have a different thing you want to say. But it&#x27;s mostly, like, it seems like we have a OLMOE, which, if you look at the plots on paper, it&#x27;s like this MOE architecture beats all of our own things and carry efficiency. But it seems like we had a path we needed to go down to make sure dense works really well and get all these improvements. And then you have to, like, feed back in. And you, like, merge the MOE streams. We have DeepSeek. We have Minimax. There&#x27;s countless other MOEs that get really high eval scores. Like, they&#x27;re not as easy to do research with because they have tons of total parameters. And people need bigger clusters to fine-tune them, blah, blah, blah. But it&#x27;s like, is MOE something that you think we just need to do to make better models?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    Well, it&#x27;s a complicated question, and we haven&#x27;t quite answered it yet for ourselves.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:37:34]: We did investigate doing a bigger MOE. And we found that the engineering is somewhat difficult. And at the time, we came to the conclusion that we could do that engineering, but then who&#x27;s going to run that thing later? They also have to have a team of engineers on top of it to make sure they can train this.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    What does the engineering look like? It&#x27;s not, like, CUDA-level kernels. It&#x27;s how you distribute parameters?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    It&#x27;s a little bit like... It&#x27;s a little bit CUDA-level kernels in that... If Mega Blocks by itself isn&#x27;t enough for you, then it gets really complicated. And we ran into that situation where if it had to be significantly bigger than what we did, it just got too complicated.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:38:22]: There is an inference. These very big models that really get advantages by... If you tailor them to, like, where you&#x27;re going to do inference with them. So if you&#x27;re a big company, you start thinking about, like, how to batch request, how to, like, serve the model. But if we could do it ourselves for the place where we&#x27;re running, but then you start thinking, like, oh, folks who want to use their model in their hardware, they&#x27;re better served by advanced model than also redoing this engineering on top. Like, there is, I think, a clear advantage if you are... Also providing an API to an MOE. Yeah. Very clear cut.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:39:10]: It depends on how we think of the product of ALMO. And the number one is still it&#x27;s an item to be researched. So other people need to be able to train on it and to modify it and so on. And that is just much easier if you have a dense model. Yeah. If you think of it as something that gets put into a product. And people will run tons of issues. But if you have a lot of inference on and you only really care about the final score that it gets, then maybe the MOE starts making a lot more sense again.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. That&#x27;s a good answer. I think it&#x27;s, like, I think people can fill in the blanks of, like, what we may or may not do.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:39:53]: And I mean... I mean, like, different, like, I&#x27;m curious, like, what, like, folks at Llama, the Llama team think about MOE.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:40:03]: If the Meta AI exists, they&#x27;re 100% going to do an MOE.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:40:06]: I mean, it&#x27;s interesting, right? It&#x27;s, like, if they&#x27;re serving few, if they&#x27;re expecting that the Llama users are going to be, in fact, one of the better smalls are few large companies that can figure out inference, then MOE makes sense. But if they&#x27;re thinking about more, like, this model that wants to, it&#x27;s great if it&#x27;s adopted by a million developers, large and small, then, you know, they&#x27;re still going to reach a lot of dense model. Yeah. Exactly. That development is so easy, so much easier for people to set up their own inference with a dense model.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:40:40]: Yeah. I think we&#x27;ve gone surprisingly long without asking about data. It&#x27;s, like, how much more, is it just an infinite hill to climb on data? It&#x27;s finding good data and filtering bad?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [00:40:53]: I mean, I think it&#x27;s an infinite hill to the extent to which everything else is also, and you can kind of keep improving, right? But yeah, it&#x27;s the main threads constantly are. Got to get more data, because if you&#x27;re working with larger pools of data that you can&#x27;t actually get easily new data that&#x27;s not in your distribution, it&#x27;s probably interesting to study how that adds in. And you have more to work from. So if you have, like, a strict quality filter, you can still get your high token yield if you start with a much larger pool and filter down. So getting more data is really, really critical, especially if you can target specific pockets that you think is missing. You can always keep iterating on better filters. Understanding how those filters affect performance. And everything kind of interacts with each other. Like, safety filters interact with quality filters, interact with deduplication, interact, like, all these together. So there&#x27;s an infinite, even ordering, search space between these operations. So keep throwing more things at it.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:41:53]: Yeah, it&#x27;s very much just stacking small improvements. Yeah, shots on goal. I think the way it looks is, like, it&#x27;s... For each... Now that we have, like, these multiple stages of pre-training, we think about, like, what kind of improvement you want to get from data at all the various stages. Like, clearly, the improvement you want to get from data you put at the end of training is different than the improvement that you want to see at the beginning. It comes with a different set of requirements. One thing that is really useful is... Intuitions are always often wrong. But one thing that it&#x27;s worth spending time on is figure out... If you have a data ablation idea, what is the fastest way to disprove it, which requires a little bit of experimental design. And then, yeah, you&#x27;ve got to fiddle with, like, especially, you know, when you do the first version so that you can take a very... It&#x27;s very easy to measure improvements. And then as you start thinking, like, refined version, then, you know, you&#x27;ve got to think of, like, how you measure your improvements or so. But, yeah, it&#x27;s... There&#x27;s no, like, big... After you&#x27;re done, you know, the basic stuff, your V1 is done. There&#x27;s never, like, a big, like, thread of, like, this is the one data thing. It&#x27;s more, like, stacking your Lego bricks to get to a better model.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:43:18]: Do you think you can iterate faster on, like, end of pre-training, whatever you want to call it, like, highest quality bit training and the only data? Yeah. Have you, like, started that recently?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:43:28]: I think it depends on the... What we&#x27;re getting, you know... We... We need a little bit more evidence of this, but it depends on the role of data. Like, it&#x27;s very much... The reason why we started doing mid-training at all is because we were interested in having base models be primed with certain capabilities that we didn&#x27;t get during the long pre-training phase. And for those, it&#x27;s really easy to iterate on new data sources that would improve on those capabilities at the end, pre-trained. But during, like, the pre-training phase, why not the important aspect that we think about is, like, efficiency of your data is, you know, if there is a version of your data that is where train on it and the model gets to performance X on 20% faster, it means that you can train 20% longer, right? Or run more experiments. Or run more experiments. And so... But for those, it&#x27;s, like, you know, it&#x27;s... In some cases, you can use mid-training as, like, a proxy for this. In other cases, it doesn&#x27;t quite make sense, so you have to come up with, like, maybe experiments through scaling laws, maybe experiments through some other technique. But yeah, it really depends on, like, what role a data set plays into, like, the various stages of pre-training.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:44:53]: So it seems like, like, compared to Dolma 1, which is, like, do the thing, it&#x27;s all targeted abilities. It&#x27;s, like, we want to be better at things. We put people on this. It&#x27;s, like, targeted abilities or where we think we can get a lot of data.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [00:45:05]: Like, a certain data source that hasn&#x27;t been mined for stuff. Yeah. Yeah. We have to be opportunistic because it&#x27;s so hard to get data. And for us, especially if we want to be open with the data, it&#x27;s, like, we have to also do it by due diligence. Like, we&#x27;re going to study this data, put all this effort in, and we&#x27;re still going to be able to share it with everyone. So...
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:45:22]: If you were in a lab that didn&#x27;t release data, do you think you could make more progress on it? Like, how, like, how much is that actually?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [00:45:27]: Oh, yeah. Oh, my God. Such a time sink.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:45:31]: I mean, it&#x27;s, like, it&#x27;s a little bit of a mistake that we put in. Yeah. Like, and this is not even, like, doing, you know, getting data that managed to not legal, right? You could form partnership. You know, you have people knocking at our door all the time saying that you want to buy this data set. And they&#x27;re, like,
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:45:48]: I&#x27;ve been contacted by one ML owner to try to facilitate a data deal.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:45:52]: Oh, yeah. Twitter. Oh, my God. But only the first, the first follow-up is, like, are you cool if we release the data? Of course, they&#x27;re not. Yeah. So, it&#x27;s, like, it&#x27;s, it&#x27;s, even, like, there&#x27;s plenty of data that you could acquire from people, but then you can&#x27;t release it. So, that&#x27;s, that&#x27;s a complication to, to progress.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:46:15]: Yeah. This is more of a self-question, but, like, how much do you think mid-training should be, like, a philosophical shift in how we organize teams? Because it&#x27;s very easy to do. I mean, we&#x27;ve already consolidated, like, our training and data to base, which is not surprising. But this is mostly hypothesizing on what other people do. It&#x27;s, like, how close do you think this kind of end of pre-training to post-training handoff should actually be?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [00:46:40]: I think it&#x27;s, it makes sense as a thing if, I think these things are, in theory, arbitrary, but you can think of, like, in the extreme, if you had a perfectly oiled machine, you have a very smooth transition between pre-training to mid-training to post-training, and it&#x27;s actually, there&#x27;s no boundaries. Like, that&#x27;s, like, a theoretical. You can probably squeeze a ton of performance by smoothing that out. But in real world, stuff, stuff is messy. So the real world is your three trillion tokens into your base model run, and then you signed a new data deal. You got to do something with this, and you&#x27;re going to undo your training one. Well, you got to figure out something. So maybe that&#x27;s mid-training, right? Mid-training is when you have an opportunistic need for something, or you&#x27;re training something and someone catches a bug, which happens all the time, like a data bug or some training bug, and you&#x27;re like, oh, I had to patch it. So then there&#x27;s the shift fundamentally. You got to know how to deal with this. So just because these things aren&#x27;t, these large training runs aren&#x27;t super repeatable, and they take so much time that the world state changes all the time, you always need some strategy on how to deal with, oh, I&#x27;m near the end of pre-training versus I&#x27;m near the beginning of pre-training versus... Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:47:47]: It&#x27;s like, we&#x27;re obviously trying to solve long context, so this fits right into this. It&#x27;s like, we&#x27;re going to do this thing. Does it go, where does it go? Some people do it in post-training. Yeah. There&#x27;s some component during pre-training.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [00:48:00]: It&#x27;s kind of just like, you have to follow a few recipes and figure out what works for your team. Yeah. And so much of it is just, if it&#x27;s expensive, try to push it off as much as possible. Because if it&#x27;s risky, push it off as much as possible. If you can intervene to get the same result much later, huge win. You can try a bunch more things. If you have to intervene because it&#x27;s some core thing that has to be baked into pre-training time, you&#x27;re kind of... It&#x27;s a sad space to be in. But then that&#x27;s the thing where you have to intervene. That&#x27;s the pre-training data.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:48:29]: There&#x27;s a big question that I&#x27;d love to get an answer to, but I don&#x27;t even really know how to think about it. But the question is, what makes a pre-training model a good candidate for mid-training fine-tuning? Because all we really try to do is we try to maximize our metrics, but we don&#x27;t really know that those metrics are what makes a good step zero for post-training.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    I think a relevant thing, I don&#x27;t even know if I&#x27;ve told you this, but I don&#x27;t know how to take action on this, is we got advice that we have the multiple stages of post-training. In this instruction tune phase, we got advice that&#x27;s like, eh, it could be a little broken. You can have some crap in there. It&#x27;ll get fixed later on. And it&#x27;s like, why is that okay?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:49:14]: It might be the same thing in pre-training. It&#x27;s like, you want to get in the right... It&#x27;s more important to get in the right ballpark than the right exact number. Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:49:21]: It feels like it&#x27;s more about not how to make a good model for post-training. But what to avoid so you don&#x27;t have a bad model post-training. Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:49:33]: There&#x27;s a whole other question, which is how to make a base model that&#x27;s easy to fine-tune in general, versus one that, if with the right finagling, can get the absolute best numbers. Which I think, for OLMo, would be really great to be like, here&#x27;s a super stable platform. A lot of people have complained about specifically That Llama Instruct, it&#x27;s hard to fine-tune. Which, after most of the post-training. Because this is where people at companies start. They&#x27;re like, this is the best open-weight model. I want to add a little thing in it. And a lot of people have difficulty in fine-tuning it. It&#x27;s different at the base, because most people can&#x27;t do this full instruct thing. But for researchers, having a stable platform at base is way more valuable.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [00:50:12]: There&#x27;s an interesting... About this, like, what makes a base model a good base model. There&#x27;s this interesting, I guess, debate that we&#x27;ve had a bunch of times. We&#x27;ve also had with other people. Which is, it seems like there&#x27;s like two hypotheses on what the role of this... How do you think about data as an effects-based model behavior? There&#x27;s one hypothesis, which is, you need quality data so that you don&#x27;t get any spikes. You have stable training. You have no bugs. And once you pass that level of quality, as diverse as possible. It&#x27;s just about an init to the model, so that it can go in literally any direction. And so, diversity is the next. That&#x27;s one hypothesis. The other one is, it&#x27;s all domain effects. The only reason why... Like, you can just keep climbing. There&#x27;s a notion of quality. But you... And you can keep getting more and more and more as long as you&#x27;re very clear about what target domain or target application you are. You just keep getting closer and closer. Well, there&#x27;s a lot of suite learning. Yeah. Well, this goes into, like, the continue pushing. I just like... It&#x27;s just domain effects all the way down. If you&#x27;re only evaluating on this particular stuff, you can always get your base model to be better for that. Just keep climbing on it to get it more and more similar. As opposed... And, like, think about, like, I care about this application, this suite of applications, all the way through. From base model... Can you not kind of have both? I feel like I&#x27;m confused with how, like, actual generalization fits into this. It&#x27;s... It&#x27;s... It&#x27;s... It&#x27;s competing ideologies in terms of, like, if you believe in the first one, then you&#x27;re all in on diverse data acquisitions. And how you set up your team. Yep. You&#x27;re all in on efficiency and stability for your pre-training. And then you just get as much different data as possible. And you&#x27;re post-training all the time. If you believe in the latter one, you solve backwards from, this is what I want the model to do. And I make all the changes everywhere to try to squeeze performance out of this class of problem. In the big... In the data, in the bit-training data, bit-training data, et cetera.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:52:01]: How important do you think the actual, like, multi-tag category of every data document is? Like, know that someone... Like, that these people have really advanced tagging of all their pre-training documents. Like, do you... Like, does it essentially say, like, doing that and choosing them? Which is, like, a very much, like, crafting a, like, recipe for your pre-training versus, like, just good numbers. So, like, just get a good classifier and roll with it.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [00:52:27]: We have tags. That&#x27;s fine.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:52:31]: The tags are useful even if you get this idea of, like, let&#x27;s use as much as possible. You know, diversity is important. A lot of web data comes with absolutely no useful metadata. You have, like, URLs. URL is very, like, you have to do things on top of it to make your URL useful. It doesn&#x27;t add much. So, the more you have in terms of, like, categories, metadata information, you can start using this as a tool to try extra technique on it. Maybe it is extra technique to mix your data in a certain way. Maybe it&#x27;s filtering out things. Maybe it&#x27;s, like, designing benchmarks. Try to correlate with those. Yeah. Otherwise, it just seems to have this giant bucket with maybe, like, one quality knob. And it&#x27;s, like, it&#x27;s very hard to make progress if all you can adjust is, like, one number we cut for quality here. So, it&#x27;s, I&#x27;m not surprised that, you know, the big labs, they almost have these tags. I want to know how they use them. That&#x27;s, like, the part that&#x27;s not good. That&#x27;s the part that&#x27;s not good. Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [00:53:51]: But it&#x27;s also not just you have more levers to pull and then, you know, the more things you can try, the better. It&#x27;s also you want tags that are actionable, right? So, like, if you had a sensible notion of a tag and you realize, oh, more of this data as you keep adding more of this lever, performance keeps going up. At some point, you might be, like, we&#x27;re out of that data. We need to go get more of that. Without that tag, you want that tag to be something that&#x27;s understandable so you can go and negotiate another deal, do synthetic generation, et cetera, of that type of data.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:54:13]: Do you think most of the synthetic data gen, is for very specific things at pre-training? I mean, it kind of has to be. Probably, yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [00:54:25]: You can&#x27;t just be, like, oh, it&#x27;s generative data. Like, that&#x27;s not something, I don&#x27;t know what that procedure is.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:54:30]: It&#x27;s probably to prime the model to whatever you need during post-training. Like, you know, we&#x27;ve seen, like, normally with math, it&#x27;s much better if your model has an elementary knowledge of math to, like, improve on that. It&#x27;s quite the same with everything that it&#x27;s, like, oh, I want to do RL on this. If the model is completely random on it, you&#x27;re going to have a very hard time.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:54:52]: Yeah, it&#x27;s, like, I guess a good transition. It&#x27;s, like, what do you three think post-training is, should be, or, like, is not doing?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [00:55:02]: It&#x27;s elicitation.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    I&#x27;m coming around to this view that it seems that you can extract abilities from the model.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   I think it&#x27;s totally elicitation. Like, the Hitchhiker&#x27;s Guide to Data paper from Google, yeah, that one was very, that one had, like, a very specific experiment. But it seemed like that was pretty strong evidence towards it. It&#x27;s, like, you filter out all of this type of data, you literally can&#x27;t fine-tune that model. You can never recover that. There was a history detection, right?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:55:28]: I think if you do more flops, you potentially can. I mean, it&#x27;s obvious, like, we&#x27;re not talking about, like, O1 stuff things here. But, like, there are even datasets that have, like, 15 million math-only instructions. Are they going to be able to really start doing a ton of math? At some point, yes. Yeah. But I think that most of it, or it&#x27;s almost easier to operate. I mean, it&#x27;s just like, assume that capabilities are in this model and are post-training to get it out.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:55:53]: Sometimes there&#x27;s this very large set of, like, things that you do in pre-training because you have a sense of, like, how they play an application. I think one day it&#x27;s, like, very obvious. It&#x27;s like, code model, you want to do, you want them to do completion, you&#x27;re going to add, fill in the middle of loss, maybe at the beginning of pre-training. It&#x27;s like, oh, then I can play my entire pipeline around like that. So it&#x27;s all about... So far, it seems all about that. I don&#x27;t think we have cracked a good recipe to do the same for things that are not capabilities, but they&#x27;re, like, recalling facts. Oh, yeah. Or, like, long-term knowledge.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:56:29]: Yeah. It&#x27;s, like, all of us, like, all know, or, like, I don&#x27;t know, at least people out there have MLMU numbers that go up in X stage. Like, instruction tuning, boosting MLMU, I&#x27;m like, what are you putting in there?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:56:42]: What do you think of mid-training then? Is that a manifestation or... Mid-training? I think it&#x27;s still...
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [00:56:47]: I think it&#x27;s still positive knowledge. I think mid-training is, it&#x27;s just, it&#x27;s still pre-training, but with strong domain effects. It&#x27;s just smoothing out the boundary between, you have a very, very sharp distribution shift when you do post-training, and we know from, like, kind of ML101 from the past five, six years, that smooth, smoothing out, helping, like, transition between major domain shifts helps. But we don&#x27;t have a clear example of where, like, it helps with specific knowledge acquisition. Yes. For them, we don&#x27;t know how to do it. But for, like, you that are really easy to evaluate, things that are really big progress on, it&#x27;s like, yeah, smooth this out.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:57:30]: So, like, why is post-training important to the release site? Some of you guys came around to, like, post-training being important for getting traction later on. Is that just, like, an ML ecosystem, how it works?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    Oh, I mean, the base model is kind of useless, right? Yeah. There&#x27;s only so many next tokens you need to know about. Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [00:57:50]: But it&#x27;s like, you know, we&#x27;ve seen papers that use all the research, for example, where the idea for that research only came by comparing base model with, you know, instruction team model, like, the one where folks, they were involved around, like, certain pattern of speech and OLMo 1. Where do they come from? Do they come from pre-training? Do they come from post-training? And, like, even if you just want to do research, it&#x27;s kind of useful to being able to compare side by side. So it feels wrong to put a model out that it, like, cuts sort of the problem that you can study in half until you have the post-training ready. And it&#x27;s useful to have all in one package so you can use it right away.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [00:58:40]: Post-training is just, like, a really, really long eval loop. Yeah. And that&#x27;s a lot like, oh, base model, you know, a few shots, a few shots on some benchmarks, like, no, no, no. We eval it by post-training it and then eval it in post-training.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:58:54]: Yeah. I mean, to some extent, it is kind of true. I mean, that&#x27;s how we should think about it.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [00:58:59]: If we could do that cheaply, we would totally hill climb on that metric.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    I think that&#x27;s the metric. Because if base model is the good in it for the post-training, which is the model people actually want to use, then we evaluate it on its own. And on its status as a good in it.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:59:16]: Yeah. So it&#x27;s like, how do we... And then the question is, like, how important do you think research for post-training on the specific checkpoint is? It&#x27;s like, how important is genealogy versus, like, general recipes? Because I think we... I openly think we under-index on using one model. Because much like the path to stability, which is a eight to ten month really specific thing, I&#x27;m guessing if you&#x27;re really just, like, in a narrower regime, you can just keep kind of turning these little things. Yeah. Hopefully at some point we can do better with new models. Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [00:59:52]: Okay. We&#x27;re kind of going to some wrap-up things. How do you think about release decisions? Like, should AI2 release everything that we ever tried? Or is it, like, when should we actually get models out the door?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    I mean, I would love to do that, actually. Especially the failed runs. You know, like, where else could you get a repository of failed runs? Yeah. I mean, I think it&#x27;s just a matter of giving other people the possibility of looking into these failed runs and finding out exactly when they failed. In practice, that&#x27;s super difficult. Because just releasing something is hard. You know, you need to upload the checkpoints and translate them in a different format. And you have to describe what you were even trying in some way that makes sense to people outside of the org. Give them access to the weights and biases and to the logs. And it&#x27;s just a lot of work. And there&#x27;s always something else that seems more pressing than that.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    Seems like a scaling. Like, how much we can share is capped by how we can scale our org. Which, like, we&#x27;re not going to have a complicated management hierarchy or, like, an entire org that is just support. And everything you upload, you build as a support burden. It&#x27;s like, literally, we just have seen the envelope grow, grow, grow. It&#x27;s like, more people use our things, you get, like, boring support. Like, people want to use it. That&#x27;s the cost of it.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    I guess it&#x27;s a great problem to have. People want to use it. People want to use us.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [01:01:15]: And it&#x27;s funny. To make a checkpoint where, like, some are very useful, you need the person who was involved. You have to fill, right? You need the person who was involved in it to sort of pour their knowledge into a format that then, you know, people can consume outside, right? Otherwise, you know, we would just open up our S3 bucket, the checkpoint, and it would be, like, utterly useless. Because what if you wanted to know more of the parameters, so, like, as long as we optimize for release, then we have the bandwidth to provide, like, the support around that. If people want the 70B fail run enough, you know, I&#x27;m sure we can release it.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [01:01:57]: It seems like it&#x27;s just finding the right medium to release things. Like, I think long-time people reports are really good for the stuff that we do, because it just puts everything in one place for people, and it almost makes on-demand easier in the future. Whereas, like, we could just drip and drag models out all the time, but, like, that&#x27;s not something we can&#x27;t do. It&#x27;s just, like, not... In terms of making progress in things that are easy to build on, it&#x27;s probably just not worth it.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [01:02:19]: In fact, there&#x27;s even a cost to it, right? The big example here is we had a release of OLMo 1 0724, or July 1. Yeah. I think research, using that for research, that has been probably one of the tougher models, because it didn&#x27;t come with a blog post, it didn&#x27;t come with, like, some docs. And so, yes, it still waits for checkpoints and everything, but comparatively, usually, even when people come to us, we&#x27;re like, oh, we recommend you use 0424. And now with OLMo 2, we&#x27;re like, oh, that&#x27;s the one we recommend, because it has all the documentation. So just dropping something doesn&#x27;t seem like it really helps.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [01:02:56]: I would say we should move faster than, like, the 1-2 iteration. But the in-between is not necessarily even worth it. Which is very odd, when you think about being fully open. It&#x27;s just, like, kind of with the costs of doing business.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [01:03:10]: It&#x27;s like being fully... You want to be fully open, but you don&#x27;t want to add noise. And you don&#x27;t want to waste people&#x27;s time. Right? So if you drop something that&#x27;s kind of half done or half baked, and people start spending time on it, only to get frustrated later, you&#x27;ve cost them something.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [01:03:22]: How does this relate to, like, how pre-training is changing? Like, do you think we need to invest in... Like, openly, a lot of startups are changing their relationship to training. And if they&#x27;re going to use Llama or pre-training or customer data, and then we have X compute budget, and does any of this come into play? Or is, like, it&#x27;s all the same with the talking? It&#x27;s, like, continue to hill climb, do what you can, reasonable trade-offs, and who will actually use the models? It&#x27;s, like, not too different.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [01:03:54]: I think that the... So for me, the cutoff point is, like, is there something useful and generally interesting to add if you pre-train? The case of Llama, all this, like, mid-train things that we concluded, we done. It couldn&#x27;t be as clean if we started with an already pre-trained model. So it&#x27;s, like, is there really something useful to add to the conversation if you pre-train? If we get to the moment when the answer is no, or, for work, like I was saying. But it feels there&#x27;s still value to add to the conversation. At least in the research side, like, pre-training, there is tonight a question of, like, we know how to help researchers. We want to help more than just researchers with the models we put out. And if we think there is this application that we can do a very good job, or just this use case, a very good job by starting with someone else&#x27;s pre-trained model, we shouldn&#x27;t waste compute on pre-training from scratch. Just saying. We can solve that. But it&#x27;s an ever-evolving question, really. It&#x27;s, like, I don&#x27;t know. We can make decisions six months out, maybe? Maybe a year?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [01:05:24]: Well, that&#x27;s what I would say.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [01:05:27]: I know. You&#x27;re the pre-training. You&#x27;re the hardcore who&#x27;s pre-trained some models.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [01:05:34]: There&#x27;s lots of runway left in pre-training. The big labs are fairly conservative because they have to be. But that doesn&#x27;t mean that we&#x27;re done. I mean, it&#x27;s not that we&#x27;re done. I also feel that the point of all is to make pre-training research accessible to more people, because even if you don&#x27;t have the resources to pre-train the whole thing from scratch, you can still use our checkpoints and use our code to prove out some sort of improvement. And as we&#x27;ve seen in other areas, even Microsoft tries to push .NET or Apple tries to push Swift or whatever. They try to, like, it&#x27;s a really big effort for them, and they try to push this. And the open-source community says, I don&#x27;t care. We&#x27;re going to use Python. And Python wins. So if you can somehow enable the vast resources of a million people banging on a thing, even a company like OpenAI or Meta cannot compete with that. And with OLMo, I&#x27;m hoping to capture that a little bit, that if we can capture something with some of the open-source enthusiasm and the academic enthusiasm.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    Do you think it&#x27;ll get better this year? Because a lot of academics are bringing on tens of hundreds of H100 clusters around the country. Like, before, it was like just Harvard had 500 and MIT or whatever. But now it&#x27;s like the long tail of universities. Like, there are a lot of people.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [01:07:12]: And then, you know, if you have 200 H100s, you can at least establish scaling laws for your idea. So, like, what I&#x27;m hoping is someone uses OLMo to try some new thing, establish the scaling laws up to a 3B model or whatever. Then we take it and we prove it up to 30B or whatever our computer allows. And if it still works, then, and if it&#x27;s probably going to open, then I take it. And let them win. Let&#x27;s not win. Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [01:07:36]: I mean, they would never tell us that they&#x27;d win. Yeah. Like, what do we need to achieve this? Do we need resources and compute and certain people? Like, do we need more feedback from the community? Do we need feedback from people at labs telling us which things to do?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [01:07:48]: Compute and people, for sure. That is undeniable. If you have more computes, you can try more things. We can go bigger. If you have more people just trying more things, especially like on our artifacts, we&#x27;ll just learn so much more and not have to just like, we spend so much time guess working, trying to piece together things from other people&#x27;s pieces. And sometimes it&#x27;s nice to just get something out of it. So if they did this on OLMo, we can immediately start working off of it. So people, compute, always, for sure.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Luca Soldaini
   &lt;/strong&gt;
   &lt;span&gt;
    [01:08:20]: One thing that I, we get a lot of feedback, but it&#x27;s like, I really like AI2. I would like to use OLMo, but it&#x27;s missing this feature, which is great. I love that feedback. It&#x27;s helped us a lot in prioritization. If we could get more, I would love to also get like aspirational feedback of like, none of the models is doing this. But I have a good case for this. Yeah. Those to me are always like very inspiring to read. Whether we&#x27;ll do it or not, it&#x27;s, you know, it&#x27;s a question of like, can we do it and how it works with other things.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [01:08:55]: But those are always very, very welcome. You know what would be really cool? I think what would be really cool is like more projects in space that you can&#x27;t do unless you have some sort of fully open constellation of artifacts. Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [01:09:09]: The thing that Dirk, does anyone ever do the thing where you load the model into one GPU and like iterate through the batches to find the one that, what happens when it blows up and the, or like when a loss spike happens?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    I mean, to some degree we did this ourselves. Yeah. But it&#x27;s like something that people can do. It&#x27;s not like we wrote a paper about that, but, but yeah, I would, I would love to see a detailed write-up of like millisecond by millisecond, what happens in a retention when a loss spike happens. You know, how, how does it actually happen? These are the things that people can do.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    And it&#x27;s like, you just have to keep, keep zooming into a specific level of details in what happens.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. I mean, right now we&#x27;re having, someone is using the various checkpoints to see how a certain metric that we&#x27;re interested in develops throughout pre-training. Yeah. And it&#x27;s like, you can do that with fairly minimal compute. You don&#x27;t have to be AI2. Yeah. It&#x27;s like one of my favorite weird language law papers. It&#x27;s the Sander Land fishing for Magic Karp paper. And it&#x27;s like, you can get much more actual feedback looking at weird tokenization. Yeah. You can get much more actual feedback looking at weird tokenizer impacts and tokenizer data interactions on old mode than just picking API models and figuring it out.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [01:10:20]: A lot of also, there&#x27;s a lot of really forward looking at the checkpoints that we have with the data patches and trying to do something like, okay, let&#x27;s replay this, the, between everything between these steps by rejecting some different data or manipulating the data between these two checkpoints, just to see how it turns to something different. How big of a fork does it go through? Yeah.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [01:10:39]: Like if you add the same intervention, like how big does it go through? Exactly. And just to see how it turns to something different.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [01:10:43]: So it&#x27;s like reconverge. Or early in pre-training versus later in pre-training same interventions, messing with the data. It&#x27;s just like, that stuff is really cool.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [01:10:49]: I mean, I think there&#x27;s, I&#x27;ve complained about this for a long time. Grad students, I think, are a little bit hesitant to go into pre-training stuff because they need to publish four papers a year. And it&#x27;s pretty difficult to do that when your cycles are so long. But on the flip side, it&#x27;s a bit less busy a field. Yeah. So less likely to get scooped if the field doesn&#x27;t change out from under you while you&#x27;re in the middle of your project. Yeah. Post-training is not quite as much as it happens on your side.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    It makes no sense. It&#x27;s just like, pick something you want to do and people will probably do it. That&#x27;s okay.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Dirk Groeneveld
   &lt;/strong&gt;
   &lt;span&gt;
    [01:11:31]: So I&#x27;m hoping that by publishing all of this stuff and making all the checkpoints available and the data and so on, we can enable more people to work in that side as well.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    Yeah. Anything else you guys want to add?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [01:11:49]: Like, comment, subscribe.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Kyle Lo
   &lt;/strong&gt;
   &lt;span&gt;
    [01:11:52]: Yeah, I think that&#x27;s it.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Nathan Lambert
   &lt;/strong&gt;
   &lt;span&gt;
    [01:12:01]: Okay. Thanks for listening. If you have questions for any of us individually, the Blue Sky and Twitter handles for everyone in this podcast are below. And you can reach out to the general OLMo contact at allenai.org. That&#x27;s an email address. Or we&#x27;re really happy to help and we want to keep building this kind of open scientific ecosystem of language models. So all the best. Bye bye. Bye.
   &lt;/span&gt;
  &lt;/p&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> DeepSeek R1&#x27;s recipe to replicate o1 and the future of reasoning LMs </title>
<link>https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1</link>
<pubDate>Tue, 21 Jan 2025 13:01:40 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;em&gt;
    I have a few shows to share with you this week:
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;em&gt;
      &lt;span&gt;
       On
      &lt;/span&gt;
      &lt;a href=&quot;https://retortai.com/episodes/we-ask-again-is-ai-a-science&quot; rel=&quot;&quot;&gt;
       The Retort
      &lt;/a&gt;
      &lt;span&gt;
       a week or two ago, we discussed the nature of AI and if it is a science (in the
      &lt;/span&gt;
      &lt;a href=&quot;https://en.wikipedia.org/wiki/The_Structure_of_Scientific_Revolutions&quot; rel=&quot;&quot;&gt;
       Kuhn’ian
      &lt;/a&gt;
      &lt;span&gt;
       sense)
      &lt;/span&gt;
     &lt;/em&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;em&gt;
      &lt;span&gt;
       I appeared on
      &lt;/span&gt;
      &lt;div&gt;
       &lt;a data-attrs=&#x27;{&quot;name&quot;:&quot;Dean W. Ball&quot;,&quot;id&quot;:5925551,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49371abf-2579-47be-8114-3e0ca580af8b_1024x1024.png&quot;,&quot;uuid&quot;:&quot;667dd053-11d2-4e27-950f-4f6e2dc383d1&quot;}&#x27; data-component-name=&quot;MentionUser&quot; href=&quot;https://open.substack.com/users/5925551-dean-w-ball?utm_source=mentions&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;
        Dean W. Ball
       &lt;/a&gt;
      &lt;/div&gt;
     &lt;/em&gt;
     &lt;span&gt;
     &lt;/span&gt;
     &lt;em&gt;
      &lt;span&gt;
       and
      &lt;/span&gt;
      &lt;div&gt;
       &lt;a data-attrs=&#x27;{&quot;name&quot;:&quot;Timothy B. Lee&quot;,&quot;id&quot;:101111787,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb1b5f15-6a93-40b4-b47e-38dd725b320b_801x801.jpeg&quot;,&quot;uuid&quot;:&quot;27350dc1-8fb2-4387-b34b-ed49aaafbf88&quot;}&#x27; data-component-name=&quot;MentionUser&quot; href=&quot;https://open.substack.com/users/101111787-timothy-b-lee?utm_source=mentions&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;
        Timothy B. Lee
       &lt;/a&gt;
      &lt;/div&gt;
      &lt;span&gt;
       ’s new podcast
      &lt;/span&gt;
      &lt;div&gt;
       &lt;a data-attrs=&#x27;{&quot;name&quot;:&quot;AI Summer&quot;,&quot;id&quot;:3699040,&quot;type&quot;:&quot;pub&quot;,&quot;url&quot;:&quot;&quot;,&quot;uuid&quot;:&quot;64b14c0d-834c-447d-8ac2-ca2c9429e490&quot;}&#x27; data-component-name=&quot;MentionPub&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;
        AI Summer
       &lt;/a&gt;
      &lt;/div&gt;
      &lt;span&gt;
       to discuss “thinking models” and the border between post-training and reasoning methods. Listen
      &lt;/span&gt;
      &lt;a href=&quot;https://www.aisummer.org/p/nathan-lambert-on-the-rise-of-thinking&quot; rel=&quot;&quot;&gt;
       here
      &lt;/a&gt;
      &lt;span&gt;
       .
      &lt;/span&gt;
     &lt;/em&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;em&gt;
      &lt;span&gt;
       Finally, a talk I gave at NeurIPs on
      &lt;/span&gt;
      &lt;a href=&quot;https://youtu.be/grpc-Wyy-Zg&quot; rel=&quot;&quot;&gt;
       how I think about post-training for AI applications
      &lt;/a&gt;
      &lt;span&gt;
       is now public.
      &lt;/span&gt;
     &lt;/em&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;p&gt;
   &lt;em&gt;
    This post is likely getting cut off in email inboxes — I recommend reading online by clicking on the title!
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;hr/&gt;
  &lt;/div&gt;
  &lt;p&gt;
   Yesterday, January 20th, China’s open-weights frontier AI laboratory, DeepSeek AI, released their first full fledged reasoning model. It came as:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      A flagship reasoning language model,
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/deepseek-ai/DeepSeek-R1&quot; rel=&quot;&quot;&gt;
      R1
     &lt;/a&gt;
     &lt;span&gt;
      , trained via a 4-stage, RL heavy process. It is
     &lt;/span&gt;
     &lt;strong&gt;
      MIT-licensed
     &lt;/strong&gt;
     &lt;span&gt;
      which means companies and researchers can build upon and train on its outputs to accelerate the development and deployment of reasoning language models (RLMs).
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      An RL-only reasoning model trained directly from their V3 base model,
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/deepseek-ai/DeepSeek-R1-Zero&quot; rel=&quot;&quot;&gt;
      R1-Zero
     &lt;/a&gt;
     &lt;span&gt;
      (used to create training data for full R1).
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     A suite of open-weight models finetuned with supervised finetuning (SFT) data derived from R1 (similar data to one of their intermediate training steps).
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      A
     &lt;/span&gt;
     &lt;a href=&quot;https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf&quot; rel=&quot;&quot;&gt;
      technical report
     &lt;/a&gt;
     &lt;span&gt;
      detailing their RL training methods.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Models are available at
     &lt;/span&gt;
     &lt;a href=&quot;http://chat.deepseek.com&quot; rel=&quot;&quot;&gt;
      chat.deepseek.com
     &lt;/a&gt;
     &lt;span&gt;
      (via DeepThink) and in their
     &lt;/span&gt;
     &lt;a href=&quot;https://apps.apple.com/us/app/deepseek-ai-assistant/id6737597349&quot; rel=&quot;&quot;&gt;
      new app
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   &lt;span&gt;
    This post is less about the evaluation results (which, of course, are
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/TheXeophon/status/1881443117787984265&quot; rel=&quot;&quot;&gt;
    extremely good
   &lt;/a&gt;
   &lt;span&gt;
    and shown below)
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1#footnote-1-155269286&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     1
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    , but rather about
   &lt;/span&gt;
   &lt;em&gt;
    how training is done
   &lt;/em&gt;
   &lt;span&gt;
    and
   &lt;/span&gt;
   &lt;em&gt;
    what it all means
   &lt;/em&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!C1n1!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2f93421-cd08-4cf9-b348-a5a20c7becaf_1476x1272.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!C1n1!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2f93421-cd08-4cf9-b348-a5a20c7becaf_1476x1272.png 424w, https://substackcdn.com/image/fetch/$s_!C1n1!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2f93421-cd08-4cf9-b348-a5a20c7becaf_1476x1272.png 848w, https://substackcdn.com/image/fetch/$s_!C1n1!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2f93421-cd08-4cf9-b348-a5a20c7becaf_1476x1272.png 1272w, https://substackcdn.com/image/fetch/$s_!C1n1!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2f93421-cd08-4cf9-b348-a5a20c7becaf_1476x1272.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a2f93421-cd08-4cf9-b348-a5a20c7becaf_1476x1272.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1255,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:351092,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;1255&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!C1n1!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2f93421-cd08-4cf9-b348-a5a20c7becaf_1476x1272.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!C1n1!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2f93421-cd08-4cf9-b348-a5a20c7becaf_1476x1272.png 424w, https://substackcdn.com/image/fetch/$s_!C1n1!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2f93421-cd08-4cf9-b348-a5a20c7becaf_1476x1272.png 848w, https://substackcdn.com/image/fetch/$s_!C1n1!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2f93421-cd08-4cf9-b348-a5a20c7becaf_1476x1272.png 1272w, https://substackcdn.com/image/fetch/$s_!C1n1!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2f93421-cd08-4cf9-b348-a5a20c7becaf_1476x1272.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    This is a major transition point in the uncertainty in reasoning model research. Until now, reasoning models have been a major area of industrial research without a clear seminal paper. Before language models took off, we had the likes of the GPT-2 paper for pretraining or InstructGPT (and Anthropic’s whitepapers) for post-training. For reasoning, we were staring at
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/openais-o1-using-search-was-a-psyop&quot; rel=&quot;&quot;&gt;
    potentially misleading
   &lt;/a&gt;
   &lt;span&gt;
    blog posts. Reasoning research and progress is now locked in — expect huge amounts of progress in 2025 and more of it in the open.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   This again confirms that new technical recipes normally aren’t moats — the motivation of a proof of concept or leaks normally get the knowledge out.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    For one, look at the pricing of these reasoning models. OpenAI was likely charging more for its model due to the costs of long-context serving and being the only model in town, but now o1’s
   &lt;/span&gt;
   &lt;a href=&quot;https://openai.com/api/pricing/&quot; rel=&quot;&quot;&gt;
    pricing
   &lt;/a&gt;
   &lt;span&gt;
    at $15 per million input tokens / $60 output looks out of place relative to R1’s
   &lt;/span&gt;
   &lt;a href=&quot;https://api-docs.deepseek.com/quick_start/pricing&quot; rel=&quot;&quot;&gt;
    pricing
   &lt;/a&gt;
   &lt;span&gt;
    at $0.55 per million input tokens / $2.19 output (yes, o1-mini is cheaper at $3/$12 per million, but still almost a 10x difference). The price war that is coming for reasoning models will look like the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.latent.space/i/140396949/mixtral-sparks-a-gpuinference-race-to-the-bottom&quot; rel=&quot;&quot;&gt;
    Mixtral inference price war from 2023
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    With o3, OpenAI is likely technically ahead, but it is not generally available nor will the weights be available anytime soon. This points to the first time since Stable Diffusion’s release that the most relevant and discussed AI model is released with a very friendly license. Looking back at the journey “
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/t/open-source&quot; rel=&quot;&quot;&gt;
    open-source
   &lt;/a&gt;
   &lt;span&gt;
    ” AI has been on over the last 2.5 years, this is a surprising moment in time marked in the history books.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   We don’t entirely know how these models will be used in the future beyond code and math, but noises are constantly bubbling up that OpenAI’s o1-Pro is the best model for many more challenging tasks (I need to try it myself before making definitive recommendations).
  &lt;/p&gt;
  &lt;p&gt;
   The most useful post to write now is one that establishes the research area, the do’s and don’ts, and the open questions. Let’s get into the details.
  &lt;/p&gt;
  &lt;h2&gt;
   The DeepSeek R1 training recipe for reasoning
  &lt;/h2&gt;
  &lt;p&gt;
   The training of R1 comes in 4 stages:
  &lt;/p&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      “Cold-start” of supervised finetuning on synthetic reasoning data from the R1-Zero model.
     &lt;/span&gt;
     &lt;span&gt;
      &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1#footnote-2-155269286&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
       2
      &lt;/a&gt;
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Large-scale reinforcement learning training on reasoning problems “until convergence.”
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;a href=&quot;https://rlhfbook.com/c/10-rejection-sampling.html&quot; rel=&quot;&quot;&gt;
      Rejection sampling
     &lt;/a&gt;
     &lt;span&gt;
      on 3/4 reasoning problems and 1/4 general queries to start the transition to a general-purpose model.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Reinforcement learning training mixing reasoning problems (verifiable rewards) with general preference tuning reward models to polish the model.
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;p&gt;
   Below, the post breaks down each training stage into its core components, insights, and open questions.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The winds of o1 replication have been blowing strongly away from any sort explicit search (especially at inference time). It really was, and is, a language model with the new reasoning behaviors coming from a lot of RL training.
  &lt;/p&gt;
  &lt;div data-component-name=&quot;DigestPostEmbed&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/openais-o1-using-search-was-a-psyop&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;
   &lt;/a&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    Before we start, remember that to do this reasoning training well you need a very strong base model with long-context capabilities. Much like for standard post-training, we
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/sea_snell/status/1881453551974805684&quot; rel=&quot;&quot;&gt;
    don’t really know
   &lt;/a&gt;
   &lt;span&gt;
    what traits of a base model make for one that is more suited for direct RL training.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   Step 0. Training R1-Zero to initialize R1 with synthetic data
  &lt;/h3&gt;
  &lt;p&gt;
   DeepSeek R1 Zero will be best known as the first open model trained with “large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step.” Rumors had mentioned this for o1, but understanding how it worked wasn’t clear. This is a funky model that DeepSeek reports will sometimes change languages in reasoning or show signs of other reliability issues.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The minor usability issues with R1-Zero show why more than
   &lt;/span&gt;
   &lt;em&gt;
    just
   &lt;/em&gt;
   &lt;span&gt;
    large-scale RL is needed to train a fantastic reasoning model, but the RL part is the key to unlocking the reasoning behaviors we are searching for.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    They include the most interesting results for R1-Zero, including the plot I’ve been asking for of RL-training time scaling. Since o1’s release, everyone has been obsessed with the plots showing how
   &lt;/span&gt;
   &lt;em&gt;
    inference time
   &lt;/em&gt;
   &lt;span&gt;
    is correlated with evaluation performance. Inference time is far easier to elicit (or force by using a framework like Monte Carlo Tree Search), but showing
   &lt;/span&gt;
   &lt;em&gt;
    training time
   &lt;/em&gt;
   &lt;span&gt;
    improvements via RL is the real foundational result. This is the result I’m searching for in my research.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!8mIS!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cc1c572-f0ab-4247-a062-04780a3321ed_1916x1074.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!8mIS!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cc1c572-f0ab-4247-a062-04780a3321ed_1916x1074.png 424w, https://substackcdn.com/image/fetch/$s_!8mIS!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cc1c572-f0ab-4247-a062-04780a3321ed_1916x1074.png 848w, https://substackcdn.com/image/fetch/$s_!8mIS!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cc1c572-f0ab-4247-a062-04780a3321ed_1916x1074.png 1272w, https://substackcdn.com/image/fetch/$s_!8mIS!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cc1c572-f0ab-4247-a062-04780a3321ed_1916x1074.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7cc1c572-f0ab-4247-a062-04780a3321ed_1916x1074.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:816,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:382961,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;816&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!8mIS!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cc1c572-f0ab-4247-a062-04780a3321ed_1916x1074.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!8mIS!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cc1c572-f0ab-4247-a062-04780a3321ed_1916x1074.png 424w, https://substackcdn.com/image/fetch/$s_!8mIS!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cc1c572-f0ab-4247-a062-04780a3321ed_1916x1074.png 848w, https://substackcdn.com/image/fetch/$s_!8mIS!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cc1c572-f0ab-4247-a062-04780a3321ed_1916x1074.png 1272w, https://substackcdn.com/image/fetch/$s_!8mIS!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cc1c572-f0ab-4247-a062-04780a3321ed_1916x1074.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   And an unsurprising, yet very satisfying plot of length growing with training. This could be mixed with the above plot to make one of the “inference time scaling” plots we have seen many versions of with less clear methods.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!KVEL!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75974ec6-d89b-4c81-a7e5-9530145f5e6c_1910x1088.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!KVEL!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75974ec6-d89b-4c81-a7e5-9530145f5e6c_1910x1088.png 424w, https://substackcdn.com/image/fetch/$s_!KVEL!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75974ec6-d89b-4c81-a7e5-9530145f5e6c_1910x1088.png 848w, https://substackcdn.com/image/fetch/$s_!KVEL!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75974ec6-d89b-4c81-a7e5-9530145f5e6c_1910x1088.png 1272w, https://substackcdn.com/image/fetch/$s_!KVEL!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75974ec6-d89b-4c81-a7e5-9530145f5e6c_1910x1088.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/75974ec6-d89b-4c81-a7e5-9530145f5e6c_1910x1088.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:829,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:436967,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;829&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!KVEL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75974ec6-d89b-4c81-a7e5-9530145f5e6c_1910x1088.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!KVEL!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75974ec6-d89b-4c81-a7e5-9530145f5e6c_1910x1088.png 424w, https://substackcdn.com/image/fetch/$s_!KVEL!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75974ec6-d89b-4c81-a7e5-9530145f5e6c_1910x1088.png 848w, https://substackcdn.com/image/fetch/$s_!KVEL!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75974ec6-d89b-4c81-a7e5-9530145f5e6c_1910x1088.png 1272w, https://substackcdn.com/image/fetch/$s_!KVEL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F75974ec6-d89b-4c81-a7e5-9530145f5e6c_1910x1088.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   In both of these plots, it looks like the numbers could still be going up if they let the RL cook longer. With the pace of progress so high, these laboratories get more gains by ending the jobs near saturation and starting the next experiment instead of seeking that last 1%.
  &lt;/p&gt;
  &lt;p&gt;
   Most, if not all, researchers will skip the step of training an R1-Zero style model because they don’t need to. DeepSeek made it clear that their “cold start” of SFT reasoning traces makes the final R1 model better — this is unsurprising, as they want R1 to be a certain type of instruction-tuned model. It’ll help avoid some of the “RL oddities” in R1-Zero that DeepSeek mentions like changing language mid-generation.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Still, the area of RL-on-base-models should be studied further. The way that R1-Zero can be trained is quite clever as most base models without any instruction tuning have a major issues with rambling and never generating a stop token. R1-Zero avoids this with a system prompt telling the model to generate &amp;lt;answer&amp;gt; HTML tags. Additionally, I suspect this type of training wouldn’t work on older base models that don’t have some standard post-training style instruction data in the pretraining corpus. For example, in OLMo 2 we had some MATH instruction data in the
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/datasets/allenai/dolmino-mix-1124&quot; rel=&quot;&quot;&gt;
    annealing mix
   &lt;/a&gt;
   &lt;span&gt;
    . Just a few instructions will let this system prompt work.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   In fact, the trend of increasing generation length via RL training could be even stronger when training directly from a base model rather than a standard post-trained model that doesn’t have a verbose chain of thought style. In order for RL to really start cranking up the response length in such an instruction-following model it will have to unlearn a certain response length that was baked in. For example, in Tülu 3’s final stage of RL finetuning, the phase where the response rate first goes down could be the barrier of misalignment between a larger round of SFT training before a smaller RL setup.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!2vF9!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dab8b2e-ee61-41d6-911a-bcc105d7f5da_1564x356.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!2vF9!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dab8b2e-ee61-41d6-911a-bcc105d7f5da_1564x356.png 424w, https://substackcdn.com/image/fetch/$s_!2vF9!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dab8b2e-ee61-41d6-911a-bcc105d7f5da_1564x356.png 848w, https://substackcdn.com/image/fetch/$s_!2vF9!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dab8b2e-ee61-41d6-911a-bcc105d7f5da_1564x356.png 1272w, https://substackcdn.com/image/fetch/$s_!2vF9!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dab8b2e-ee61-41d6-911a-bcc105d7f5da_1564x356.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8dab8b2e-ee61-41d6-911a-bcc105d7f5da_1564x356.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:331,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:236004,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;331&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!2vF9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dab8b2e-ee61-41d6-911a-bcc105d7f5da_1564x356.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!2vF9!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dab8b2e-ee61-41d6-911a-bcc105d7f5da_1564x356.png 424w, https://substackcdn.com/image/fetch/$s_!2vF9!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dab8b2e-ee61-41d6-911a-bcc105d7f5da_1564x356.png 848w, https://substackcdn.com/image/fetch/$s_!2vF9!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dab8b2e-ee61-41d6-911a-bcc105d7f5da_1564x356.png 1272w, https://substackcdn.com/image/fetch/$s_!2vF9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dab8b2e-ee61-41d6-911a-bcc105d7f5da_1564x356.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
      &lt;div&gt;
      &lt;/div&gt;
     &lt;/div&gt;
    &lt;/a&gt;
    &lt;figcaption&gt;
     Note, the x axis here is episodes, which is different than the “step” used in the DeepSeek plots.
    &lt;/figcaption&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    Zooming in on the x-axes of these R1-Zero plots, you can see that they’re doing 1000s of “RL steps.” RL step in this case refers to the model update step, which comes after multiple generations are made for the prompts in the batch and then answers are verified.
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1#footnote-3-155269286&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     3
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    This is a large amount of RL training, especially with such a large model. For reference, in our
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2411.15124&quot; rel=&quot;&quot;&gt;
    Tülu 3
   &lt;/a&gt;
   &lt;span&gt;
    work, we finetuned our models for 100s of steps normally, and the biggest models we are releasing soon only trained for ~50 steps of RL.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   This is scaled-up RL relative to existing literature. R1 proper surely uses a similar setup, but DeepSeek did not include the same details, so the rest of this post relies more on explicit text in the paper.
  &lt;/p&gt;
  &lt;h3&gt;
   Step 1. Reasoning SFT “Cold Start”
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;span&gt;
    In order to
   &lt;/span&gt;
   &lt;strong&gt;
    improve the readability
   &lt;/strong&gt;
   &lt;span&gt;
    (i.e. help maintain formatting) and
   &lt;/span&gt;
   &lt;strong&gt;
    increase the final performance
   &lt;/strong&gt;
   &lt;span&gt;
    of the final reasoning model, DeepSeek performs a small amount of supervised finetuning on the original base model with “a few thousand” filtered completions from the R1-Zero model. This involves a few tricks (none of which seem essential, you just need some of this data), such as:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    Using few-shot prompting with a long CoT as an example, directly prompting models to generate detailed answers with reflection and verification, gathering DeepSeek-R1-Zero outputs in a readable format, and refining the results through post-processing by human annotators.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   For replication efforts, any of these can be done. In fact, using DeepSeek-R1 itself is likely the easiest way.
  &lt;/p&gt;
  &lt;p&gt;
   This phase readies the loss landscape of the model to make the “emergent” behaviors like “wait, let me check my work” or “that was wrong” come forth more easily in RL training.
  &lt;/p&gt;
  &lt;h3&gt;
   Step 2. Large-scale RL for reasoning
  &lt;/h3&gt;
  &lt;p&gt;
   As a reminder, RL for reasoning models is built on a simple idea where you should reward the model for getting correct answers to problems where you can check if it has a correct answer. A basic feedback loop of this looks like the following:
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!4T2d!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b709d1-9bb7-436f-9d07-08ead28eef2d_923x477.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!4T2d!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b709d1-9bb7-436f-9d07-08ead28eef2d_923x477.png 424w, https://substackcdn.com/image/fetch/$s_!4T2d!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b709d1-9bb7-436f-9d07-08ead28eef2d_923x477.png 848w, https://substackcdn.com/image/fetch/$s_!4T2d!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b709d1-9bb7-436f-9d07-08ead28eef2d_923x477.png 1272w, https://substackcdn.com/image/fetch/$s_!4T2d!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b709d1-9bb7-436f-9d07-08ead28eef2d_923x477.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f1b709d1-9bb7-436f-9d07-08ead28eef2d_923x477.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:477,&quot;width&quot;:923,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:86239,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;477&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!4T2d!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b709d1-9bb7-436f-9d07-08ead28eef2d_923x477.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!4T2d!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b709d1-9bb7-436f-9d07-08ead28eef2d_923x477.png 424w, https://substackcdn.com/image/fetch/$s_!4T2d!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b709d1-9bb7-436f-9d07-08ead28eef2d_923x477.png 848w, https://substackcdn.com/image/fetch/$s_!4T2d!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b709d1-9bb7-436f-9d07-08ead28eef2d_923x477.png 1272w, https://substackcdn.com/image/fetch/$s_!4T2d!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b709d1-9bb7-436f-9d07-08ead28eef2d_923x477.png 1456w&quot; width=&quot;923&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
    &lt;figcaption&gt;
     System diagram for the RLVR finetuning in Tülu 3. https://arxiv.org/abs/2411.15124
    &lt;/figcaption&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    Exactly what the “reward” is here (the same question applies for R1-Zero) isn’t detailed. DeepSeek mentions three reward components during the reasoning phase of RL:
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1#footnote-4-155269286&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     4
    &lt;/a&gt;
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Accuracy rewards:
     &lt;/strong&gt;
     &lt;span&gt;
      These are score bonuses if the response to a prompt is correct. I’ve been referring to these as “verifiable” domains and in OpenAI’s
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/openais-reinforcement-finetuning&quot; rel=&quot;&quot;&gt;
      Reinforcement Finetuning
     &lt;/a&gt;
     &lt;span&gt;
      this is handled by their graders. TLDR: If the answer is correct, the reward is positive, if not, it is 0.
     &lt;/span&gt;
     &lt;span&gt;
      &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1#footnote-5-155269286&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
       5
      &lt;/a&gt;
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Format rewards:
     &lt;/strong&gt;
     &lt;span&gt;
      These are rewards (or penalties if not satisfied) to check and make sure that the model follows the correct formatting of &amp;lt;think&amp;gt; or &amp;lt;/think&amp;gt; and &amp;lt;answer&amp;gt; and &amp;lt;/answer&amp;gt; for stable inference.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Language consistency rewards
     &lt;/strong&gt;
     &lt;span&gt;
      : A reward is added to the model if the language of the answer is 100% matching the language of the question. DeepSeek writes that this additional reward shows a “slight degradation in the model’s performance,” but better human preferences. It’s added to make the model nice to use, which is a wonderful reminder that evaluation scores are not all that matters.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;p&gt;
   &lt;span&gt;
    The first reward here drives the majority of the learning and the other two are guardrails for creating a stable model (which is not to say they aren’t important implementation details, but rather that the first one is necessary and the others may not be). To optimize this reward, DeepSeek uses the RL algorithm that they introduced,
   &lt;/span&gt;
   &lt;a href=&quot;https://rlhfbook.com/c/11-policy-gradients.html#group-relative-policy-optimization&quot; rel=&quot;&quot;&gt;
    Group Relative Policy Optimization
   &lt;/a&gt;
   &lt;span&gt;
    , which is the PPO update rule with a different value approximation method based on Monte Carlo advantage estimates rather than holding a separate value model in memory. The most likely explanation for this choice (much like how OpenAI has always used PPO) is that it is the mature implementation in their infrastructure.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    This image from the
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2402.03300&quot; rel=&quot;&quot;&gt;
    DeepSeekMath
   &lt;/a&gt;
   &lt;span&gt;
    paper is a fantastic comparison of PPO to GRPO (this is fine to skip this if you only care about the big picture recipe):
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!douJ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F21ce968f-4017-498f-a286-1f0ef034fa2a_883x441.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!douJ!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F21ce968f-4017-498f-a286-1f0ef034fa2a_883x441.png 424w, https://substackcdn.com/image/fetch/$s_!douJ!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F21ce968f-4017-498f-a286-1f0ef034fa2a_883x441.png 848w, https://substackcdn.com/image/fetch/$s_!douJ!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F21ce968f-4017-498f-a286-1f0ef034fa2a_883x441.png 1272w, https://substackcdn.com/image/fetch/$s_!douJ!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F21ce968f-4017-498f-a286-1f0ef034fa2a_883x441.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;Image&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/21ce968f-4017-498f-a286-1f0ef034fa2a_883x441.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:441,&quot;width&quot;:883,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;441&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!douJ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F21ce968f-4017-498f-a286-1f0ef034fa2a_883x441.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!douJ!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F21ce968f-4017-498f-a286-1f0ef034fa2a_883x441.png 424w, https://substackcdn.com/image/fetch/$s_!douJ!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F21ce968f-4017-498f-a286-1f0ef034fa2a_883x441.png 848w, https://substackcdn.com/image/fetch/$s_!douJ!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F21ce968f-4017-498f-a286-1f0ef034fa2a_883x441.png 1272w, https://substackcdn.com/image/fetch/$s_!douJ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F21ce968f-4017-498f-a286-1f0ef034fa2a_883x441.png 1456w&quot; title=&quot;Image&quot; width=&quot;883&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   The nature of the reward setup (and the data) is the key to this sort of reasoning training and many of the small RL details can be substituted for each other.
  &lt;/p&gt;
  &lt;p&gt;
   Much like the DeepSeek V3 paper, the details of what data they used to train the model are not included here. This is absolutely crucial and almost certainly involves many, many verifiable prompts with answers. In order to study these models the community needs open versions of these datasets.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    I would’ve loved to see details of their RL infrastructure (similar to the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/i/154176259/deepseeks-learning-efficiency&quot; rel=&quot;&quot;&gt;
    details
   &lt;/a&gt;
   &lt;span&gt;
    in the DeepSeek V3 paper), as many people are looking to build on these models. RL training requires holding multiple models in memory and alternating between generating, verifying, and taking loss steps. As
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/srush_nlp/status/1881383080528924868&quot; rel=&quot;&quot;&gt;
    Sasha Rush says
   &lt;/a&gt;
   &lt;span&gt;
    , “We need to code up verifiers ASAP,” which is what we are trying to do at Ai2 building on Tülu 3 and could use a lot of help with the
   &lt;/span&gt;
   &lt;a href=&quot;https://github.com/allenai/open-instruct&quot; rel=&quot;&quot;&gt;
    open-source code
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1#footnote-6-155269286&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     6
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    A good approach for entities interested here is to develop tooling and data for one domain at a time.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   These first two steps are not new but rather scaled-up versions of ideas people have been discussing extensively. The final two steps DeepSeek details in the paper are new applications of known techniques to help take their raw reasoning performance and “train a user-friendly model.”
  &lt;/p&gt;
  &lt;h3&gt;
   Step 3. Rejection Sampling to introduce general abilities
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;a href=&quot;https://rlhfbook.com/c/10-rejection-sampling.html&quot; rel=&quot;&quot;&gt;
    Rejection sampling
   &lt;/a&gt;
   &lt;span&gt;
    is a technique where you generate completions from a model, rank them via a reward model, and then finetune the original model (normally with the supervised finetuning loss) to improve performance on a variety of tasks. It’s one of the standard post-training tools used by Llama 3 and many others.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   DeepSeek uses rejection sampling to begin to introduce general capabilities back into the model. It is also the one stage where they include data numbers — 800K completions total, split as 600K for reasoning and 200K for general chat problems. The 800K number is not surprising to me given this is just a late-stage SFT training, but it is similar in size to the ~1M prompts we used in the Tülu 3 SFT mix which is the ballpark for leading post-training recipes.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The details in the paper are largely around methods for
   &lt;/span&gt;
   &lt;em&gt;
    generating responses
   &lt;/em&gt;
   &lt;span&gt;
    to prompts and
   &lt;/span&gt;
   &lt;em&gt;
    filtering
   &lt;/em&gt;
   &lt;span&gt;
    to prioritize high-quality training data. In order to bring more domains into the scope of abilities for the model, DeepSeek has a variety of tricks, such as:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     Using generative reward models (i.e. LLM-as-a-judge) to verify answers to questions that may not be explicitly verifiable,
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Data from the DeepSeek-V3 standard post-training pipeline, and
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Standard (nonverifiable) chat data augmented with extended chain of thought before answering to help the model generalize from reasoning training to broader use cases.
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   All in, we currently have very few details here and there is a lot of open space to learn (and likely improve).
  &lt;/p&gt;
  &lt;h3&gt;
   Step 4. Final RL training for general use
  &lt;/h3&gt;
  &lt;p&gt;
   Finally, DeepSeek R1 goes back to reinforcement learning, which really seems to be how most finetuning is ending these days. The second RL stage is “aimed at improving the model’s helpfulness and harmlessness while simultaneously refining its reasoning capabilities.”
  &lt;/p&gt;
  &lt;p&gt;
   In order to do this, they do RL training that mixes prompts from the verifiable domains (as done for R1-Zero) and prompts for standard RLHF preference tuning. In order to do this they have multiple reward models and build upon their post-training recipe in DeepSeek V3.
  &lt;/p&gt;
  &lt;p&gt;
   This is not easy to do and involves many questions: What is the right data balance? Can you use an off-the-shelf existing reward model or does it need to have seen long reasoning traces? Are there additional steps needed to not degrade performance? And so on.
  &lt;/p&gt;
  &lt;p&gt;
   As this grows into a larger area of research and development these questions will slowly be answered.
  &lt;/p&gt;
  &lt;p&gt;
   As this post has transitioned into the later stages of training, it is clear that many details are unknown. We have the general shape of how to sequence things and will fill in the details from here. I have a very long stack of reasoning-related research papers to poke through, and while they came before DeepSeek R1, they still will point toward answers.
  &lt;/p&gt;
  &lt;p&gt;
   All of this is solvable, as proven by how quickly DeepSeek went from the o1 release to matching performance with an open weights model.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div&gt;
   &lt;hr/&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   Discussions and next steps
  &lt;/h2&gt;
  &lt;p&gt;
   The DeepSeek R1 report has an entire other subsection dedicated to its distillation experiments, where it took completions from the R1 model and finetuned existing open-weight models with them to boost performance. This is a fantastic service for them to release this and provides a solid baseline for RL experiments on smaller models to try and match in the near future.
  &lt;/p&gt;
  &lt;p&gt;
   The discussion in the paper on how large models are required to see the biggest reasoning gains (and generate effective synthetic data) is likely the biggest open question:
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    First, distilling more powerful models into smaller ones yields excellent results, whereas smaller models relying on the large-scale RL mentioned in this paper require enormous computational power and may not even achieve the performance of distillation. Second, while distillation strategies are both economical and effective, advancing beyond the boundaries of intelligence may still require more powerful base models and larger-scale reinforcement learning.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   &lt;span&gt;
    As smaller models continually improve over the years, it is likely that the same type of training could work on something like Llama 5 or 6 8B. It leaves us with the same, open question as to
   &lt;/span&gt;
   &lt;em&gt;
    why
   &lt;/em&gt;
   &lt;span&gt;
    different abilities “emerge” at larger models. Scaling laws are the reasons that each generation’s
   &lt;/span&gt;
   &lt;em&gt;
    frontier
   &lt;/em&gt;
   &lt;span&gt;
    models tend to be the largest models available. The exciting form of this question for 2025 is: How
   &lt;/span&gt;
   &lt;em&gt;
    small
   &lt;/em&gt;
   &lt;span&gt;
    will the slow progress of language modeling research drive advanced reasoning capabilities?
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Every so often a paper comes around that makes the path forward clear. The last time I felt this way was with the Llama 3 report for post-training, which solidified into the
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/tulu-3&quot; rel=&quot;&quot;&gt;
    Tülu 3 paper
   &lt;/a&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div data-component-name=&quot;DigestPostEmbed&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/frontier-model-post-training&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;
   &lt;/a&gt;
  &lt;/div&gt;
  &lt;p&gt;
   Soon, I’ll comment on…
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     Distillation of reasoning traces (as done in the R1 paper),
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     The demise of process reward models (PRMs) and Monte Carlo Tree Search (MCTS),
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     Some things in the DeepSeek paper, like the “Aha” moment and over-indexing on human priors, that annoy me,
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     The new reasoning research coming out from academia,
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      The other reasoning model that dropped yesterday —
     &lt;/span&gt;
     &lt;a href=&quot;https://github.com/MoonshotAI/Kimi-k1.5/blob/main/Kimi_k1.5.pdf&quot; rel=&quot;&quot;&gt;
      Kimi 1.5
     &lt;/a&gt;
     &lt;span&gt;
      ,
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     The biggest application of Tülu 3 RLVR yet, and
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     All the other ideas that are under debate in the reasoning model space.
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   R1 is surely not the only way to train these models, but it is the recipe that people will build off immediately. Let’s get cranking on more datasets and infrastructure.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;em&gt;
    &lt;span&gt;
     For those new here, you can check out the
    &lt;/span&gt;
    &lt;a href=&quot;https://www.interconnects.ai/t/inference&quot; rel=&quot;&quot;&gt;
     Inference &amp; Reasoning
    &lt;/a&gt;
    &lt;span&gt;
     tag on Interconnects!
    &lt;/span&gt;
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1#footnote-anchor-1-155269286&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     It will take a substantial amount of work to be confident in how close the models actually are. If you had to have me choose I would choose OpenAI, as they’re serving a larger user base and in my opinion are less structurally inclined to maximize evaluation scores relative to actual usefulness. I’ll formulate stronger opinions here over time, but initial conversations make me think that the R1 model is in the ballpark.
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1#footnote-anchor-2-155269286&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    2
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     I do not count generating the reasoning data as step 0 as this can now be done easily with R1, Qwen QwQ, or alternatives. Soon, there will be plenty on HuggingFace.
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1#footnote-anchor-3-155269286&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    3
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     In our Tülu 3 paper we generally have reported episodes, which is related to steps, as it is the total numbers of prompts that we generate for and verify. The number of episodes is proportional to the batch size times the number of RL steps.
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1#footnote-anchor-4-155269286&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    4
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     DeepSeek says they “directly sum” these rewards, but without knowing the scales and shapes, that is not particularly insightful.
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1#footnote-anchor-5-155269286&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    5
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     Or a scaled/shaped version of this.
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1#footnote-anchor-6-155269286&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    6
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     &lt;span&gt;
      Ross Taylor is
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/rosstaylor90/status/1881372810485899716&quot; rel=&quot;&quot;&gt;
      also asking
     &lt;/a&gt;
     &lt;span&gt;
      about their reward shaping, which interacts very closely with the verifiers.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> DeepSeek V3 and the actual cost of training frontier AI models </title>
<link>https://www.interconnects.ai/p/deepseek-v3-and-the-actual-cost-of</link>
<pubDate>Thu, 09 Jan 2025 20:54:34 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    On December 26th, 2024, while most of the Western AI world was off on their Christmas holiday, China’s DeepSeek AI released their
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/deepseek-ai/DeepSeek-V3&quot; rel=&quot;&quot;&gt;
    DeepSeek-V3
   &lt;/a&gt;
   &lt;span&gt;
    general use model (and
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/deepseek-ai/DeepSeek-V3-Base&quot; rel=&quot;&quot;&gt;
    base model
   &lt;/a&gt;
   &lt;span&gt;
    ) with a detailed
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2412.19437&quot; rel=&quot;&quot;&gt;
    technical report
   &lt;/a&gt;
   &lt;span&gt;
    and a demo at
   &lt;/span&gt;
   &lt;a href=&quot;https://chat.deepseek.com/&quot; rel=&quot;&quot;&gt;
    chat.deepseek.com
   &lt;/a&gt;
   &lt;span&gt;
    . It’s their latest mixture of experts (MoE) model trained on 14.8T tokens with 671B total and 37B active parameters. Most people are aware of the extremely impressive results relative to other frontier language models — most notable of which are the substantial improvements over Llama 405B instruct with way fewer active parameters than the previous best open weights model:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!xjRN!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9714caa3-b0cc-44c8-a098-f0cd1cf1a564_1574x1058.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!xjRN!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9714caa3-b0cc-44c8-a098-f0cd1cf1a564_1574x1058.png 424w, https://substackcdn.com/image/fetch/$s_!xjRN!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9714caa3-b0cc-44c8-a098-f0cd1cf1a564_1574x1058.png 848w, https://substackcdn.com/image/fetch/$s_!xjRN!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9714caa3-b0cc-44c8-a098-f0cd1cf1a564_1574x1058.png 1272w, https://substackcdn.com/image/fetch/$s_!xjRN!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9714caa3-b0cc-44c8-a098-f0cd1cf1a564_1574x1058.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9714caa3-b0cc-44c8-a098-f0cd1cf1a564_1574x1058.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:979,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:279309,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; fetchpriority=&quot;high&quot; height=&quot;979&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!xjRN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9714caa3-b0cc-44c8-a098-f0cd1cf1a564_1574x1058.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!xjRN!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9714caa3-b0cc-44c8-a098-f0cd1cf1a564_1574x1058.png 424w, https://substackcdn.com/image/fetch/$s_!xjRN!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9714caa3-b0cc-44c8-a098-f0cd1cf1a564_1574x1058.png 848w, https://substackcdn.com/image/fetch/$s_!xjRN!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9714caa3-b0cc-44c8-a098-f0cd1cf1a564_1574x1058.png 1272w, https://substackcdn.com/image/fetch/$s_!xjRN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9714caa3-b0cc-44c8-a098-f0cd1cf1a564_1574x1058.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    The most impressive part of these results are all on evaluations considered extremely hard — MATH 500 (which is a
   &lt;/span&gt;
   &lt;a href=&quot;https://github.com/openai/prm800k/tree/main?tab=readme-ov-file#math-splits&quot; rel=&quot;&quot;&gt;
    random 500 problems from the full test set
   &lt;/a&gt;
   &lt;span&gt;
    ), AIME 2024 (the super hard competition math problems), Codeforces (competition code as
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/i/153428255/o-overview&quot; rel=&quot;&quot;&gt;
    featured in o3
   &lt;/a&gt;
   &lt;span&gt;
    ), and SWE-bench Verified (
   &lt;/span&gt;
   &lt;a href=&quot;https://openai.com/index/introducing-swe-bench-verified/&quot; rel=&quot;&quot;&gt;
    OpenAI’s improved dataset split
   &lt;/a&gt;
   &lt;span&gt;
    ). Beating the pair of GPT-4o and Claude 3.5 together, and by some margin, is extremely rare.
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/deepseek-v3-and-the-actual-cost-of#footnote-1-154176259&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     1
    &lt;/a&gt;
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Since release, we’ve also gotten confirmation of the ChatBotArena ranking that places them in the top 10 and over the likes of recent Gemini pro models, Grok 2, o1-mini, etc. With only 37B active parameters, this is extremely appealing for many enterprise applications.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!hKO_!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd40aec66-636c-4ed6-a988-61d0e9beb813_2468x1512.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!hKO_!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd40aec66-636c-4ed6-a988-61d0e9beb813_2468x1512.png 424w, https://substackcdn.com/image/fetch/$s_!hKO_!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd40aec66-636c-4ed6-a988-61d0e9beb813_2468x1512.png 848w, https://substackcdn.com/image/fetch/$s_!hKO_!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd40aec66-636c-4ed6-a988-61d0e9beb813_2468x1512.png 1272w, https://substackcdn.com/image/fetch/$s_!hKO_!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd40aec66-636c-4ed6-a988-61d0e9beb813_2468x1512.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d40aec66-636c-4ed6-a988-61d0e9beb813_2468x1512.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:892,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:439031,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;892&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!hKO_!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd40aec66-636c-4ed6-a988-61d0e9beb813_2468x1512.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!hKO_!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd40aec66-636c-4ed6-a988-61d0e9beb813_2468x1512.png 424w, https://substackcdn.com/image/fetch/$s_!hKO_!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd40aec66-636c-4ed6-a988-61d0e9beb813_2468x1512.png 848w, https://substackcdn.com/image/fetch/$s_!hKO_!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd40aec66-636c-4ed6-a988-61d0e9beb813_2468x1512.png 1272w, https://substackcdn.com/image/fetch/$s_!hKO_!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd40aec66-636c-4ed6-a988-61d0e9beb813_2468x1512.png 1456w&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    For the last week, I’ve been using DeepSeek V3 as my daily driver for normal chat tasks. This is everything from checking basic facts to asking for feedback on a piece of work. In all of these, DeepSeek V3 feels very capable, but how it presents its information doesn’t feel exactly in line with
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/switched-to-claude-from-chatgpt&quot; rel=&quot;&quot;&gt;
    my expectations from something like Claude
   &lt;/a&gt;
   &lt;span&gt;
    or ChatGPT. It almost feels like the character or post-training of the model being shallow makes it feel like the model has more to offer than it delivers. It’s a very capable model, but not one that sparks as much joy when using it like Claude or with super polished apps like ChatGPT, so I don’t expect to keep using it long term.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The striking part of this release was how much DeepSeek shared in how they did this. The technical report shares countless details on modeling and infrastructure decisions that dictated the final outcome. Many of these details were shocking and extremely unexpected — highlighting numbers that made Meta look wasteful with GPUs, which prompted many online AI circles to more or less freakout.
  &lt;/p&gt;
  &lt;p&gt;
   This post revisits the technical details of DeepSeek V3, but focuses on how best to view the cost of training models at the frontier of AI and how these costs may be changing.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;h2&gt;
   DeepSeek’s learning efficiency
  &lt;/h2&gt;
  &lt;p&gt;
   &lt;span&gt;
    We’ll get into the specific numbers below, but the question is, which of the many technical innovations listed in the DeepSeek V3 report contributed most to its
   &lt;/span&gt;
   &lt;em&gt;
    learning
   &lt;/em&gt;
   &lt;span&gt;
    efficiency — i.e. model performance relative to compute used.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Among the universal and loud praise, there has been some
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/giffmana/status/1872303369379082366&quot; rel=&quot;&quot;&gt;
    skepticism
   &lt;/a&gt;
   &lt;span&gt;
    on how much of this report is all novel breakthroughs,
   &lt;/span&gt;
   &lt;em&gt;
    a la
   &lt;/em&gt;
   &lt;span&gt;
    “did DeepSeek actually need Pipeline Parallelism” or “HPC has been doing this type of compute optimization forever (or also in TPU land)”.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The way to interpret both discussions should be grounded in the fact that
   &lt;/span&gt;
   &lt;strong&gt;
    &lt;span&gt;
     the DeepSeek V3 model is extremely good on a
    &lt;/span&gt;
    &lt;a href=&quot;https://x.com/cHHillee/status/1872395009267495407&quot; rel=&quot;&quot;&gt;
     per-FLOP comparison to peer models
    &lt;/a&gt;
   &lt;/strong&gt;
   &lt;span&gt;
    (likely even some closed API models, more on this below). All bells and whistles aside, the deliverable that matters is how good the models are relative to FLOPs spent. That is comparing efficiency.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Some of the noteworthy improvements in DeepSeek’s training stack include the following. It is debatable which of these is the largest factor in the model’s learning efficiency:
  &lt;/p&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Multi-head latent attention
     &lt;/strong&gt;
     &lt;span&gt;
      (MLA)
     &lt;/span&gt;
     &lt;span&gt;
      &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/deepseek-v3-and-the-actual-cost-of#footnote-2-154176259&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
       2
      &lt;/a&gt;
     &lt;/span&gt;
     &lt;span&gt;
      to minimize the memory usage of attention operators while maintaining modeling performance.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Multi-token prediction
     &lt;/strong&gt;
     &lt;span&gt;
      similar to as studied in this
     &lt;/span&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2404.19737&quot; rel=&quot;&quot;&gt;
      Meta paper
     &lt;/a&gt;
     &lt;span&gt;
      earlier in the year to improve modeling performance;
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Efficient mixture of expert architectures
     &lt;/strong&gt;
     &lt;span&gt;
      , which are continuing to perform better on benchmarks per FLOP of training compute (as we found
     &lt;/span&gt;
     &lt;a href=&quot;https://www.interconnects.ai/p/olmoe-and-building-better-llms?utm_source=publication-search&quot; rel=&quot;&quot;&gt;
      with OLMoE
     &lt;/a&gt;
     &lt;span&gt;
      );
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Partial 8-bit native training,
     &lt;/strong&gt;
     &lt;span&gt;
      &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/deepseek-v3-and-the-actual-cost-of#footnote-3-154176259&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
       3
      &lt;/a&gt;
     &lt;/span&gt;
     &lt;strong&gt;
     &lt;/strong&gt;
     &lt;span&gt;
      which can effectively double your compute by letting you fit twice as big a model in the same memory (in practice, you only quantize part of the weights or optimizer state, so the gain is &amp;lt;2X than one may think from 16-bit default of today); and
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Custom multi-GPU communication protocols
     &lt;/strong&gt;
     &lt;span&gt;
      to make up for the slower communication speed of the H800 and optimize pretraining throughput.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;p&gt;
   Each of these advancements in DeepSeek V3 could be covered in short blog posts of their own.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The post-training side is less innovative, but gives more credence to those optimizing for online RL training as DeepSeek did this (with a form of
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2212.08073&quot; rel=&quot;&quot;&gt;
    Constitutional AI
   &lt;/a&gt;
   &lt;span&gt;
    , as pioneered by Anthropic)
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/deepseek-v3-and-the-actual-cost-of#footnote-4-154176259&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     4
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    . The fact that the model of this quality is
   &lt;/span&gt;
   &lt;em&gt;
    distilled from
   &lt;/em&gt;
   &lt;span&gt;
    DeepSeek’s reasoning model series, R1, makes me more optimistic about the reasoning model being the real deal.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    There’s some
   &lt;/span&gt;
   &lt;a href=&quot;https://techcrunch.com/2024/12/27/why-deepseeks-new-ai-model-thinks-its-chatgpt/&quot; rel=&quot;&quot;&gt;
    controversy of DeepSeek training on outputs from OpenAI models, which is forbidden to “competitors” in OpenAI’s terms of service
   &lt;/a&gt;
   &lt;span&gt;
    , but this is now harder to prove with how many outputs from ChatGPT are now generally available on the web. It’s hard to filter it out at pretraining, especially if it makes the model better (so you may want to turn a blind eye to it).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Many of the techniques DeepSeek describes in their paper are things that our OLMo team at Ai2 would benefit from having access to and is taking direct inspiration from.
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/deepseek-v3-and-the-actual-cost-of#footnote-5-154176259&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     5
    &lt;/a&gt;
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    DeepSeek implemented many tricks to optimize their stack that has only been done well at 3-5 other AI laboratories in the world. Reproducing this is not impossible and bodes well for a future where AI ability is distributed across more players. The cost will come down over time, but the cited numbers are not yet true.
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/deepseek-v3-and-the-actual-cost-of#footnote-6-154176259&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     6
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;em&gt;
    &lt;strong&gt;
     Edit
    &lt;/strong&gt;
    &lt;span&gt;
     :
    &lt;/span&gt;
   &lt;/em&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;em&gt;
    &lt;span&gt;
     The “cited numbers” here mostly refers to the general reaction to the release among the general public, as DeepSeek explicitly states that the costs are not the full picture (thanks to
    &lt;/span&gt;
    &lt;a href=&quot;https://x.com/teortaxesTex/status/1877467302989295673/photo/1&quot; rel=&quot;&quot;&gt;
     Teortaxes for raising
    &lt;/a&gt;
    &lt;span&gt;
     ):
    &lt;/span&gt;
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    &lt;em&gt;
     Note that the aforementioned costs include only the official training of DeepSeek-V3, excluding the costs associated with prior research and ablation experiments on architectures, algorithms, or data.
    &lt;/em&gt;
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   &lt;em&gt;
    Onto the analysis.
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;h2&gt;
   DeepSeek’s compute transparency and reality
  &lt;/h2&gt;
  &lt;p&gt;
   &lt;a href=&quot;https://x.com/elonmusk/status/1815325410667749760&quot; rel=&quot;&quot;&gt;
    Flexing
   &lt;/a&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;a href=&quot;https://www.yahoo.com/tech/mark-zuckerberg-flexes-metas-cluster-184110557.html?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAAChJ4H5af7D-0GExpCN90r4ppqz2y1_sEXmuD1Ms50hRF-iZZYr7tV8u5SETv9X3xAcpoXhRLhTKp6KEjsTZKdApr6c37Nce69SqjuFHLu7Lhc6t5ZARLuwKtC6clhO8V6iohl7S3IIit9hIW9lwupemqRkqYnAJszAHs1Isg7ke&quot; rel=&quot;&quot;&gt;
    on
   &lt;/a&gt;
   &lt;span&gt;
    how much compute you have access to is common practice among AI companies. It’s also a powerful recruiting tool. It is strongly correlated with how much progress you or the organization you’re joining can make.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    For Chinese companies that are feeling the pressure of
   &lt;/span&gt;
   &lt;a href=&quot;https://semianalysis.com/2024/10/28/fab-whack-a-mole-chinese-companies/&quot; rel=&quot;&quot;&gt;
    substantial chip export controls
   &lt;/a&gt;
   &lt;span&gt;
    , it cannot be seen as particularly surprising to have the angle be “Wow we can do way more than you with less.” I’d probably do the same in their shoes, it is far more motivating than “my cluster is bigger than yours.” This goes to say that we need to understand how important the
   &lt;/span&gt;
   &lt;em&gt;
    narrative
   &lt;/em&gt;
   &lt;span&gt;
    of compute numbers is to their reporting.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   DeepSeek AI took Meta directly in their sights to convincingly claim the title of “lead open-weight frontier model laboratory.” They shared the following table in their paper about the amount of compute used to train their models:
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!pRUG!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c2fe4e2-4a9a-42ab-ba21-01ef31903bb7_888x168.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!pRUG!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c2fe4e2-4a9a-42ab-ba21-01ef31903bb7_888x168.png 424w, https://substackcdn.com/image/fetch/$s_!pRUG!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c2fe4e2-4a9a-42ab-ba21-01ef31903bb7_888x168.png 848w, https://substackcdn.com/image/fetch/$s_!pRUG!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c2fe4e2-4a9a-42ab-ba21-01ef31903bb7_888x168.png 1272w, https://substackcdn.com/image/fetch/$s_!pRUG!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c2fe4e2-4a9a-42ab-ba21-01ef31903bb7_888x168.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4c2fe4e2-4a9a-42ab-ba21-01ef31903bb7_888x168.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:168,&quot;width&quot;:888,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;168&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!pRUG!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c2fe4e2-4a9a-42ab-ba21-01ef31903bb7_888x168.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!pRUG!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c2fe4e2-4a9a-42ab-ba21-01ef31903bb7_888x168.png 424w, https://substackcdn.com/image/fetch/$s_!pRUG!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c2fe4e2-4a9a-42ab-ba21-01ef31903bb7_888x168.png 848w, https://substackcdn.com/image/fetch/$s_!pRUG!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c2fe4e2-4a9a-42ab-ba21-01ef31903bb7_888x168.png 1272w, https://substackcdn.com/image/fetch/$s_!pRUG!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c2fe4e2-4a9a-42ab-ba21-01ef31903bb7_888x168.png 1456w&quot; title=&quot;&quot; width=&quot;888&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
      &lt;div&gt;
      &lt;/div&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   With additional explanation in the text:
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    &lt;span&gt;
     During the pre-training state, training DeepSeek-V3 on each trillion tokens requires only 180K H800 GPU hours, i.e., 3.7 days on our own cluster with 2048 H800 GPUs. Consequently, our pre-training stage is completed
    &lt;/span&gt;
    &lt;strong&gt;
     in less than two months
    &lt;/strong&gt;
    &lt;span&gt;
     and costs 2664K GPU hours.
    &lt;/span&gt;
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   &lt;span&gt;
    First, we need to contextualize the GPU hours themselves. This is the raw measure of infrastructure efficiency.
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/rasbt/status/1872432770691318224&quot; rel=&quot;&quot;&gt;
    Llama 3 405B used 30.8M
   &lt;/a&gt;
   &lt;span&gt;
    GPU hours for training relative to DeepSeek V3’s 2.6M GPU hours (more information in the Llama 3
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/meta-llama/Llama-3.1-405B&quot; rel=&quot;&quot;&gt;
    model card
   &lt;/a&gt;
   &lt;span&gt;
    ).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    DeepSeek’s engineering team is incredible at making use of constrained resources. For reference, the Nvidia H800 is a “nerfed” version of the H100 chip. SemiAnalysis has a
   &lt;/span&gt;
   &lt;a href=&quot;https://semianalysis.com/2023/09/12/china-ai-and-semiconductors-rise/#china-ai-capabilities&quot; rel=&quot;&quot;&gt;
    good explanation for what is different
   &lt;/a&gt;
   &lt;span&gt;
    :
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    Nvidia quickly made new versions of their A100 and H100 GPUs that are effectively just as capable named the A800 and H800. These GPUs do not cut down the total compute or memory bandwidth. While NVLink speed are cut to 400GB/s, that is not restrictive for most parallelism strategies that are employed such as 8x Tensor Parallel, Fully Sharded Data Parallel, and Pipeline Parallelism. These cut downs are not able to be end use checked either and could potentially be reversed like Nvidia’s former crypto mining limiters, if the HW isn’t fused off.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   &lt;span&gt;
    To translate — they’re still very strong GPUs, but restrict the effective configurations you can use them in. A second point to consider is why DeepSeek is training on only 2048 GPUs while Meta highlights training their model on a
   &lt;/span&gt;
   &lt;a href=&quot;https://ai.meta.com/blog/meta-llama-3-1/&quot; rel=&quot;&quot;&gt;
    greater than 16K GPU cluster
   &lt;/a&gt;
   &lt;span&gt;
    . This is likely DeepSeek’s most effective pretraining cluster and they have many other GPUs that are either not geographically co-located or lack chip-ban-restricted communication equipment making the throughput of other GPUs lower. Multiple estimates put DeepSeek in the 20K (on
   &lt;/span&gt;
   &lt;a href=&quot;https://open.spotify.com/episode/1kHJdie6V8UA0QW9AvrFOm?go=1&amp;sp_cid=69363785e1a2e4e75c4c33ced05f8610&amp;utm_source=embed_player_p&amp;utm_medium=desktop&amp;nd=1&amp;dlsi=cf916ab2416d4910&quot; rel=&quot;&quot;&gt;
    ChinaTalk
   &lt;/a&gt;
   &lt;span&gt;
    ) to 50K (
   &lt;/span&gt;
   &lt;a href=&quot;https://x.com/dylan522p/status/1859302712803807696&quot; rel=&quot;&quot;&gt;
    Dylan Patel
   &lt;/a&gt;
   &lt;span&gt;
    ) A100 equivalent of GPUs. This is far less than Meta, but it is still one of the organizations in the world with the most access to compute.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    If DeepSeek could,  they’d happily train on more GPUs concurrently. Training one model for multiple months is extremely risky in allocating an organization’s most valuable assets — the GPUs.
   &lt;/span&gt;
   &lt;a href=&quot;https://semianalysis.com/2024/12/11/scaling-laws-o1-pro-architecture-reasoning-training-infrastructure-orion-and-claude-3-5-opus-failures/&quot; rel=&quot;&quot;&gt;
    According to SemiAnalysis
   &lt;/a&gt;
   &lt;span&gt;
    ($), one of the “failures” of OpenAI’s Orion was that it needed so much compute that it took over 3 months to train. This is a situation OpenAI explicitly wants to avoid — it’s better for them to iterate quickly on new models like o3.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    For example, for
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/tulu-3&quot; rel=&quot;&quot;&gt;
    Tülu 3
   &lt;/a&gt;
   &lt;span&gt;
    , we fine-tuned about 1000 models to converge on the post-training recipe we were happy with. Only 1 of those 100s of runs would appear in the post-training compute category above.
   &lt;/span&gt;
   &lt;strong&gt;
    Lower bounds for compute are essential to understanding the progress of technology and peak efficiency, but without substantial compute headroom to experiment on large-scale models DeepSeek-V3 would never have existed.
   &lt;/strong&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The cumulative question of how much total compute is used in experimentation for a model like this is much trickier. Common practice in language modeling laboratories is to
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/i/148458085/de-risking-training-complexity&quot; rel=&quot;&quot;&gt;
    use scaling laws to de-risk ideas
   &lt;/a&gt;
   &lt;span&gt;
    for pretraining, so that you spend very little time training at the largest sizes that do not result in working models. This looks like 1000s of runs at a very small size, likely 1B-7B, to intermediate data amounts (anywhere from
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2203.15556&quot; rel=&quot;&quot;&gt;
    Chinchilla optimal
   &lt;/a&gt;
   &lt;span&gt;
    to 1T tokens). Surely DeepSeek did this. The total compute used for the DeepSeek V3 model for pretraining experiments would likely be 2-4 times the reported number in the paper.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    This does not account for other projects they used as ingredients for DeepSeek V3, such as
   &lt;/span&gt;
   &lt;a href=&quot;https://api-docs.deepseek.com/news/news1120&quot; rel=&quot;&quot;&gt;
    DeepSeek r1 lite
   &lt;/a&gt;
   &lt;span&gt;
    , which was used for synthetic data. Like any laboratory, DeepSeek surely has other experimental items going in the background too.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Tracking the compute used for a project just off the final pretraining run is a very unhelpful way to estimate actual cost. It’s a very useful measure for understanding the actual utilization of the compute and the efficiency of the underlying
   &lt;/span&gt;
   &lt;em&gt;
    learning
   &lt;/em&gt;
   &lt;span&gt;
    , but assigning a cost to the model based on the market price for the GPUs used for the final run is deceptive.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    A true cost of ownership of the GPUs — to be clear, we don’t know if DeepSeek owns or rents the GPUs — would follow an analysis similar to the
   &lt;/span&gt;
   &lt;a href=&quot;https://semianalysis.com/ai-cloud-tco-model/&quot; rel=&quot;&quot;&gt;
    SemiAnalysis total cost of ownership model
   &lt;/a&gt;
   &lt;span&gt;
    (paid feature on top of the newsletter) that incorporates costs in addition to the actual GPUs. For large GPU clusters of 10K+ A/H100s, line items such as
   &lt;/span&gt;
   &lt;a href=&quot;https://semianalysis.com/2024/06/17/100000-h100-clusters-power-network/&quot; rel=&quot;&quot;&gt;
    electricity end up costing over $10M per year
   &lt;/a&gt;
   &lt;span&gt;
    . The CapEx on the GPUs themselves, at least for H100s, is probably over $1B (based on a market price of $30K for a single H100).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   These costs are not necessarily all borne directly by DeepSeek, i.e. they could be working with a cloud provider, but their cost on compute alone (before anything like electricity) is at least $100M’s per year.
  &lt;/p&gt;
  &lt;p&gt;
   For one example, consider comparing how the DeepSeek V3 paper has 139 technical authors. This is a very large technical team.With headcount costs that can also easily be over $10M per year, estimating the cost of a year of operations for DeepSeek AI would be closer to $500M (or even $1B+ easily if operating in the U.S., but error bars are added due to my lack of knowledge on costs of business operation in China) than any of the $5.5M numbers tossed around for this model. The success here is that they’re relevant among American technology companies spending what is approaching or surpassing $10B per year on AI models.
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/deepseek-v3-and-the-actual-cost-of?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/deepseek-v3-and-the-actual-cost-of?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Share
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The price of progress in AI is far closer to this, at least until substantial improvements are made to the open versions of infrastructure (code and data
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/deepseek-v3-and-the-actual-cost-of#footnote-7-154176259&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     7
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    ). This brings us back to the same debate —
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/t/open-source&quot; rel=&quot;&quot;&gt;
    what is actually open-source AI
   &lt;/a&gt;
   &lt;span&gt;
    ? The costs to train models will continue to fall with
   &lt;/span&gt;
   &lt;em&gt;
    open weight
   &lt;/em&gt;
   &lt;span&gt;
    models, especially when accompanied by detailed technical reports, but the pace of diffusion is bottlenecked by the need for challenging reverse engineering / reproduction efforts.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   We’re seeing this with o1 style models. Now that we know they exist, many teams will build what OpenAI did with 1/10th the cost. Knowing what DeepSeek did, more people are going to be willing to spend on building large AI models. The risk of these projects going wrong decreases as more people gain the knowledge to do so.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    If DeepSeek V3, or a similar model, was released with full training data and code, as a true open-source language model, then the cost numbers would be true on their face value. Open-source makes continued progress and dispersion of the technology accelerate. For now, the most valuable part of DeepSeek V3 is likely the technical report. Given the vast size of the model,
   &lt;/span&gt;
   &lt;strong&gt;
    most users won’t be leveraging the fact that the weights are available and will be using it directly on chat.deepseek.com or via the API
   &lt;/strong&gt;
   &lt;span&gt;
    , pointing to pressing questions on the “why” of open-source AI.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Regardless, at this rate
   &lt;/span&gt;
   &lt;strong&gt;
    it will be true that you can train a model at the performance of DeepSeek V3 for ~$5.5M in a few years
   &lt;/strong&gt;
   &lt;span&gt;
    . For now, the costs are far higher, as they involve a combination of extending open-source tools like the
   &lt;/span&gt;
   &lt;a href=&quot;https://github.com/allenai/OLMo&quot; rel=&quot;&quot;&gt;
    OLMo code
   &lt;/a&gt;
   &lt;span&gt;
    and poaching expensive employees that can re-solve problems at the frontier of AI.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The paths are clear. DeepSeek shows that a lot of the modern AI pipeline is not magic — it’s consistent gains accumulated on careful engineering and decision making. In face of the dramatic capital expenditures from Big Tech, billion dollar fundraises from Anthropic and OpenAI, and continued export controls on AI chips, DeepSeek has made it far further than many experts predicted. The ability to make cutting edge AI is not restricted to a select cohort of the San Francisco in-group. The costs are currently high, but organizations like DeepSeek are cutting them down by the day.
  &lt;/p&gt;
  &lt;p&gt;
   Earlier last year, many would have thought that scaling and GPT-5 class models would operate in a cost that DeepSeek cannot afford. As Meta utilizes their Llama models more deeply in their products, from recommendation systems to Meta AI, they’d also be the expected winner in open-weight models. Today, these trends are refuted. Meta has to use their financial advantages to close the gap — this is a possibility, but not a given. I certainly expect a Llama 4 MoE model within the next few months and am even more excited to watch this story of open models unfold.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;hr/&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;em&gt;
    I’ll be sharing more soon on how to interpret the balance of power in open weight language models between the U.S. and China — i.e. how much is intentional policy vs. happenstance of companies?
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/deepseek-v3-and-the-actual-cost-of#footnote-anchor-1-154176259&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     Qwen 2.5 72B is also probably still underrated based on these evaluations.
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/deepseek-v3-and-the-actual-cost-of#footnote-anchor-2-154176259&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    2
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     &lt;span&gt;
      Innovations in the attention mechanism underpinning the Transformer come to either a) increase learning capacity or b) improve performance. The
     &lt;/span&gt;
     &lt;em&gt;
      Attention is All You Need
     &lt;/em&gt;
     &lt;span&gt;
      paper introduced multi-head attention, which can be
     &lt;/span&gt;
     &lt;a href=&quot;https://lilianweng.github.io/posts/2018-06-24-attention/#multi-head-self-attention&quot; rel=&quot;&quot;&gt;
      thought of as
     &lt;/a&gt;
     &lt;span&gt;
      : “multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions. With a single attention head, averaging inhibits this.”
     &lt;/span&gt;
     &lt;br/&gt;
     &lt;br/&gt;
     &lt;span&gt;
      Then, the
     &lt;/span&gt;
     &lt;strong&gt;
      latent
     &lt;/strong&gt;
     &lt;span&gt;
      part is what DeepSeek introduced for the
     &lt;/span&gt;
     &lt;a href=&quot;https://arxiv.org/abs/2405.04434&quot; rel=&quot;&quot;&gt;
      DeepSeek V2 paper
     &lt;/a&gt;
     &lt;span&gt;
      , where the model saves on memory usage of the KV cache by using a low rank projection of the attention heads (at the potential cost of modeling performance). Alternatives to MLA include
     &lt;/span&gt;
     &lt;a href=&quot;https://arxiv.org/pdf/2305.13245&quot; rel=&quot;&quot;&gt;
      Group-Query Attention
     &lt;/a&gt;
     &lt;span&gt;
      and
     &lt;/span&gt;
     &lt;a href=&quot;https://arxiv.org/pdf/1911.02150&quot; rel=&quot;&quot;&gt;
      Multi-Query Attention
     &lt;/a&gt;
     &lt;span&gt;
      . Read more on MLA
     &lt;/span&gt;
     &lt;a href=&quot;https://planetbanatt.net/articles/mla.html&quot; rel=&quot;&quot;&gt;
      here
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/deepseek-v3-and-the-actual-cost-of#footnote-anchor-3-154176259&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    3
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     This is coming natively to Blackwell GPUs, which will be banned in China, but DeepSeek built it themselves!
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/deepseek-v3-and-the-actual-cost-of#footnote-anchor-4-154176259&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    4
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     &lt;span&gt;
      As did
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/AIatMeta/status/1865079068833780155&quot; rel=&quot;&quot;&gt;
      Meta’s update to Llama 3.3 model
     &lt;/a&gt;
     &lt;span&gt;
      , which is a better post train of the 3.1 base models. RL keeps coming.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/deepseek-v3-and-the-actual-cost-of#footnote-anchor-5-154176259&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    5
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     &lt;span&gt;
      There’s
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/main_horse/status/1872294985888059612?s=46&quot; rel=&quot;&quot;&gt;
      a lot
     &lt;/a&gt;
     &lt;span&gt;
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/nrehiew_/status/1872318173648736381&quot; rel=&quot;&quot;&gt;
      more
     &lt;/a&gt;
     &lt;span&gt;
     &lt;/span&gt;
     &lt;a href=&quot;https://x.com/p_nawrot/status/1788479672067481664?lang=en&quot; rel=&quot;&quot;&gt;
      commentary
     &lt;/a&gt;
     &lt;span&gt;
      on the models online if you’re looking for it.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/deepseek-v3-and-the-actual-cost-of#footnote-anchor-6-154176259&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    6
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     I hope most of my audience would’ve had this reaction too, but laying it out simply why frontier models are so expensive is an important exercise to keep doing.
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/deepseek-v3-and-the-actual-cost-of#footnote-anchor-7-154176259&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    7
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     &lt;span&gt;
      And permissive licenses.
     &lt;/span&gt;
     &lt;a href=&quot;https://github.com/deepseek-ai/DeepSeek-V3/blob/main/LICENSE-MODEL&quot; rel=&quot;&quot;&gt;
      DeepSeek V3 License
     &lt;/a&gt;
     &lt;span&gt;
      is probably more permissive than the Llama 3.1 license, but there are still some odd terms.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> The Q* hypothesis: Tree-of-thoughts reasoning, process reward models, and supercharging synthetic data </title>
<link>https://www.interconnects.ai/p/q-star</link>
<pubDate>Fri, 24 Nov 2023 13:00:25 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;em&gt;
    Programming note: this counts as next week’s post. I pulled it forward for timeliness, as RLAIF and process reward models were on my hit list anyway. We’ll see if there are more
   &lt;/em&gt;
   &lt;span&gt;
   &lt;/span&gt;
   &lt;em&gt;
    emergency posts.
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;hr/&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    On Wednesday, right when we were all ready to sign off for Thanksgiving,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.reuters.com/technology/sam-altmans-ouster-openai-was-precipitated-by-letter-board-about-ai-breakthrough-2023-11-22/&quot; rel=&quot;&quot;&gt;
    Reuters reported on OpenAI one last time
   &lt;/a&gt;
   &lt;span&gt;
    , revealing just the name and high-level evaluations of a new OpenAI method, Q*, touted with vague powerful capabilities:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;blockquote&gt;
   &lt;p&gt;
    After being contacted by Reuters, OpenAI, which declined to comment, acknowledged in an internal message to staffers a project called Q*…
   &lt;/p&gt;
   &lt;p&gt;
    Some at OpenAI believe Q* (pronounced Q-Star) could be a breakthrough in the startup&#x27;s search for what&#x27;s known as artificial general intelligence (AGI), one of the people told Reuters. OpenAI defines AGI as autonomous systems that surpass humans in most economically valuable tasks.
   &lt;/p&gt;
   &lt;p&gt;
    Given vast computing resources, the new model was able to solve certain mathematical problems, the person said on condition of anonymity because the individual was not authorized to speak on behalf of the company. Though only performing math on the level of grade-school students, acing such tests made researchers very optimistic about Q*’s future success, the source said.
   &lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;p&gt;
   &lt;span&gt;
    Such extensive speculation has never unfolded from only the name of a method. Though, the name is pretty simple in this case, and
   &lt;/span&gt;
   &lt;a href=&quot;https://www.theinformation.com/articles/openai-dropped-work-on-new-arrakis-ai-model-in-rare-setback&quot; rel=&quot;&quot;&gt;
    not just another codename from the Dune universe
   &lt;/a&gt;
   &lt;span&gt;
    . Q* (Q-Star), if real, clearly links two core themes from the RL literature: Q-values and
   &lt;/span&gt;
   &lt;a href=&quot;https://en.wikipedia.org/wiki/A*_search_algorithm&quot; rel=&quot;&quot;&gt;
    A*
   &lt;/a&gt;
   &lt;em&gt;
    , a classic graph search algorithm. Y
   &lt;/em&gt;
   &lt;span&gt;
    es, there’s an argument that Q could just refer to the value function of the optimal policy, but this would need to be a fabricated leak for it to be so silly, and OpenAI has pretty much had everything leaked, so fabricating them seems unlikely.
   &lt;/span&gt;
   &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/q-star#footnote-1-139117155&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   My initial hypothesis, which I clearly labeled as a tin hat theory, was a vague merging of Q-learning and A* search. What I didn’t answer is, what is being searched over? My initial guess of searching over dialogue turns is almost certainly wrong due to infrastructure reasons I’ll touch on later.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    As I’ve dug into this in more detail, I’ve become convinced that they are doing something powerful by
   &lt;/span&gt;
   &lt;strong&gt;
    searching over language steps via tree-of-thoughts reasoning
   &lt;/strong&gt;
   &lt;span&gt;
    , but it is much smaller of a leap than people believe. The reason for the hyperbole is the goal of linking large language model training and usage to the core components of Deep RL that enabled success like AlphaGo: self-play and look-ahead planning.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Self-play
     &lt;/strong&gt;
     &lt;span&gt;
      is the idea that an agent can improve its gameplay by playing against slightly different versions of itself because it’ll progressively encounter more challenging situations. In the space of LLMs, it is almost certain that the largest portion of self-play will look like AI Feedback rather than competitive processes.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Look-ahead planning
     &lt;/strong&gt;
     &lt;span&gt;
      is the idea of using a model of the world to reason into the future and produce better actions or outputs. The two variants are based on
     &lt;/span&gt;
     &lt;a href=&quot;https://en.wikipedia.org/wiki/Model_predictive_control#:~:text=Model%20predictive%20control%20(MPC)%20is,oil%20refineries%20since%20the%201980s.&quot; rel=&quot;&quot;&gt;
      Model Predictive Control
     &lt;/a&gt;
     &lt;span&gt;
      (MPC), which is often used on continuous states, and
     &lt;/span&gt;
     &lt;a href=&quot;https://en.wikipedia.org/wiki/Monte_Carlo_tree_search&quot; rel=&quot;&quot;&gt;
      Monte-Carlo Tree Search
     &lt;/a&gt;
     &lt;span&gt;
      (MCTS), which works with discrete actions and states.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   To understand how this links together, we need to cover recent results published from OpenAI and others that’ll answer two questions:
  &lt;/p&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     How do we construct a representation of language that we can search over?
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     How do we construct a notion of value over compartmentalized and meaningful language chunks (rather than the entire completion)?
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;p&gt;
   With answers to these, it should be clear how we could use existing RL methods that are used for RLHF. We use an RL optimizer to fine-tune the language model and get higher-quality generations with modular rewards (rather than the full sequence, as is done today).
  &lt;/p&gt;
  &lt;div&gt;
   &lt;div&gt;
    &lt;div&gt;
     &lt;p&gt;
      Interconnects is a reader-supported publication. Consider becoming a subscriber.
     &lt;/p&gt;
    &lt;/div&gt;
    &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
    &lt;/div&gt;
   &lt;/div&gt;
  &lt;/div&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!UBhC!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77dd8242-6d53-4f2c-a401-243aa58019e3_1820x1024.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!UBhC!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77dd8242-6d53-4f2c-a401-243aa58019e3_1820x1024.jpeg 424w, https://substackcdn.com/image/fetch/$s_!UBhC!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77dd8242-6d53-4f2c-a401-243aa58019e3_1820x1024.jpeg 848w, https://substackcdn.com/image/fetch/$s_!UBhC!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77dd8242-6d53-4f2c-a401-243aa58019e3_1820x1024.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!UBhC!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77dd8242-6d53-4f2c-a401-243aa58019e3_1820x1024.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;Runway 2023-11-23T16\_55\_51.562Z Expand Image.jpeg&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/77dd8242-6d53-4f2c-a401-243aa58019e3_1820x1024.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Runway 2023-11-23T16\\_55\\_51.562Z Expand Image.jpeg&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;819&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!UBhC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77dd8242-6d53-4f2c-a401-243aa58019e3_1820x1024.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!UBhC!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77dd8242-6d53-4f2c-a401-243aa58019e3_1820x1024.jpeg 424w, https://substackcdn.com/image/fetch/$s_!UBhC!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77dd8242-6d53-4f2c-a401-243aa58019e3_1820x1024.jpeg 848w, https://substackcdn.com/image/fetch/$s_!UBhC!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77dd8242-6d53-4f2c-a401-243aa58019e3_1820x1024.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!UBhC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77dd8242-6d53-4f2c-a401-243aa58019e3_1820x1024.jpeg 1456w&quot; title=&quot;Runway 2023-11-23T16\_55\_51.562Z Expand Image.jpeg&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
    &lt;figcaption&gt;
     DALLE3
    &lt;/figcaption&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;h3&gt;
   Modular reasoning with LLMs: Tree-of-Thoughts (ToT) prompting
  &lt;/h3&gt;
  &lt;p&gt;
   Promoting techniques like “take a deep breath” and “think step by step” are now expanding into advanced methods for inference with parallel computation and heuristics (some fundamentals of search).
  &lt;/p&gt;
  &lt;p&gt;
   Tree-of-thoughts is really how it sounds. It is a way to prompt a language model to create a tree of reasoning paths that may or may not converge at a correct answer. A comparison to other ways of problem-solving with LLMs was shown in the paper:
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!kxaA!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86601708-3c01-43ee-b196-9f227e1eb983_1582x842.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!kxaA!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86601708-3c01-43ee-b196-9f227e1eb983_1582x842.png 424w, https://substackcdn.com/image/fetch/$s_!kxaA!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86601708-3c01-43ee-b196-9f227e1eb983_1582x842.png 848w, https://substackcdn.com/image/fetch/$s_!kxaA!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86601708-3c01-43ee-b196-9f227e1eb983_1582x842.png 1272w, https://substackcdn.com/image/fetch/$s_!kxaA!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86601708-3c01-43ee-b196-9f227e1eb983_1582x842.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;Image.png&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/86601708-3c01-43ee-b196-9f227e1eb983_1582x842.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:775,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image.png&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;775&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!kxaA!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86601708-3c01-43ee-b196-9f227e1eb983_1582x842.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!kxaA!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86601708-3c01-43ee-b196-9f227e1eb983_1582x842.png 424w, https://substackcdn.com/image/fetch/$s_!kxaA!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86601708-3c01-43ee-b196-9f227e1eb983_1582x842.png 848w, https://substackcdn.com/image/fetch/$s_!kxaA!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86601708-3c01-43ee-b196-9f227e1eb983_1582x842.png 1272w, https://substackcdn.com/image/fetch/$s_!kxaA!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86601708-3c01-43ee-b196-9f227e1eb983_1582x842.png 1456w&quot; title=&quot;Image.png&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    The innovations that make this click are the chunking of reasoning steps and prompting a model to create new reasoning steps.
   &lt;/span&gt;
   &lt;strong&gt;
    ToT seems like the first “recursive” prompting technique for improving inference performance
   &lt;/strong&gt;
   &lt;span&gt;
    , which sounds remarkably close to the AI Safety concern of recursively self-improving models (though I am not an expert).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   With the reasoning trees, different methods can be applied to score each vertex (the nodes) or to sample the final path. It can be based on things like minimum length to the most agreed answer, or complex things that require external feedback, which points us back in the direction of RLHF.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Read the Tree of Thoughts paper here:
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2305.10601&quot; rel=&quot;&quot;&gt;
    https://arxiv.org/abs/2305.10601
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;em&gt;
    &lt;span&gt;
     Note: there are two more papers that seem worth mentioning here, at least for bookkeeping. 1) a
    &lt;/span&gt;
    &lt;a href=&quot;https://arxiv.org/abs/2305.08291&quot; rel=&quot;&quot;&gt;
     concurrent ToT paper
    &lt;/a&gt;
    &lt;span&gt;
     from a solo-author and 2)
    &lt;/span&gt;
    &lt;a href=&quot;https://arxiv.org/abs/2310.04406&quot; rel=&quot;&quot;&gt;
     Language Agent Tree Search
    &lt;/a&gt;
    &lt;span&gt;
     which has better links to AlphaGo ideas.
    &lt;/span&gt;
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;h3&gt;
   Fine-grained reward labels in generation: Process Reward Models (PRM)
  &lt;/h3&gt;
  &lt;p&gt;
   The way that most RLHF is done to date has the entire response from a language model get an associated score. To anyone with an RL background, this is disappointing, because it limits the ability for RL methods to make connections about the value of each sub-component of text. Futures have been pointed to where this multi-step optimization comes at the level of multiple dialogue turns, but that is still far-fetched due to the requirement of having humans or some prompt source in the loop.
  &lt;/p&gt;
  &lt;p&gt;
   This could easily be extended to a self-play style dialogue but is hard to give an LLMs goals that translate to the self-play dynamics of consistently improving. Most of the things we want to do with LLMs are repetitive tasks without near-infinite ceilings on performance like the game of Go.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    On the other hand,
   &lt;/span&gt;
   &lt;strong&gt;
    there is a type of LLM use case that naturally abstracts to contained chunks of text: step-by-step reasoning
   &lt;/strong&gt;
   &lt;span&gt;
    , best exemplified by math problems.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Process Reward Models (PRMs) have been a topic I’ve heard a lot about from RLHF folks off the record for the last 6 months. It turns out there is a lot of literature on these models, but very little on how to use them with RL.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    The core idea of a PRM is to assign a score to each step of reasoning, rather than a complete message. An example from the OpenAI paper
   &lt;/span&gt;
   &lt;a href=&quot;https://arxiv.org/abs/2305.20050&quot; rel=&quot;&quot;&gt;
    Let’s Verify Step by Step
   &lt;/a&gt;
   &lt;span&gt;
    is shown below:
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!JDTO!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9eaa85b-db2e-4b79-8879-ee88c13e4b78_1614x1164.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!JDTO!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9eaa85b-db2e-4b79-8879-ee88c13e4b78_1614x1164.png 424w, https://substackcdn.com/image/fetch/$s_!JDTO!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9eaa85b-db2e-4b79-8879-ee88c13e4b78_1614x1164.png 848w, https://substackcdn.com/image/fetch/$s_!JDTO!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9eaa85b-db2e-4b79-8879-ee88c13e4b78_1614x1164.png 1272w, https://substackcdn.com/image/fetch/$s_!JDTO!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9eaa85b-db2e-4b79-8879-ee88c13e4b78_1614x1164.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;Image.png&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a9eaa85b-db2e-4b79-8879-ee88c13e4b78_1614x1164.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1050,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image.png&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;1050&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!JDTO!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9eaa85b-db2e-4b79-8879-ee88c13e4b78_1614x1164.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!JDTO!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9eaa85b-db2e-4b79-8879-ee88c13e4b78_1614x1164.png 424w, https://substackcdn.com/image/fetch/$s_!JDTO!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9eaa85b-db2e-4b79-8879-ee88c13e4b78_1614x1164.png 848w, https://substackcdn.com/image/fetch/$s_!JDTO!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9eaa85b-db2e-4b79-8879-ee88c13e4b78_1614x1164.png 1272w, https://substackcdn.com/image/fetch/$s_!JDTO!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9eaa85b-db2e-4b79-8879-ee88c13e4b78_1614x1164.png 1456w&quot; title=&quot;Image.png&quot; width=&quot;1456&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   And the funny feedback interface they used (which will be replaced by AIs), but is instructive:
  &lt;/p&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!dg4S!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f4e5bd9-0d69-421b-a841-f09d95ad9004_1454x756.png&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!dg4S!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f4e5bd9-0d69-421b-a841-f09d95ad9004_1454x756.png 424w, https://substackcdn.com/image/fetch/$s_!dg4S!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f4e5bd9-0d69-421b-a841-f09d95ad9004_1454x756.png 848w, https://substackcdn.com/image/fetch/$s_!dg4S!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f4e5bd9-0d69-421b-a841-f09d95ad9004_1454x756.png 1272w, https://substackcdn.com/image/fetch/$s_!dg4S!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f4e5bd9-0d69-421b-a841-f09d95ad9004_1454x756.png 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;Screenshot 2023-11-23 at 3.48.54 PM.png&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6f4e5bd9-0d69-421b-a841-f09d95ad9004_1454x756.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:756,&quot;width&quot;:1454,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Screenshot 2023-11-23 at 3.48.54 PM.png&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;756&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!dg4S!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f4e5bd9-0d69-421b-a841-f09d95ad9004_1454x756.png&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!dg4S!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f4e5bd9-0d69-421b-a841-f09d95ad9004_1454x756.png 424w, https://substackcdn.com/image/fetch/$s_!dg4S!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f4e5bd9-0d69-421b-a841-f09d95ad9004_1454x756.png 848w, https://substackcdn.com/image/fetch/$s_!dg4S!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f4e5bd9-0d69-421b-a841-f09d95ad9004_1454x756.png 1272w, https://substackcdn.com/image/fetch/$s_!dg4S!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f4e5bd9-0d69-421b-a841-f09d95ad9004_1454x756.png 1456w&quot; title=&quot;Screenshot 2023-11-23 at 3.48.54 PM.png&quot; width=&quot;1454&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    This allows finer-tuned generation with reasoning problems, by sampling over the maximum average reward or other metrics, instead of just relying on one score (standard RMs are called outcome RMs in this literature). Using
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/docs/trl/main/en/best_of_n&quot; rel=&quot;&quot;&gt;
    Best-of-N sampling
   &lt;/a&gt;
   &lt;span&gt;
    , essentially generating a bunch of times and using the one that scored the highest by the reward model (the inference time cousin of Rejection Sampling popularized with Llama 2), PRMs outperform standard RMs on reasoning tasks.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    To date, most of the resources for PRMs just show how to use them at inference time. The true power will come when this signal is optimized against training. To create the richest optimization setting, having the ability to generate diverse reasoning pathways for scoring and learning from is essential. This is where Tree-of-Thoughts comes in.
   &lt;/span&gt;
   &lt;strong&gt;
    The prompting from ToT gives diversity to the generations, which a policy can learn to exploit with access to a PRM
   &lt;/strong&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   For more resources on PRMs, see the following:
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;em&gt;
      &lt;a href=&quot;https://arxiv.org/abs/2305.20050&quot; rel=&quot;&quot;&gt;
       Let’s Verify Step by Step
      &lt;/a&gt;
     &lt;/em&gt;
     &lt;span&gt;
      : a good introduction to PRMs.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;em&gt;
      &lt;a href=&quot;https://arxiv.org/abs/2211.14275&quot; rel=&quot;&quot;&gt;
       Solving math word problems with process- and outcome-based feedback
      &lt;/a&gt;
     &lt;/em&gt;
     &lt;span&gt;
      : the canonical citation in all PRM and reasoning works in 2023.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;em&gt;
      &lt;a href=&quot;https://arxiv.org/abs/2308.01825&quot; rel=&quot;&quot;&gt;
       Scaling Relationship on Learning Mathematical Reasoning with Large Language Models
      &lt;/a&gt;
     &lt;/em&gt;
     &lt;span&gt;
      : A paper that studies the method of rejection sampling for reasoning problems, among other contributions.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;em&gt;
      &lt;a href=&quot;https://arxiv.org/abs/2310.10080&quot; rel=&quot;&quot;&gt;
       Let&#x27;s reward step by step: Step-Level reward model as the Navigators for Reasoning
      &lt;/a&gt;
     &lt;/em&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;p&gt;
   &lt;span&gt;
    Additionally, there’s one popular openly available math model that is documented as training with PRMs:
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/WizardLM/WizardMath-70B-V1.0&quot; rel=&quot;&quot;&gt;
    Wizard-LM-Math
   &lt;/a&gt;
   &lt;span&gt;
    . Second, OpenAI
   &lt;/span&gt;
   &lt;a href=&quot;https://github.com/openai/prm800k&quot; rel=&quot;&quot;&gt;
    released their fine-grained reward labels
   &lt;/a&gt;
   &lt;span&gt;
    from the Verify Step by Step paper for training a PRM earlier this year.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;hr/&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;span&gt;
    🧪🎙️ Tom and I discussed Q* and all of the OpenAI drama on
   &lt;/span&gt;
   &lt;a href=&quot;https://retortai.com/episodes/q-and-openais-strange-loop-we-pecant-even&quot; rel=&quot;&quot;&gt;
    this week’s episode of The Retort
   &lt;/a&gt;
   &lt;span&gt;
    , check it out!
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;hr/&gt;
  &lt;/div&gt;
  &lt;h3&gt;
   Putting it together: what Q* could be
  &lt;/h3&gt;
  &lt;p&gt;
   Q* seems to be using PRMs to score Tree of Thoughts reasoning data that then is optimized with Offline RL. This wouldn’t look too different from existing RLHF toolings that use offline algorithms like DPO or ILQL that do not need to generate from the LLM during training. The ‘trajectory’ seen by the RL algorithm is the sequence of reasoning steps, so we’re finally doing RLHF in a multi-step fashion rather than contextual bandits!
  &lt;/p&gt;
  &lt;p&gt;
   Given that the rumors I’ve heard already indicated OpenAI was using offline RL for RLHF (which doesn’t say that much), this doesn’t seem like a big leap to me. The intricacies of this method involve collecting the right prompts, having a model to generate great reasoning steps, and most importantly: accurately scoring tens of thousands of completions.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    This last step is where the rumored “vast computing resources”: use AI to label every step with a score instead of humans
   &lt;/strong&gt;
   &lt;span&gt;
    . Synthetic data is king, and with trees rather than single-width paths (via chain-of-thought) giving more and more options later on to arrive at the right answer.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The ton of compute resources tracks with the rumor that I’ve heard one or more of the big tech players (Google, Anthropic, Cohere, etc) are creating a pretraining-sized dataset from process supervision or RLAIF-like methods, which would take 10s of thousands of GPU hours easily. The gap to openly available models in this area worries me.
  &lt;/p&gt;
  &lt;p&gt;
   All of this said while the core ideas seem clear to me, implementing this takes levels of model whispering few poses. Distribution control, massive inference, and RL finickiness are well beyond my knowledge or experience. All of this information just seems so natural. All the evaluations for ToT and PRMs are on reasoning problems like math, which is what all the news articles were saying this leaked method was about. Even if it isn’t Q*, it would be a fun experiment.
  &lt;/p&gt;
  &lt;h3&gt;
   Super-scale AI feedback data and the future
  &lt;/h3&gt;
  &lt;p&gt;
   &lt;span&gt;
    As I’ve written about before,
   &lt;/span&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/beyond-human-data-rlaif?utm_source=%2Fsearch%2Frlaif&amp;utm_medium=reader2&quot; rel=&quot;&quot;&gt;
    AI Feedback and Constitutional AI are underrepresented in public awareness
   &lt;/a&gt;
   &lt;span&gt;
    . Synthetic data represents the shortest path to expanding datasets. In the short term, it’s clear we can create some useful data with this. What is not clear is the extent to which it can be scaled — ie can it replace internet scale data entirely?
   &lt;/span&gt;
  &lt;/p&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
<item>
<title> Behind the curtain: what it feels like to work in AI right now (April 2023) </title>
<link>https://www.interconnects.ai/p/behind-the-curtain-ai</link>
<pubDate>Wed, 05 Apr 2023 23:01:39 -0000</pubDate>
<description>
&lt;div&gt;
 &lt;div dir=&quot;auto&quot;&gt;
  &lt;p&gt;
   &lt;span&gt;
    Every single person I know working in AI these days (in both the academy and industry) has been sparked by the ChatGPT moment. The
   &lt;/span&gt;
   &lt;em&gt;
    first
   &lt;/em&gt;
   &lt;span&gt;
    iPhone moment of AI. Working in this environment is extremely straining, for a plethora of reasons — burnout, ambition, noise, influencers, financial upside, ethical worries, and more.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The ChatGPT spark has caused career changes, projects to be abandoned, and tons of people to try and start new companies in the area. The entire industry has been collectively shaken up — it added a ton of energy into the system. We now have model and product announcements on an almost daily basis. Talking to a professor friend in NLP, it&#x27;s to the point where all sorts of established researchers are ready to jump ship and join/build companies. This is not something that happens every day — getting academics to stop wanting to do research is a hilarious accomplishment. Everything just feels so frothy.
  &lt;/p&gt;
  &lt;p&gt;
   Graduate students are competing with venture-backed companies. From a high-level technologist&#x27;s perspective, it is awesome. From an engineer-on-the-ground’s perspective, it leaves some stability and naps to be desired. Seeing all of the noise makes it very hard to keep one&#x27;s head on straight and actually do the work.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    It seems like everyone is simultaneously extremely motivated and extremely close to burning out. Given the density of people in all the project spaces of generative AI or chatbots, there is a serious
   &lt;/span&gt;
   &lt;em&gt;
    be the first or be the best
   &lt;/em&gt;
   &lt;span&gt;
    syndrome (with a third axis of success being
   &lt;/span&gt;
   &lt;em&gt;
    openness
   &lt;/em&gt;
   &lt;span&gt;
    ). This keeps you on your toes, to say the least. In the end, these pressures shape the products people are building away from a thoroughness of engineering and documentation. Clickyness is the driving trend in the last few months, which has such a sour flavor.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   To start, let&#x27;s take a step back and state pretty clearly how my worldview has updated post-ChatGPT. I&#x27;ve mostly accepted two assumptions to be true:
  &lt;/p&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Large language models (LLMs) are here to stay as a part of the machine learning toolbox across most domains
     &lt;/strong&gt;
     &lt;span&gt;
      . This is much like deep learning was viewed 6 years ago when I started my Ph.D. There are some domains where other techniques win out, but it won&#x27;t be the norm.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      AI Safety is a real problem that is entering the discourse as a public problem.
     &lt;/strong&gt;
     &lt;span&gt;
      As someone who just started coming around to the first half of that, it is really exhausting to be thrust into the public portion right away.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;p&gt;
   These two assumptions make it pretty funny that the pace is so high. I&#x27;ve just said that being safe is important and the tools we are using are here to stay, so for people focused on learning and doing good, some simple logic implies that there shouldn’t be an AI race. The race dynamic is purely down to capitalistic incentives. Acknowledging these pressures and steering around them is the only way to do this work for a longer timeline.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    This post flows as a deeper dive into the dynamics we have right now,
   &lt;/span&gt;
   &lt;strong&gt;
    The State
   &lt;/strong&gt;
   &lt;span&gt;
    , followed by some things I prioritize to make it easier to have a long-term impact,
   &lt;/span&gt;
   &lt;strong&gt;
    The Solutions
   &lt;/strong&gt;
   &lt;span&gt;
    .
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;div data-component-name=&quot;SubscribeWidget&quot;&gt;
  &lt;/div&gt;
  &lt;div&gt;
   &lt;figure&gt;
    &lt;a data-component-name=&quot;Image2ToDOM&quot; href=&quot;https://substackcdn.com/image/fetch/$s_!tYwz!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2cfd20-1fe6-4a63-aa56-db90fd4cf888_768x768.jpeg&quot; rel=&quot;&quot; target=&quot;_blank&quot;&gt;
     &lt;div&gt;
      &lt;picture&gt;
       &lt;source sizes=&quot;100vw&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!tYwz!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2cfd20-1fe6-4a63-aa56-db90fd4cf888_768x768.jpeg 424w, https://substackcdn.com/image/fetch/$s_!tYwz!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2cfd20-1fe6-4a63-aa56-db90fd4cf888_768x768.jpeg 848w, https://substackcdn.com/image/fetch/$s_!tYwz!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2cfd20-1fe6-4a63-aa56-db90fd4cf888_768x768.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!tYwz!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2cfd20-1fe6-4a63-aa56-db90fd4cf888_768x768.jpeg 1456w&quot; type=&quot;image/webp&quot;&gt;
        &lt;img alt=&quot;download (22).jpeg&quot; data-attrs=&#x27;{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3a2cfd20-1fe6-4a63-aa56-db90fd4cf888_768x768.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:768,&quot;width&quot;:768,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;download (22).jpeg&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}&#x27; height=&quot;768&quot; loading=&quot;lazy&quot; sizes=&quot;100vw&quot; src=&quot;https://substackcdn.com/image/fetch/$s_!tYwz!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2cfd20-1fe6-4a63-aa56-db90fd4cf888_768x768.jpeg&quot; srcset=&quot;https://substackcdn.com/image/fetch/$s_!tYwz!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2cfd20-1fe6-4a63-aa56-db90fd4cf888_768x768.jpeg 424w, https://substackcdn.com/image/fetch/$s_!tYwz!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2cfd20-1fe6-4a63-aa56-db90fd4cf888_768x768.jpeg 848w, https://substackcdn.com/image/fetch/$s_!tYwz!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2cfd20-1fe6-4a63-aa56-db90fd4cf888_768x768.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!tYwz!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2cfd20-1fe6-4a63-aa56-db90fd4cf888_768x768.jpeg 1456w&quot; title=&quot;download (22).jpeg&quot; width=&quot;768&quot;/&gt;
       &lt;/source&gt;
      &lt;/picture&gt;
     &lt;/div&gt;
    &lt;/a&gt;
    &lt;figcaption&gt;
     The scene in the room where the scientists solve AI once and for all, artistic — Stable Diffusion 2.1.
    &lt;/figcaption&gt;
   &lt;/figure&gt;
  &lt;/div&gt;
  &lt;h1&gt;
   The State
  &lt;/h1&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Prioritization is really hard these days
   &lt;/strong&gt;
   &lt;span&gt;
    . If you&#x27;re obsessed with being first, the goalposts will keep moving as the next models get released. The need to be better and different is really strong. For some companies that are already established, this is compounded by the question &quot;why wasn&#x27;t this release/product/model you?” For researchers with freedom, it is extremely hard to balance goals between attainable, scoop-able, and impactful.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    In the case of the recent zoo of instruction-tuned Llama models (
   &lt;/span&gt;
   &lt;a href=&quot;https://crfm.stanford.edu/2023/03/13/alpaca.html&quot; rel=&quot;&quot;&gt;
    Alpaca
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/lmsys/vicuna-13b-delta-v0&quot; rel=&quot;&quot;&gt;
    Vicuna
   &lt;/a&gt;
   &lt;span&gt;
    ,
   &lt;/span&gt;
   &lt;a href=&quot;https://bair.berkeley.edu/blog/2023/04/03/koala/&quot; rel=&quot;&quot;&gt;
    Koala
   &lt;/a&gt;
   &lt;span&gt;
    , and
   &lt;/span&gt;
   &lt;a href=&quot;https://huggingface.co/project-baize&quot; rel=&quot;&quot;&gt;
    Baize
   &lt;/a&gt;
   &lt;span&gt;
    ), this pace pressure generally comes at the cost of the evaluation. All these models (except Alpaca, because it was the first) come and go from the narrative quickly. There&#x27;s a viral spike on Twitter, chatter on the streets for a couple of days, and then everything is back to baseline. These artifacts are not really full research productions. Without substantial evaluation, the claims are unvetted and
   &lt;/span&gt;
   &lt;em&gt;
    should
   &lt;/em&gt;
   &lt;span&gt;
    be mostly ignored by conference reviewers until their documentation improves (which I think they will, unlike GPT4).
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Behind the scenes, there are surely many projects that get axed and shifted whenever one of these releases happens. Designing a playbook that&#x27;s resilient to external changes is hard when the incentives are so motivated by markets.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Another symptom of the dynamics that make prioritization hard is that
   &lt;/span&gt;
   &lt;strong&gt;
    leadership and vision are increasingly strained
   &lt;/strong&gt;
   &lt;span&gt;
    . When AI was going slower, it was easier for researchers to sort of nod their heads and know what was coming next. Now so much of the progress comes from different mediums than research, so most prediction abilities are out the window. Many companies will try to make plans to please employees, but it is truly very challenging to come up with a plan that&#x27;ll survive the next major open model release. Keeping up with the trends is an art, but the few who manage it best will enable their employees to have an easier time prioritizing. Long-term, I see this paying off for a few organizations that double-down as process-focused ML labs. Those focused on artifact production can easily be subject to higher employee turnover and other consequences.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   Engineering teams are desperate for leadership to provide these strategies so they can come up with better tactics. I find the best plans are ones that don&#x27;t really change when the next SOTA model comes up, but are rather reinforced.
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    While making long-term plans is hard,
   &lt;/span&gt;
   &lt;strong&gt;
    being an ML influencer is easy right now
   &lt;/strong&gt;
   &lt;span&gt;
    because there are so many eyes on the field. The paper posters have proliferated — people tweeting out abstracts from new papers on Arxiv, in the style of
   &lt;/span&gt;
   &lt;a href=&quot;https://twitter.com/_akhaliq&quot; rel=&quot;&quot;&gt;
    AK
   &lt;/a&gt;
   &lt;span&gt;
    . I&#x27;ve found that anything that I think is remotely on-topic can be an easily successful tweet. Though, a lot of people doing this are mistaking reputation for following. In ML and tech broadly as industries, people are hired because of their reputation not because of their following. There&#x27;s a correlation between the two, but there&#x27;s a difference between having a megaphone for a general AI audience and having a megaphone for researchers/engineers at companies that will be your customers. Since studying my Substack stats (where I have &amp;lt;10% overlap in subscribers with any publication) I&#x27;ve come to think that people can curate a pretty specific audience to them. Posting all popular papers makes your audience and therefore reputational leverage more diffuse.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   The algorithms we built as a community are pushing us to double down on these influencer dynamics. For a while, it felt like ML communities acted independently of them (e.g. on the chronological feed), but now the boundaries of our groups are blurred and the incentives of chronological feeds have changed people. Everyone wanted to leave Twitter when Elon took over, but not many of us did (props if you got out). This kind of has two effects that I see:
  &lt;/p&gt;
  &lt;ol&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      The people who are the most focused on building AI have been pulling back from social engagements. This likely compounded the influencer dynamics, where there is a gap that people used to fill
     &lt;/span&gt;
     &lt;em&gt;
      and
     &lt;/em&gt;
     &lt;span&gt;
      the ballooning of general attention in the area. I try my best to use Twitter as a distribution network, but it really feels like that is where ML is unfolding. Not sure which way is best, it&#x27;s just important to keep in touch with what your body and mind need.
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;strong&gt;
      Societal issues loom large
     &lt;/strong&gt;
     &lt;span&gt;
      , so the people who are the most focused on designing ML systems with good societal outcomes feel obligated to engage. Doubly, when you realize ML has such a strong impact on societal structures, it makes the work more emotional and draining. Caring is hard!
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ol&gt;
  &lt;p&gt;
   Many of the issues regarding the responsible development of AI have transitioned from research to reality with 100million+ people using ChatGPT. Everyone along the distribution from theoretical AI safety to the ML fairness researcher just got the largest call-to-arms of their career so far. This often involves engaging with stakeholders from other backgrounds than AI research and responding to criticism of their ideas, which is very tiring.
  &lt;/p&gt;
  &lt;p&gt;
   For example, I see a ton of research and sociotechnical questions around RLHF that OpenAI / Anthropic likely won&#x27;t engage with for primarily political or product reasons. It feels like the field is charging ahead with rapid progress on the technical side, where there is a down-the-line wall of safety and bias concerns that are very hard for small teams to comply with. Whether or not I am on the train going ahead, it seems obvious that the issues will become front of public perception in the coming months. For that reason, I have been deciding to keep going while discussing the sociotechnical issues openly. Eventually, safety concerns could easily trump my desire for technical progress. This sort of sociotechnical urgency is something I did not expect to feel in AI development for quite some time (or I expected the subjective feeling of it to approach much more gradually, like climate concerns rather than Ukraine concerns that happened overnight for me).
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    All of these low-level concerns make working in AI feel like the candle that
   &lt;/span&gt;
   &lt;strong&gt;
    burns bright and short
   &lt;/strong&gt;
   &lt;span&gt;
    . I&#x27;m oscillating between the most motivated I&#x27;ve ever been and some of the closest to burnt-out I&#x27;ve ever felt. This whiplash effect is very exhausting. The discourse is motivating and pressuring for all of us in AI, so just try to remember to see the humanity in those you work with and those you compete with.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Underpinning all of this are
   &lt;/span&gt;
   &lt;strong&gt;
    serious geopolitical overtones
   &lt;/strong&gt;
   &lt;span&gt;
    , brought to the front of mind by the
   &lt;/span&gt;
   &lt;a href=&quot;https://futureoflife.org/open-letter/pause-giant-ai-experiments/&quot; rel=&quot;&quot;&gt;
    Future of Life Institute&#x27;s call to pause AI
   &lt;/a&gt;
   &lt;span&gt;
    . I don&#x27;t really feel qualified to comment (or really want to comment) on all of these issues, but as AI becomes increasingly powerful, the calls for nationalization and comparison across borders will become stronger. There will be metaphors like &quot;The Manhattan Project for AI&quot; or &quot;The AI Bill of Rights&quot; that come with immense societal weight during an already fractured national and global world order. AI is expanding and will tap into all of the issues straining modern society. This zoomed-out perspective can also be extremely isolating for people working on AI.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;h1&gt;
   The Solutions
  &lt;/h1&gt;
  &lt;p&gt;
   &lt;span&gt;
    Most of the things I&#x27;m trying to implement come down to being process rather than outcome-oriented.
   &lt;/span&gt;
   &lt;em&gt;
    This section is a work in process, so please leave a comment if you have something that works for you!
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;p data-attrs=&#x27;{&quot;url&quot;:&quot;https://www.interconnects.ai/p/behind-the-curtain-ai/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}&#x27; data-component-name=&quot;ButtonCreateButton&quot;&gt;
   &lt;a href=&quot;https://www.interconnects.ai/p/behind-the-curtain-ai/comments&quot; rel=&quot;&quot;&gt;
    &lt;span&gt;
     Leave a comment
    &lt;/span&gt;
   &lt;/a&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;strong&gt;
    Taking solace in the scientific method
   &lt;/strong&gt;
   &lt;span&gt;
    can make things easier. When your goals are about progress rather than virality, it is much easier to have equanimity with the constant model releases that could be seen as partial scoops of your current project.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    Ambition for ambition&#x27;s sake is not particularly interesting when there is so much obvious money to be made.
   &lt;/span&gt;
   &lt;span&gt;
    &lt;a data-component-name=&quot;FootnoteAnchorToDOM&quot; href=&quot;https://www.interconnects.ai/p/behind-the-curtain-ai#footnote-1-112453991&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
     1
    &lt;/a&gt;
   &lt;/span&gt;
   &lt;span&gt;
    I don&#x27;t fault anyone that decides it&#x27;s time to leave a research career to try and obtain generational wealth right now. I do, though, extremely admire those people who want to stay put and get to the bottom of (and hopefully share) what is happening. I&#x27;m not the only one trying to navigate these pressures on a daily basis. How do we balance trying to release the best model soon with building the best engineering infrastructure so we can build the best models in 3, 6, or 9 months? How do I balance writing for my smart and niche audience when I could make my posts more general and get a bigger audience? All of these are unknowns.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   People tend to enjoy their research work most when they&#x27;re obsessed with the details and figuring something out. Openly, it feels like the more AI-oriented my work has become through my career, the less process-oriented I have become. Wanting to “make it” shortens the time window of your optimization. It&#x27;s really easy to be caught up in the wave of progress, hype, and prestige. All you can do is keep asking yourself, &quot;why&quot;?
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    To help address the plentiful competition (and to quote
   &lt;/span&gt;
   &lt;a href=&quot;https://www.youtube.com/watch?v=8PmX7zEUg_w&quot; rel=&quot;&quot;&gt;
    Ted Lasso
   &lt;/a&gt;
   &lt;span&gt;
    ):
   &lt;/span&gt;
   &lt;strong&gt;
    be a goldfish
   &lt;/strong&gt;
   &lt;span&gt;
    . When things are moving so fast, it&#x27;s good to remember that sometimes you&#x27;ll waste a lot of effort or get scooped. The best thing you can do is to just accept it and keep going on your process. You&#x27;re not alone in this one.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;span&gt;
    For individual contributors out there, it&#x27;s the right time to
   &lt;/span&gt;
   &lt;strong&gt;
    manage up
   &lt;/strong&gt;
   &lt;span&gt;
    to help make these mini-scoops not seem like failures: ask your manger and skip-manager some of the questions posed in this article. If your company doesn&#x27;t have a plan, your asking will at least make them realize it is not entirely your fault if you get scooped.
   &lt;/span&gt;
  &lt;/p&gt;
  &lt;p&gt;
   To end, I wanted to remember a common lesson from surfing: it takes a lot of paddling to catch a wave. That applies to how AI is going right now — while it seems like a lot of people are surfing these giant waves of success, it normally takes a lot of boring consistent work (and luck) to get there.
  &lt;/p&gt;
  &lt;div&gt;
   &lt;hr/&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;em&gt;
    &lt;span&gt;
     Want more? You can read the
    &lt;/span&gt;
    &lt;a href=&quot;https://news.ycombinator.com/item?id=35469908&quot; rel=&quot;&quot;&gt;
     comments on HackerNews
    &lt;/a&gt;
    &lt;span&gt;
     .
    &lt;/span&gt;
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;div&gt;
   &lt;hr/&gt;
  &lt;/div&gt;
  &lt;p&gt;
   &lt;em&gt;
    Thanks to Nazneen Rajani for some brief feedback on the construction of this post. Thanks to Meg Mitchell for a typo fix.
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;p&gt;
   &lt;em&gt;
    Elsewhere from me:
   &lt;/em&gt;
  &lt;/p&gt;
  &lt;ul&gt;
   &lt;li&gt;
    &lt;p&gt;
     &lt;span&gt;
      Another Ethics &amp; Society blog post from my HuggingGroup, on
     &lt;/span&gt;
     &lt;a href=&quot;https://huggingface.co/blog/ethics-soc-3&quot; rel=&quot;&quot;&gt;
      openness
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/li&gt;
  &lt;/ul&gt;
  &lt;div data-component-name=&quot;FootnoteToDOM&quot;&gt;
   &lt;a contenteditable=&quot;false&quot; href=&quot;https://www.interconnects.ai/p/behind-the-curtain-ai#footnote-anchor-1-112453991&quot; rel=&quot;&quot; target=&quot;_self&quot;&gt;
    1
   &lt;/a&gt;
   &lt;div&gt;
    &lt;p&gt;
     &lt;span&gt;
      This was discussed on a recent
     &lt;/span&gt;
     &lt;a href=&quot;https://www.youtube.com/watch?v=OGe1bTccCyg&quot; rel=&quot;&quot;&gt;
      Peter Attia podcast with Andrew Huberman
     &lt;/a&gt;
     &lt;span&gt;
      .
     &lt;/span&gt;
    &lt;/p&gt;
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;

</description>
</item>
</channel>
</rss>
